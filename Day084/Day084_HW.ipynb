{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l1_ratio=0.1, l2_ratio=0.1, drp_rate=0.1):\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    for i, n_unit in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_unit,\n",
    "                                   activation=\"relu\",\n",
    "                                   kernel_regularizer=l1_l2(l1=l1_ratio, l2=l2_ratio))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(drp_rate)(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_unit,\n",
    "                                   activation=\"relu\",\n",
    "                                   kernel_regularizer=l1_l2(l1=l1_ratio, l2=l2_ratio))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(drp_rate)(x)\n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\")(x)\n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = [32, 128, 256]\n",
    "Dropout_EXP = [0.1, 0.2, 0.4]\n",
    "l1_exp = [1e-2, 1e-4, 1e-8]\n",
    "l2_exp = [1e-2, 1e-4, 1e-8]\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172C658438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172C658438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 32.6066 - accuracy: 0.2375WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172CED08B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172CED08B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 32.5978 - accuracy: 0.2376 - val_loss: 2.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 3.9338 - accuracy: 0.2436 - val_loss: 1.4221 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 3.5141 - accuracy: 0.2541 - val_loss: 1.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.4678 - accuracy: 0.2477 - val_loss: 1.3378 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.3657 - accuracy: 0.2492 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.4088 - accuracy: 0.2487 - val_loss: 1.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.3643 - accuracy: 0.2488 - val_loss: 1.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.3641 - accuracy: 0.2519 - val_loss: 1.2535 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.2871 - accuracy: 0.2531 - val_loss: 1.2526 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.2428 - accuracy: 0.2525 - val_loss: 1.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.2373 - accuracy: 0.2485 - val_loss: 1.3797 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.2545 - accuracy: 0.2503 - val_loss: 1.1212 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.2545 - accuracy: 0.2480 - val_loss: 1.1143 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 3.2397 - accuracy: 0.2564 - val_loss: 1.3893 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.2878 - accuracy: 0.2493 - val_loss: 1.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.2453 - accuracy: 0.2485 - val_loss: 1.1823 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.2029 - accuracy: 0.2519 - val_loss: 1.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.1598 - accuracy: 0.2491 - val_loss: 1.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.1636 - accuracy: 0.2491 - val_loss: 1.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 3.1359 - accuracy: 0.2469 - val_loss: 1.0398 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.1843 - accuracy: 0.2477 - val_loss: 1.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 3.1202 - accuracy: 0.2501 - val_loss: 1.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 3.1258 - accuracy: 0.2495 - val_loss: 1.0314 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 3.1560 - accuracy: 0.2465 - val_loss: 1.2758 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 3.1445 - accuracy: 0.2464 - val_loss: 1.0926 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 3.1463 - accuracy: 0.2482 - val_loss: 1.0301 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 3.1127 - accuracy: 0.2500 - val_loss: 1.0796 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.1039 - accuracy: 0.2462 - val_loss: 1.0871 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 3.0469 - accuracy: 0.2495 - val_loss: 0.9484 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.0241 - accuracy: 0.2469 - val_loss: 0.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.0579 - accuracy: 0.2471 - val_loss: 1.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.0577 - accuracy: 0.2464 - val_loss: 0.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.0395 - accuracy: 0.2501 - val_loss: 1.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.0482 - accuracy: 0.2490 - val_loss: 0.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 3.0120 - accuracy: 0.2485 - val_loss: 1.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 2.9973 - accuracy: 0.2483 - val_loss: 1.0149 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.0528 - accuracy: 0.2466 - val_loss: 0.9960 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 2.9834 - accuracy: 0.2468 - val_loss: 0.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.0452 - accuracy: 0.2496 - val_loss: 0.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.0323 - accuracy: 0.2478 - val_loss: 1.0526 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 2.9765 - accuracy: 0.2479 - val_loss: 0.8118 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 53s 34ms/step - loss: 2.9934 - accuracy: 0.2469 - val_loss: 0.7567 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.9369 - accuracy: 0.2504 - val_loss: 0.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 2.9938 - accuracy: 0.2477 - val_loss: 1.0211 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 2.9861 - accuracy: 0.2478 - val_loss: 0.9674 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.9909 - accuracy: 0.2425 - val_loss: 1.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 2.9568 - accuracy: 0.2485 - val_loss: 0.9918 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 2.9674 - accuracy: 0.2487 - val_loss: 0.8910 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 2.9704 - accuracy: 0.2486 - val_loss: 1.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.0116 - accuracy: 0.2472 - val_loss: 0.9553 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217302DAAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217302DAAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 33.3695 - accuracy: 0.2379WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730AA2CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730AA2CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 33.3602 - accuracy: 0.2380 - val_loss: 2.5340 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 4.0285 - accuracy: 0.2504 - val_loss: 1.5903 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.6511 - accuracy: 0.2496 - val_loss: 1.5816 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.5488 - accuracy: 0.2497 - val_loss: 1.5386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 3.5454 - accuracy: 0.2518 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 3.4139 - accuracy: 0.2527 - val_loss: 1.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.3519 - accuracy: 0.2486 - val_loss: 1.1838 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 3.3682 - accuracy: 0.2479 - val_loss: 1.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.3552 - accuracy: 0.2467 - val_loss: 1.4023 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.3445 - accuracy: 0.2507 - val_loss: 1.3300 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.2699 - accuracy: 0.2511 - val_loss: 1.1881 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.2521 - accuracy: 0.2479 - val_loss: 1.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2083 - accuracy: 0.2531 - val_loss: 1.1580 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2943 - accuracy: 0.2491 - val_loss: 1.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.3134 - accuracy: 0.2479 - val_loss: 1.2208 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.2309 - accuracy: 0.2512 - val_loss: 1.1646 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2138 - accuracy: 0.2496 - val_loss: 1.1930 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2413 - accuracy: 0.2521 - val_loss: 1.2383 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.2280 - accuracy: 0.2492 - val_loss: 1.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1748 - accuracy: 0.2514 - val_loss: 1.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.1368 - accuracy: 0.2498 - val_loss: 1.4424 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1687 - accuracy: 0.2486 - val_loss: 1.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2515 - accuracy: 0.2485 - val_loss: 1.1193 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2158 - accuracy: 0.2463 - val_loss: 1.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.1726 - accuracy: 0.2501 - val_loss: 1.3241 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1827 - accuracy: 0.2494 - val_loss: 1.3323 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2179 - accuracy: 0.2486 - val_loss: 1.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.1509 - accuracy: 0.2514 - val_loss: 0.9870 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.0591 - accuracy: 0.2515 - val_loss: 1.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1499 - accuracy: 0.2460 - val_loss: 1.1101 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.1283 - accuracy: 0.2478 - val_loss: 1.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.1169 - accuracy: 0.2479 - val_loss: 0.9954 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0798 - accuracy: 0.2495 - val_loss: 0.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0779 - accuracy: 0.2511 - val_loss: 1.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0722 - accuracy: 0.2498 - val_loss: 0.9828 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.0081 - accuracy: 0.2502 - val_loss: 1.1442 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.0607 - accuracy: 0.2502 - val_loss: 0.9815 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0436 - accuracy: 0.2536 - val_loss: 1.0016 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0960 - accuracy: 0.2478 - val_loss: 1.2439 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.9801 - accuracy: 0.2474 - val_loss: 1.0952 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9723 - accuracy: 0.2509 - val_loss: 0.8593 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.0051 - accuracy: 0.2461 - val_loss: 1.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9894 - accuracy: 0.2474 - val_loss: 0.8932 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.9743 - accuracy: 0.2506 - val_loss: 0.8961 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9656 - accuracy: 0.2518 - val_loss: 0.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0057 - accuracy: 0.2473 - val_loss: 0.9664 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.9923 - accuracy: 0.2472 - val_loss: 1.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9912 - accuracy: 0.2480 - val_loss: 1.0553 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.9753 - accuracy: 0.2478 - val_loss: 0.9046 - val_accuracy: 0.0000e+001 - accuracy - ETA: 0s - loss: 2.9759 - \n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.9621 - accuracy: 0.2484 - val_loss: 1.0369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730C85C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730C85C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 33.5823 - accuracy: 0.2334WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173415A0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173415A0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 33.5823 - accuracy: 0.2334 - val_loss: 2.5304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.1062 - accuracy: 0.2449 - val_loss: 1.5242 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5575 - accuracy: 0.2468 - val_loss: 1.4861 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5161 - accuracy: 0.2516 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4670 - accuracy: 0.2482 - val_loss: 1.3989 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4433 - accuracy: 0.2510 - val_loss: 1.2057 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3943 - accuracy: 0.2489 - val_loss: 1.3235 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3793 - accuracy: 0.2501 - val_loss: 1.4811 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3488 - accuracy: 0.2470 - val_loss: 1.2585 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 3.3117 - accuracy: 0.2509 - val_loss: 1.2063 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3037 - accuracy: 0.2503 - val_loss: 1.2680 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2891 - accuracy: 0.2509 - val_loss: 1.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2198 - accuracy: 0.2490 - val_loss: 1.1500 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2613 - accuracy: 0.2527 - val_loss: 1.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2472 - accuracy: 0.2505 - val_loss: 1.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3550 - accuracy: 0.2476 - val_loss: 1.2096 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2941 - accuracy: 0.2503 - val_loss: 1.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2858 - accuracy: 0.2525 - val_loss: 1.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2315 - accuracy: 0.2496 - val_loss: 1.2829 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2472 - accuracy: 0.2422 - val_loss: 1.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2523 - accuracy: 0.2501 - val_loss: 1.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2182 - accuracy: 0.2497 - val_loss: 1.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2232 - accuracy: 0.2489 - val_loss: 1.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1900 - accuracy: 0.2454 - val_loss: 1.0986 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2098 - accuracy: 0.2476 - val_loss: 1.2768 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1952 - accuracy: 0.2476 - val_loss: 1.1829 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1617 - accuracy: 0.2478 - val_loss: 1.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0858 - accuracy: 0.2521 - val_loss: 1.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1248 - accuracy: 0.2511 - val_loss: 1.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1076 - accuracy: 0.2480 - val_loss: 1.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1071 - accuracy: 0.2516 - val_loss: 0.9447 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1273 - accuracy: 0.2469 - val_loss: 1.1174 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0883 - accuracy: 0.2514 - val_loss: 0.9821 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0763 - accuracy: 0.2506 - val_loss: 0.8952 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0361 - accuracy: 0.2523 - val_loss: 0.9548 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0437 - accuracy: 0.2494 - val_loss: 1.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0760 - accuracy: 0.2481 - val_loss: 1.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0565 - accuracy: 0.2524 - val_loss: 0.9740 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0829 - accuracy: 0.2459 - val_loss: 1.1696 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.0681 - accuracy: 0.2463 - val_loss: 1.0277 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.0652 - accuracy: 0.2485 - val_loss: 1.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0510 - accuracy: 0.2509 - val_loss: 0.9495 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0458 - accuracy: 0.2492 - val_loss: 0.9732 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0187 - accuracy: 0.2461 - val_loss: 1.1273 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0515 - accuracy: 0.2479 - val_loss: 0.9026 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9882 - accuracy: 0.2503 - val_loss: 0.8773 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.9680 - accuracy: 0.2461 - val_loss: 0.9269 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.9757 - accuracy: 0.2477 - val_loss: 0.8898 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.9839 - accuracy: 0.2461 - val_loss: 0.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9973 - accuracy: 0.2470 - val_loss: 0.9972 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021734255558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021734255558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 12.1475 - accuracy: 0.3550 - ETA: 5s - loss: 12.8198 - - ETA: 4s  - WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217344F74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217344F74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 12.1475 - accuracy: 0.3550 - val_loss: 5.0579 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.5515 - accuracy: 0.3927 - val_loss: 1.4054 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 2.5186 - accuracy: 0.3865 - val_loss: 0.4207 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 2.0244 - accuracy: 0.3835 - val_loss: 0.2663 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.9556 - accuracy: 0.3917 - val_loss: 0.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.9568 - accuracy: 0.3904 - val_loss: 0.2539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9526 - accuracy: 0.3861 - val_loss: 0.2560 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9485 - accuracy: 0.3866 - val_loss: 0.2398 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9254 - accuracy: 0.3991 - val_loss: 0.2385 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.9413 - accuracy: 0.3931 - val_loss: 0.2543 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.9451 - accuracy: 0.3911 - val_loss: 0.2447 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9222 - accuracy: 0.3972 - val_loss: 0.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9276 - accuracy: 0.3941 - val_loss: 0.2396 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9283 - accuracy: 0.3940 - val_loss: 0.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9334 - accuracy: 0.3933 - val_loss: 0.2427 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9238 - accuracy: 0.3959 - val_loss: 0.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9551 - accuracy: 0.3883 - val_loss: 0.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9365 - accuracy: 0.3937 - val_loss: 0.2415 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9155 - accuracy: 0.3964 - val_loss: 0.2387 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9398 - accuracy: 0.3927 - val_loss: 0.2457 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9299 - accuracy: 0.3934 - val_loss: 0.2300 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9060 - accuracy: 0.4003 - val_loss: 0.2292 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9293 - accuracy: 0.3956 - val_loss: 0.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9273 - accuracy: 0.3949 - val_loss: 0.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9302 - accuracy: 0.3938 - val_loss: 0.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9309 - accuracy: 0.3940 - val_loss: 0.2352 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9381 - accuracy: 0.3912 - val_loss: 0.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9199 - accuracy: 0.3990 - val_loss: 0.2281 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9103 - accuracy: 0.4015 - val_loss: 0.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9346 - accuracy: 0.3955 - val_loss: 0.2442 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9108 - accuracy: 0.4021 - val_loss: 0.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9165 - accuracy: 0.4010 - val_loss: 0.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9256 - accuracy: 0.3973 - val_loss: 0.2469 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9193 - accuracy: 0.3971 - val_loss: 0.2368 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9327 - accuracy: 0.3943 - val_loss: 0.2460 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9405 - accuracy: 0.3949 - val_loss: 0.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9398 - accuracy: 0.3900 - val_loss: 0.2357 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9209 - accuracy: 0.3963 - val_loss: 0.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9111 - accuracy: 0.3980 - val_loss: 0.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9087 - accuracy: 0.3980 - val_loss: 0.2342 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9187 - accuracy: 0.3967 - val_loss: 0.2374 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9203 - accuracy: 0.3982 - val_loss: 0.2397 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9246 - accuracy: 0.3955 - val_loss: 0.2419 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9262 - accuracy: 0.3944 - val_loss: 0.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9164 - accuracy: 0.3952 - val_loss: 0.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9210 - accuracy: 0.3970 - val_loss: 0.2414 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9081 - accuracy: 0.4027 - val_loss: 0.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9162 - accuracy: 0.3999 - val_loss: 0.2352 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9100 - accuracy: 0.4024 - val_loss: 0.2409 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9238 - accuracy: 0.3958 - val_loss: 0.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730CD3EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730CD3EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 5.7187 - accuracy: 0.3544WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172CE8DAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172CE8DAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 5.7187 - accuracy: 0.3544 - val_loss: 3.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 4.9872 - accuracy: 0.4188 - val_loss: 3.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 4.4602 - accuracy: 0.4395 - val_loss: 2.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 4.0105 - accuracy: 0.4414 - val_loss: 2.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6104 - accuracy: 0.4488 - val_loss: 1.8856 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2560 - accuracy: 0.4502 - val_loss: 1.5652 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9630 - accuracy: 0.4508 - val_loss: 1.2946 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.7201 - accuracy: 0.4475 - val_loss: 1.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 2.5261 - accuracy: 0.4440 - val_loss: 0.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.3290 - accuracy: 0.4547 - val_loss: 0.7214 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.1824 - accuracy: 0.4607 - val_loss: 0.6067 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.0767 - accuracy: 0.4617 - val_loss: 0.5279 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.0055 - accuracy: 0.4633 - val_loss: 0.4776 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9602 - accuracy: 0.4639 - val_loss: 0.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9179 - accuracy: 0.4660 - val_loss: 0.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8938 - accuracy: 0.4672 - val_loss: 0.3893 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8760 - accuracy: 0.4680 - val_loss: 0.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8562 - accuracy: 0.4676 - val_loss: 0.3570 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8559 - accuracy: 0.4651 - val_loss: 0.3410 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8182 - accuracy: 0.4702 - val_loss: 0.3277 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8034 - accuracy: 0.4709 - val_loss: 0.3190 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.7827 - accuracy: 0.4729 - val_loss: 0.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7765 - accuracy: 0.4753 - val_loss: 0.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7490 - accuracy: 0.4793 - val_loss: 0.2905 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7556 - accuracy: 0.4768 - val_loss: 0.2823 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7484 - accuracy: 0.4782 - val_loss: 0.2798 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7412 - accuracy: 0.4777 - val_loss: 0.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7292 - accuracy: 0.4826 - val_loss: 0.2795 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.7218 - accuracy: 0.4872 - val_loss: 0.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.7363 - accuracy: 0.4796 - val_loss: 0.2745 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.7280 - accuracy: 0.4800 - val_loss: 0.2737 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7247 - accuracy: 0.4804 - val_loss: 0.2713 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7161 - accuracy: 0.4824 - val_loss: 0.2722 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7154 - accuracy: 0.4868 - val_loss: 0.2706 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7082 - accuracy: 0.4888 - val_loss: 0.2720 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7094 - accuracy: 0.4874 - val_loss: 0.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7078 - accuracy: 0.4870 - val_loss: 0.2715 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7214 - accuracy: 0.4849 - val_loss: 0.2711 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7136 - accuracy: 0.4844 - val_loss: 0.2682 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7030 - accuracy: 0.4878 - val_loss: 0.2659 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6806 - accuracy: 0.4959 - val_loss: 0.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6884 - accuracy: 0.4937 - val_loss: 0.2631 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6922 - accuracy: 0.4907 - val_loss: 0.2678 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6926 - accuracy: 0.4913 - val_loss: 0.2624 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6998 - accuracy: 0.4890 - val_loss: 0.2661 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6875 - accuracy: 0.4940 - val_loss: 0.2655 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7044 - accuracy: 0.4898 - val_loss: 0.2720 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6971 - accuracy: 0.4918 - val_loss: 0.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7039 - accuracy: 0.4911 - val_loss: 0.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7084 - accuracy: 0.4856 - val_loss: 0.2695 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172C6E5EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172C6E5EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 5.5914 - accuracy: 0.3576WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730AC1048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730AC1048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 5.5914 - accuracy: 0.3576 - val_loss: 3.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 4.9104 - accuracy: 0.4185 - val_loss: 3.0558 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.4226 - accuracy: 0.4343 - val_loss: 2.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.9968 - accuracy: 0.4429 - val_loss: 2.2488 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.6419 - accuracy: 0.4396 - val_loss: 1.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.3119 - accuracy: 0.4421 - val_loss: 1.6024 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.0010 - accuracy: 0.4522 - val_loss: 1.3332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.7361 - accuracy: 0.4560 - val_loss: 1.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 2.5115 - accuracy: 0.4626 - val_loss: 0.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.3303 - accuracy: 0.4649 - val_loss: 0.7600 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.1837 - accuracy: 0.4679 - val_loss: 0.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0960 - accuracy: 0.4642 - val_loss: 0.5581 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0147 - accuracy: 0.4665 - val_loss: 0.4996 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9642 - accuracy: 0.4704 - val_loss: 0.4662 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9197 - accuracy: 0.4770 - val_loss: 0.4370 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9121 - accuracy: 0.4696 - val_loss: 0.4222 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9225 - accuracy: 0.4610 - val_loss: 0.4080 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9151 - accuracy: 0.4625 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8890 - accuracy: 0.4602 - val_loss: 0.3666 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8369 - accuracy: 0.4723 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8128 - accuracy: 0.4730 - val_loss: 0.3355 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7947 - accuracy: 0.4759 - val_loss: 0.3190 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7697 - accuracy: 0.4799 - val_loss: 0.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7626 - accuracy: 0.4827 - val_loss: 0.2990 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7559 - accuracy: 0.4812 - val_loss: 0.2964 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7365 - accuracy: 0.4814 - val_loss: 0.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7265 - accuracy: 0.4838 - val_loss: 0.2759 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7058 - accuracy: 0.4897 - val_loss: 0.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7154 - accuracy: 0.4836 - val_loss: 0.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7209 - accuracy: 0.4852 - val_loss: 0.2696 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7032 - accuracy: 0.4903 - val_loss: 0.2722 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6988 - accuracy: 0.4874 - val_loss: 0.2680 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7089 - accuracy: 0.4842 - val_loss: 0.2683 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7072 - accuracy: 0.4866 - val_loss: 0.2664 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6974 - accuracy: 0.4898 - val_loss: 0.2651 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6903 - accuracy: 0.4915 - val_loss: 0.2655 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7011 - accuracy: 0.4889 - val_loss: 0.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6991 - accuracy: 0.4895 - val_loss: 0.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6840 - accuracy: 0.4961 - val_loss: 0.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7142 - accuracy: 0.4812 - val_loss: 0.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7083 - accuracy: 0.4848 - val_loss: 0.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7025 - accuracy: 0.4870 - val_loss: 0.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6862 - accuracy: 0.4944 - val_loss: 0.2652 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6878 - accuracy: 0.4902 - val_loss: 0.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6753 - accuracy: 0.4913 - val_loss: 0.2596 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6567 - accuracy: 0.5024 - val_loss: 0.2570 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6765 - accuracy: 0.4953 - val_loss: 0.2680 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6860 - accuracy: 0.4952 - val_loss: 0.2642 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.6768 - accuracy: 0.4954 - val_loss: 0.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6831 - accuracy: 0.4971 - val_loss: 0.2722 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730D4AC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730D4AC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 9.9931 - accuracy: 0.3538WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737B14798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737B14798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 9.9931 - accuracy: 0.3538 - val_loss: 4.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.1412 - accuracy: 0.3983 - val_loss: 1.3297 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.5058 - accuracy: 0.4035 - val_loss: 0.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0158 - accuracy: 0.4040 - val_loss: 0.2558 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.8833 - accuracy: 0.4024 - val_loss: 0.1780 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8376 - accuracy: 0.4015 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8070 - accuracy: 0.4047 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7901 - accuracy: 0.4066 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.7813 - accuracy: 0.4166 - val_loss: 0.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8217 - accuracy: 0.4015 - val_loss: 0.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.8046 - accuracy: 0.4053 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8074 - accuracy: 0.4074 - val_loss: 0.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8087 - accuracy: 0.4044 - val_loss: 0.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.8127 - accuracy: 0.4055 - val_loss: 0.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8125 - accuracy: 0.4036 - val_loss: 0.1594 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8104 - accuracy: 0.4078 - val_loss: 0.1551 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8067 - accuracy: 0.4086 - val_loss: 0.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7958 - accuracy: 0.4093 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7929 - accuracy: 0.4145 - val_loss: 0.1564 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8099 - accuracy: 0.4089 - val_loss: 0.1565 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8050 - accuracy: 0.4077 - val_loss: 0.1513 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7879 - accuracy: 0.4143 - val_loss: 0.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7880 - accuracy: 0.4153 - val_loss: 0.1597 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.8024 - accuracy: 0.4109 - val_loss: 0.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8034 - accuracy: 0.4120 - val_loss: 0.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7929 - accuracy: 0.4132 - val_loss: 0.1619 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8038 - accuracy: 0.4145 - val_loss: 0.1596 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7934 - accuracy: 0.4138 - val_loss: 0.1556 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7888 - accuracy: 0.4166 - val_loss: 0.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7819 - accuracy: 0.4203 - val_loss: 0.1631 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7768 - accuracy: 0.4213 - val_loss: 0.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7920 - accuracy: 0.4189 - val_loss: 0.1657 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7965 - accuracy: 0.4172 - val_loss: 0.1646 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8039 - accuracy: 0.4127 - val_loss: 0.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8004 - accuracy: 0.4109 - val_loss: 0.1573 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7936 - accuracy: 0.4119 - val_loss: 0.1570 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7936 - accuracy: 0.4149 - val_loss: 0.1595 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.8045 - accuracy: 0.4114 - val_loss: 0.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8033 - accuracy: 0.4110 - val_loss: 0.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8053 - accuracy: 0.4130 - val_loss: 0.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7917 - accuracy: 0.4170 - val_loss: 0.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8262 - accuracy: 0.4014 - val_loss: 0.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8164 - accuracy: 0.4045 - val_loss: 0.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8118 - accuracy: 0.4082 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.8046 - accuracy: 0.4133 - val_loss: 0.1599 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8125 - accuracy: 0.4080 - val_loss: 0.1601 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8089 - accuracy: 0.4110 - val_loss: 0.1564 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7965 - accuracy: 0.4126 - val_loss: 0.1552 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7936 - accuracy: 0.4133 - val_loss: 0.1542 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7916 - accuracy: 0.4168 - val_loss: 0.1561 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737CA4678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737CA4678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.9794 - accuracy: 0.3547WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172C6E5CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172C6E5CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9794 - accuracy: 0.3547 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.7764 - accuracy: 0.4165 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.7162 - accuracy: 0.4378 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.6816 - accuracy: 0.4498 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.6616 - accuracy: 0.4559 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6563 - accuracy: 0.4580 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6407 - accuracy: 0.4656 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.6104 - accuracy: 0.4729 - val_loss: 0.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5977 - accuracy: 0.4797 - val_loss: 0.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5841 - accuracy: 0.4827 - val_loss: 0.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5697 - accuracy: 0.4903 - val_loss: 0.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5531 - accuracy: 0.4961 - val_loss: 0.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.5351 - accuracy: 0.4993 - val_loss: 0.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5236 - accuracy: 0.5044 - val_loss: 0.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5111 - accuracy: 0.5076 - val_loss: 0.1321 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5050 - accuracy: 0.5091 - val_loss: 0.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4949 - accuracy: 0.5162 - val_loss: 0.1307 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4798 - accuracy: 0.5185 - val_loss: 0.1300 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4706 - accuracy: 0.5216 - val_loss: 0.1294 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4575 - accuracy: 0.5270 - val_loss: 0.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4583 - accuracy: 0.5295 - val_loss: 0.1281 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.4452 - accuracy: 0.5308 - val_loss: 0.1274 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4447 - accuracy: 0.5302 - val_loss: 0.1268 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4365 - accuracy: 0.5343 - val_loss: 0.1261 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4231 - accuracy: 0.5390 - val_loss: 0.1255 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4198 - accuracy: 0.5386 - val_loss: 0.1249 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4144 - accuracy: 0.5407 - val_loss: 0.1243 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4124 - accuracy: 0.5432 - val_loss: 0.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4023 - accuracy: 0.5462 - val_loss: 0.1232 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3996 - accuracy: 0.5461 - val_loss: 0.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3960 - accuracy: 0.5479 - val_loss: 0.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3902 - accuracy: 0.5491 - val_loss: 0.1215 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3746 - accuracy: 0.5558 - val_loss: 0.1210 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3721 - accuracy: 0.5551 - val_loss: 0.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3731 - accuracy: 0.5533 - val_loss: 0.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3681 - accuracy: 0.5537 - val_loss: 0.1194 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3656 - accuracy: 0.5553 - val_loss: 0.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3589 - accuracy: 0.5594 - val_loss: 0.1184 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3591 - accuracy: 0.5554 - val_loss: 0.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3582 - accuracy: 0.5589 - val_loss: 0.1175 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3453 - accuracy: 0.5608 - val_loss: 0.1171 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.3492 - accuracy: 0.5613 - val_loss: 0.1166 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.3431 - accuracy: 0.5633 - val_loss: 0.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3475 - accuracy: 0.5606 - val_loss: 0.1158 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3351 - accuracy: 0.5649 - val_loss: 0.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3305 - accuracy: 0.5676 - val_loss: 0.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3271 - accuracy: 0.5666 - val_loss: 0.1146 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3143 - accuracy: 0.5716 - val_loss: 0.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3269 - accuracy: 0.5714 - val_loss: 0.1138 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3267 - accuracy: 0.5688 - val_loss: 0.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730AC1558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730AC1558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.8279 - accuracy: 0.3576WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173036ECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173036ECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8279 - accuracy: 0.3576 - val_loss: 4.1685e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6249 - accuracy: 0.4201 - val_loss: 4.1807e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5652 - accuracy: 0.4404 - val_loss: 4.1931e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5352 - accuracy: 0.4528 - val_loss: 4.2052e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5150 - accuracy: 0.4607 - val_loss: 4.2170e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4972 - accuracy: 0.4666 - val_loss: 4.2283e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4813 - accuracy: 0.4724 - val_loss: 4.2392e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4698 - accuracy: 0.4772 - val_loss: 4.2502e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4552 - accuracy: 0.4808 - val_loss: 4.2614e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4445 - accuracy: 0.4845 - val_loss: 4.2721e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4376 - accuracy: 0.4883 - val_loss: 4.2823e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4378 - accuracy: 0.4847 - val_loss: 4.2927e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4200 - accuracy: 0.4970 - val_loss: 4.3025e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3986 - accuracy: 0.4997 - val_loss: 4.3117e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3868 - accuracy: 0.5068 - val_loss: 4.3208e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3719 - accuracy: 0.5115 - val_loss: 4.3298e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.3673 - accuracy: 0.5131 - val_loss: 4.3394e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3521 - accuracy: 0.5157 - val_loss: 4.3485e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3414 - accuracy: 0.5209 - val_loss: 4.3569e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3420 - accuracy: 0.5220 - val_loss: 4.3655e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3267 - accuracy: 0.5270 - val_loss: 4.3742e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3271 - accuracy: 0.5282 - val_loss: 4.3823e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3139 - accuracy: 0.5299 - val_loss: 4.3905e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3142 - accuracy: 0.5335 - val_loss: 4.3988e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3063 - accuracy: 0.5338 - val_loss: 4.4066e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2959 - accuracy: 0.5358 - val_loss: 4.4148e-04 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2983 - accuracy: 0.5380 - val_loss: 4.4226e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2896 - accuracy: 0.5418 - val_loss: 4.4308e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2782 - accuracy: 0.5446 - val_loss: 4.4383e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.2769 - accuracy: 0.5449 - val_loss: 4.4463e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2738 - accuracy: 0.5468 - val_loss: 4.4535e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2636 - accuracy: 0.5493 - val_loss: 4.4610e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2571 - accuracy: 0.5513 - val_loss: 4.4686e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2558 - accuracy: 0.5515 - val_loss: 4.4762e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2546 - accuracy: 0.5531 - val_loss: 4.4835e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2455 - accuracy: 0.5541 - val_loss: 4.4908e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2494 - accuracy: 0.5542 - val_loss: 4.4979e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2423 - accuracy: 0.5572 - val_loss: 4.5051e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2268 - accuracy: 0.5618 - val_loss: 4.5126e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2450 - accuracy: 0.5568 - val_loss: 4.5201e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2418 - accuracy: 0.5557 - val_loss: 4.5271e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2322 - accuracy: 0.5603 - val_loss: 4.5340e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2251 - accuracy: 0.5624 - val_loss: 4.5411e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.2201 - accuracy: 0.5649 - val_loss: 4.5480e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2132 - accuracy: 0.5692 - val_loss: 4.5548e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.2236 - accuracy: 0.5610 - val_loss: 4.5617e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2151 - accuracy: 0.5667 - val_loss: 4.5684e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2103 - accuracy: 0.5692 - val_loss: 4.5750e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2071 - accuracy: 0.5718 - val_loss: 4.5817e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2097 - accuracy: 0.5692 - val_loss: 4.5885e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172D053438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172D053438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 33.0953 - accuracy: 0.2205WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730B48A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730B48A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 33.0953 - accuracy: 0.2205 - val_loss: 2.3729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.9739 - accuracy: 0.2343 - val_loss: 1.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.6457 - accuracy: 0.2387 - val_loss: 1.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.6325 - accuracy: 0.2368 - val_loss: 1.5417 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.5500 - accuracy: 0.2361 - val_loss: 1.6553 - val_accuracy: 0.0000e+00 loss: 3.546\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.5399 - accuracy: 0.2369 - val_loss: 1.5339 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.5022 - accuracy: 0.2366 - val_loss: 1.3044 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.5058 - accuracy: 0.2364 - val_loss: 1.5888 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.4400 - accuracy: 0.2394 - val_loss: 1.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.4891 - accuracy: 0.2364 - val_loss: 1.5459 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.4186 - accuracy: 0.2401 - val_loss: 1.5771 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.4268 - accuracy: 0.2376 - val_loss: 1.1573 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.3719 - accuracy: 0.2341 - val_loss: 1.4893 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.3666 - accuracy: 0.2400 - val_loss: 1.3866 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.3624 - accuracy: 0.2382 - val_loss: 1.4744 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.3913 - accuracy: 0.2359 - val_loss: 1.4061 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3803 - accuracy: 0.2356 - val_loss: 1.3629 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4142 - accuracy: 0.2376 - val_loss: 1.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3620 - accuracy: 0.2384 - val_loss: 1.1887 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3525 - accuracy: 0.2382 - val_loss: 1.3110 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3927 - accuracy: 0.2364 - val_loss: 1.3632 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3480 - accuracy: 0.2360 - val_loss: 1.2270 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3404 - accuracy: 0.2346 - val_loss: 1.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.3183 - accuracy: 0.2337 - val_loss: 1.3515 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3297 - accuracy: 0.2372 - val_loss: 1.3695 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3352 - accuracy: 0.2374 - val_loss: 1.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3187 - accuracy: 0.2394 - val_loss: 1.1927 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3236 - accuracy: 0.2345 - val_loss: 1.3855 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3365 - accuracy: 0.2353 - val_loss: 1.3895 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3318 - accuracy: 0.2354 - val_loss: 1.2905 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 3.3101 - accuracy: 0.2341 - val_loss: 1.3993 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3284 - accuracy: 0.2340 - val_loss: 1.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3250 - accuracy: 0.2360 - val_loss: 1.2652 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2975 - accuracy: 0.2381 - val_loss: 1.2014 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3152 - accuracy: 0.2361 - val_loss: 1.2144 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2723 - accuracy: 0.2372 - val_loss: 1.3641 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2891 - accuracy: 0.2354 - val_loss: 1.2483 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2632 - accuracy: 0.2355 - val_loss: 1.1244 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2941 - accuracy: 0.2352 - val_loss: 1.3257 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2977 - accuracy: 0.2393 - val_loss: 1.1821 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2767 - accuracy: 0.2360 - val_loss: 1.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2628 - accuracy: 0.2355 - val_loss: 1.1842 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2521 - accuracy: 0.2357 - val_loss: 1.2392 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2239 - accuracy: 0.2357 - val_loss: 1.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2662 - accuracy: 0.2333 - val_loss: 1.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2391 - accuracy: 0.2374 - val_loss: 1.2419 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.2355 - accuracy: 0.2356 - val_loss: 1.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2047 - accuracy: 0.2366 - val_loss: 1.1275 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2402 - accuracy: 0.2357 - val_loss: 1.1152 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2210 - accuracy: 0.2365 - val_loss: 1.2097 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172CEE0CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172CEE0CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 33.8129 - accuracy: 0.22778 ETA: 10s - loss: 42.5964 - accurWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021734490558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021734490558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 33.8129 - accuracy: 0.2277 - val_loss: 2.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 4.0815 - accuracy: 0.2389 - val_loss: 1.6965 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.7977 - accuracy: 0.2411 - val_loss: 1.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.6199 - accuracy: 0.2412 - val_loss: 1.5373 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.6664 - accuracy: 0.2389 - val_loss: 1.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.6388 - accuracy: 0.2378 - val_loss: 1.5707 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.5994 - accuracy: 0.2381 - val_loss: 1.5690 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5830 - accuracy: 0.2375 - val_loss: 1.7871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5490 - accuracy: 0.2356 - val_loss: 1.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5304 - accuracy: 0.2425 - val_loss: 1.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.4773 - accuracy: 0.2384 - val_loss: 1.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5007 - accuracy: 0.2394 - val_loss: 1.3554 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4425 - accuracy: 0.2371 - val_loss: 1.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3784 - accuracy: 0.2387 - val_loss: 1.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3984 - accuracy: 0.2408 - val_loss: 1.2816 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4203 - accuracy: 0.2407 - val_loss: 1.2890 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3897 - accuracy: 0.2413 - val_loss: 1.2794 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3921 - accuracy: 0.2369 - val_loss: 1.2483 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3628 - accuracy: 0.2427 - val_loss: 1.2654 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3841 - accuracy: 0.2365 - val_loss: 1.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2837 - accuracy: 0.2366 - val_loss: 1.1531 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3379 - accuracy: 0.2358 - val_loss: 1.2263 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3110 - accuracy: 0.2391 - val_loss: 1.2926 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.3355 - accuracy: 0.2392 - val_loss: 1.1829 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3555 - accuracy: 0.2359 - val_loss: 1.2295 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3272 - accuracy: 0.2401 - val_loss: 1.3482 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3039 - accuracy: 0.2408 - val_loss: 1.2451 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2859 - accuracy: 0.2365 - val_loss: 1.1922 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3185 - accuracy: 0.2364 - val_loss: 1.3502 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2627 - accuracy: 0.2374 - val_loss: 1.0616 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2601 - accuracy: 0.2389 - val_loss: 1.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2446 - accuracy: 0.2384 - val_loss: 1.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2364 - accuracy: 0.2396 - val_loss: 1.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2638 - accuracy: 0.2394 - val_loss: 1.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2759 - accuracy: 0.2371 - val_loss: 1.2535 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2383 - accuracy: 0.2401 - val_loss: 1.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2008 - accuracy: 0.2366 - val_loss: 1.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.1820 - accuracy: 0.2391 - val_loss: 1.0214 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2076 - accuracy: 0.2423 - val_loss: 1.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.2320 - accuracy: 0.2381 - val_loss: 1.0303 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1988 - accuracy: 0.2378 - val_loss: 1.3495 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1802 - accuracy: 0.2388 - val_loss: 1.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1699 - accuracy: 0.2396 - val_loss: 1.2293 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2229 - accuracy: 0.2347 - val_loss: 1.1266 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.1417 - accuracy: 0.2384 - val_loss: 1.0286 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1652 - accuracy: 0.2383 - val_loss: 1.0861 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1891 - accuracy: 0.2372 - val_loss: 1.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1519 - accuracy: 0.2383 - val_loss: 1.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1841 - accuracy: 0.2355 - val_loss: 1.2717 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.1481 - accuracy: 0.2374 - val_loss: 1.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737F32798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737F32798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 33.8197 - accuracy: 0.2231- ETA: 3s - loss: 36.0252 - accuracy: 0 - ETA: 3s - loss: 35.8115 - accuracy: 0 -  - ETA: 0s - loss: 33.9315 - accuracy: 0.2WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217346391F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217346391F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 49s 32ms/step - loss: 33.8104 - accuracy: 0.2231 - val_loss: 2.6546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 4.1185 - accuracy: 0.2380 - val_loss: 1.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 3.7634 - accuracy: 0.2370 - val_loss: 1.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.6140 - accuracy: 0.2385 - val_loss: 1.4063 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.5642 - accuracy: 0.2395 - val_loss: 1.3917 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 3.4941 - accuracy: 0.2375 - val_loss: 1.5348 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.5006 - accuracy: 0.2372 - val_loss: 1.3821 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.4795 - accuracy: 0.2390 - val_loss: 1.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.4728 - accuracy: 0.2396 - val_loss: 1.3630 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 3.4577 - accuracy: 0.2392 - val_loss: 1.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.4458 - accuracy: 0.2395 - val_loss: 1.3316 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.3915 - accuracy: 0.2383 - val_loss: 1.2150 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.4207 - accuracy: 0.2408 - val_loss: 1.3534 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.4123 - accuracy: 0.2340 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.3877 - accuracy: 0.2373 - val_loss: 1.3762 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.3630 - accuracy: 0.2389 - val_loss: 1.6122 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.3504 - accuracy: 0.2419 - val_loss: 1.1717 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3586 - accuracy: 0.2361 - val_loss: 1.1728 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3682 - accuracy: 0.2329 - val_loss: 1.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.3258 - accuracy: 0.2430 - val_loss: 1.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3400 - accuracy: 0.2369 - val_loss: 1.0980 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3018 - accuracy: 0.2414 - val_loss: 1.3482 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3222 - accuracy: 0.2424 - val_loss: 1.3437 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2957 - accuracy: 0.2377 - val_loss: 1.1977 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2946 - accuracy: 0.2412 - val_loss: 1.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 3.2676 - accuracy: 0.2384 - val_loss: 1.2292 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2607 - accuracy: 0.2368 - val_loss: 1.1571 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2587 - accuracy: 0.2330 - val_loss: 1.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2724 - accuracy: 0.2382 - val_loss: 1.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2646 - accuracy: 0.2368 - val_loss: 1.2016 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2413 - accuracy: 0.2400 - val_loss: 1.2702 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2744 - accuracy: 0.2396 - val_loss: 1.3094 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2836 - accuracy: 0.2393 - val_loss: 1.2273 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2539 - accuracy: 0.2385 - val_loss: 1.2670 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2622 - accuracy: 0.2353 - val_loss: 1.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2564 - accuracy: 0.2390 - val_loss: 1.1156 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2298 - accuracy: 0.2394 - val_loss: 1.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.2222 - accuracy: 0.2364 - val_loss: 1.1602 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2361 - accuracy: 0.2406 - val_loss: 1.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2899 - accuracy: 0.2371 - val_loss: 1.2993 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2553 - accuracy: 0.2385 - val_loss: 1.1011 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2485 - accuracy: 0.2377 - val_loss: 1.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.2474 - accuracy: 0.2365 - val_loss: 1.2504 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2253 - accuracy: 0.2340 - val_loss: 1.0584 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.2044 - accuracy: 0.2379 - val_loss: 1.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2216 - accuracy: 0.2381 - val_loss: 1.2142 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2031 - accuracy: 0.2360 - val_loss: 1.1883 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2302 - accuracy: 0.2369 - val_loss: 1.2101 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.2325 - accuracy: 0.2377 - val_loss: 1.2361 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.2233 - accuracy: 0.2349 - val_loss: 1.3038 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217343AE048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217343AE048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 12.2559 - accuracy: 0.3252WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730AA2168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730AA2168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 12.2559 - accuracy: 0.3252 - val_loss: 5.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 4.5828 - accuracy: 0.3723 - val_loss: 1.3876 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.5465 - accuracy: 0.3679 - val_loss: 0.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0709 - accuracy: 0.3674 - val_loss: 0.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.0233 - accuracy: 0.3661 - val_loss: 0.2568 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0174 - accuracy: 0.3655 - val_loss: 0.2660 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.0198 - accuracy: 0.3628 - val_loss: 0.2548 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.0455 - accuracy: 0.3570 - val_loss: 0.2507 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0122 - accuracy: 0.3644 - val_loss: 0.2312 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9854 - accuracy: 0.3703 - val_loss: 0.2488 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0184 - accuracy: 0.3612 - val_loss: 0.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0291 - accuracy: 0.3605 - val_loss: 0.2528 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0231 - accuracy: 0.3609 - val_loss: 0.2542 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0055 - accuracy: 0.3658 - val_loss: 0.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9860 - accuracy: 0.3710 - val_loss: 0.2334 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0091 - accuracy: 0.3627 - val_loss: 0.2440 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0098 - accuracy: 0.3631 - val_loss: 0.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0171 - accuracy: 0.3592 - val_loss: 0.2388 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0071 - accuracy: 0.3630 - val_loss: 0.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9948 - accuracy: 0.3667 - val_loss: 0.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0010 - accuracy: 0.3700 - val_loss: 0.2379 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0033 - accuracy: 0.3633 - val_loss: 0.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9872 - accuracy: 0.3673 - val_loss: 0.2369 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0042 - accuracy: 0.3664 - val_loss: 0.2540 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0171 - accuracy: 0.3607 - val_loss: 0.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9967 - accuracy: 0.3665 - val_loss: 0.2342 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9986 - accuracy: 0.3677 - val_loss: 0.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9913 - accuracy: 0.3672 - val_loss: 0.2360 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9943 - accuracy: 0.3686 - val_loss: 0.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0001 - accuracy: 0.3659 - val_loss: 0.2446 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0011 - accuracy: 0.3672 - val_loss: 0.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0045 - accuracy: 0.3616 - val_loss: 0.2309 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9970 - accuracy: 0.3675 - val_loss: 0.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9916 - accuracy: 0.3734 - val_loss: 0.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0083 - accuracy: 0.3679 - val_loss: 0.2471 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.9987 - accuracy: 0.3707 - val_loss: 0.2427 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9847 - accuracy: 0.3760 - val_loss: 0.2444 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9927 - accuracy: 0.3687 - val_loss: 0.2496 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9889 - accuracy: 0.3721 - val_loss: 0.2376 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9830 - accuracy: 0.3741 - val_loss: 0.2369 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9848 - accuracy: 0.3768 - val_loss: 0.2469 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0005 - accuracy: 0.3718 - val_loss: 0.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9772 - accuracy: 0.3732 - val_loss: 0.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9784 - accuracy: 0.3768 - val_loss: 0.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9800 - accuracy: 0.3755 - val_loss: 0.2434 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9789 - accuracy: 0.3782 - val_loss: 0.2411 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9780 - accuracy: 0.3736 - val_loss: 0.2447 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9945 - accuracy: 0.3709 - val_loss: 0.2469 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0042 - accuracy: 0.3696 - val_loss: 0.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9799 - accuracy: 0.3729 - val_loss: 0.2423 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172CED0288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172CED0288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 5.8017 - accuracy: 0.3243WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730D4AC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730D4AC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 5.8017 - accuracy: 0.3243 - val_loss: 3.6130 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 5.0600 - accuracy: 0.3904 - val_loss: 3.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.5437 - accuracy: 0.4023 - val_loss: 2.6486 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 4.1127 - accuracy: 0.4018 - val_loss: 2.2399 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.7148 - accuracy: 0.4054 - val_loss: 1.8717 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.3685 - accuracy: 0.4028 - val_loss: 1.5480 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.0669 - accuracy: 0.4049 - val_loss: 1.2657 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.8156 - accuracy: 0.3998 - val_loss: 1.0264 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.5954 - accuracy: 0.4021 - val_loss: 0.8296 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.4087 - accuracy: 0.4071 - val_loss: 0.6772 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.2574 - accuracy: 0.4122 - val_loss: 0.5581 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.1575 - accuracy: 0.4123 - val_loss: 0.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.0831 - accuracy: 0.4182 - val_loss: 0.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0653 - accuracy: 0.4088 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.0182 - accuracy: 0.4159 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9766 - accuracy: 0.4224 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9381 - accuracy: 0.4309 - val_loss: 0.3347 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9265 - accuracy: 0.4303 - val_loss: 0.3186 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9150 - accuracy: 0.4292 - val_loss: 0.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9121 - accuracy: 0.4255 - val_loss: 0.2962 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8734 - accuracy: 0.4356 - val_loss: 0.2822 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8660 - accuracy: 0.4319 - val_loss: 0.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8543 - accuracy: 0.4341 - val_loss: 0.2653 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8368 - accuracy: 0.4327 - val_loss: 0.2535 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8207 - accuracy: 0.4409 - val_loss: 0.2535 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8081 - accuracy: 0.4456 - val_loss: 0.2486 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8382 - accuracy: 0.4329 - val_loss: 0.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8350 - accuracy: 0.4337 - val_loss: 0.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8222 - accuracy: 0.4374 - val_loss: 0.2429 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8078 - accuracy: 0.4396 - val_loss: 0.2389 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8193 - accuracy: 0.4362 - val_loss: 0.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8398 - accuracy: 0.4339 - val_loss: 0.2472 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8521 - accuracy: 0.4266 - val_loss: 0.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8399 - accuracy: 0.4326 - val_loss: 0.2481 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8288 - accuracy: 0.4375 - val_loss: 0.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8311 - accuracy: 0.4363 - val_loss: 0.2489 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8041 - accuracy: 0.4420 - val_loss: 0.2420 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8003 - accuracy: 0.4449 - val_loss: 0.2415 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8301 - accuracy: 0.4346 - val_loss: 0.2465 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.8118 - accuracy: 0.4428 - val_loss: 0.2475 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8047 - accuracy: 0.4424 - val_loss: 0.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8114 - accuracy: 0.4397 - val_loss: 0.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8151 - accuracy: 0.4387 - val_loss: 0.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7966 - accuracy: 0.4478 - val_loss: 0.2468 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8140 - accuracy: 0.4396 - val_loss: 0.2468 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7926 - accuracy: 0.4425 - val_loss: 0.2465 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8017 - accuracy: 0.4445 - val_loss: 0.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7986 - accuracy: 0.4450 - val_loss: 0.2453 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7892 - accuracy: 0.4476 - val_loss: 0.2442 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8099 - accuracy: 0.4377 - val_loss: 0.2468 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737DFA288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737DFA288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 5.6825 - accuracy: 0.3285WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737E7F8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737E7F8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 5.6825 - accuracy: 0.3285 - val_loss: 3.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 4.9791 - accuracy: 0.3917 - val_loss: 3.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.4860 - accuracy: 0.4110 - val_loss: 2.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.0764 - accuracy: 0.4129 - val_loss: 2.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.6882 - accuracy: 0.4198 - val_loss: 1.8954 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.3720 - accuracy: 0.4154 - val_loss: 1.5946 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.1097 - accuracy: 0.4088 - val_loss: 1.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8559 - accuracy: 0.4098 - val_loss: 1.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.6262 - accuracy: 0.4151 - val_loss: 0.8993 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.4567 - accuracy: 0.4138 - val_loss: 0.7464 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.3120 - accuracy: 0.4150 - val_loss: 0.6188 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.1946 - accuracy: 0.4217 - val_loss: 0.5353 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1292 - accuracy: 0.4190 - val_loss: 0.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.0749 - accuracy: 0.4190 - val_loss: 0.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0438 - accuracy: 0.4241 - val_loss: 0.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.0412 - accuracy: 0.4151 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.9961 - accuracy: 0.4258 - val_loss: 0.3738 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9735 - accuracy: 0.4242 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9480 - accuracy: 0.4307 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9209 - accuracy: 0.4313 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9179 - accuracy: 0.4287 - val_loss: 0.3090 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9043 - accuracy: 0.4279 - val_loss: 0.3023 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8766 - accuracy: 0.4387 - val_loss: 0.2840 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8686 - accuracy: 0.4342 - val_loss: 0.2819 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8865 - accuracy: 0.4270 - val_loss: 0.2785 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8622 - accuracy: 0.4325 - val_loss: 0.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8563 - accuracy: 0.4359 - val_loss: 0.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8393 - accuracy: 0.4375 - val_loss: 0.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8265 - accuracy: 0.4412 - val_loss: 0.2553 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8283 - accuracy: 0.4367 - val_loss: 0.2527 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7979 - accuracy: 0.4483 - val_loss: 0.2453 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8078 - accuracy: 0.4434 - val_loss: 0.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8049 - accuracy: 0.4436 - val_loss: 0.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7968 - accuracy: 0.4461 - val_loss: 0.2478 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8079 - accuracy: 0.4437 - val_loss: 0.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8161 - accuracy: 0.4396 - val_loss: 0.2476 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8142 - accuracy: 0.4380 - val_loss: 0.2491 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8154 - accuracy: 0.4383 - val_loss: 0.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8087 - accuracy: 0.4413 - val_loss: 0.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7942 - accuracy: 0.4474 - val_loss: 0.2466 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7851 - accuracy: 0.4514 - val_loss: 0.2427 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7898 - accuracy: 0.4486 - val_loss: 0.2470 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7885 - accuracy: 0.4494 - val_loss: 0.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7863 - accuracy: 0.4522 - val_loss: 0.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7718 - accuracy: 0.4530 - val_loss: 0.2425 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.7727 - accuracy: 0.4535 - val_loss: 0.2415 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7842 - accuracy: 0.4509 - val_loss: 0.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7874 - accuracy: 0.4506 - val_loss: 0.2489 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7839 - accuracy: 0.4512 - val_loss: 0.2429 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7871 - accuracy: 0.4487 - val_loss: 0.2463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173A7BB798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173A7BB798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 10.0879 - accuracy: 0.3303WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217380FA438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217380FA438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 10.0879 - accuracy: 0.3303 - val_loss: 4.1637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.1906 - accuracy: 0.3787 - val_loss: 1.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.5684 - accuracy: 0.3731 - val_loss: 0.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0923 - accuracy: 0.3714 - val_loss: 0.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9277 - accuracy: 0.3791 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.8766 - accuracy: 0.3818 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8580 - accuracy: 0.3824 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.8696 - accuracy: 0.3759 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.9149 - accuracy: 0.3564 - val_loss: 0.1245 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8885 - accuracy: 0.3634 - val_loss: 0.1211 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8739 - accuracy: 0.3712 - val_loss: 0.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8676 - accuracy: 0.3745 - val_loss: 0.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.9053 - accuracy: 0.3614 - val_loss: 0.1342 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9081 - accuracy: 0.3609 - val_loss: 0.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.8885 - accuracy: 0.3653 - val_loss: 0.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8680 - accuracy: 0.3746 - val_loss: 0.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.8616 - accuracy: 0.3733 - val_loss: 0.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8752 - accuracy: 0.3703 - val_loss: 0.1275 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8815 - accuracy: 0.3689 - val_loss: 0.1267 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8733 - accuracy: 0.3715 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.8924 - accuracy: 0.3686 - val_loss: 0.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.8752 - accuracy: 0.3752 - val_loss: 0.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9065 - accuracy: 0.3604 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8805 - accuracy: 0.3675 - val_loss: 0.1270 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8631 - accuracy: 0.3768 - val_loss: 0.1268 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8767 - accuracy: 0.3741 - val_loss: 0.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8740 - accuracy: 0.3723 - val_loss: 0.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8701 - accuracy: 0.3747 - val_loss: 0.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8800 - accuracy: 0.3745 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8686 - accuracy: 0.3806 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8700 - accuracy: 0.3796 - val_loss: 0.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8713 - accuracy: 0.3753 - val_loss: 0.1351 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8608 - accuracy: 0.3822 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8639 - accuracy: 0.3809 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8617 - accuracy: 0.3808 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8972 - accuracy: 0.3686 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8611 - accuracy: 0.3807 - val_loss: 0.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8637 - accuracy: 0.3794 - val_loss: 0.1311 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8497 - accuracy: 0.3830 - val_loss: 0.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8430 - accuracy: 0.3868 - val_loss: 0.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8586 - accuracy: 0.3832 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8549 - accuracy: 0.3847 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8608 - accuracy: 0.3818 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8339 - accuracy: 0.3937 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8438 - accuracy: 0.3908 - val_loss: 0.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8516 - accuracy: 0.3928 - val_loss: 0.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8665 - accuracy: 0.3851 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 1.8651 - accuracy: 0.3831 - val_loss: 0.1473 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.8702 - accuracy: 0.3804 - val_loss: 0.1473 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8720 - accuracy: 0.3813 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730AC1558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730AC1558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 2.0507 - accuracy: 0.3311 ETA: 0s - loss: 2.0519 - accuWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172D053168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172D053168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 2.0507 - accuracy: 0.3311 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8295 - accuracy: 0.3981 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.7782 - accuracy: 0.4136 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.7623 - accuracy: 0.4187 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.7452 - accuracy: 0.4307 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.7331 - accuracy: 0.4297 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.7173 - accuracy: 0.4332 - val_loss: 0.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7107 - accuracy: 0.4392 - val_loss: 0.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6873 - accuracy: 0.4484 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6831 - accuracy: 0.4496 - val_loss: 0.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.6769 - accuracy: 0.4495 - val_loss: 0.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6688 - accuracy: 0.4539 - val_loss: 0.1322 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6621 - accuracy: 0.4539 - val_loss: 0.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6677 - accuracy: 0.4535 - val_loss: 0.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6598 - accuracy: 0.4549 - val_loss: 0.1297 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6472 - accuracy: 0.4572 - val_loss: 0.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6439 - accuracy: 0.4623 - val_loss: 0.1280 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6244 - accuracy: 0.4634 - val_loss: 0.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6139 - accuracy: 0.4695 - val_loss: 0.1264 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6136 - accuracy: 0.4690 - val_loss: 0.1255 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6074 - accuracy: 0.4712 - val_loss: 0.1247 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5965 - accuracy: 0.4742 - val_loss: 0.1239 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5978 - accuracy: 0.4772 - val_loss: 0.1231 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5900 - accuracy: 0.4782 - val_loss: 0.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5924 - accuracy: 0.4746 - val_loss: 0.1215 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5727 - accuracy: 0.4825 - val_loss: 0.1206 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5665 - accuracy: 0.4830 - val_loss: 0.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.5708 - accuracy: 0.4849 - val_loss: 0.1191 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5600 - accuracy: 0.4862 - val_loss: 0.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5526 - accuracy: 0.4866 - val_loss: 0.1176 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5430 - accuracy: 0.4919 - val_loss: 0.1168 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5417 - accuracy: 0.4919 - val_loss: 0.1161 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5373 - accuracy: 0.4932 - val_loss: 0.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5332 - accuracy: 0.4921 - val_loss: 0.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5351 - accuracy: 0.4920 - val_loss: 0.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5272 - accuracy: 0.4975 - val_loss: 0.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5260 - accuracy: 0.4947 - val_loss: 0.1126 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.5431 - accuracy: 0.4908 - val_loss: 0.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5520 - accuracy: 0.4848 - val_loss: 0.1113 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5404 - accuracy: 0.4910 - val_loss: 0.1107 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5324 - accuracy: 0.4928 - val_loss: 0.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5299 - accuracy: 0.4928 - val_loss: 0.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5275 - accuracy: 0.4947 - val_loss: 0.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5202 - accuracy: 0.4986 - val_loss: 0.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5326 - accuracy: 0.4926 - val_loss: 0.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5264 - accuracy: 0.4958 - val_loss: 0.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5194 - accuracy: 0.4982 - val_loss: 0.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5152 - accuracy: 0.4977 - val_loss: 0.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5245 - accuracy: 0.4939 - val_loss: 0.1050 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5185 - accuracy: 0.4969 - val_loss: 0.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172CEE0948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002172CEE0948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.9100 - accuracy: 0.3296WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737F328B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737F328B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 1.9100 - accuracy: 0.3296 - val_loss: 4.1699e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6960 - accuracy: 0.3920 - val_loss: 4.1801e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6442 - accuracy: 0.4116 - val_loss: 4.1907e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.6053 - accuracy: 0.4252 - val_loss: 4.2006e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5877 - accuracy: 0.4333 - val_loss: 4.2102e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5722 - accuracy: 0.4421 - val_loss: 4.2201e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5683 - accuracy: 0.4405 - val_loss: 4.2302e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.5725 - accuracy: 0.4399 - val_loss: 4.2395e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5645 - accuracy: 0.4417 - val_loss: 4.2485e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5563 - accuracy: 0.4427 - val_loss: 4.2575e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5645 - accuracy: 0.4415 - val_loss: 4.2664e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5491 - accuracy: 0.4486 - val_loss: 4.2743e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 1.5365 - accuracy: 0.4545 - val_loss: 4.2822e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5258 - accuracy: 0.4539 - val_loss: 4.2898e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5073 - accuracy: 0.4621 - val_loss: 4.2970e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5004 - accuracy: 0.4661 - val_loss: 4.3045e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4925 - accuracy: 0.4670 - val_loss: 4.3115e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4874 - accuracy: 0.4713 - val_loss: 4.3186e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4763 - accuracy: 0.4752 - val_loss: 4.3254e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4833 - accuracy: 0.4725 - val_loss: 4.3324e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4751 - accuracy: 0.4749 - val_loss: 4.3391e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4860 - accuracy: 0.4713 - val_loss: 4.3461e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4771 - accuracy: 0.4729 - val_loss: 4.3526e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4673 - accuracy: 0.4768 - val_loss: 4.3592e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4599 - accuracy: 0.4800 - val_loss: 4.3651e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4547 - accuracy: 0.4816 - val_loss: 4.3710e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4483 - accuracy: 0.4828 - val_loss: 4.3769e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.4456 - accuracy: 0.4844 - val_loss: 4.3829e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4448 - accuracy: 0.4852 - val_loss: 4.3888e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4335 - accuracy: 0.4908 - val_loss: 4.3945e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4381 - accuracy: 0.4876 - val_loss: 4.4003e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4358 - accuracy: 0.4875 - val_loss: 4.4057e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4393 - accuracy: 0.4869 - val_loss: 4.4113e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4270 - accuracy: 0.4882 - val_loss: 4.4168e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4197 - accuracy: 0.4936 - val_loss: 4.4220e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4184 - accuracy: 0.4944 - val_loss: 4.4274e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4194 - accuracy: 0.4949 - val_loss: 4.4328e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.4214 - accuracy: 0.4931 - val_loss: 4.4382e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.4102 - accuracy: 0.4982 - val_loss: 4.4434e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4040 - accuracy: 0.4996 - val_loss: 4.4485e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3983 - accuracy: 0.4990 - val_loss: 4.4536e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4040 - accuracy: 0.5022 - val_loss: 4.4587e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4004 - accuracy: 0.5004 - val_loss: 4.4639e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4043 - accuracy: 0.4990 - val_loss: 4.4689e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4025 - accuracy: 0.4989 - val_loss: 4.4739e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3975 - accuracy: 0.5010 - val_loss: 4.4786e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3957 - accuracy: 0.5016 - val_loss: 4.4835e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3897 - accuracy: 0.5049 - val_loss: 4.4885e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3934 - accuracy: 0.5029 - val_loss: 4.4933e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3864 - accuracy: 0.5026 - val_loss: 4.4981e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173806ACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173806ACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 34.1393 - accuracy: 0.2075- ETA: 0s - loss: 34.6267 - accWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173A97B558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173A97B558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 34.1393 - accuracy: 0.2075 - val_loss: 2.5637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.4216 - accuracy: 0.2198 - val_loss: 2.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 4.0655 - accuracy: 0.2177 - val_loss: 1.7497 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.9621 - accuracy: 0.2167 - val_loss: 1.8716 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.9329 - accuracy: 0.2196 - val_loss: 1.7846 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.8534 - accuracy: 0.2187 - val_loss: 1.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.8665 - accuracy: 0.2155 - val_loss: 1.7735 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.7567 - accuracy: 0.2177 - val_loss: 1.6924 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7344 - accuracy: 0.2197 - val_loss: 1.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.7425 - accuracy: 0.2184 - val_loss: 1.5934 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.7267 - accuracy: 0.2201 - val_loss: 1.6045 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7378 - accuracy: 0.2225 - val_loss: 1.7017 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.7360 - accuracy: 0.2194 - val_loss: 1.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7274 - accuracy: 0.2178 - val_loss: 1.5181 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6917 - accuracy: 0.2174 - val_loss: 1.5816 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.7122 - accuracy: 0.2192 - val_loss: 1.5825 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.6804 - accuracy: 0.2140 - val_loss: 1.5051 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6652 - accuracy: 0.2204 - val_loss: 1.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.6693 - accuracy: 0.2192 - val_loss: 1.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.6790 - accuracy: 0.2212 - val_loss: 1.5410 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 3.6159 - accuracy: 0.2158 - val_loss: 1.5227 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.6325 - accuracy: 0.2188 - val_loss: 1.4734 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.6314 - accuracy: 0.2216 - val_loss: 1.5611 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5990 - accuracy: 0.2202 - val_loss: 1.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5986 - accuracy: 0.2162 - val_loss: 1.5380 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5757 - accuracy: 0.2228 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6255 - accuracy: 0.2208 - val_loss: 1.3927 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.6112 - accuracy: 0.2188 - val_loss: 1.6178 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5967 - accuracy: 0.2176 - val_loss: 1.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 3.5691 - accuracy: 0.2183 - val_loss: 1.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5538 - accuracy: 0.2169 - val_loss: 1.3958 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5650 - accuracy: 0.2162 - val_loss: 1.4952 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5567 - accuracy: 0.2209 - val_loss: 1.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5612 - accuracy: 0.2227 - val_loss: 1.5233 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5831 - accuracy: 0.2214 - val_loss: 1.4805 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5531 - accuracy: 0.2198 - val_loss: 1.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5347 - accuracy: 0.2196 - val_loss: 1.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5617 - accuracy: 0.2192 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4951 - accuracy: 0.2160 - val_loss: 1.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5152 - accuracy: 0.2211 - val_loss: 1.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.5450 - accuracy: 0.2187 - val_loss: 1.2864 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.5291 - accuracy: 0.2211 - val_loss: 1.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5018 - accuracy: 0.2168 - val_loss: 1.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5007 - accuracy: 0.2179 - val_loss: 1.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5301 - accuracy: 0.2209 - val_loss: 1.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5148 - accuracy: 0.2217 - val_loss: 1.4904 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.4803 - accuracy: 0.2205 - val_loss: 1.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4654 - accuracy: 0.2170 - val_loss: 1.3913 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.4779 - accuracy: 0.2198 - val_loss: 1.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.4845 - accuracy: 0.2200 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217380FA0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217380FA0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 34.8010 - accuracy: 0.2091WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737C6ECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737C6ECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 34.8010 - accuracy: 0.2091 - val_loss: 3.0427 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.5376 - accuracy: 0.2184 - val_loss: 2.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.2299 - accuracy: 0.2210 - val_loss: 2.1190 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 4.0762 - accuracy: 0.2184 - val_loss: 1.8437 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 4.0316 - accuracy: 0.2208 - val_loss: 1.8932 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.9592 - accuracy: 0.2206 - val_loss: 1.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 3.9603 - accuracy: 0.2170 - val_loss: 1.8312 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.8612 - accuracy: 0.2191 - val_loss: 1.7458 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 3.8524 - accuracy: 0.2211 - val_loss: 2.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.8804 - accuracy: 0.2191 - val_loss: 1.7176 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.8356 - accuracy: 0.2200 - val_loss: 1.8074 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.8193 - accuracy: 0.2187 - val_loss: 1.9935 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.8296 - accuracy: 0.2234 - val_loss: 1.6909 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.8224 - accuracy: 0.2205 - val_loss: 1.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.7965 - accuracy: 0.2239 - val_loss: 1.7943 - val_accuracy: 0.0000e+00 - ETA: 2s - loss: 3.7883 - accuracy -\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.7984 - accuracy: 0.2223 - val_loss: 1.6699 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.7936 - accuracy: 0.2230 - val_loss: 1.8725 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.8030 - accuracy: 0.2205 - val_loss: 1.5638 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7591 - accuracy: 0.2224 - val_loss: 1.5814 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7950 - accuracy: 0.2211 - val_loss: 1.6002 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7638 - accuracy: 0.2212 - val_loss: 1.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7316 - accuracy: 0.2214 - val_loss: 1.6995 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7382 - accuracy: 0.2213 - val_loss: 1.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7151 - accuracy: 0.2235 - val_loss: 1.5374 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6923 - accuracy: 0.2218 - val_loss: 1.5117 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6774 - accuracy: 0.2181 - val_loss: 1.5967 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6590 - accuracy: 0.2179 - val_loss: 1.6554 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7008 - accuracy: 0.2230 - val_loss: 1.4795 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6533 - accuracy: 0.2235 - val_loss: 1.5201 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.6473 - accuracy: 0.2183 - val_loss: 1.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6014 - accuracy: 0.2228 - val_loss: 1.5421 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6384 - accuracy: 0.2196 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5791 - accuracy: 0.2240 - val_loss: 1.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6208 - accuracy: 0.2222 - val_loss: 1.6627 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6064 - accuracy: 0.2208 - val_loss: 1.4997 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6457 - accuracy: 0.2229 - val_loss: 1.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6154 - accuracy: 0.2223 - val_loss: 1.3436 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6044 - accuracy: 0.2262 - val_loss: 1.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6118 - accuracy: 0.2241 - val_loss: 1.4083 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5879 - accuracy: 0.2224 - val_loss: 1.4788 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5807 - accuracy: 0.2191 - val_loss: 1.3791 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5826 - accuracy: 0.2208 - val_loss: 1.5264 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6097 - accuracy: 0.2180 - val_loss: 1.4379 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5643 - accuracy: 0.2205 - val_loss: 1.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6133 - accuracy: 0.2229 - val_loss: 1.4630 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.5800 - accuracy: 0.2186 - val_loss: 1.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6045 - accuracy: 0.2235 - val_loss: 1.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5994 - accuracy: 0.2243 - val_loss: 1.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5757 - accuracy: 0.2236 - val_loss: 1.4668 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.5968 - accuracy: 0.2223 - val_loss: 1.4182 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173036E438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173036E438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 34.6612 - accuracy: 0.2076WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737E7F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737E7F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 34.6612 - accuracy: 0.2076 - val_loss: 2.7362 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.4952 - accuracy: 0.2138 - val_loss: 2.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 4.1340 - accuracy: 0.2163 - val_loss: 2.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.0340 - accuracy: 0.2201 - val_loss: 1.7920 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.9007 - accuracy: 0.2170 - val_loss: 1.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 3.9140 - accuracy: 0.2208 - val_loss: 1.7299 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.8989 - accuracy: 0.2189 - val_loss: 1.5482 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.8569 - accuracy: 0.2216 - val_loss: 1.9289 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.8616 - accuracy: 0.2207 - val_loss: 1.8154 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.8242 - accuracy: 0.2209 - val_loss: 1.8762 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.8255 - accuracy: 0.2236 - val_loss: 1.9282 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.8208 - accuracy: 0.2209 - val_loss: 1.8933 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7808 - accuracy: 0.2181 - val_loss: 1.6592 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7585 - accuracy: 0.2196 - val_loss: 1.7125 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.7328 - accuracy: 0.2216 - val_loss: 1.7346 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7351 - accuracy: 0.2179 - val_loss: 1.7274 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7324 - accuracy: 0.2167 - val_loss: 1.6022 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.7130 - accuracy: 0.2183 - val_loss: 1.6671 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.7146 - accuracy: 0.2163 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.7128 - accuracy: 0.2181 - val_loss: 1.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6880 - accuracy: 0.2189 - val_loss: 1.6814 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7153 - accuracy: 0.2175 - val_loss: 1.5345 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6948 - accuracy: 0.2156 - val_loss: 1.5877 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.7066 - accuracy: 0.2197 - val_loss: 1.5410 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6507 - accuracy: 0.2184 - val_loss: 1.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6826 - accuracy: 0.2206 - val_loss: 1.5251 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6593 - accuracy: 0.2201 - val_loss: 1.4603 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6241 - accuracy: 0.2215 - val_loss: 1.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6617 - accuracy: 0.2205 - val_loss: 1.5484 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6651 - accuracy: 0.2170 - val_loss: 1.7066 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6395 - accuracy: 0.2211 - val_loss: 1.5760 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6443 - accuracy: 0.2179 - val_loss: 1.5766 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 3.6248 - accuracy: 0.2187 - val_loss: 1.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6115 - accuracy: 0.2195 - val_loss: 1.5431 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6329 - accuracy: 0.2172 - val_loss: 1.6239 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.6104 - accuracy: 0.2196 - val_loss: 1.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6230 - accuracy: 0.2192 - val_loss: 1.3740 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6062 - accuracy: 0.2171 - val_loss: 1.5521 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 3.6079 - accuracy: 0.2213 - val_loss: 1.5188 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 3.6383 - accuracy: 0.2225 - val_loss: 1.4996 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6139 - accuracy: 0.2196 - val_loss: 1.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.5908 - accuracy: 0.2220 - val_loss: 1.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6080 - accuracy: 0.2191 - val_loss: 1.4468 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5922 - accuracy: 0.2217 - val_loss: 1.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.5847 - accuracy: 0.2209 - val_loss: 1.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.5838 - accuracy: 0.2225 - val_loss: 1.4635 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5838 - accuracy: 0.2200 - val_loss: 1.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.5637 - accuracy: 0.2223 - val_loss: 1.5077 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 3.5564 - accuracy: 0.2237 - val_loss: 1.3676 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.5648 - accuracy: 0.2218 - val_loss: 1.3764 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173A7BB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173A7BB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 12.4222 - accuracy: 0.2827- ETA: 1s - loss:WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737DABB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737DABB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 12.4222 - accuracy: 0.2827 - val_loss: 5.0576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 4.6675 - accuracy: 0.3316 - val_loss: 1.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.6309 - accuracy: 0.3273 - val_loss: 0.3873 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.1733 - accuracy: 0.3160 - val_loss: 0.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.1296 - accuracy: 0.3240 - val_loss: 0.2609 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.1368 - accuracy: 0.3190 - val_loss: 0.2501 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.1194 - accuracy: 0.3183 - val_loss: 0.2345 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 2.1301 - accuracy: 0.3143 - val_loss: 0.2334 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 2.1249 - accuracy: 0.3133 - val_loss: 0.2262 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.1264 - accuracy: 0.3120 - val_loss: 0.2226 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.1088 - accuracy: 0.3187 - val_loss: 0.2377 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.1067 - accuracy: 0.3243 - val_loss: 0.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.0927 - accuracy: 0.3252 - val_loss: 0.2293 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.1014 - accuracy: 0.3215 - val_loss: 0.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.1028 - accuracy: 0.3236 - val_loss: 0.2345 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.1045 - accuracy: 0.3225 - val_loss: 0.2362 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1061 - accuracy: 0.3238 - val_loss: 0.2286 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0902 - accuracy: 0.3264 - val_loss: 0.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0916 - accuracy: 0.3259 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1001 - accuracy: 0.3213 - val_loss: 0.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.1013 - accuracy: 0.3232 - val_loss: 0.2250 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1082 - accuracy: 0.3146 - val_loss: 0.2222 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1074 - accuracy: 0.3165 - val_loss: 0.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0883 - accuracy: 0.3223 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1006 - accuracy: 0.3161 - val_loss: 0.2241 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0897 - accuracy: 0.3262 - val_loss: 0.2256 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0951 - accuracy: 0.3242 - val_loss: 0.2300 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1232 - accuracy: 0.3112 - val_loss: 0.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0879 - accuracy: 0.3228 - val_loss: 0.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0814 - accuracy: 0.3263 - val_loss: 0.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0842 - accuracy: 0.3261 - val_loss: 0.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1005 - accuracy: 0.3214 - val_loss: 0.2236 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0948 - accuracy: 0.3210 - val_loss: 0.2277 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 2.1096 - accuracy: 0.3194 - val_loss: 0.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0846 - accuracy: 0.3255 - val_loss: 0.2227 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0798 - accuracy: 0.3266 - val_loss: 0.2198 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0681 - accuracy: 0.3326 - val_loss: 0.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0954 - accuracy: 0.3268 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0993 - accuracy: 0.3206 - val_loss: 0.2248 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0735 - accuracy: 0.3334 - val_loss: 0.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0899 - accuracy: 0.3266 - val_loss: 0.2256 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0888 - accuracy: 0.3268 - val_loss: 0.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0767 - accuracy: 0.3283 - val_loss: 0.2274 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0917 - accuracy: 0.3246 - val_loss: 0.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0824 - accuracy: 0.3251 - val_loss: 0.2176 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0837 - accuracy: 0.3289 - val_loss: 0.2277 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.0784 - accuracy: 0.3296 - val_loss: 0.2223 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0913 - accuracy: 0.3245 - val_loss: 0.2223 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0863 - accuracy: 0.3264 - val_loss: 0.2227 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0725 - accuracy: 0.3312 - val_loss: 0.2241 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737DABA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737DABA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 5.9433 - accuracy: 0.2844WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC27678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC27678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 5.9433 - accuracy: 0.2844 - val_loss: 3.6179 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 5.1840 - accuracy: 0.3430 - val_loss: 3.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 4.6600 - accuracy: 0.3599 - val_loss: 2.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 4.2282 - accuracy: 0.3541 - val_loss: 2.2343 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 3.8428 - accuracy: 0.3543 - val_loss: 1.8698 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 3.5040 - accuracy: 0.3526 - val_loss: 1.5414 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 3.1749 - accuracy: 0.3592 - val_loss: 1.2567 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.9599 - accuracy: 0.3434 - val_loss: 1.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.7430 - accuracy: 0.3436 - val_loss: 0.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.5560 - accuracy: 0.3443 - val_loss: 0.6653 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.4017 - accuracy: 0.3496 - val_loss: 0.5460 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.2830 - accuracy: 0.3604 - val_loss: 0.4606 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.2206 - accuracy: 0.3581 - val_loss: 0.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.1843 - accuracy: 0.3532 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.1765 - accuracy: 0.3455 - val_loss: 0.3588 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.1633 - accuracy: 0.3485 - val_loss: 0.3450 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.1398 - accuracy: 0.3505 - val_loss: 0.3312 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.1388 - accuracy: 0.3474 - val_loss: 0.3142 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 2.1166 - accuracy: 0.3474 - val_loss: 0.2952 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.0829 - accuracy: 0.3532 - val_loss: 0.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.0669 - accuracy: 0.3515 - val_loss: 0.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0408 - accuracy: 0.3597 - val_loss: 0.2523 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 2.0154 - accuracy: 0.3635 - val_loss: 0.2451 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0020 - accuracy: 0.3652 - val_loss: 0.2369 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0056 - accuracy: 0.3662 - val_loss: 0.2288 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9983 - accuracy: 0.3667 - val_loss: 0.2326 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0000 - accuracy: 0.3652 - val_loss: 0.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9784 - accuracy: 0.3721 - val_loss: 0.2315 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9792 - accuracy: 0.3705 - val_loss: 0.2258 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0018 - accuracy: 0.3636 - val_loss: 0.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9992 - accuracy: 0.3608 - val_loss: 0.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9967 - accuracy: 0.3595 - val_loss: 0.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9658 - accuracy: 0.3709 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9720 - accuracy: 0.3738 - val_loss: 0.2232 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9838 - accuracy: 0.3682 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9522 - accuracy: 0.3737 - val_loss: 0.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9483 - accuracy: 0.3772 - val_loss: 0.2223 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9922 - accuracy: 0.3642 - val_loss: 0.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9678 - accuracy: 0.3716 - val_loss: 0.2211 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9798 - accuracy: 0.3691 - val_loss: 0.2268 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9897 - accuracy: 0.3646 - val_loss: 0.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9948 - accuracy: 0.3669 - val_loss: 0.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9829 - accuracy: 0.3680 - val_loss: 0.2209 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9595 - accuracy: 0.3764 - val_loss: 0.2200 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9661 - accuracy: 0.3764 - val_loss: 0.2243 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9709 - accuracy: 0.3736 - val_loss: 0.2175 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9655 - accuracy: 0.3728 - val_loss: 0.2237 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9695 - accuracy: 0.3707 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 1.9504 - accuracy: 0.3814 - val_loss: 0.2161 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9443 - accuracy: 0.3807 - val_loss: 0.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737DAB288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737DAB288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 5.8312 - accuracy: 0.2808WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737E7FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737E7FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 5.8312 - accuracy: 0.2808 - val_loss: 3.5239 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 5.1160 - accuracy: 0.3376 - val_loss: 3.0546 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.6399 - accuracy: 0.3503 - val_loss: 2.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 4.2350 - accuracy: 0.3506 - val_loss: 2.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.8686 - accuracy: 0.3492 - val_loss: 1.8923 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 3.5506 - accuracy: 0.3445 - val_loss: 1.5824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 3.2621 - accuracy: 0.3432 - val_loss: 1.3057 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.9907 - accuracy: 0.3509 - val_loss: 1.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.7851 - accuracy: 0.3496 - val_loss: 0.8770 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.6181 - accuracy: 0.3429 - val_loss: 0.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 2.4605 - accuracy: 0.3497 - val_loss: 0.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3605 - accuracy: 0.3478 - val_loss: 0.5089 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.2761 - accuracy: 0.3506 - val_loss: 0.4426 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 2.2147 - accuracy: 0.3558 - val_loss: 0.4030 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.2130 - accuracy: 0.3428 - val_loss: 0.3782 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1689 - accuracy: 0.3538 - val_loss: 0.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.1331 - accuracy: 0.3616 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.1200 - accuracy: 0.3600 - val_loss: 0.3217 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0775 - accuracy: 0.3646 - val_loss: 0.3124 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 2.0670 - accuracy: 0.3668 - val_loss: 0.2989 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0577 - accuracy: 0.3649 - val_loss: 0.2860 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0497 - accuracy: 0.3624 - val_loss: 0.2636 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0231 - accuracy: 0.3657 - val_loss: 0.2545 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0279 - accuracy: 0.3643 - val_loss: 0.2562 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.0069 - accuracy: 0.3700 - val_loss: 0.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0004 - accuracy: 0.3715 - val_loss: 0.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0115 - accuracy: 0.3620 - val_loss: 0.2314 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9962 - accuracy: 0.3657 - val_loss: 0.2283 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9624 - accuracy: 0.3731 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9592 - accuracy: 0.3753 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9924 - accuracy: 0.3638 - val_loss: 0.2199 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9778 - accuracy: 0.3637 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9752 - accuracy: 0.3674 - val_loss: 0.2199 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9715 - accuracy: 0.3721 - val_loss: 0.2153 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9637 - accuracy: 0.3728 - val_loss: 0.2158 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9605 - accuracy: 0.3719 - val_loss: 0.2154 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9645 - accuracy: 0.3712 - val_loss: 0.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9704 - accuracy: 0.3712 - val_loss: 0.2153 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9735 - accuracy: 0.3683 - val_loss: 0.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9783 - accuracy: 0.3631 - val_loss: 0.2132 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9593 - accuracy: 0.3710 - val_loss: 0.2077 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9619 - accuracy: 0.3686 - val_loss: 0.2075 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9750 - accuracy: 0.3625 - val_loss: 0.2093 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9550 - accuracy: 0.3701 - val_loss: 0.2070 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9338 - accuracy: 0.3781 - val_loss: 0.2071 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9521 - accuracy: 0.3749 - val_loss: 0.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.9584 - accuracy: 0.3748 - val_loss: 0.2112 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.9422 - accuracy: 0.3779 - val_loss: 0.2095 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9221 - accuracy: 0.3851 - val_loss: 0.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.9342 - accuracy: 0.3827 - val_loss: 0.2144 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730B48168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021730B48168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 10.2537 - accuracy: 0.2815- ETA: 0s - loss: 10.3122 - accurWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217380FA048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217380FA048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 10.2537 - accuracy: 0.2815 - val_loss: 4.1586 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 4.2638 - accuracy: 0.3383 - val_loss: 1.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.6460 - accuracy: 0.3374 - val_loss: 0.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.2143 - accuracy: 0.3218 - val_loss: 0.2325 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0748 - accuracy: 0.3126 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0320 - accuracy: 0.3069 - val_loss: 0.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0132 - accuracy: 0.3060 - val_loss: 0.1008 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0190 - accuracy: 0.3001 - val_loss: 0.0978 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0432 - accuracy: 0.2856 - val_loss: 0.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0108 - accuracy: 0.3008 - val_loss: 0.0963 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9886 - accuracy: 0.3143 - val_loss: 0.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9724 - accuracy: 0.3281 - val_loss: 0.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9870 - accuracy: 0.3244 - val_loss: 0.1184 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0071 - accuracy: 0.3139 - val_loss: 0.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0065 - accuracy: 0.3090 - val_loss: 0.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9919 - accuracy: 0.3180 - val_loss: 0.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9869 - accuracy: 0.3222 - val_loss: 0.1118 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9966 - accuracy: 0.3171 - val_loss: 0.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0084 - accuracy: 0.3081 - val_loss: 0.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9818 - accuracy: 0.3205 - val_loss: 0.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9860 - accuracy: 0.3203 - val_loss: 0.1158 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0058 - accuracy: 0.3117 - val_loss: 0.1156 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0042 - accuracy: 0.3148 - val_loss: 0.1123 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9959 - accuracy: 0.3157 - val_loss: 0.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9871 - accuracy: 0.3211 - val_loss: 0.1152 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.9931 - accuracy: 0.3199 - val_loss: 0.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9809 - accuracy: 0.3239 - val_loss: 0.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9908 - accuracy: 0.3192 - val_loss: 0.1152 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9693 - accuracy: 0.3277 - val_loss: 0.1137 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9808 - accuracy: 0.3232 - val_loss: 0.1201 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9807 - accuracy: 0.3237 - val_loss: 0.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9873 - accuracy: 0.3250 - val_loss: 0.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9644 - accuracy: 0.3339 - val_loss: 0.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9611 - accuracy: 0.3376 - val_loss: 0.1203 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9849 - accuracy: 0.3285 - val_loss: 0.1236 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9826 - accuracy: 0.3260 - val_loss: 0.1238 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.9831 - accuracy: 0.3260 - val_loss: 0.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9788 - accuracy: 0.3284 - val_loss: 0.1212 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 1.9845 - accuracy: 0.3259 - val_loss: 0.1269 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.9916 - accuracy: 0.3264 - val_loss: 0.1300 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 2.0035 - accuracy: 0.3203 - val_loss: 0.1244 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 1.9756 - accuracy: 0.3284 - val_loss: 0.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 1.9914 - accuracy: 0.3215 - val_loss: 0.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 1.9922 - accuracy: 0.3212 - val_loss: 0.1137 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.9677 - accuracy: 0.3287 - val_loss: 0.1174 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 74s 47ms/step - loss: 1.9668 - accuracy: 0.3329 - val_loss: 0.1159 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.9663 - accuracy: 0.3339 - val_loss: 0.1219 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.9785 - accuracy: 0.3263 - val_loss: 0.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 1.9638 - accuracy: 0.3350 - val_loss: 0.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.9795 - accuracy: 0.3336 - val_loss: 0.1236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737E3D558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737E3D558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 2.2032 - accuracy: 0.2818WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021734535DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021734535DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 76s 49ms/step - loss: 2.2032 - accuracy: 0.2818 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 71s 46ms/step - loss: 1.9634 - accuracy: 0.3412 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 78s 50ms/step - loss: 1.9321 - accuracy: 0.3539 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 77s 49ms/step - loss: 1.9057 - accuracy: 0.3660 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 1.8928 - accuracy: 0.3703 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.8870 - accuracy: 0.3704 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.8744 - accuracy: 0.3754 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.8716 - accuracy: 0.3781 - val_loss: 0.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.8594 - accuracy: 0.3803 - val_loss: 0.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.8637 - accuracy: 0.3833 - val_loss: 0.1323 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 1.8522 - accuracy: 0.3803 - val_loss: 0.1313 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 1.8364 - accuracy: 0.3887 - val_loss: 0.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 1.8474 - accuracy: 0.3866 - val_loss: 0.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 1.8486 - accuracy: 0.3850 - val_loss: 0.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.8288 - accuracy: 0.3941 - val_loss: 0.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 1.8428 - accuracy: 0.3886 - val_loss: 0.1261 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.8300 - accuracy: 0.3921 - val_loss: 0.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.8268 - accuracy: 0.3919 - val_loss: 0.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.8441 - accuracy: 0.3859 - val_loss: 0.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 1.8414 - accuracy: 0.3862 - val_loss: 0.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 1.8385 - accuracy: 0.3861 - val_loss: 0.1210 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.8252 - accuracy: 0.3893 - val_loss: 0.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 73s 46ms/step - loss: 1.8138 - accuracy: 0.3968 - val_loss: 0.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 1.8091 - accuracy: 0.3969 - val_loss: 0.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 74s 47ms/step - loss: 1.8090 - accuracy: 0.3978 - val_loss: 0.1169 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 1.8154 - accuracy: 0.3944 - val_loss: 0.1159 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.8221 - accuracy: 0.3917 - val_loss: 0.1149 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.8255 - accuracy: 0.3891 - val_loss: 0.1139 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 1.8066 - accuracy: 0.3984 - val_loss: 0.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 1.8022 - accuracy: 0.3976 - val_loss: 0.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.7992 - accuracy: 0.3982 - val_loss: 0.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7899 - accuracy: 0.4004 - val_loss: 0.1101 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.7865 - accuracy: 0.4010 - val_loss: 0.1091 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7919 - accuracy: 0.3976 - val_loss: 0.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.7897 - accuracy: 0.3982 - val_loss: 0.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 1.7908 - accuracy: 0.4002 - val_loss: 0.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7757 - accuracy: 0.4014 - val_loss: 0.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 75s 48ms/step - loss: 1.7794 - accuracy: 0.4025 - val_loss: 0.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.7579 - accuracy: 0.4105 - val_loss: 0.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.7699 - accuracy: 0.4051 - val_loss: 0.1029 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.7666 - accuracy: 0.4056 - val_loss: 0.1021 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.7716 - accuracy: 0.4050 - val_loss: 0.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 1.7646 - accuracy: 0.4049 - val_loss: 0.1005 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7602 - accuracy: 0.4073 - val_loss: 0.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 1.7656 - accuracy: 0.4080 - val_loss: 0.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.7680 - accuracy: 0.4023 - val_loss: 0.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.7629 - accuracy: 0.4076 - val_loss: 0.0974 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.7617 - accuracy: 0.4049 - val_loss: 0.0966 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 1.7530 - accuracy: 0.4089 - val_loss: 0.0959 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 1.7468 - accuracy: 0.4138 - val_loss: 0.0951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A1A3288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A1A3288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 2.0594 - accuracy: 0.2789WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172CED0F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002172CED0F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 2.0593 - accuracy: 0.2790 - val_loss: 4.1765e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 70s 44ms/step - loss: 1.8272 - accuracy: 0.3382 - val_loss: 4.1834e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 1.7820 - accuracy: 0.3608 - val_loss: 4.1902e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 63s 41ms/step - loss: 1.7658 - accuracy: 0.3646 - val_loss: 4.1978e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.7546 - accuracy: 0.3716 - val_loss: 4.2056e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.7560 - accuracy: 0.3729 - val_loss: 4.2133e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.7564 - accuracy: 0.3701 - val_loss: 4.2208e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 59s 37ms/step - loss: 1.7462 - accuracy: 0.3753 - val_loss: 4.2281e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.7548 - accuracy: 0.3706 - val_loss: 4.2352e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.7470 - accuracy: 0.3743 - val_loss: 4.2418e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 1.7434 - accuracy: 0.3755 - val_loss: 4.2480e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.7288 - accuracy: 0.3805 - val_loss: 4.2537e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.7388 - accuracy: 0.3775 - val_loss: 4.2593e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.7299 - accuracy: 0.3804 - val_loss: 4.2645e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.7376 - accuracy: 0.3802 - val_loss: 4.2702e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7054 - accuracy: 0.3864 - val_loss: 4.2750e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.7000 - accuracy: 0.3923 - val_loss: 4.2798e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.6979 - accuracy: 0.3960 - val_loss: 4.2847e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.6959 - accuracy: 0.3933 - val_loss: 4.2898e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.6824 - accuracy: 0.4022 - val_loss: 4.2942e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.6890 - accuracy: 0.3964 - val_loss: 4.2989e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 1.6924 - accuracy: 0.3962 - val_loss: 4.3036e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.6880 - accuracy: 0.3982 - val_loss: 4.3082e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.6848 - accuracy: 0.3969 - val_loss: 4.3127e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 77s 49ms/step - loss: 1.6946 - accuracy: 0.3920 - val_loss: 4.3169e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 63s 41ms/step - loss: 1.7039 - accuracy: 0.3908 - val_loss: 4.3212e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 1.6911 - accuracy: 0.3960 - val_loss: 4.3257e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.6921 - accuracy: 0.3983 - val_loss: 4.3300e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7040 - accuracy: 0.3916 - val_loss: 4.3342e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.6906 - accuracy: 0.3975 - val_loss: 4.3380e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.6866 - accuracy: 0.3991 - val_loss: 4.3420e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.6761 - accuracy: 0.4018 - val_loss: 4.3458e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.6707 - accuracy: 0.4044 - val_loss: 4.3493e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.6721 - accuracy: 0.4032 - val_loss: 4.3529e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 1.6729 - accuracy: 0.4056 - val_loss: 4.3569e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 1.6592 - accuracy: 0.4104 - val_loss: 4.3603e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.6515 - accuracy: 0.4102 - val_loss: 4.3642e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.6541 - accuracy: 0.4091 - val_loss: 4.3679e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.6471 - accuracy: 0.4108 - val_loss: 4.3714e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 1.6566 - accuracy: 0.4093 - val_loss: 4.3752e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.6663 - accuracy: 0.4037 - val_loss: 4.3789e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.6454 - accuracy: 0.4147 - val_loss: 4.3823e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 1.6495 - accuracy: 0.4148 - val_loss: 4.3858e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.6454 - accuracy: 0.4149 - val_loss: 4.3891e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 1.6396 - accuracy: 0.4159 - val_loss: 4.3928e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 59s 37ms/step - loss: 1.6473 - accuracy: 0.4113 - val_loss: 4.3961e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 1.6418 - accuracy: 0.4170 - val_loss: 4.3995e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 1.6439 - accuracy: 0.4156 - val_loss: 4.4029e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 1.6356 - accuracy: 0.4169 - val_loss: 4.4062e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.6359 - accuracy: 0.4207 - val_loss: 4.4099e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173469F1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173469F1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 111.2498 - accuracy: 0.2956WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737F32678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021737F32678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 111.0872 - accuracy: 0.2956 - val_loss: 7.5174 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 5.4374 - accuracy: 0.2810 - val_loss: 2.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.7944 - accuracy: 0.2864 - val_loss: 1.5744 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.2766 - accuracy: 0.2958 - val_loss: 1.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2019 - accuracy: 0.2960 - val_loss: 1.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0669 - accuracy: 0.3003 - val_loss: 1.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0767 - accuracy: 0.2990 - val_loss: 1.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0427 - accuracy: 0.3017 - val_loss: 1.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9892 - accuracy: 0.3018 - val_loss: 1.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.9760 - accuracy: 0.3008 - val_loss: 1.0234 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9963 - accuracy: 0.2978 - val_loss: 1.0878 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.9580 - accuracy: 0.2994 - val_loss: 1.0364 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.9334 - accuracy: 0.2995 - val_loss: 1.0172 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.9554 - accuracy: 0.3008 - val_loss: 0.9789 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9394 - accuracy: 0.3006 - val_loss: 0.9828 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.9266 - accuracy: 0.2994 - val_loss: 1.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.8719 - accuracy: 0.3026 - val_loss: 0.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.8829 - accuracy: 0.2965 - val_loss: 0.9442 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8463 - accuracy: 0.2996 - val_loss: 0.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8376 - accuracy: 0.2999 - val_loss: 0.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8406 - accuracy: 0.2978 - val_loss: 0.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9039 - accuracy: 0.2987 - val_loss: 0.9500 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.8677 - accuracy: 0.2969 - val_loss: 0.9499 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8427 - accuracy: 0.2980 - val_loss: 0.9748 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8505 - accuracy: 0.2978 - val_loss: 0.9275 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8429 - accuracy: 0.3004 - val_loss: 0.8747 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8334 - accuracy: 0.3009 - val_loss: 0.9249 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8438 - accuracy: 0.3017 - val_loss: 0.8976 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8223 - accuracy: 0.2985 - val_loss: 0.8192 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 2.8064 - accuracy: 0.3023 - val_loss: 0.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 2.8491 - accuracy: 0.3004 - val_loss: 0.8905 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.8146 - accuracy: 0.2992 - val_loss: 0.8504 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 2.8276 - accuracy: 0.2997 - val_loss: 0.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.8156 - accuracy: 0.3011 - val_loss: 0.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.8350 - accuracy: 0.3014 - val_loss: 0.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.8416 - accuracy: 0.2962 - val_loss: 0.8756 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 2.8200 - accuracy: 0.2984 - val_loss: 0.8565 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.8304 - accuracy: 0.2997 - val_loss: 0.8783 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.8436 - accuracy: 0.2982 - val_loss: 0.9464 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8030 - accuracy: 0.2987 - val_loss: 0.9039 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8291 - accuracy: 0.2998 - val_loss: 0.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.8275 - accuracy: 0.2991 - val_loss: 0.9007 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.7944 - accuracy: 0.3009 - val_loss: 0.9379 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.8019 - accuracy: 0.2987 - val_loss: 0.8076 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.7673 - accuracy: 0.3005 - val_loss: 0.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.7847 - accuracy: 0.2969 - val_loss: 0.8842 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8002 - accuracy: 0.2979 - val_loss: 0.8900 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.7753 - accuracy: 0.2973 - val_loss: 0.8323 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.7828 - accuracy: 0.2981 - val_loss: 0.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.7627 - accuracy: 0.3030 - val_loss: 0.9269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737E7F1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021737E7F1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 113.2189 - accuracy: 0.2939WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC27DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC27DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 113.0576 - accuracy: 0.2938 - val_loss: 10.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 6.1150 - accuracy: 0.2854 - val_loss: 1.9870 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.6581 - accuracy: 0.2946 - val_loss: 1.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.3290 - accuracy: 0.2978 - val_loss: 1.2302 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1572 - accuracy: 0.2982 - val_loss: 1.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0798 - accuracy: 0.3000 - val_loss: 1.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0031 - accuracy: 0.2997 - val_loss: 0.9620 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9015 - accuracy: 0.2988 - val_loss: 0.9288 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9318 - accuracy: 0.2998 - val_loss: 0.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9856 - accuracy: 0.2997 - val_loss: 0.9652 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.9051 - accuracy: 0.3020 - val_loss: 1.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9416 - accuracy: 0.3000 - val_loss: 0.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9086 - accuracy: 0.2973 - val_loss: 1.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8497 - accuracy: 0.3028 - val_loss: 0.9549 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.8651 - accuracy: 0.2998 - val_loss: 0.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8240 - accuracy: 0.3016 - val_loss: 0.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8244 - accuracy: 0.3010 - val_loss: 0.9270 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8382 - accuracy: 0.2974 - val_loss: 0.9009 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8176 - accuracy: 0.3016 - val_loss: 0.8689 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8032 - accuracy: 0.2978 - val_loss: 0.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.8215 - accuracy: 0.2967 - val_loss: 0.8219 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7680 - accuracy: 0.2996 - val_loss: 0.8410 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.7546 - accuracy: 0.2991 - val_loss: 0.8127 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7660 - accuracy: 0.3009 - val_loss: 0.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.7549 - accuracy: 0.2983 - val_loss: 0.9056 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.7436 - accuracy: 0.2973 - val_loss: 0.8834 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7401 - accuracy: 0.3000 - val_loss: 0.8168 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.7406 - accuracy: 0.2964 - val_loss: 0.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.7426 - accuracy: 0.2996 - val_loss: 0.8020 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.7380 - accuracy: 0.2988 - val_loss: 0.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.7679 - accuracy: 0.2997 - val_loss: 0.8995 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.7858 - accuracy: 0.2978 - val_loss: 0.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.7675 - accuracy: 0.2978 - val_loss: 0.7872 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.7300 - accuracy: 0.2961 - val_loss: 0.8266 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.7045 - accuracy: 0.2973 - val_loss: 0.8042 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.7311 - accuracy: 0.2967 - val_loss: 0.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.7136 - accuracy: 0.2956 - val_loss: 0.7833 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.7055 - accuracy: 0.3018 - val_loss: 0.7615 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7212 - accuracy: 0.2943 - val_loss: 0.8721 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.7213 - accuracy: 0.2984 - val_loss: 0.7498 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.6803 - accuracy: 0.2976 - val_loss: 0.7507 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.6845 - accuracy: 0.2995 - val_loss: 0.7784 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.6928 - accuracy: 0.2990 - val_loss: 0.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.6928 - accuracy: 0.2999 - val_loss: 0.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.7098 - accuracy: 0.2985 - val_loss: 0.7260 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.6991 - accuracy: 0.2992 - val_loss: 0.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.7131 - accuracy: 0.2998 - val_loss: 0.7982 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.7072 - accuracy: 0.2959 - val_loss: 0.7526 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.6525 - accuracy: 0.2994 - val_loss: 0.7461 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.6856 - accuracy: 0.2982 - val_loss: 0.8254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A30BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A30BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 113.1861 - accuracy: 0.2954 ETA: 0s - loss: 115.0276 - accuracyWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB5F4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB5F4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 23s 59ms/step - loss: 113.0245 - accuracy: 0.2954 - val_loss: 10.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 6.1188 - accuracy: 0.2836 - val_loss: 2.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.6572 - accuracy: 0.2918 - val_loss: 1.3794 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 3.2413 - accuracy: 0.2984 - val_loss: 1.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 3.1634 - accuracy: 0.2962 - val_loss: 1.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 3.1193 - accuracy: 0.2936 - val_loss: 1.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 21s 52ms/step - loss: 3.0635 - accuracy: 0.2979 - val_loss: 1.1656 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 2.9730 - accuracy: 0.3006 - val_loss: 1.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.9114 - accuracy: 0.3015 - val_loss: 0.9580 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8914 - accuracy: 0.3045 - val_loss: 1.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.9158 - accuracy: 0.3012 - val_loss: 0.9425 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 2.8598 - accuracy: 0.3008 - val_loss: 0.9468 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 2.8958 - accuracy: 0.2986 - val_loss: 1.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 2.8733 - accuracy: 0.2977 - val_loss: 0.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 2.8815 - accuracy: 0.2997 - val_loss: 0.9489 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 2.9202 - accuracy: 0.3023 - val_loss: 0.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 2.9001 - accuracy: 0.3023 - val_loss: 0.9581 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 2.8507 - accuracy: 0.3028 - val_loss: 0.9451 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 2.8572 - accuracy: 0.3032 - val_loss: 0.9693 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 2.8388 - accuracy: 0.2998 - val_loss: 0.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 2.8380 - accuracy: 0.3028 - val_loss: 0.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 2.8189 - accuracy: 0.2985 - val_loss: 0.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 2.8408 - accuracy: 0.3026 - val_loss: 0.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 2.8408 - accuracy: 0.3014 - val_loss: 1.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 2.8628 - accuracy: 0.3023 - val_loss: 0.9361 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 2.8301 - accuracy: 0.2990 - val_loss: 0.8619 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 2.7827 - accuracy: 0.3025 - val_loss: 0.8388 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 2.8400 - accuracy: 0.2988 - val_loss: 0.8745 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 2.7930 - accuracy: 0.3028 - val_loss: 0.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.7880 - accuracy: 0.3024 - val_loss: 0.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 2.8125 - accuracy: 0.3020 - val_loss: 0.9647 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 2.8318 - accuracy: 0.3018 - val_loss: 0.8754 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.8661 - accuracy: 0.3011 - val_loss: 0.8936 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 2.8289 - accuracy: 0.2998 - val_loss: 0.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 2.8048 - accuracy: 0.3015 - val_loss: 0.8679 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 2.8282 - accuracy: 0.3029 - val_loss: 0.8823 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8067 - accuracy: 0.3046 - val_loss: 0.8863 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.7698 - accuracy: 0.3014 - val_loss: 0.8020 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.7310 - accuracy: 0.3053 - val_loss: 0.8397 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 2.7791 - accuracy: 0.3032 - val_loss: 0.9003 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.7736 - accuracy: 0.3049 - val_loss: 0.9526 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.7874 - accuracy: 0.3030 - val_loss: 0.8871 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8116 - accuracy: 0.2982 - val_loss: 0.9452 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.7957 - accuracy: 0.2986 - val_loss: 0.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8028 - accuracy: 0.3012 - val_loss: 0.8651 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.8002 - accuracy: 0.3002 - val_loss: 0.8547 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.7670 - accuracy: 0.3035 - val_loss: 0.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.8126 - accuracy: 0.3019 - val_loss: 0.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.7652 - accuracy: 0.3028 - val_loss: 0.8862 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.7536 - accuracy: 0.2994 - val_loss: 0.8322 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB5F798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB5F798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 17.4825 - accuracy: 0.3440WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB90168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB90168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 17.4787 - accuracy: 0.3439 - val_loss: 13.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 12.9250 - accuracy: 0.4237 - val_loss: 9.5544 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 9.7006 - accuracy: 0.4543 - val_loss: 6.8967 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 7.3848 - accuracy: 0.4659 - val_loss: 4.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 5.7142 - accuracy: 0.4732 - val_loss: 3.5745 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 4.5034 - accuracy: 0.4821 - val_loss: 2.5666 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 3.6417 - accuracy: 0.4815 - val_loss: 1.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.0282 - accuracy: 0.4798 - val_loss: 1.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 2.5845 - accuracy: 0.4788 - val_loss: 0.9570 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.2579 - accuracy: 0.4868 - val_loss: 0.6937 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.0426 - accuracy: 0.4841 - val_loss: 0.5182 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8907 - accuracy: 0.4872 - val_loss: 0.3997 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7874 - accuracy: 0.4901 - val_loss: 0.3233 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7321 - accuracy: 0.4888 - val_loss: 0.2853 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6985 - accuracy: 0.4914 - val_loss: 0.2717 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6880 - accuracy: 0.4920 - val_loss: 0.2632 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6645 - accuracy: 0.4956 - val_loss: 0.2569 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6728 - accuracy: 0.4949 - val_loss: 0.2618 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6796 - accuracy: 0.4910 - val_loss: 0.2592 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.6795 - accuracy: 0.4899 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6771 - accuracy: 0.4927 - val_loss: 0.2582 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6546 - accuracy: 0.4997 - val_loss: 0.2542 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.6475 - accuracy: 0.5004 - val_loss: 0.2523 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6432 - accuracy: 0.5034 - val_loss: 0.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 1.6417 - accuracy: 0.5015 - val_loss: 0.2509 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6379 - accuracy: 0.5018 - val_loss: 0.2518 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6578 - accuracy: 0.4997 - val_loss: 0.2549 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.6526 - accuracy: 0.5016 - val_loss: 0.2564 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6422 - accuracy: 0.5043 - val_loss: 0.2556 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6483 - accuracy: 0.5031 - val_loss: 0.2579 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.6307 - accuracy: 0.5080 - val_loss: 0.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6232 - accuracy: 0.5121 - val_loss: 0.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6351 - accuracy: 0.5045 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6302 - accuracy: 0.5095 - val_loss: 0.2567 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6368 - accuracy: 0.5088 - val_loss: 0.2604 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.6465 - accuracy: 0.5041 - val_loss: 0.2639 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.6318 - accuracy: 0.5122 - val_loss: 0.2601 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.6392 - accuracy: 0.5083 - val_loss: 0.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.6463 - accuracy: 0.5050 - val_loss: 0.2638 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.6388 - accuracy: 0.5073 - val_loss: 0.2605 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6377 - accuracy: 0.5099 - val_loss: 0.2608 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6375 - accuracy: 0.5081 - val_loss: 0.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6268 - accuracy: 0.5103 - val_loss: 0.2602 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.6258 - accuracy: 0.5118 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6346 - accuracy: 0.5088 - val_loss: 0.2629 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.6346 - accuracy: 0.5095 - val_loss: 0.2610 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.6296 - accuracy: 0.5095 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.6231 - accuracy: 0.5105 - val_loss: 0.2573 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6270 - accuracy: 0.5121 - val_loss: 0.2625 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6300 - accuracy: 0.5126 - val_loss: 0.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB5FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB5FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 5.9863 - accuracy: 0.3425WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC97828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC97828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.9860 - accuracy: 0.3425 - val_loss: 4.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 5.5649 - accuracy: 0.4263 - val_loss: 3.8670 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.3396 - accuracy: 0.4554 - val_loss: 3.7287 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 5.1502 - accuracy: 0.4692 - val_loss: 3.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.9777 - accuracy: 0.4880 - val_loss: 3.4611 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.8190 - accuracy: 0.4943 - val_loss: 3.3323 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.6695 - accuracy: 0.5037 - val_loss: 3.2066 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 4.5303 - accuracy: 0.5076 - val_loss: 3.0837 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 4.3877 - accuracy: 0.5138 - val_loss: 2.9638 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.2517 - accuracy: 0.5182 - val_loss: 2.8469 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 4.1281 - accuracy: 0.5212 - val_loss: 2.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.0069 - accuracy: 0.5241 - val_loss: 2.6233 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.8862 - accuracy: 0.5324 - val_loss: 2.5152 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.7823 - accuracy: 0.5313 - val_loss: 2.4113 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 3.6728 - accuracy: 0.5337 - val_loss: 2.3107 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 3.5738 - accuracy: 0.5330 - val_loss: 2.2130 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 3.4703 - accuracy: 0.5343 - val_loss: 2.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 3.3638 - accuracy: 0.5358 - val_loss: 2.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 3.2743 - accuracy: 0.5353 - val_loss: 1.9347 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 3.1801 - accuracy: 0.5367 - val_loss: 1.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0854 - accuracy: 0.5415 - val_loss: 1.7632 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 3.0082 - accuracy: 0.5391 - val_loss: 1.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 2.9274 - accuracy: 0.5397 - val_loss: 1.6053 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 2.8463 - accuracy: 0.5416 - val_loss: 1.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.7727 - accuracy: 0.5413 - val_loss: 1.4583 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.6888 - accuracy: 0.5496 - val_loss: 1.3876 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.6047 - accuracy: 0.5513 - val_loss: 1.3200 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 2.5314 - accuracy: 0.5550 - val_loss: 1.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 24s 63ms/step - loss: 2.4668 - accuracy: 0.5560 - val_loss: 1.1940 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.4218 - accuracy: 0.5506 - val_loss: 1.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.3554 - accuracy: 0.5555 - val_loss: 1.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.3031 - accuracy: 0.5514 - val_loss: 1.0286 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.2601 - accuracy: 0.5512 - val_loss: 0.9798 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.1987 - accuracy: 0.5564 - val_loss: 0.9331 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1412 - accuracy: 0.5592 - val_loss: 0.8881 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0893 - accuracy: 0.5614 - val_loss: 0.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 2.0659 - accuracy: 0.5549 - val_loss: 0.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 2.0251 - accuracy: 0.5578 - val_loss: 0.7705 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.9694 - accuracy: 0.5638 - val_loss: 0.7346 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9385 - accuracy: 0.5641 - val_loss: 0.7040 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9150 - accuracy: 0.5595 - val_loss: 0.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.8880 - accuracy: 0.5620 - val_loss: 0.6481 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.8767 - accuracy: 0.5574 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8293 - accuracy: 0.5639 - val_loss: 0.5999 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.7983 - accuracy: 0.5684 - val_loss: 0.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 19s 48ms/step - loss: 1.7778 - accuracy: 0.5705 - val_loss: 0.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.7547 - accuracy: 0.5689 - val_loss: 0.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.7274 - accuracy: 0.5746 - val_loss: 0.5271 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.7064 - accuracy: 0.5754 - val_loss: 0.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.7052 - accuracy: 0.5720 - val_loss: 0.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217342EC678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217342EC678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 5.8485 - accuracy: 0.3419WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173469F0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173469F0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.8485 - accuracy: 0.3419 - val_loss: 3.8810 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 5.4514 - accuracy: 0.4206 - val_loss: 3.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 5.2296 - accuracy: 0.4517 - val_loss: 3.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 5.0548 - accuracy: 0.4703 - val_loss: 3.5003 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 4.8902 - accuracy: 0.4855 - val_loss: 3.3790 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.7446 - accuracy: 0.4915 - val_loss: 3.2604 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.6084 - accuracy: 0.5003 - val_loss: 3.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.4655 - accuracy: 0.5108 - val_loss: 3.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.3289 - accuracy: 0.5172 - val_loss: 2.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.2122 - accuracy: 0.5190 - val_loss: 2.8106 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.0899 - accuracy: 0.5248 - val_loss: 2.7052 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.9739 - accuracy: 0.5292 - val_loss: 2.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.8645 - accuracy: 0.5312 - val_loss: 2.5024 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.7561 - accuracy: 0.5361 - val_loss: 2.4042 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 3.6399 - accuracy: 0.5430 - val_loss: 2.3094 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.5509 - accuracy: 0.5412 - val_loss: 2.2172 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.4543 - accuracy: 0.5414 - val_loss: 2.1285 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.3623 - accuracy: 0.5458 - val_loss: 2.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.2656 - accuracy: 0.5470 - val_loss: 1.9562 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1855 - accuracy: 0.5460 - val_loss: 1.8745 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0937 - accuracy: 0.5530 - val_loss: 1.7952 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.0168 - accuracy: 0.5516 - val_loss: 1.7194 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9439 - accuracy: 0.5489 - val_loss: 1.6449 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8756 - accuracy: 0.5494 - val_loss: 1.5741 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8012 - accuracy: 0.5486 - val_loss: 1.5057 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7483 - accuracy: 0.5423 - val_loss: 1.4405 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.6854 - accuracy: 0.5443 - val_loss: 1.3765 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.6133 - accuracy: 0.5483 - val_loss: 1.3143 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.5351 - accuracy: 0.5510 - val_loss: 1.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.4825 - accuracy: 0.5527 - val_loss: 1.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.4214 - accuracy: 0.5516 - val_loss: 1.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.3515 - accuracy: 0.5585 - val_loss: 1.0895 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.3004 - accuracy: 0.5579 - val_loss: 1.0394 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.2360 - accuracy: 0.5637 - val_loss: 0.9927 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.2090 - accuracy: 0.5569 - val_loss: 0.9497 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.1508 - accuracy: 0.5628 - val_loss: 0.9070 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.1113 - accuracy: 0.5620 - val_loss: 0.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 45ms/step - loss: 2.0684 - accuracy: 0.5637 - val_loss: 0.8305 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0387 - accuracy: 0.5630 - val_loss: 0.7977 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.0067 - accuracy: 0.5606 - val_loss: 0.7644 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.9658 - accuracy: 0.5642 - val_loss: 0.7355 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.9425 - accuracy: 0.5634 - val_loss: 0.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8999 - accuracy: 0.5691 - val_loss: 0.6791 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8758 - accuracy: 0.5670 - val_loss: 0.6538 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.8579 - accuracy: 0.5649 - val_loss: 0.6315 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.8224 - accuracy: 0.5708 - val_loss: 0.6092 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.7952 - accuracy: 0.5735 - val_loss: 0.5898 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.7810 - accuracy: 0.5723 - val_loss: 0.5740 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.7582 - accuracy: 0.5727 - val_loss: 0.5579 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.7382 - accuracy: 0.5743 - val_loss: 0.5461 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A1A3A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A1A3A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 14.0842 - accuracy: 0.3402WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A33A0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A33A0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 14.0842 - accuracy: 0.3402 - val_loss: 10.3695 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 10.5480 - accuracy: 0.4211 - val_loss: 7.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 8.0791 - accuracy: 0.4482 - val_loss: 5.5644 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 6.2816 - accuracy: 0.4699 - val_loss: 4.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.9959 - accuracy: 0.4797 - val_loss: 3.0214 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 4.0542 - accuracy: 0.4854 - val_loss: 2.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.3803 - accuracy: 0.4862 - val_loss: 1.6798 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.8955 - accuracy: 0.4886 - val_loss: 1.2702 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.5275 - accuracy: 0.4948 - val_loss: 0.9703 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2551 - accuracy: 0.5017 - val_loss: 0.7517 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.0701 - accuracy: 0.4972 - val_loss: 0.5940 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.9164 - accuracy: 0.5055 - val_loss: 0.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8261 - accuracy: 0.5040 - val_loss: 0.3949 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7534 - accuracy: 0.5026 - val_loss: 0.3339 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.6815 - accuracy: 0.5079 - val_loss: 0.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6408 - accuracy: 0.5082 - val_loss: 0.2574 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.6125 - accuracy: 0.5129 - val_loss: 0.2337 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.5944 - accuracy: 0.5108 - val_loss: 0.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5815 - accuracy: 0.5101 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5551 - accuracy: 0.5133 - val_loss: 0.1944 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5339 - accuracy: 0.5198 - val_loss: 0.1867 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5277 - accuracy: 0.5178 - val_loss: 0.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5327 - accuracy: 0.5173 - val_loss: 0.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5349 - accuracy: 0.5141 - val_loss: 0.1773 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5117 - accuracy: 0.5216 - val_loss: 0.1743 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.5051 - accuracy: 0.5230 - val_loss: 0.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5196 - accuracy: 0.5172 - val_loss: 0.1741 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5020 - accuracy: 0.5263 - val_loss: 0.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5111 - accuracy: 0.5244 - val_loss: 0.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5120 - accuracy: 0.5221 - val_loss: 0.1756 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.5033 - accuracy: 0.5275 - val_loss: 0.1745 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.4947 - accuracy: 0.5275 - val_loss: 0.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4854 - accuracy: 0.5309 - val_loss: 0.1753 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4936 - accuracy: 0.5296 - val_loss: 0.1761 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4814 - accuracy: 0.5337 - val_loss: 0.1751 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4972 - accuracy: 0.5283 - val_loss: 0.1767 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5112 - accuracy: 0.5233 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5121 - accuracy: 0.5244 - val_loss: 0.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5037 - accuracy: 0.5255 - val_loss: 0.1788 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4951 - accuracy: 0.5293 - val_loss: 0.1782 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4936 - accuracy: 0.5305 - val_loss: 0.1784 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4900 - accuracy: 0.5300 - val_loss: 0.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4839 - accuracy: 0.5339 - val_loss: 0.1789 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4885 - accuracy: 0.5338 - val_loss: 0.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4929 - accuracy: 0.5294 - val_loss: 0.1799 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.4965 - accuracy: 0.5283 - val_loss: 0.1809 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.4938 - accuracy: 0.5304 - val_loss: 0.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4788 - accuracy: 0.5354 - val_loss: 0.1813 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4831 - accuracy: 0.5340 - val_loss: 0.1815 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.4778 - accuracy: 0.5348 - val_loss: 0.1810 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174ABEF288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174ABEF288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.0373 - accuracy: 0.3468WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FB358B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FB358B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.0369 - accuracy: 0.3469 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7736 - accuracy: 0.4235 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6809 - accuracy: 0.4539 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.6324 - accuracy: 0.4721 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.5866 - accuracy: 0.4850 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.5495 - accuracy: 0.4998 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5205 - accuracy: 0.5070 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.4973 - accuracy: 0.5141 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4784 - accuracy: 0.5242 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4585 - accuracy: 0.5297 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4447 - accuracy: 0.5363 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4354 - accuracy: 0.5399 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4178 - accuracy: 0.5457 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4004 - accuracy: 0.5508 - val_loss: 0.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.3837 - accuracy: 0.5558 - val_loss: 0.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3706 - accuracy: 0.5650 - val_loss: 0.1364 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.3573 - accuracy: 0.5644 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.3474 - accuracy: 0.5697 - val_loss: 0.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.3356 - accuracy: 0.5721 - val_loss: 0.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.3230 - accuracy: 0.5765 - val_loss: 0.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.3241 - accuracy: 0.5787 - val_loss: 0.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3170 - accuracy: 0.5773 - val_loss: 0.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.3117 - accuracy: 0.5788 - val_loss: 0.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.2968 - accuracy: 0.5854 - val_loss: 0.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.2881 - accuracy: 0.5902 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2865 - accuracy: 0.5896 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2793 - accuracy: 0.5924 - val_loss: 0.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2697 - accuracy: 0.5950 - val_loss: 0.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2554 - accuracy: 0.5992 - val_loss: 0.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2453 - accuracy: 0.6034 - val_loss: 0.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2489 - accuracy: 0.6002 - val_loss: 0.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2406 - accuracy: 0.6053 - val_loss: 0.1339 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2295 - accuracy: 0.6102 - val_loss: 0.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2299 - accuracy: 0.6069 - val_loss: 0.1336 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.2262 - accuracy: 0.6113 - val_loss: 0.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.2266 - accuracy: 0.6089 - val_loss: 0.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2202 - accuracy: 0.6109 - val_loss: 0.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2155 - accuracy: 0.6119 - val_loss: 0.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 1.1973 - accuracy: 0.6180 - val_loss: 0.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.1890 - accuracy: 0.6222 - val_loss: 0.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.1862 - accuracy: 0.6231 - val_loss: 0.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1910 - accuracy: 0.6216 - val_loss: 0.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.1940 - accuracy: 0.6190 - val_loss: 0.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.1886 - accuracy: 0.6231 - val_loss: 0.1325 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.1861 - accuracy: 0.6235 - val_loss: 0.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.1704 - accuracy: 0.6283 - val_loss: 0.1323 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.1573 - accuracy: 0.6322 - val_loss: 0.1322 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.1599 - accuracy: 0.6321 - val_loss: 0.1321 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.1541 - accuracy: 0.6353 - val_loss: 0.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.1652 - accuracy: 0.6253 - val_loss: 0.1319 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173A90D708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173A90D708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.9174 - accuracy: 0.3397WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730EB7B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730EB7B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9172 - accuracy: 0.3397 - val_loss: 4.1470e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6307 - accuracy: 0.4220 - val_loss: 4.1489e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5458 - accuracy: 0.4532 - val_loss: 4.1505e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4859 - accuracy: 0.4743 - val_loss: 4.1522e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4418 - accuracy: 0.4858 - val_loss: 4.1537e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4114 - accuracy: 0.4986 - val_loss: 4.1554e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.3877 - accuracy: 0.5070 - val_loss: 4.1572e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3609 - accuracy: 0.5150 - val_loss: 4.1591e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3367 - accuracy: 0.5223 - val_loss: 4.1609e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3173 - accuracy: 0.5324 - val_loss: 4.1628e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3008 - accuracy: 0.5336 - val_loss: 4.1648e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2886 - accuracy: 0.5402 - val_loss: 4.1669e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 45ms/step - loss: 1.2710 - accuracy: 0.5466 - val_loss: 4.1690e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2617 - accuracy: 0.5475 - val_loss: 4.1713e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2413 - accuracy: 0.5574 - val_loss: 4.1733e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2302 - accuracy: 0.5620 - val_loss: 4.1754e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2154 - accuracy: 0.5685 - val_loss: 4.1776e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2085 - accuracy: 0.5701 - val_loss: 4.1801e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2014 - accuracy: 0.5736 - val_loss: 4.1825e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2035 - accuracy: 0.5671 - val_loss: 4.1848e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.1796 - accuracy: 0.5775 - val_loss: 4.1873e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1675 - accuracy: 0.5822 - val_loss: 4.1898e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.1602 - accuracy: 0.5848 - val_loss: 4.1924e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1565 - accuracy: 0.5870 - val_loss: 4.1950e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1504 - accuracy: 0.5906 - val_loss: 4.1978e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.1369 - accuracy: 0.5947 - val_loss: 4.2004e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.1311 - accuracy: 0.5974 - val_loss: 4.2031e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.1198 - accuracy: 0.5993 - val_loss: 4.2059e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.1190 - accuracy: 0.5973 - val_loss: 4.2088e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.1225 - accuracy: 0.5980 - val_loss: 4.2117e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1143 - accuracy: 0.6002 - val_loss: 4.2146e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0992 - accuracy: 0.6082 - val_loss: 4.2174e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0931 - accuracy: 0.6106 - val_loss: 4.2202e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.0843 - accuracy: 0.6121 - val_loss: 4.2232e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0748 - accuracy: 0.6153 - val_loss: 4.2263e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0728 - accuracy: 0.6130 - val_loss: 4.2295e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.0640 - accuracy: 0.6196 - val_loss: 4.2324e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0673 - accuracy: 0.6184 - val_loss: 4.2355e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.0600 - accuracy: 0.6194 - val_loss: 4.2387e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0552 - accuracy: 0.6213 - val_loss: 4.2418e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.0398 - accuracy: 0.6262 - val_loss: 4.2448e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0404 - accuracy: 0.6289 - val_loss: 4.2480e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0268 - accuracy: 0.6341 - val_loss: 4.2513e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0236 - accuracy: 0.6333 - val_loss: 4.2545e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.0171 - accuracy: 0.6344 - val_loss: 4.2579e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0250 - accuracy: 0.6317 - val_loss: 4.2613e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.0031 - accuracy: 0.6410 - val_loss: 4.2645e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0008 - accuracy: 0.6414 - val_loss: 4.2679e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.9930 - accuracy: 0.6435 - val_loss: 4.2711e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.9880 - accuracy: 0.6456 - val_loss: 4.2746e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173AA6AEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002173AA6AEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 111.6225 - accuracy: 0.2689WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB5FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB5FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 111.4607 - accuracy: 0.2689 - val_loss: 8.2301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 5.8481 - accuracy: 0.2651 - val_loss: 2.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.8717 - accuracy: 0.2740 - val_loss: 1.5667 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 3.4053 - accuracy: 0.2830 - val_loss: 1.2878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.2689 - accuracy: 0.2829 - val_loss: 1.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.2015 - accuracy: 0.2809 - val_loss: 1.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1743 - accuracy: 0.2786 - val_loss: 1.2184 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1472 - accuracy: 0.2814 - val_loss: 1.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1092 - accuracy: 0.2799 - val_loss: 1.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0887 - accuracy: 0.2820 - val_loss: 1.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0536 - accuracy: 0.2829 - val_loss: 1.0546 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1037 - accuracy: 0.2788 - val_loss: 1.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0830 - accuracy: 0.2810 - val_loss: 1.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0434 - accuracy: 0.2830 - val_loss: 1.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0551 - accuracy: 0.2818 - val_loss: 1.0654 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0052 - accuracy: 0.2814 - val_loss: 0.9916 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0087 - accuracy: 0.2868 - val_loss: 1.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0338 - accuracy: 0.2827 - val_loss: 1.1480 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0390 - accuracy: 0.2819 - val_loss: 1.1135 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0456 - accuracy: 0.2818 - val_loss: 1.1068 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0163 - accuracy: 0.2823 - val_loss: 1.0921 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0634 - accuracy: 0.2816 - val_loss: 0.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0010 - accuracy: 0.2868 - val_loss: 1.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0499 - accuracy: 0.2826 - val_loss: 0.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0071 - accuracy: 0.2816 - val_loss: 1.0284 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0352 - accuracy: 0.2813 - val_loss: 1.1018 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0544 - accuracy: 0.2822 - val_loss: 1.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0288 - accuracy: 0.2864 - val_loss: 1.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0090 - accuracy: 0.2801 - val_loss: 1.0426 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9863 - accuracy: 0.2869 - val_loss: 0.9979 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9612 - accuracy: 0.2868 - val_loss: 1.0252 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9867 - accuracy: 0.2797 - val_loss: 1.0910 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9790 - accuracy: 0.2864 - val_loss: 1.0182 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9665 - accuracy: 0.2825 - val_loss: 1.0501 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.9768 - accuracy: 0.2842 - val_loss: 0.9640 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9719 - accuracy: 0.2801 - val_loss: 0.9989 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.9798 - accuracy: 0.2830 - val_loss: 0.9971 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9555 - accuracy: 0.2835 - val_loss: 0.9408 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9318 - accuracy: 0.2818 - val_loss: 1.0265 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0061 - accuracy: 0.2796 - val_loss: 1.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9443 - accuracy: 0.2841 - val_loss: 1.0269 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.9842 - accuracy: 0.2858 - val_loss: 1.0548 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9414 - accuracy: 0.2849 - val_loss: 0.9474 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9387 - accuracy: 0.2849 - val_loss: 0.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9276 - accuracy: 0.2838 - val_loss: 0.9233 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9368 - accuracy: 0.2823 - val_loss: 0.9837 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9308 - accuracy: 0.2889 - val_loss: 0.9703 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9295 - accuracy: 0.2805 - val_loss: 0.9279 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9258 - accuracy: 0.2833 - val_loss: 0.9477 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9104 - accuracy: 0.2844 - val_loss: 0.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB851F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB851F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 113.7774 - accuracy: 0.2682WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A316828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A316828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 113.6156 - accuracy: 0.2681 - val_loss: 10.6123 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 6.8018 - accuracy: 0.2670 - val_loss: 2.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.9881 - accuracy: 0.2724 - val_loss: 1.5845 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.3988 - accuracy: 0.2827 - val_loss: 1.3113 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2235 - accuracy: 0.2779 - val_loss: 1.2507 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1684 - accuracy: 0.2828 - val_loss: 1.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1391 - accuracy: 0.2823 - val_loss: 1.1030 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0869 - accuracy: 0.2823 - val_loss: 1.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1322 - accuracy: 0.2805 - val_loss: 1.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0634 - accuracy: 0.2831 - val_loss: 1.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0527 - accuracy: 0.2813 - val_loss: 1.0525 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0748 - accuracy: 0.2792 - val_loss: 1.0411 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0751 - accuracy: 0.2834 - val_loss: 1.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0577 - accuracy: 0.2805 - val_loss: 1.0438 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0404 - accuracy: 0.2851 - val_loss: 1.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0044 - accuracy: 0.2865 - val_loss: 1.0440 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0022 - accuracy: 0.2874 - val_loss: 1.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9889 - accuracy: 0.2852 - val_loss: 1.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0370 - accuracy: 0.2829 - val_loss: 1.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0325 - accuracy: 0.2847 - val_loss: 1.0921 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9895 - accuracy: 0.2843 - val_loss: 1.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9827 - accuracy: 0.2832 - val_loss: 1.0849 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.0183 - accuracy: 0.2840 - val_loss: 1.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9772 - accuracy: 0.2859 - val_loss: 0.9993 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9631 - accuracy: 0.2829 - val_loss: 0.9877 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9408 - accuracy: 0.2867 - val_loss: 1.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9603 - accuracy: 0.2852 - val_loss: 0.9537 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9661 - accuracy: 0.2861 - val_loss: 0.9622 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9607 - accuracy: 0.2875 - val_loss: 1.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9599 - accuracy: 0.2854 - val_loss: 0.9402 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.9387 - accuracy: 0.2856 - val_loss: 0.9516 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9540 - accuracy: 0.2808 - val_loss: 0.9614 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9716 - accuracy: 0.2851 - val_loss: 1.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 2.9647 - accuracy: 0.2805 - val_loss: 0.9955 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 2.9453 - accuracy: 0.2837 - val_loss: 0.9754 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.9207 - accuracy: 0.2863 - val_loss: 0.9335 - val_accuracy: 0.0000e+00: 4s - los - ETA: 2s - loss: 2.9115 - accura - ETA: 0s - loss: 2.9200 - ac\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9487 - accuracy: 0.2845 - val_loss: 1.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.9589 - accuracy: 0.2824 - val_loss: 0.9439 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.9691 - accuracy: 0.2829 - val_loss: 0.9695 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 2.9296 - accuracy: 0.2829 - val_loss: 0.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 2.8956 - accuracy: 0.2877 - val_loss: 0.9808 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9419 - accuracy: 0.2807 - val_loss: 0.9706 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 2.9341 - accuracy: 0.2850 - val_loss: 0.9789 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.9236 - accuracy: 0.2864 - val_loss: 0.9799 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.9538 - accuracy: 0.2832 - val_loss: 1.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9650 - accuracy: 0.2820 - val_loss: 1.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9533 - accuracy: 0.2821 - val_loss: 0.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.9557 - accuracy: 0.2847 - val_loss: 1.0394 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.9542 - accuracy: 0.2821 - val_loss: 0.9011 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9497 - accuracy: 0.2811 - val_loss: 0.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A5BDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A5BDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 113.2713 - accuracy: 0.2657WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FDE7438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FDE7438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 113.2713 - accuracy: 0.2657 - val_loss: 10.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 6.6602 - accuracy: 0.2716 - val_loss: 2.3799 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.9763 - accuracy: 0.2792 - val_loss: 1.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.3813 - accuracy: 0.2828 - val_loss: 1.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.2978 - accuracy: 0.2836 - val_loss: 1.2820 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.2983 - accuracy: 0.2830 - val_loss: 1.3143 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1783 - accuracy: 0.2844 - val_loss: 1.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1323 - accuracy: 0.2849 - val_loss: 1.2186 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1450 - accuracy: 0.2859 - val_loss: 1.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1074 - accuracy: 0.2819 - val_loss: 1.1829 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0840 - accuracy: 0.2839 - val_loss: 1.1034 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0684 - accuracy: 0.2848 - val_loss: 1.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0854 - accuracy: 0.2827 - val_loss: 1.0619 - val_accuracy: 0.0000e+00oss: 3.0\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0957 - accuracy: 0.2839 - val_loss: 1.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0719 - accuracy: 0.2837 - val_loss: 1.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0840 - accuracy: 0.2838 - val_loss: 1.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0497 - accuracy: 0.2839 - val_loss: 1.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.0934 - accuracy: 0.2836 - val_loss: 1.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0591 - accuracy: 0.2857 - val_loss: 1.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0575 - accuracy: 0.2821 - val_loss: 1.0510 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0184 - accuracy: 0.2847 - val_loss: 1.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 3.0290 - accuracy: 0.2848 - val_loss: 1.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.9853 - accuracy: 0.2881 - val_loss: 1.0284 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0044 - accuracy: 0.2866 - val_loss: 1.0664 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0070 - accuracy: 0.2827 - val_loss: 1.0251 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0185 - accuracy: 0.2865 - val_loss: 1.0844 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9982 - accuracy: 0.2825 - val_loss: 1.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0120 - accuracy: 0.2831 - val_loss: 1.1679 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0482 - accuracy: 0.2838 - val_loss: 1.0468 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9925 - accuracy: 0.2876 - val_loss: 0.9613 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 2.9763 - accuracy: 0.2838 - val_loss: 1.0775 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 3.0251 - accuracy: 0.2847 - val_loss: 1.0479 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 2.9904 - accuracy: 0.2835 - val_loss: 1.0315 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 3.0097 - accuracy: 0.2850 - val_loss: 1.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9764 - accuracy: 0.2807 - val_loss: 1.0266 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9575 - accuracy: 0.2808 - val_loss: 1.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 2.9665 - accuracy: 0.2838 - val_loss: 1.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 22s 58ms/step - loss: 2.9735 - accuracy: 0.2816 - val_loss: 0.9926 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 2.9406 - accuracy: 0.2856 - val_loss: 0.9277 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.9412 - accuracy: 0.2830 - val_loss: 0.9857 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 2.9847 - accuracy: 0.2845 - val_loss: 1.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.9781 - accuracy: 0.2826 - val_loss: 0.9494 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.9822 - accuracy: 0.2818 - val_loss: 0.9829 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.9697 - accuracy: 0.2838 - val_loss: 1.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9154 - accuracy: 0.2827 - val_loss: 0.9533 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 47ms/step - loss: 2.9219 - accuracy: 0.2811 - val_loss: 1.0143 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.9597 - accuracy: 0.2831 - val_loss: 1.0246 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9454 - accuracy: 0.2831 - val_loss: 1.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.9552 - accuracy: 0.2812 - val_loss: 0.9365 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.9429 - accuracy: 0.2792 - val_loss: 0.9647 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FFB4438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FFB4438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 17.6215 - accuracy: 0.3105WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173AA6AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002173AA6AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 17.6172 - accuracy: 0.3107 - val_loss: 13.2185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 13.0281 - accuracy: 0.3891 - val_loss: 9.5578 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 9.7937 - accuracy: 0.4194 - val_loss: 6.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 7.4692 - accuracy: 0.4304 - val_loss: 4.9584 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 5.7816 - accuracy: 0.4438 - val_loss: 3.5582 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 4.5847 - accuracy: 0.4417 - val_loss: 2.5479 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 3.7323 - accuracy: 0.4412 - val_loss: 1.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 3.1005 - accuracy: 0.4422 - val_loss: 1.2949 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 2.6405 - accuracy: 0.4473 - val_loss: 0.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 2.3464 - accuracy: 0.4413 - val_loss: 0.6611 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 2.1243 - accuracy: 0.4405 - val_loss: 0.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.9677 - accuracy: 0.4477 - val_loss: 0.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.8686 - accuracy: 0.4470 - val_loss: 0.2897 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 1.8205 - accuracy: 0.4444 - val_loss: 0.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 1.7855 - accuracy: 0.4509 - val_loss: 0.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 1.7633 - accuracy: 0.4545 - val_loss: 0.2363 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.7467 - accuracy: 0.4609 - val_loss: 0.2333 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.7671 - accuracy: 0.4534 - val_loss: 0.2410 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.7792 - accuracy: 0.4510 - val_loss: 0.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.7668 - accuracy: 0.4542 - val_loss: 0.2408 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.7697 - accuracy: 0.4524 - val_loss: 0.2429 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7633 - accuracy: 0.4575 - val_loss: 0.2412 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.7550 - accuracy: 0.4577 - val_loss: 0.2401 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.7542 - accuracy: 0.4595 - val_loss: 0.2405 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.7441 - accuracy: 0.4606 - val_loss: 0.2377 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 1.7458 - accuracy: 0.4603 - val_loss: 0.2433 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7432 - accuracy: 0.4622 - val_loss: 0.2397 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7316 - accuracy: 0.4636 - val_loss: 0.2366 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.7299 - accuracy: 0.4678 - val_loss: 0.2383 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.7425 - accuracy: 0.4653 - val_loss: 0.2382 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.7499 - accuracy: 0.4594 - val_loss: 0.2434 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7312 - accuracy: 0.4683 - val_loss: 0.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7305 - accuracy: 0.4628 - val_loss: 0.2387 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7311 - accuracy: 0.4676 - val_loss: 0.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7624 - accuracy: 0.4552 - val_loss: 0.2472 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.7514 - accuracy: 0.4641 - val_loss: 0.2479 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7601 - accuracy: 0.4577 - val_loss: 0.2497 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 41ms/step - loss: 1.7438 - accuracy: 0.4625 - val_loss: 0.2420 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.7369 - accuracy: 0.4662 - val_loss: 0.2427 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7521 - accuracy: 0.4603 - val_loss: 0.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.7600 - accuracy: 0.4589 - val_loss: 0.2458 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.7587 - accuracy: 0.4601 - val_loss: 0.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.7443 - accuracy: 0.4625 - val_loss: 0.2433 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7340 - accuracy: 0.4683 - val_loss: 0.2391 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.7480 - accuracy: 0.4626 - val_loss: 0.2473 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.7500 - accuracy: 0.4629 - val_loss: 0.2472 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7444 - accuracy: 0.4636 - val_loss: 0.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7403 - accuracy: 0.4616 - val_loss: 0.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.7454 - accuracy: 0.4656 - val_loss: 0.2471 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.7402 - accuracy: 0.4671 - val_loss: 0.2420 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB853A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB853A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 6.1334 - accuracy: 0.3057WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC97168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AC97168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 6.1330 - accuracy: 0.3058 - val_loss: 4.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.6734 - accuracy: 0.3808 - val_loss: 3.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 5.4451 - accuracy: 0.4136 - val_loss: 3.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 5.2496 - accuracy: 0.4343 - val_loss: 3.5889 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 23s 59ms/step - loss: 5.0684 - accuracy: 0.4485 - val_loss: 3.4556 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 4.9166 - accuracy: 0.4562 - val_loss: 3.3254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 4.7689 - accuracy: 0.4620 - val_loss: 3.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 4.6329 - accuracy: 0.4664 - val_loss: 3.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 4.4981 - accuracy: 0.4680 - val_loss: 2.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 4.3771 - accuracy: 0.4718 - val_loss: 2.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.2513 - accuracy: 0.4761 - val_loss: 2.7222 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.1253 - accuracy: 0.4795 - val_loss: 2.6102 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.9989 - accuracy: 0.4861 - val_loss: 2.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.9012 - accuracy: 0.4816 - val_loss: 2.3967 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.8009 - accuracy: 0.4804 - val_loss: 2.2948 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.6958 - accuracy: 0.4843 - val_loss: 2.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.6021 - accuracy: 0.4800 - val_loss: 2.0985 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.4981 - accuracy: 0.4840 - val_loss: 2.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.3988 - accuracy: 0.4858 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.3081 - accuracy: 0.4825 - val_loss: 1.8243 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.2252 - accuracy: 0.4841 - val_loss: 1.7400 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1369 - accuracy: 0.4863 - val_loss: 1.6570 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0449 - accuracy: 0.4911 - val_loss: 1.5777 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.9688 - accuracy: 0.4907 - val_loss: 1.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.8978 - accuracy: 0.4860 - val_loss: 1.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.8267 - accuracy: 0.4833 - val_loss: 1.3579 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.7360 - accuracy: 0.4971 - val_loss: 1.2896 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.6700 - accuracy: 0.4934 - val_loss: 1.2245 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.5995 - accuracy: 0.4950 - val_loss: 1.1629 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 2.5365 - accuracy: 0.4989 - val_loss: 1.1030 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.4814 - accuracy: 0.5002 - val_loss: 1.0479 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4303 - accuracy: 0.4958 - val_loss: 0.9955 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3898 - accuracy: 0.4930 - val_loss: 0.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3312 - accuracy: 0.4978 - val_loss: 0.8957 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2757 - accuracy: 0.4982 - val_loss: 0.8489 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2308 - accuracy: 0.4959 - val_loss: 0.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.2114 - accuracy: 0.4905 - val_loss: 0.7671 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1695 - accuracy: 0.4918 - val_loss: 0.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.1302 - accuracy: 0.4914 - val_loss: 0.6934 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0874 - accuracy: 0.4963 - val_loss: 0.6618 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.0377 - accuracy: 0.5028 - val_loss: 0.6302 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.0126 - accuracy: 0.4992 - val_loss: 0.6012 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9732 - accuracy: 0.5070 - val_loss: 0.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.9489 - accuracy: 0.5052 - val_loss: 0.5527 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.9241 - accuracy: 0.5056 - val_loss: 0.5318 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9032 - accuracy: 0.5067 - val_loss: 0.5131 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8771 - accuracy: 0.5098 - val_loss: 0.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.8698 - accuracy: 0.5082 - val_loss: 0.4864 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8765 - accuracy: 0.5006 - val_loss: 0.4761 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8543 - accuracy: 0.5048 - val_loss: 0.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A33AD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A33AD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 5.9994 - accuracy: 0.3078WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AD0F4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AD0F4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 5.9994 - accuracy: 0.3078 - val_loss: 3.8816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 5.5435 - accuracy: 0.3866 - val_loss: 3.7519 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 5.3270 - accuracy: 0.4174 - val_loss: 3.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.1525 - accuracy: 0.4329 - val_loss: 3.5001 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.9872 - accuracy: 0.4476 - val_loss: 3.3776 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 4.8475 - accuracy: 0.4544 - val_loss: 3.2582 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 4.7132 - accuracy: 0.4616 - val_loss: 3.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 4.5791 - accuracy: 0.4679 - val_loss: 3.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.4558 - accuracy: 0.4707 - val_loss: 2.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.3338 - accuracy: 0.4733 - val_loss: 2.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.2156 - accuracy: 0.4794 - val_loss: 2.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.0982 - accuracy: 0.4814 - val_loss: 2.5960 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.9942 - accuracy: 0.4825 - val_loss: 2.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.8859 - accuracy: 0.4849 - val_loss: 2.3957 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.7734 - accuracy: 0.4898 - val_loss: 2.2987 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 3.6712 - accuracy: 0.4937 - val_loss: 2.2064 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.5879 - accuracy: 0.4901 - val_loss: 2.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.5137 - accuracy: 0.4847 - val_loss: 2.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.4300 - accuracy: 0.4816 - val_loss: 1.9446 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.3417 - accuracy: 0.4828 - val_loss: 1.8607 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 3.2553 - accuracy: 0.4867 - val_loss: 1.7797 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 19s 49ms/step - loss: 3.1746 - accuracy: 0.4880 - val_loss: 1.7013 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.0859 - accuracy: 0.4926 - val_loss: 1.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 3.0023 - accuracy: 0.4932 - val_loss: 1.5507 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 2.9449 - accuracy: 0.4903 - val_loss: 1.4806 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.8736 - accuracy: 0.4901 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 2.7997 - accuracy: 0.4924 - val_loss: 1.3465 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.7289 - accuracy: 0.4942 - val_loss: 1.2833 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.6740 - accuracy: 0.4897 - val_loss: 1.2223 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 2.5939 - accuracy: 0.4978 - val_loss: 1.1639 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 2.5380 - accuracy: 0.4975 - val_loss: 1.1083 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.4832 - accuracy: 0.4980 - val_loss: 1.0543 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.4220 - accuracy: 0.5015 - val_loss: 1.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.3594 - accuracy: 0.5064 - val_loss: 0.9546 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3281 - accuracy: 0.5007 - val_loss: 0.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.2917 - accuracy: 0.4962 - val_loss: 0.8662 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.2440 - accuracy: 0.4995 - val_loss: 0.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.1971 - accuracy: 0.5035 - val_loss: 0.7869 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.1757 - accuracy: 0.4973 - val_loss: 0.7540 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.1219 - accuracy: 0.5059 - val_loss: 0.7196 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.0807 - accuracy: 0.5090 - val_loss: 0.6866 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 2.0578 - accuracy: 0.5047 - val_loss: 0.6579 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.0204 - accuracy: 0.5071 - val_loss: 0.6293 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.9870 - accuracy: 0.5110 - val_loss: 0.6044 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.9661 - accuracy: 0.5103 - val_loss: 0.5820 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.9569 - accuracy: 0.5048 - val_loss: 0.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9433 - accuracy: 0.5028 - val_loss: 0.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9281 - accuracy: 0.5025 - val_loss: 0.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.9088 - accuracy: 0.5052 - val_loss: 0.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8851 - accuracy: 0.5043 - val_loss: 0.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AC76948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AC76948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 14.2058 - accuracy: 0.3064WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A30A168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A30A168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 14.2058 - accuracy: 0.3064 - val_loss: 10.3727 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 10.6533 - accuracy: 0.3811 - val_loss: 7.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 8.1678 - accuracy: 0.4114 - val_loss: 5.5614 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 6.3797 - accuracy: 0.4326 - val_loss: 4.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.0826 - accuracy: 0.4409 - val_loss: 3.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 4.1444 - accuracy: 0.4489 - val_loss: 2.2252 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.4766 - accuracy: 0.4457 - val_loss: 1.6579 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.9697 - accuracy: 0.4532 - val_loss: 1.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.6084 - accuracy: 0.4557 - val_loss: 0.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.3524 - accuracy: 0.4552 - val_loss: 0.7223 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1365 - accuracy: 0.4625 - val_loss: 0.5609 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.0056 - accuracy: 0.4609 - val_loss: 0.4464 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.8987 - accuracy: 0.4639 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 46ms/step - loss: 1.8083 - accuracy: 0.4735 - val_loss: 0.2996 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7644 - accuracy: 0.4680 - val_loss: 0.2574 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.7330 - accuracy: 0.4669 - val_loss: 0.2253 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.7055 - accuracy: 0.4671 - val_loss: 0.2022 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.6875 - accuracy: 0.4660 - val_loss: 0.1847 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.6494 - accuracy: 0.4751 - val_loss: 0.1706 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.6390 - accuracy: 0.4730 - val_loss: 0.1618 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6253 - accuracy: 0.4745 - val_loss: 0.1551 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.6227 - accuracy: 0.4770 - val_loss: 0.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.6224 - accuracy: 0.4728 - val_loss: 0.1480 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.6391 - accuracy: 0.4661 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.6245 - accuracy: 0.4726 - val_loss: 0.1464 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.6035 - accuracy: 0.4781 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.6130 - accuracy: 0.4735 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.6136 - accuracy: 0.4750 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.6198 - accuracy: 0.4714 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.6097 - accuracy: 0.4789 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.6029 - accuracy: 0.4786 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 21s 52ms/step - loss: 1.6047 - accuracy: 0.4788 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.6090 - accuracy: 0.4761 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.6001 - accuracy: 0.4792 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 23s 59ms/step - loss: 1.6043 - accuracy: 0.4761 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.6051 - accuracy: 0.4787 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.6013 - accuracy: 0.4802 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.5943 - accuracy: 0.4819 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5942 - accuracy: 0.4829 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5905 - accuracy: 0.4829 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.5937 - accuracy: 0.4841 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.5903 - accuracy: 0.4822 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5899 - accuracy: 0.4860 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.5798 - accuracy: 0.4880 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5840 - accuracy: 0.4878 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5914 - accuracy: 0.4844 - val_loss: 0.1481 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5833 - accuracy: 0.4862 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.6019 - accuracy: 0.4826 - val_loss: 0.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.6013 - accuracy: 0.4813 - val_loss: 0.1515 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 1.6198 - accuracy: 0.4749 - val_loss: 0.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FBA3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FBA3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.1810 - accuracy: 0.3074WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757023CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757023CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 24s 60ms/step - loss: 2.1807 - accuracy: 0.3074 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.8770 - accuracy: 0.3861 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.7870 - accuracy: 0.4139 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.7312 - accuracy: 0.4324 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6928 - accuracy: 0.4471 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6638 - accuracy: 0.4545 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.6396 - accuracy: 0.4637 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 1.6173 - accuracy: 0.4719 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 1.6089 - accuracy: 0.4749 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6011 - accuracy: 0.4767 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.5786 - accuracy: 0.4865 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5663 - accuracy: 0.4890 - val_loss: 0.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.5576 - accuracy: 0.4935 - val_loss: 0.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.5435 - accuracy: 0.5011 - val_loss: 0.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.5445 - accuracy: 0.4968 - val_loss: 0.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5340 - accuracy: 0.5011 - val_loss: 0.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5216 - accuracy: 0.5033 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.5147 - accuracy: 0.5064 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5153 - accuracy: 0.5080 - val_loss: 0.1351 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5095 - accuracy: 0.5102 - val_loss: 0.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5081 - accuracy: 0.5089 - val_loss: 0.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4948 - accuracy: 0.5147 - val_loss: 0.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4931 - accuracy: 0.5141 - val_loss: 0.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4832 - accuracy: 0.5190 - val_loss: 0.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4749 - accuracy: 0.5204 - val_loss: 0.1336 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.4732 - accuracy: 0.5198 - val_loss: 0.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4784 - accuracy: 0.5204 - val_loss: 0.1331 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4653 - accuracy: 0.5235 - val_loss: 0.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4465 - accuracy: 0.5284 - val_loss: 0.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4459 - accuracy: 0.5286 - val_loss: 0.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4403 - accuracy: 0.5325 - val_loss: 0.1322 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4407 - accuracy: 0.5315 - val_loss: 0.1319 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.4408 - accuracy: 0.5338 - val_loss: 0.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4310 - accuracy: 0.5366 - val_loss: 0.1315 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4194 - accuracy: 0.5399 - val_loss: 0.1312 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4204 - accuracy: 0.5414 - val_loss: 0.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4192 - accuracy: 0.5406 - val_loss: 0.1308 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4099 - accuracy: 0.5415 - val_loss: 0.1305 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4019 - accuracy: 0.5469 - val_loss: 0.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.3969 - accuracy: 0.5466 - val_loss: 0.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4054 - accuracy: 0.5439 - val_loss: 0.1299 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.3922 - accuracy: 0.5474 - val_loss: 0.1296 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.3841 - accuracy: 0.5506 - val_loss: 0.1294 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.3786 - accuracy: 0.5537 - val_loss: 0.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3715 - accuracy: 0.5549 - val_loss: 0.1290 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.3708 - accuracy: 0.5558 - val_loss: 0.1288 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.3672 - accuracy: 0.5567 - val_loss: 0.1285 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.3531 - accuracy: 0.5613 - val_loss: 0.1283 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.3520 - accuracy: 0.5618 - val_loss: 0.1281 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.3498 - accuracy: 0.5647 - val_loss: 0.1279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A1A3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A1A3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0437 - accuracy: 0.3055WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FAAEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FAAEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 19s 50ms/step - loss: 2.0437 - accuracy: 0.3055 - val_loss: 4.1486e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.7370 - accuracy: 0.3840 - val_loss: 4.1501e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6431 - accuracy: 0.4139 - val_loss: 4.1513e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5919 - accuracy: 0.4335 - val_loss: 4.1524e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5553 - accuracy: 0.4441 - val_loss: 4.1536e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5212 - accuracy: 0.4582 - val_loss: 4.1549e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.5045 - accuracy: 0.4619 - val_loss: 4.1561e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4948 - accuracy: 0.4666 - val_loss: 4.1574e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4703 - accuracy: 0.4763 - val_loss: 4.1586e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4605 - accuracy: 0.4812 - val_loss: 4.1599e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4450 - accuracy: 0.4858 - val_loss: 4.1612e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4370 - accuracy: 0.4868 - val_loss: 4.1626e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4220 - accuracy: 0.4914 - val_loss: 4.1640e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4058 - accuracy: 0.4962 - val_loss: 4.1653e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4017 - accuracy: 0.4988 - val_loss: 4.1668e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3937 - accuracy: 0.5021 - val_loss: 4.1683e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3797 - accuracy: 0.5074 - val_loss: 4.1699e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.3679 - accuracy: 0.5119 - val_loss: 4.1714e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3559 - accuracy: 0.5141 - val_loss: 4.1730e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3521 - accuracy: 0.5159 - val_loss: 4.1745e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3538 - accuracy: 0.5173 - val_loss: 4.1761e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3499 - accuracy: 0.5186 - val_loss: 4.1778e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.3363 - accuracy: 0.5220 - val_loss: 4.1795e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.3353 - accuracy: 0.5215 - val_loss: 4.1812e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3292 - accuracy: 0.5262 - val_loss: 4.1829e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.3259 - accuracy: 0.5244 - val_loss: 4.1846e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.3244 - accuracy: 0.5293 - val_loss: 4.1863e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.3158 - accuracy: 0.5294 - val_loss: 4.1881e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3025 - accuracy: 0.5352 - val_loss: 4.1898e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3143 - accuracy: 0.5298 - val_loss: 4.1917e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.2980 - accuracy: 0.5363 - val_loss: 4.1934e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.3016 - accuracy: 0.5321 - val_loss: 4.1954e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2879 - accuracy: 0.5374 - val_loss: 4.1971e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2976 - accuracy: 0.5353 - val_loss: 4.1990e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2790 - accuracy: 0.5431 - val_loss: 4.2008e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2806 - accuracy: 0.5408 - val_loss: 4.2027e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.2680 - accuracy: 0.5471 - val_loss: 4.2045e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2657 - accuracy: 0.5480 - val_loss: 4.2064e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2615 - accuracy: 0.5470 - val_loss: 4.2083e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2607 - accuracy: 0.5517 - val_loss: 4.2102e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2628 - accuracy: 0.5479 - val_loss: 4.2122e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2601 - accuracy: 0.5487 - val_loss: 4.2141e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2457 - accuracy: 0.5530 - val_loss: 4.2160e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2435 - accuracy: 0.5570 - val_loss: 4.2179e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.2397 - accuracy: 0.5558 - val_loss: 4.2200e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.2355 - accuracy: 0.5560 - val_loss: 4.2218e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.2370 - accuracy: 0.5572 - val_loss: 4.2238e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.2346 - accuracy: 0.5587 - val_loss: 4.2257e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.2181 - accuracy: 0.5623 - val_loss: 4.2276e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.2251 - accuracy: 0.5605 - val_loss: 4.2297e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AD0FB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AD0FB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/391 [============================>.] - ETA: 0s - loss: 112.1621 - accuracy: 0.2166WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730EB74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730EB74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 111.9998 - accuracy: 0.2168 - val_loss: 8.8081 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 6.6325 - accuracy: 0.2404 - val_loss: 2.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 4.1770 - accuracy: 0.2466 - val_loss: 1.7687 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.5697 - accuracy: 0.2491 - val_loss: 1.3862 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.3765 - accuracy: 0.2512 - val_loss: 1.3623 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 3.3471 - accuracy: 0.2510 - val_loss: 1.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2921 - accuracy: 0.2499 - val_loss: 1.2884 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 3.2573 - accuracy: 0.2508 - val_loss: 1.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2350 - accuracy: 0.2519 - val_loss: 1.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.2283 - accuracy: 0.2532 - val_loss: 1.2322 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 3.2267 - accuracy: 0.2497 - val_loss: 1.2408 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 3.2079 - accuracy: 0.2526 - val_loss: 1.2129 - val_accuracy: 0.0000e+00 loss: 3.207\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.1800 - accuracy: 0.2512 - val_loss: 1.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1657 - accuracy: 0.2516 - val_loss: 1.1969 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.1734 - accuracy: 0.2513 - val_loss: 1.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.1878 - accuracy: 0.2511 - val_loss: 1.1671 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.1849 - accuracy: 0.2502 - val_loss: 1.1719 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.1480 - accuracy: 0.2472 - val_loss: 1.0833 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1542 - accuracy: 0.2488 - val_loss: 1.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1277 - accuracy: 0.2525 - val_loss: 1.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1165 - accuracy: 0.2487 - val_loss: 1.0569 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1002 - accuracy: 0.2507 - val_loss: 1.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1094 - accuracy: 0.2508 - val_loss: 1.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1038 - accuracy: 0.2537 - val_loss: 1.0947 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1306 - accuracy: 0.2509 - val_loss: 1.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1197 - accuracy: 0.2475 - val_loss: 1.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1070 - accuracy: 0.2508 - val_loss: 1.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1104 - accuracy: 0.2524 - val_loss: 1.1175 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1023 - accuracy: 0.2516 - val_loss: 1.1461 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1239 - accuracy: 0.2528 - val_loss: 1.0515 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0870 - accuracy: 0.2523 - val_loss: 1.0946 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0854 - accuracy: 0.2531 - val_loss: 1.0333 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1160 - accuracy: 0.2503 - val_loss: 1.0644 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1098 - accuracy: 0.2472 - val_loss: 1.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0780 - accuracy: 0.2538 - val_loss: 1.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0826 - accuracy: 0.2513 - val_loss: 1.0242 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1029 - accuracy: 0.2501 - val_loss: 1.0468 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1057 - accuracy: 0.2509 - val_loss: 1.1294 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0854 - accuracy: 0.2497 - val_loss: 1.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0999 - accuracy: 0.2500 - val_loss: 1.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0798 - accuracy: 0.2533 - val_loss: 1.0927 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0803 - accuracy: 0.2504 - val_loss: 1.0450 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0823 - accuracy: 0.2493 - val_loss: 1.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0618 - accuracy: 0.2514 - val_loss: 1.0001 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.0806 - accuracy: 0.2534 - val_loss: 1.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0702 - accuracy: 0.2518 - val_loss: 0.9847 - val_accuracy: 0.0000e+00s: 3.0734 \n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0412 - accuracy: 0.2481 - val_loss: 1.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0660 - accuracy: 0.2516 - val_loss: 1.0478 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 42ms/step - loss: 3.0641 - accuracy: 0.2498 - val_loss: 1.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0668 - accuracy: 0.2507 - val_loss: 1.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB614C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AB614C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 113.9446 - accuracy: 0.2182WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FFB4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FFB4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 113.9446 - accuracy: 0.2182 - val_loss: 11.1175 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 7.2669 - accuracy: 0.2425 - val_loss: 2.8669 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.2131 - accuracy: 0.2484 - val_loss: 1.7359 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.6089 - accuracy: 0.2501 - val_loss: 1.4605 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.4587 - accuracy: 0.2521 - val_loss: 1.3763 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.3596 - accuracy: 0.2537 - val_loss: 1.2827 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.3073 - accuracy: 0.2499 - val_loss: 1.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.2945 - accuracy: 0.2495 - val_loss: 1.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.2355 - accuracy: 0.2507 - val_loss: 1.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2332 - accuracy: 0.2518 - val_loss: 1.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2562 - accuracy: 0.2525 - val_loss: 1.2440 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.2150 - accuracy: 0.2532 - val_loss: 1.2331 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.2446 - accuracy: 0.2550 - val_loss: 1.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1926 - accuracy: 0.2521 - val_loss: 1.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1848 - accuracy: 0.2504 - val_loss: 1.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1757 - accuracy: 0.2487 - val_loss: 1.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1837 - accuracy: 0.2495 - val_loss: 1.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1597 - accuracy: 0.2484 - val_loss: 1.1004 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1954 - accuracy: 0.2510 - val_loss: 1.1652 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1794 - accuracy: 0.2492 - val_loss: 1.2244 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1521 - accuracy: 0.2514 - val_loss: 1.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1577 - accuracy: 0.2504 - val_loss: 1.0798 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1631 - accuracy: 0.2528 - val_loss: 1.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.1412 - accuracy: 0.2506 - val_loss: 1.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.1171 - accuracy: 0.2491 - val_loss: 1.1505 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1239 - accuracy: 0.2518 - val_loss: 1.0637 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 3.1483 - accuracy: 0.2490 - val_loss: 1.1083 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1387 - accuracy: 0.2533 - val_loss: 1.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.1021 - accuracy: 0.2540 - val_loss: 1.0379 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.1095 - accuracy: 0.2498 - val_loss: 1.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 3.1038 - accuracy: 0.2543 - val_loss: 1.0438 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 3.1095 - accuracy: 0.2524 - val_loss: 1.1673 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.1269 - accuracy: 0.2519 - val_loss: 1.0455 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0993 - accuracy: 0.2504 - val_loss: 1.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.1221 - accuracy: 0.2519 - val_loss: 1.0594 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.1298 - accuracy: 0.2493 - val_loss: 1.0607 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 3.0893 - accuracy: 0.2544 - val_loss: 1.0978 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0959 - accuracy: 0.2533 - val_loss: 1.0610 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.0944 - accuracy: 0.2530 - val_loss: 1.0649 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.0864 - accuracy: 0.2503 - val_loss: 1.0468 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 19s 49ms/step - loss: 3.0620 - accuracy: 0.2528 - val_loss: 1.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0835 - accuracy: 0.2510 - val_loss: 1.0246 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 3.0832 - accuracy: 0.2535 - val_loss: 1.0442 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.1004 - accuracy: 0.2452 - val_loss: 1.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0888 - accuracy: 0.2472 - val_loss: 1.1146 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0876 - accuracy: 0.2536 - val_loss: 1.0964 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0860 - accuracy: 0.2490 - val_loss: 1.0428 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0577 - accuracy: 0.2502 - val_loss: 1.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0863 - accuracy: 0.2495 - val_loss: 1.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 3.0913 - accuracy: 0.2509 - val_loss: 1.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FD91EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FD91EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 114.2823 - accuracy: 0.2208WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217571D19D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217571D19D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 114.1207 - accuracy: 0.2208 - val_loss: 10.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 7.2058 - accuracy: 0.2406 - val_loss: 2.8012 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.1861 - accuracy: 0.2499 - val_loss: 1.7428 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 3.5574 - accuracy: 0.2465 - val_loss: 1.4741 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.4160 - accuracy: 0.2512 - val_loss: 1.3290 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.3164 - accuracy: 0.2547 - val_loss: 1.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.2902 - accuracy: 0.2501 - val_loss: 1.1657 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.2456 - accuracy: 0.2480 - val_loss: 1.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 3.2073 - accuracy: 0.2473 - val_loss: 1.1450 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.2256 - accuracy: 0.2498 - val_loss: 1.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.2010 - accuracy: 0.2536 - val_loss: 1.2181 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.1982 - accuracy: 0.2543 - val_loss: 1.2725 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1892 - accuracy: 0.2523 - val_loss: 1.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1652 - accuracy: 0.2510 - val_loss: 1.1045 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1782 - accuracy: 0.2503 - val_loss: 1.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1449 - accuracy: 0.2542 - val_loss: 1.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 3.1618 - accuracy: 0.2547 - val_loss: 1.1815 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1629 - accuracy: 0.2526 - val_loss: 1.1227 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1716 - accuracy: 0.2517 - val_loss: 1.1930 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1451 - accuracy: 0.2492 - val_loss: 1.0899 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1225 - accuracy: 0.2520 - val_loss: 1.1522 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1315 - accuracy: 0.2515 - val_loss: 1.0961 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1517 - accuracy: 0.2507 - val_loss: 1.1115 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1274 - accuracy: 0.2536 - val_loss: 1.1040 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1428 - accuracy: 0.2490 - val_loss: 1.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.1507 - accuracy: 0.2514 - val_loss: 1.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1233 - accuracy: 0.2519 - val_loss: 1.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1281 - accuracy: 0.2525 - val_loss: 1.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1184 - accuracy: 0.2512 - val_loss: 1.0965 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.1232 - accuracy: 0.2533 - val_loss: 1.0768 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1180 - accuracy: 0.2527 - val_loss: 1.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0821 - accuracy: 0.2515 - val_loss: 1.1193 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1125 - accuracy: 0.2520 - val_loss: 1.0416 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1003 - accuracy: 0.2501 - val_loss: 1.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.1015 - accuracy: 0.2483 - val_loss: 1.1617 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 3.1003 - accuracy: 0.2509 - val_loss: 1.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 3.1159 - accuracy: 0.2504 - val_loss: 1.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.1114 - accuracy: 0.2521 - val_loss: 1.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.0763 - accuracy: 0.2527 - val_loss: 1.1033 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0811 - accuracy: 0.2513 - val_loss: 1.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.0932 - accuracy: 0.2553 - val_loss: 1.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0747 - accuracy: 0.2486 - val_loss: 1.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 3.1055 - accuracy: 0.2515 - val_loss: 1.0515 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0868 - accuracy: 0.2474 - val_loss: 1.1231 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.0823 - accuracy: 0.2523 - val_loss: 1.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 3.0890 - accuracy: 0.2484 - val_loss: 1.0578 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 3.0774 - accuracy: 0.2509 - val_loss: 1.0844 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.0836 - accuracy: 0.2533 - val_loss: 1.0332 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.0964 - accuracy: 0.2497 - val_loss: 1.1148 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.0564 - accuracy: 0.2520 - val_loss: 1.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175735B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175735B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 17.9371 - accuracy: 0.2478WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757CB5168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757CB5168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 17.9326 - accuracy: 0.2479 - val_loss: 13.2518 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 13.2063 - accuracy: 0.3273 - val_loss: 9.5769 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 9.9529 - accuracy: 0.3589 - val_loss: 6.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 7.6223 - accuracy: 0.3705 - val_loss: 4.9545 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 5.9330 - accuracy: 0.3842 - val_loss: 3.5460 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.7241 - accuracy: 0.3851 - val_loss: 2.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 3.8629 - accuracy: 0.3835 - val_loss: 1.7923 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.2188 - accuracy: 0.3876 - val_loss: 1.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.7693 - accuracy: 0.3875 - val_loss: 0.8888 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.4644 - accuracy: 0.3857 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.2327 - accuracy: 0.3916 - val_loss: 0.4467 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1054 - accuracy: 0.3833 - val_loss: 0.3287 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.0094 - accuracy: 0.3810 - val_loss: 0.2573 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.9482 - accuracy: 0.3838 - val_loss: 0.2185 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.9119 - accuracy: 0.3907 - val_loss: 0.2116 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.9015 - accuracy: 0.3957 - val_loss: 0.2150 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.9126 - accuracy: 0.3914 - val_loss: 0.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.8979 - accuracy: 0.3951 - val_loss: 0.2128 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8967 - accuracy: 0.3966 - val_loss: 0.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8977 - accuracy: 0.3966 - val_loss: 0.2150 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.9107 - accuracy: 0.3909 - val_loss: 0.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9065 - accuracy: 0.3933 - val_loss: 0.2107 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8977 - accuracy: 0.3952 - val_loss: 0.2132 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8866 - accuracy: 0.3986 - val_loss: 0.2080 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8884 - accuracy: 0.3979 - val_loss: 0.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.8983 - accuracy: 0.3960 - val_loss: 0.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8960 - accuracy: 0.3990 - val_loss: 0.2154 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8993 - accuracy: 0.3962 - val_loss: 0.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.8846 - accuracy: 0.4029 - val_loss: 0.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8861 - accuracy: 0.4024 - val_loss: 0.2136 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.8729 - accuracy: 0.4061 - val_loss: 0.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8887 - accuracy: 0.3994 - val_loss: 0.2100 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.8899 - accuracy: 0.3992 - val_loss: 0.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.8965 - accuracy: 0.3990 - val_loss: 0.2187 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.9140 - accuracy: 0.3934 - val_loss: 0.2284 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9018 - accuracy: 0.3985 - val_loss: 0.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.9159 - accuracy: 0.3930 - val_loss: 0.2244 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8846 - accuracy: 0.4060 - val_loss: 0.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8775 - accuracy: 0.4085 - val_loss: 0.2205 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8874 - accuracy: 0.4023 - val_loss: 0.2184 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8836 - accuracy: 0.4044 - val_loss: 0.2232 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.9039 - accuracy: 0.3960 - val_loss: 0.2243 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.8935 - accuracy: 0.3996 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.8852 - accuracy: 0.4068 - val_loss: 0.2245 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8891 - accuracy: 0.4027 - val_loss: 0.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.8936 - accuracy: 0.4034 - val_loss: 0.2285 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.8922 - accuracy: 0.4037 - val_loss: 0.2250 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.9011 - accuracy: 0.4030 - val_loss: 0.2242 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.8924 - accuracy: 0.3991 - val_loss: 0.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8894 - accuracy: 0.4032 - val_loss: 0.2226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AD0FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AD0FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 6.3690 - accuracy: 0.2493WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A3DACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A3DACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 6.3681 - accuracy: 0.2495 - val_loss: 4.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 5.8272 - accuracy: 0.3254 - val_loss: 3.8694 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 5.5881 - accuracy: 0.3556 - val_loss: 3.7295 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.4060 - accuracy: 0.3747 - val_loss: 3.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 5.2388 - accuracy: 0.3861 - val_loss: 3.4588 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 5.0910 - accuracy: 0.3939 - val_loss: 3.3283 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 4.9406 - accuracy: 0.4008 - val_loss: 3.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 4.8029 - accuracy: 0.4039 - val_loss: 3.0760 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.6780 - accuracy: 0.4044 - val_loss: 2.9544 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.5483 - accuracy: 0.4067 - val_loss: 2.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.4203 - accuracy: 0.4107 - val_loss: 2.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.3017 - accuracy: 0.4142 - val_loss: 2.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 4.1801 - accuracy: 0.4167 - val_loss: 2.4978 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.0697 - accuracy: 0.4186 - val_loss: 2.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.9585 - accuracy: 0.4225 - val_loss: 2.2866 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.8634 - accuracy: 0.4188 - val_loss: 2.1867 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 46ms/step - loss: 3.7589 - accuracy: 0.4190 - val_loss: 2.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.6681 - accuracy: 0.4177 - val_loss: 1.9934 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.5772 - accuracy: 0.4189 - val_loss: 1.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.4753 - accuracy: 0.4210 - val_loss: 1.8117 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 3.3961 - accuracy: 0.4204 - val_loss: 1.7259 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.3122 - accuracy: 0.4196 - val_loss: 1.6427 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.2313 - accuracy: 0.4163 - val_loss: 1.5622 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.1543 - accuracy: 0.4146 - val_loss: 1.4851 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0797 - accuracy: 0.4183 - val_loss: 1.4097 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0133 - accuracy: 0.4145 - val_loss: 1.3380 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.9372 - accuracy: 0.4185 - val_loss: 1.2687 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8789 - accuracy: 0.4118 - val_loss: 1.2035 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.8065 - accuracy: 0.4162 - val_loss: 1.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7333 - accuracy: 0.4212 - val_loss: 1.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.6671 - accuracy: 0.4247 - val_loss: 1.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.6135 - accuracy: 0.4212 - val_loss: 0.9653 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.5795 - accuracy: 0.4122 - val_loss: 0.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.5117 - accuracy: 0.4201 - val_loss: 0.8642 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.4693 - accuracy: 0.4164 - val_loss: 0.8180 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.4297 - accuracy: 0.4142 - val_loss: 0.7749 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.3765 - accuracy: 0.4196 - val_loss: 0.7321 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.3227 - accuracy: 0.4255 - val_loss: 0.6934 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2810 - accuracy: 0.4246 - val_loss: 0.6571 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2427 - accuracy: 0.4238 - val_loss: 0.6233 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2175 - accuracy: 0.4232 - val_loss: 0.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.1941 - accuracy: 0.4255 - val_loss: 0.5670 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1658 - accuracy: 0.4231 - val_loss: 0.5406 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.1235 - accuracy: 0.4286 - val_loss: 0.5145 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.0895 - accuracy: 0.4342 - val_loss: 0.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.0744 - accuracy: 0.4334 - val_loss: 0.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.0602 - accuracy: 0.4296 - val_loss: 0.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 2.0401 - accuracy: 0.4307 - val_loss: 0.4393 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 2.0332 - accuracy: 0.4298 - val_loss: 0.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 2.0186 - accuracy: 0.4288 - val_loss: 0.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AC97CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174AC97CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 6.2502 - accuracy: 0.2495WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FAE8558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FAE8558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 6.2495 - accuracy: 0.2496 - val_loss: 3.8803 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 5.7129 - accuracy: 0.3216 - val_loss: 3.7499 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 5.4795 - accuracy: 0.3569 - val_loss: 3.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 5.3058 - accuracy: 0.3720 - val_loss: 3.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 5.1530 - accuracy: 0.3828 - val_loss: 3.3729 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 5.0085 - accuracy: 0.3910 - val_loss: 3.2527 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.8755 - accuracy: 0.3962 - val_loss: 3.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.7497 - accuracy: 0.4030 - val_loss: 3.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 44ms/step - loss: 4.6214 - accuracy: 0.4070 - val_loss: 2.9076 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.5055 - accuracy: 0.4092 - val_loss: 2.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 4.3947 - accuracy: 0.4104 - val_loss: 2.6907 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 4.2668 - accuracy: 0.4176 - val_loss: 2.5857 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 4.1714 - accuracy: 0.4149 - val_loss: 2.4837 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 4.0548 - accuracy: 0.4224 - val_loss: 2.3841 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 3.9626 - accuracy: 0.4170 - val_loss: 2.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.8615 - accuracy: 0.4193 - val_loss: 2.1923 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.7679 - accuracy: 0.4184 - val_loss: 2.1011 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.6804 - accuracy: 0.4193 - val_loss: 2.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.5812 - accuracy: 0.4226 - val_loss: 1.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 3.4981 - accuracy: 0.4205 - val_loss: 1.8386 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.4106 - accuracy: 0.4239 - val_loss: 1.7564 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 3.3327 - accuracy: 0.4208 - val_loss: 1.6776 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 3.2644 - accuracy: 0.4190 - val_loss: 1.6013 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 3.1897 - accuracy: 0.4210 - val_loss: 1.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1144 - accuracy: 0.4207 - val_loss: 1.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 3.0479 - accuracy: 0.4193 - val_loss: 1.3869 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 2.9813 - accuracy: 0.4180 - val_loss: 1.3203 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.9214 - accuracy: 0.4155 - val_loss: 1.2572 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 2.8474 - accuracy: 0.4218 - val_loss: 1.1942 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.7715 - accuracy: 0.4253 - val_loss: 1.1339 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 2.7195 - accuracy: 0.4239 - val_loss: 1.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 2.6636 - accuracy: 0.4240 - val_loss: 1.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 2.6147 - accuracy: 0.4240 - val_loss: 0.9728 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.5633 - accuracy: 0.4233 - val_loss: 0.9241 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.4953 - accuracy: 0.4303 - val_loss: 0.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.4522 - accuracy: 0.4285 - val_loss: 0.8332 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3984 - accuracy: 0.4345 - val_loss: 0.7916 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.3659 - accuracy: 0.4307 - val_loss: 0.7535 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.3235 - accuracy: 0.4319 - val_loss: 0.7162 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2920 - accuracy: 0.4300 - val_loss: 0.6816 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.2606 - accuracy: 0.4300 - val_loss: 0.6495 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.2239 - accuracy: 0.4351 - val_loss: 0.6191 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2024 - accuracy: 0.4286 - val_loss: 0.5945 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 2.1856 - accuracy: 0.4271 - val_loss: 0.5686 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1462 - accuracy: 0.4311 - val_loss: 0.5446 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.1310 - accuracy: 0.4300 - val_loss: 0.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.0952 - accuracy: 0.4339 - val_loss: 0.5037 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0813 - accuracy: 0.4357 - val_loss: 0.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0642 - accuracy: 0.4313 - val_loss: 0.4726 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0478 - accuracy: 0.4351 - val_loss: 0.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FED95E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FED95E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 14.4534 - accuracy: 0.2481WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FBBEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174FBBEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 14.4501 - accuracy: 0.2481 - val_loss: 10.3627 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 10.7818 - accuracy: 0.3272 - val_loss: 7.5782 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 8.2885 - accuracy: 0.3598 - val_loss: 5.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 6.5010 - accuracy: 0.3773 - val_loss: 4.0661 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 5.2041 - accuracy: 0.3897 - val_loss: 2.9887 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 4.2665 - accuracy: 0.3931 - val_loss: 2.2066 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 3.6028 - accuracy: 0.3917 - val_loss: 1.6374 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 3.1031 - accuracy: 0.3975 - val_loss: 1.2202 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 2.7407 - accuracy: 0.3967 - val_loss: 0.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 2.4796 - accuracy: 0.4004 - val_loss: 0.6948 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 2.2893 - accuracy: 0.3987 - val_loss: 0.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 2.1500 - accuracy: 0.4000 - val_loss: 0.4182 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 2.0500 - accuracy: 0.4004 - val_loss: 0.3340 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 1.9825 - accuracy: 0.3968 - val_loss: 0.2741 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.9366 - accuracy: 0.3964 - val_loss: 0.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.8861 - accuracy: 0.4024 - val_loss: 0.1948 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.8542 - accuracy: 0.4032 - val_loss: 0.1701 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.8374 - accuracy: 0.3998 - val_loss: 0.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 1.8183 - accuracy: 0.4018 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 1.7998 - accuracy: 0.4012 - val_loss: 0.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.7956 - accuracy: 0.4004 - val_loss: 0.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.7902 - accuracy: 0.4043 - val_loss: 0.1170 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.7763 - accuracy: 0.4055 - val_loss: 0.1144 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 1.7653 - accuracy: 0.4070 - val_loss: 0.1106 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.7721 - accuracy: 0.4064 - val_loss: 0.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7839 - accuracy: 0.4006 - val_loss: 0.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.7790 - accuracy: 0.4036 - val_loss: 0.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.7736 - accuracy: 0.4040 - val_loss: 0.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 1.7734 - accuracy: 0.4044 - val_loss: 0.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 1.7779 - accuracy: 0.4020 - val_loss: 0.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.7776 - accuracy: 0.4011 - val_loss: 0.1050 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.7622 - accuracy: 0.4056 - val_loss: 0.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7862 - accuracy: 0.3968 - val_loss: 0.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7960 - accuracy: 0.3955 - val_loss: 0.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7703 - accuracy: 0.4048 - val_loss: 0.1054 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.7679 - accuracy: 0.4035 - val_loss: 0.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7660 - accuracy: 0.4043 - val_loss: 0.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.7674 - accuracy: 0.4051 - val_loss: 0.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.7656 - accuracy: 0.4060 - val_loss: 0.1098 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.7692 - accuracy: 0.4092 - val_loss: 0.1115 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 1.7843 - accuracy: 0.4017 - val_loss: 0.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.7930 - accuracy: 0.3986 - val_loss: 0.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.7777 - accuracy: 0.4036 - val_loss: 0.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 1.7665 - accuracy: 0.4090 - val_loss: 0.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 1.7569 - accuracy: 0.4103 - val_loss: 0.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 1.7606 - accuracy: 0.4090 - val_loss: 0.1103 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.7763 - accuracy: 0.4055 - val_loss: 0.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 1.7865 - accuracy: 0.4007 - val_loss: 0.1116 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.7792 - accuracy: 0.4053 - val_loss: 0.1107 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.7721 - accuracy: 0.4053 - val_loss: 0.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217572884C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217572884C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/391 [============================>.] - ETA: 0s - loss: 2.4471 - accuracy: 0.2489WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217571DCAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217571DCAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 2.4465 - accuracy: 0.2489 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 2.0273 - accuracy: 0.3240 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 1.9256 - accuracy: 0.3595 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.8804 - accuracy: 0.3746 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.8547 - accuracy: 0.3855 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.8290 - accuracy: 0.3976 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.8056 - accuracy: 0.4039 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.7956 - accuracy: 0.4063 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.7870 - accuracy: 0.4098 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.7678 - accuracy: 0.4177 - val_loss: 0.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7610 - accuracy: 0.4213 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.7531 - accuracy: 0.4212 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7430 - accuracy: 0.4264 - val_loss: 0.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.7379 - accuracy: 0.4276 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7310 - accuracy: 0.4287 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.7248 - accuracy: 0.4300 - val_loss: 0.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7213 - accuracy: 0.4354 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.7197 - accuracy: 0.4333 - val_loss: 0.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.7102 - accuracy: 0.4370 - val_loss: 0.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7026 - accuracy: 0.4392 - val_loss: 0.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6989 - accuracy: 0.4408 - val_loss: 0.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.6930 - accuracy: 0.4449 - val_loss: 0.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.6856 - accuracy: 0.4437 - val_loss: 0.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6856 - accuracy: 0.4439 - val_loss: 0.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6816 - accuracy: 0.4457 - val_loss: 0.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6701 - accuracy: 0.4517 - val_loss: 0.1321 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6653 - accuracy: 0.4540 - val_loss: 0.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.6597 - accuracy: 0.4528 - val_loss: 0.1315 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6596 - accuracy: 0.4550 - val_loss: 0.1312 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6515 - accuracy: 0.4557 - val_loss: 0.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6570 - accuracy: 0.4526 - val_loss: 0.1307 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.6518 - accuracy: 0.4528 - val_loss: 0.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.6430 - accuracy: 0.4581 - val_loss: 0.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6447 - accuracy: 0.4583 - val_loss: 0.1298 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6474 - accuracy: 0.4600 - val_loss: 0.1296 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6507 - accuracy: 0.4568 - val_loss: 0.1293 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.6479 - accuracy: 0.4570 - val_loss: 0.1290 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6494 - accuracy: 0.4572 - val_loss: 0.1288 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6459 - accuracy: 0.4608 - val_loss: 0.1285 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.6424 - accuracy: 0.4618 - val_loss: 0.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.6295 - accuracy: 0.4642 - val_loss: 0.1280 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.6394 - accuracy: 0.4619 - val_loss: 0.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.6381 - accuracy: 0.4608 - val_loss: 0.1274 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.6325 - accuracy: 0.4627 - val_loss: 0.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 1.6302 - accuracy: 0.4624 - val_loss: 0.1269 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6234 - accuracy: 0.4654 - val_loss: 0.1266 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6131 - accuracy: 0.4700 - val_loss: 0.1264 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6173 - accuracy: 0.4653 - val_loss: 0.1261 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 20s 52ms/step - loss: 1.6217 - accuracy: 0.4677 - val_loss: 0.1258 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6171 - accuracy: 0.4687 - val_loss: 0.1256 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FA3E9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FA3E9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.3125 - accuracy: 0.2510WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A54B5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A54B5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3123 - accuracy: 0.2510 - val_loss: 4.1479e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.8923 - accuracy: 0.3241 - val_loss: 4.1491e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.7970 - accuracy: 0.3556 - val_loss: 4.1499e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.7441 - accuracy: 0.3750 - val_loss: 4.1505e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.7123 - accuracy: 0.3875 - val_loss: 4.1513e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.6892 - accuracy: 0.3951 - val_loss: 4.1520e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.6713 - accuracy: 0.4027 - val_loss: 4.1527e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.6511 - accuracy: 0.4106 - val_loss: 4.1535e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6414 - accuracy: 0.4131 - val_loss: 4.1545e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.6327 - accuracy: 0.4169 - val_loss: 4.1554e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 1.6180 - accuracy: 0.4200 - val_loss: 4.1563e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.6060 - accuracy: 0.4268 - val_loss: 4.1571e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5961 - accuracy: 0.4290 - val_loss: 4.1580e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.5872 - accuracy: 0.4337 - val_loss: 4.1590e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.5862 - accuracy: 0.4329 - val_loss: 4.1600e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 1.5738 - accuracy: 0.4376 - val_loss: 4.1609e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.5743 - accuracy: 0.4354 - val_loss: 4.1620e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 1.5669 - accuracy: 0.4409 - val_loss: 4.1631e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 1.5618 - accuracy: 0.4410 - val_loss: 4.1643e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.5611 - accuracy: 0.4401 - val_loss: 4.1654e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 1.5592 - accuracy: 0.4404 - val_loss: 4.1665e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.5552 - accuracy: 0.4454 - val_loss: 4.1676e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.5558 - accuracy: 0.4446 - val_loss: 4.1688e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5432 - accuracy: 0.4497 - val_loss: 4.1699e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5374 - accuracy: 0.4500 - val_loss: 4.1711e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.5329 - accuracy: 0.4542 - val_loss: 4.1723e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5358 - accuracy: 0.4529 - val_loss: 4.1735e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.5291 - accuracy: 0.4526 - val_loss: 4.1748e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.5213 - accuracy: 0.4557 - val_loss: 4.1760e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.5207 - accuracy: 0.4545 - val_loss: 4.1773e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.5237 - accuracy: 0.4556 - val_loss: 4.1785e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.5167 - accuracy: 0.4582 - val_loss: 4.1798e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.5175 - accuracy: 0.4594 - val_loss: 4.1810e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.5172 - accuracy: 0.4567 - val_loss: 4.1822e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 1.5098 - accuracy: 0.4604 - val_loss: 4.1836e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5083 - accuracy: 0.4623 - val_loss: 4.1849e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5022 - accuracy: 0.4600 - val_loss: 4.1861e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.5049 - accuracy: 0.4655 - val_loss: 4.1874e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.5010 - accuracy: 0.4651 - val_loss: 4.1886e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4987 - accuracy: 0.4640 - val_loss: 4.1900e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.4904 - accuracy: 0.4676 - val_loss: 4.1913e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.4862 - accuracy: 0.4716 - val_loss: 4.1926e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4770 - accuracy: 0.4744 - val_loss: 4.1939e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4747 - accuracy: 0.4723 - val_loss: 4.1953e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.4765 - accuracy: 0.4709 - val_loss: 4.1965e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4760 - accuracy: 0.4726 - val_loss: 4.1979e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4730 - accuracy: 0.4738 - val_loss: 4.1994e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.4678 - accuracy: 0.4766 - val_loss: 4.2008e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.4655 - accuracy: 0.4749 - val_loss: 4.2021e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.4613 - accuracy: 0.4777 - val_loss: 4.2035e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A5F54C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A5F54C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 200.7884 - accuracy: 0.3185WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A54B288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A54B288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 200.5304 - accuracy: 0.3187 - val_loss: 37.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 20.1122 - accuracy: 0.3125 - val_loss: 6.7032 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 5.5388 - accuracy: 0.3088 - val_loss: 1.9424 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 13s 67ms/step - loss: 3.4101 - accuracy: 0.3186 - val_loss: 1.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 3.0276 - accuracy: 0.3231 - val_loss: 1.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 2.9853 - accuracy: 0.3246 - val_loss: 1.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 2.9224 - accuracy: 0.3252 - val_loss: 1.0184 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 11s 57ms/step - loss: 2.8551 - accuracy: 0.3239 - val_loss: 1.0536 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 2.8583 - accuracy: 0.3193 - val_loss: 0.9701 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 2.7814 - accuracy: 0.3270 - val_loss: 0.9346 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 2.7431 - accuracy: 0.3276 - val_loss: 0.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 2.7369 - accuracy: 0.3268 - val_loss: 0.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 2.7656 - accuracy: 0.3245 - val_loss: 0.8697 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 11s 56ms/step - loss: 2.7354 - accuracy: 0.3263 - val_loss: 0.8656 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.7887 - accuracy: 0.3234 - val_loss: 0.9234 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 2.7810 - accuracy: 0.3216 - val_loss: 0.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.7109 - accuracy: 0.3231 - val_loss: 0.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.7062 - accuracy: 0.3322 - val_loss: 0.8629 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 2.6891 - accuracy: 0.3294 - val_loss: 0.8427 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 12s 60ms/step - loss: 2.6791 - accuracy: 0.3302 - val_loss: 0.8373 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 2.6880 - accuracy: 0.3284 - val_loss: 0.8211 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 2.6861 - accuracy: 0.3281 - val_loss: 0.8430 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 2.7405 - accuracy: 0.3232 - val_loss: 0.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 2.6656 - accuracy: 0.3258 - val_loss: 0.8033 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 13s 67ms/step - loss: 2.6458 - accuracy: 0.3247 - val_loss: 0.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.6503 - accuracy: 0.3325 - val_loss: 0.7835 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 13s 67ms/step - loss: 2.6406 - accuracy: 0.3245 - val_loss: 0.7900 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 2.6678 - accuracy: 0.3210 - val_loss: 0.7690 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 2.6707 - accuracy: 0.3243 - val_loss: 0.8302 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 12s 59ms/step - loss: 2.6547 - accuracy: 0.3254 - val_loss: 0.8074 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 14s 70ms/step - loss: 2.6508 - accuracy: 0.3286 - val_loss: 0.7591 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 2.6704 - accuracy: 0.3227 - val_loss: 0.7856 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.6952 - accuracy: 0.3193 - val_loss: 0.8339 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 2.6491 - accuracy: 0.3218 - val_loss: 0.7761 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 12s 63ms/step - loss: 2.6616 - accuracy: 0.3228 - val_loss: 0.7920 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 2.6769 - accuracy: 0.3215 - val_loss: 0.7854 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 2.6514 - accuracy: 0.3215 - val_loss: 0.7880 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 2.6235 - accuracy: 0.3282 - val_loss: 0.7506 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 2.6211 - accuracy: 0.3260 - val_loss: 0.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 13s 65ms/step - loss: 2.6125 - accuracy: 0.3258 - val_loss: 0.7224 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 14s 71ms/step - loss: 2.5852 - accuracy: 0.3281 - val_loss: 0.7395 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 13s 67ms/step - loss: 2.5929 - accuracy: 0.3286 - val_loss: 0.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 12s 61ms/step - loss: 2.6248 - accuracy: 0.3240 - val_loss: 0.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 11s 57ms/step - loss: 2.6308 - accuracy: 0.3241 - val_loss: 0.7749 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.6107 - accuracy: 0.3257 - val_loss: 0.7773 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 11s 56ms/step - loss: 2.6286 - accuracy: 0.3276 - val_loss: 0.7576 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 11s 57ms/step - loss: 2.6053 - accuracy: 0.3234 - val_loss: 0.7546 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 2.6309 - accuracy: 0.3240 - val_loss: 0.7153 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 11s 57ms/step - loss: 2.6273 - accuracy: 0.3243 - val_loss: 0.7994 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 2.6102 - accuracy: 0.3293 - val_loss: 0.7397 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FBBE708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FBBE708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - ETA: 0s - loss: 201.1273 - accuracy: 0.3180WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A50B3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174A50B3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 14s 71ms/step - loss: 201.1273 - accuracy: 0.3180 - val_loss: 41.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 23.3196 - accuracy: 0.3078 - val_loss: 9.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 6.7851 - accuracy: 0.3124 - val_loss: 2.3946 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 3.6542 - accuracy: 0.3113 - val_loss: 1.3593 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 13s 65ms/step - loss: 3.0997 - accuracy: 0.3199 - val_loss: 1.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.9257 - accuracy: 0.3272 - val_loss: 1.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.8354 - accuracy: 0.3274 - val_loss: 0.9415 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.8369 - accuracy: 0.3261 - val_loss: 0.9523 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.7820 - accuracy: 0.3234 - val_loss: 0.8761 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.7658 - accuracy: 0.3261 - val_loss: 0.8976 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 2.7901 - accuracy: 0.3221 - val_loss: 0.9053 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.7549 - accuracy: 0.3280 - val_loss: 0.8964 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.7377 - accuracy: 0.3268 - val_loss: 0.8636 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.7388 - accuracy: 0.3210 - val_loss: 0.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.7492 - accuracy: 0.3190 - val_loss: 0.8761 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.7251 - accuracy: 0.3221 - val_loss: 0.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 11s 57ms/step - loss: 2.7242 - accuracy: 0.3214 - val_loss: 0.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 2.7132 - accuracy: 0.3248 - val_loss: 0.8908 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.7168 - accuracy: 0.3264 - val_loss: 0.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.6817 - accuracy: 0.3269 - val_loss: 0.7897 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.6843 - accuracy: 0.3270 - val_loss: 0.8002 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6362 - accuracy: 0.3294 - val_loss: 0.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6788 - accuracy: 0.3272 - val_loss: 0.8098 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 2.6663 - accuracy: 0.3258 - val_loss: 0.8091 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.6501 - accuracy: 0.3277 - val_loss: 0.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6647 - accuracy: 0.3272 - val_loss: 0.7564 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.6364 - accuracy: 0.3263 - val_loss: 0.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6919 - accuracy: 0.3238 - val_loss: 0.7919 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.6816 - accuracy: 0.3264 - val_loss: 0.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.6700 - accuracy: 0.3259 - val_loss: 0.7983 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6597 - accuracy: 0.3252 - val_loss: 0.8099 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.6800 - accuracy: 0.3248 - val_loss: 0.8104 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 2.6499 - accuracy: 0.3255 - val_loss: 0.8189 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.6473 - accuracy: 0.3239 - val_loss: 0.8205 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.6537 - accuracy: 0.3251 - val_loss: 0.7698 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.6868 - accuracy: 0.3231 - val_loss: 0.8139 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.6502 - accuracy: 0.3291 - val_loss: 0.8002 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.6555 - accuracy: 0.3278 - val_loss: 0.7703 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.6478 - accuracy: 0.3252 - val_loss: 0.7560 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6264 - accuracy: 0.3263 - val_loss: 0.7891 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.6414 - accuracy: 0.3263 - val_loss: 0.7783 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6520 - accuracy: 0.3261 - val_loss: 0.7716 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6218 - accuracy: 0.3250 - val_loss: 0.7423 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6099 - accuracy: 0.3263 - val_loss: 0.7654 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6426 - accuracy: 0.3222 - val_loss: 0.7922 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.6130 - accuracy: 0.3285 - val_loss: 0.7857 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6551 - accuracy: 0.3272 - val_loss: 0.7889 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6403 - accuracy: 0.3260 - val_loss: 0.7614 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6453 - accuracy: 0.3255 - val_loss: 0.8095 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 2.6243 - accuracy: 0.3267 - val_loss: 0.7475 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A33A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A33A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - ETA: 0s - loss: 201.1393 - accuracy: 0.3196WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217572DB678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217572DB678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 201.1393 - accuracy: 0.3196 - val_loss: 42.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 23.3065 - accuracy: 0.3097 - val_loss: 9.1741 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 6.7931 - accuracy: 0.3127 - val_loss: 2.2269 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 3.5999 - accuracy: 0.3106 - val_loss: 1.4261 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 3.0921 - accuracy: 0.3182 - val_loss: 1.0655 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.9872 - accuracy: 0.3141 - val_loss: 1.0397 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.9970 - accuracy: 0.3163 - val_loss: 1.0972 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.9120 - accuracy: 0.3191 - val_loss: 0.9912 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.8423 - accuracy: 0.3235 - val_loss: 0.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.7742 - accuracy: 0.3237 - val_loss: 0.9545 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.7837 - accuracy: 0.3316 - val_loss: 0.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.8193 - accuracy: 0.3219 - val_loss: 0.9154 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.8233 - accuracy: 0.3263 - val_loss: 0.9659 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.8413 - accuracy: 0.3247 - val_loss: 0.9323 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 8s 43ms/step - loss: 2.7977 - accuracy: 0.3232 - val_loss: 0.9697 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.8284 - accuracy: 0.3230 - val_loss: 0.9363 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.7648 - accuracy: 0.3257 - val_loss: 0.9548 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.7743 - accuracy: 0.3219 - val_loss: 0.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.7041 - accuracy: 0.3306 - val_loss: 0.8742 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.7291 - accuracy: 0.3292 - val_loss: 0.8928 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 2.7832 - accuracy: 0.3274 - val_loss: 0.8980 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 13s 67ms/step - loss: 2.7465 - accuracy: 0.3269 - val_loss: 0.8674 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 11s 59ms/step - loss: 2.7717 - accuracy: 0.3262 - val_loss: 0.8674 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 12s 59ms/step - loss: 2.7156 - accuracy: 0.3271 - val_loss: 0.9000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 13s 65ms/step - loss: 2.7234 - accuracy: 0.3298 - val_loss: 0.8415 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 13s 67ms/step - loss: 2.6841 - accuracy: 0.3269 - val_loss: 0.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 11s 58ms/step - loss: 2.6625 - accuracy: 0.3308 - val_loss: 0.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 2.6946 - accuracy: 0.3279 - val_loss: 0.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 11s 56ms/step - loss: 2.6997 - accuracy: 0.3267 - val_loss: 0.8461 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 2.6767 - accuracy: 0.3297 - val_loss: 0.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 2.7276 - accuracy: 0.3234 - val_loss: 0.8627 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 2.7218 - accuracy: 0.3226 - val_loss: 0.8986 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 10s 50ms/step - loss: 2.7388 - accuracy: 0.3261 - val_loss: 0.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6746 - accuracy: 0.3313 - val_loss: 0.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.6946 - accuracy: 0.3237 - val_loss: 0.8065 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6913 - accuracy: 0.3244 - val_loss: 0.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6849 - accuracy: 0.3263 - val_loss: 0.8275 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.7316 - accuracy: 0.3261 - val_loss: 0.8301 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.6955 - accuracy: 0.3265 - val_loss: 0.8386 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.6704 - accuracy: 0.3306 - val_loss: 0.8236 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.6838 - accuracy: 0.3264 - val_loss: 0.8003 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.6852 - accuracy: 0.3275 - val_loss: 0.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.6579 - accuracy: 0.3314 - val_loss: 0.7839 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.6443 - accuracy: 0.3311 - val_loss: 0.7974 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.6672 - accuracy: 0.3246 - val_loss: 0.7891 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 2.6698 - accuracy: 0.3257 - val_loss: 0.7819 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.6571 - accuracy: 0.3262 - val_loss: 0.8005 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.6431 - accuracy: 0.3295 - val_loss: 0.7645 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.6472 - accuracy: 0.3273 - val_loss: 0.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 2.6227 - accuracy: 0.3287 - val_loss: 0.7911 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217575910D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217575910D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - ETA: 0s - loss: 18.8038 - accuracy: 0.3183WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757039288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757039288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 18.8038 - accuracy: 0.3183 - val_loss: 15.4928 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 15.9874 - accuracy: 0.4134 - val_loss: 13.1762 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 13.7499 - accuracy: 0.4431 - val_loss: 11.1991 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 11.8682 - accuracy: 0.4594 - val_loss: 9.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 10.2667 - accuracy: 0.4748 - val_loss: 8.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 8.8930 - accuracy: 0.4906 - val_loss: 6.8513 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 8s 42ms/step - loss: 7.7334 - accuracy: 0.4997 - val_loss: 5.8086 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 6.7505 - accuracy: 0.5057 - val_loss: 4.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 5.9233 - accuracy: 0.5084 - val_loss: 4.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 5.2051 - accuracy: 0.5142 - val_loss: 3.5296 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 4.6161 - accuracy: 0.5179 - val_loss: 2.9879 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 4.1153 - accuracy: 0.5177 - val_loss: 2.5296 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 3.7006 - accuracy: 0.5134 - val_loss: 2.1407 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 3.3279 - accuracy: 0.5156 - val_loss: 1.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 3.0153 - accuracy: 0.5202 - val_loss: 1.5315 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 9s 44ms/step - loss: 2.7501 - accuracy: 0.5226 - val_loss: 1.2953 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 2.5304 - accuracy: 0.5227 - val_loss: 1.0975 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 2.3382 - accuracy: 0.5237 - val_loss: 0.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.1817 - accuracy: 0.5254 - val_loss: 0.7939 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 2.0529 - accuracy: 0.5286 - val_loss: 0.6779 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 1.9326 - accuracy: 0.5349 - val_loss: 0.5805 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 10s 50ms/step - loss: 1.8494 - accuracy: 0.5299 - val_loss: 0.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.7723 - accuracy: 0.5365 - val_loss: 0.4424 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 1.7016 - accuracy: 0.5401 - val_loss: 0.3903 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6648 - accuracy: 0.5381 - val_loss: 0.3522 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6383 - accuracy: 0.5375 - val_loss: 0.3239 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5920 - accuracy: 0.5407 - val_loss: 0.3016 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5732 - accuracy: 0.5407 - val_loss: 0.2887 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5695 - accuracy: 0.5400 - val_loss: 0.2852 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5617 - accuracy: 0.5401 - val_loss: 0.2808 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 1.5551 - accuracy: 0.5428 - val_loss: 0.2751 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 1.5520 - accuracy: 0.5409 - val_loss: 0.2705 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.5422 - accuracy: 0.5458 - val_loss: 0.2693 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5302 - accuracy: 0.5470 - val_loss: 0.2647 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5281 - accuracy: 0.5469 - val_loss: 0.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5247 - accuracy: 0.5496 - val_loss: 0.2639 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5216 - accuracy: 0.5505 - val_loss: 0.2623 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5154 - accuracy: 0.5515 - val_loss: 0.2595 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5200 - accuracy: 0.5523 - val_loss: 0.2620 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5236 - accuracy: 0.5508 - val_loss: 0.2631 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.5218 - accuracy: 0.5505 - val_loss: 0.2654 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5094 - accuracy: 0.5520 - val_loss: 0.2641 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5178 - accuracy: 0.5497 - val_loss: 0.2641 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5196 - accuracy: 0.5498 - val_loss: 0.2650 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5087 - accuracy: 0.5558 - val_loss: 0.2658 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5104 - accuracy: 0.5530 - val_loss: 0.2646 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5111 - accuracy: 0.5528 - val_loss: 0.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5162 - accuracy: 0.5526 - val_loss: 0.2670 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5115 - accuracy: 0.5551 - val_loss: 0.2674 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5109 - accuracy: 0.5574 - val_loss: 0.2697 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217571AF3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217571AF3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.1099 - accuracy: 0.3221WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021756FF8C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021756FF8C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 37ms/step - loss: 6.1095 - accuracy: 0.3222 - val_loss: 4.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.7262 - accuracy: 0.4062 - val_loss: 4.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.5571 - accuracy: 0.4381 - val_loss: 3.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.4264 - accuracy: 0.4578 - val_loss: 3.8612 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.3087 - accuracy: 0.4762 - val_loss: 3.7909 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.1990 - accuracy: 0.4878 - val_loss: 3.7212 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 5.1004 - accuracy: 0.4983 - val_loss: 3.6525 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.0092 - accuracy: 0.5084 - val_loss: 3.5845 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.9196 - accuracy: 0.5153 - val_loss: 3.5174 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.8398 - accuracy: 0.5212 - val_loss: 3.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.7521 - accuracy: 0.5279 - val_loss: 3.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.6743 - accuracy: 0.5335 - val_loss: 3.3211 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.5875 - accuracy: 0.5391 - val_loss: 3.2575 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.5143 - accuracy: 0.5414 - val_loss: 3.1944 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.4337 - accuracy: 0.5503 - val_loss: 3.1322 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.3632 - accuracy: 0.5512 - val_loss: 3.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.2907 - accuracy: 0.5537 - val_loss: 3.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.2193 - accuracy: 0.5599 - val_loss: 2.9505 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.1423 - accuracy: 0.5634 - val_loss: 2.8918 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.0839 - accuracy: 0.5658 - val_loss: 2.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.0232 - accuracy: 0.5676 - val_loss: 2.7772 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.9619 - accuracy: 0.5699 - val_loss: 2.7209 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.9040 - accuracy: 0.5655 - val_loss: 2.6654 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.8430 - accuracy: 0.5696 - val_loss: 2.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.7872 - accuracy: 0.5715 - val_loss: 2.5570 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7272 - accuracy: 0.5698 - val_loss: 2.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.6717 - accuracy: 0.5749 - val_loss: 2.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.6055 - accuracy: 0.5809 - val_loss: 2.3992 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5449 - accuracy: 0.5825 - val_loss: 2.3481 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4851 - accuracy: 0.5866 - val_loss: 2.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4372 - accuracy: 0.5852 - val_loss: 2.2491 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3798 - accuracy: 0.5887 - val_loss: 2.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3422 - accuracy: 0.5847 - val_loss: 2.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.2819 - accuracy: 0.5893 - val_loss: 2.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.2212 - accuracy: 0.5912 - val_loss: 2.0593 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1841 - accuracy: 0.5884 - val_loss: 2.0144 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1309 - accuracy: 0.5934 - val_loss: 1.9695 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0891 - accuracy: 0.5917 - val_loss: 1.9262 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0453 - accuracy: 0.5903 - val_loss: 1.8832 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9906 - accuracy: 0.5954 - val_loss: 1.8407 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9475 - accuracy: 0.5971 - val_loss: 1.7991 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.8968 - accuracy: 0.5986 - val_loss: 1.7577 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8605 - accuracy: 0.5965 - val_loss: 1.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8392 - accuracy: 0.5937 - val_loss: 1.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8030 - accuracy: 0.5929 - val_loss: 1.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7626 - accuracy: 0.5904 - val_loss: 1.6052 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7209 - accuracy: 0.5947 - val_loss: 1.5678 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.6671 - accuracy: 0.6008 - val_loss: 1.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.6264 - accuracy: 0.6015 - val_loss: 1.4953 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.5961 - accuracy: 0.5986 - val_loss: 1.4607 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021756FF8678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021756FF8678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/196 [============================>.] - ETA: 0s - loss: 6.0026 - accuracy: 0.3186WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757CB55E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757CB55E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 6.0025 - accuracy: 0.3186 - val_loss: 3.9410 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.6099 - accuracy: 0.4037 - val_loss: 3.8749 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.4490 - accuracy: 0.4308 - val_loss: 3.8094 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.3222 - accuracy: 0.4521 - val_loss: 3.7445 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.2099 - accuracy: 0.4684 - val_loss: 3.6802 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.1043 - accuracy: 0.4814 - val_loss: 3.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.0083 - accuracy: 0.4951 - val_loss: 3.5537 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.9220 - accuracy: 0.5027 - val_loss: 3.4914 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.8412 - accuracy: 0.5097 - val_loss: 3.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.7588 - accuracy: 0.5154 - val_loss: 3.3691 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.6729 - accuracy: 0.5254 - val_loss: 3.3088 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.6003 - accuracy: 0.5295 - val_loss: 3.2493 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.5207 - accuracy: 0.5337 - val_loss: 3.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.4541 - accuracy: 0.5386 - val_loss: 3.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 4.3838 - accuracy: 0.5441 - val_loss: 3.0757 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 4.3158 - accuracy: 0.5509 - val_loss: 3.0189 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 4.2446 - accuracy: 0.5534 - val_loss: 2.9631 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.1895 - accuracy: 0.5547 - val_loss: 2.9078 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.1170 - accuracy: 0.5593 - val_loss: 2.8533 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 4.0623 - accuracy: 0.5599 - val_loss: 2.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 4.0006 - accuracy: 0.5634 - val_loss: 2.7465 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.9337 - accuracy: 0.5680 - val_loss: 2.6938 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.8777 - accuracy: 0.5698 - val_loss: 2.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.8187 - accuracy: 0.5681 - val_loss: 2.5910 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7656 - accuracy: 0.5705 - val_loss: 2.5407 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7200 - accuracy: 0.5711 - val_loss: 2.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.6528 - accuracy: 0.5790 - val_loss: 2.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.6040 - accuracy: 0.5782 - val_loss: 2.3939 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.5599 - accuracy: 0.5750 - val_loss: 2.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.5148 - accuracy: 0.5718 - val_loss: 2.3002 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.4609 - accuracy: 0.5772 - val_loss: 2.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.4066 - accuracy: 0.5808 - val_loss: 2.2076 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.3595 - accuracy: 0.5806 - val_loss: 2.1629 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3105 - accuracy: 0.5836 - val_loss: 2.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.2661 - accuracy: 0.5826 - val_loss: 2.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.2071 - accuracy: 0.5870 - val_loss: 2.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.1660 - accuracy: 0.5910 - val_loss: 1.9896 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1253 - accuracy: 0.5849 - val_loss: 1.9487 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0939 - accuracy: 0.5844 - val_loss: 1.9076 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.0295 - accuracy: 0.5925 - val_loss: 1.8664 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9924 - accuracy: 0.5892 - val_loss: 1.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9612 - accuracy: 0.5855 - val_loss: 1.7884 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.9028 - accuracy: 0.5951 - val_loss: 1.7496 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8574 - accuracy: 0.5994 - val_loss: 1.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8246 - accuracy: 0.5942 - val_loss: 1.6753 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7826 - accuracy: 0.5973 - val_loss: 1.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7401 - accuracy: 0.5999 - val_loss: 1.6032 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7011 - accuracy: 0.5995 - val_loss: 1.5681 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.6582 - accuracy: 0.6045 - val_loss: 1.5338 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.6306 - accuracy: 0.6015 - val_loss: 1.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757458AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757458AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 15.0879 - accuracy: 0.3212WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217590D85E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217590D85E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 15.0860 - accuracy: 0.3213 - val_loss: 12.0874 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 12.8803 - accuracy: 0.4082 - val_loss: 10.3306 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 11.1560 - accuracy: 0.4405 - val_loss: 8.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 9.7027 - accuracy: 0.4609 - val_loss: 7.5484 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 8.4687 - accuracy: 0.4785 - val_loss: 6.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 7.4266 - accuracy: 0.4906 - val_loss: 5.5232 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 6.5301 - accuracy: 0.4989 - val_loss: 4.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.7727 - accuracy: 0.5057 - val_loss: 4.0507 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.1290 - accuracy: 0.5145 - val_loss: 3.4740 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.5820 - accuracy: 0.5162 - val_loss: 2.9831 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.1169 - accuracy: 0.5213 - val_loss: 2.5649 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.7173 - accuracy: 0.5237 - val_loss: 2.2091 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3823 - accuracy: 0.5267 - val_loss: 1.9058 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0925 - accuracy: 0.5297 - val_loss: 1.6481 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8453 - accuracy: 0.5342 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.6390 - accuracy: 0.5370 - val_loss: 1.2415 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.4624 - accuracy: 0.5361 - val_loss: 1.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.2981 - accuracy: 0.5401 - val_loss: 0.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.1677 - accuracy: 0.5447 - val_loss: 0.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.0461 - accuracy: 0.5493 - val_loss: 0.7333 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.9457 - accuracy: 0.5537 - val_loss: 0.6490 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.8668 - accuracy: 0.5526 - val_loss: 0.5784 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.8034 - accuracy: 0.5515 - val_loss: 0.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7354 - accuracy: 0.5556 - val_loss: 0.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6815 - accuracy: 0.5567 - val_loss: 0.4237 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6435 - accuracy: 0.5561 - val_loss: 0.3874 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6006 - accuracy: 0.5635 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5702 - accuracy: 0.5606 - val_loss: 0.3296 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5406 - accuracy: 0.5625 - val_loss: 0.3069 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5333 - accuracy: 0.5581 - val_loss: 0.2892 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5003 - accuracy: 0.5645 - val_loss: 0.2724 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4795 - accuracy: 0.5672 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4758 - accuracy: 0.5624 - val_loss: 0.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4632 - accuracy: 0.5657 - val_loss: 0.2380 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4582 - accuracy: 0.5619 - val_loss: 0.2304 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4416 - accuracy: 0.5660 - val_loss: 0.2232 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4439 - accuracy: 0.5637 - val_loss: 0.2172 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4175 - accuracy: 0.5693 - val_loss: 0.2110 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4117 - accuracy: 0.5694 - val_loss: 0.2069 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3989 - accuracy: 0.5736 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3928 - accuracy: 0.5723 - val_loss: 0.1994 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 38ms/step - loss: 1.3894 - accuracy: 0.5753 - val_loss: 0.1969 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.3639 - accuracy: 0.5821 - val_loss: 0.1938 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3666 - accuracy: 0.5797 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3640 - accuracy: 0.5809 - val_loss: 0.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3597 - accuracy: 0.5817 - val_loss: 0.1905 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3657 - accuracy: 0.5803 - val_loss: 0.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3549 - accuracy: 0.5836 - val_loss: 0.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3617 - accuracy: 0.5799 - val_loss: 0.1907 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3676 - accuracy: 0.5823 - val_loss: 0.1920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217590D88B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217590D88B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.1654 - accuracy: 0.3154WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730EB70D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021730EB70D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 2.1650 - accuracy: 0.3155 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 1.8346 - accuracy: 0.3993 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 1.7425 - accuracy: 0.4327 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.6855 - accuracy: 0.4546 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6332 - accuracy: 0.4700 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5945 - accuracy: 0.4846 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5654 - accuracy: 0.4939 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5385 - accuracy: 0.5032 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5161 - accuracy: 0.5105 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4881 - accuracy: 0.5218 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4712 - accuracy: 0.5284 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4523 - accuracy: 0.5335 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4342 - accuracy: 0.5388 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4213 - accuracy: 0.5458 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4052 - accuracy: 0.5499 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3962 - accuracy: 0.5529 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.3785 - accuracy: 0.5572 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3628 - accuracy: 0.5648 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3440 - accuracy: 0.5704 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3375 - accuracy: 0.5734 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3223 - accuracy: 0.5807 - val_loss: 0.1369 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3111 - accuracy: 0.5797 - val_loss: 0.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3018 - accuracy: 0.5844 - val_loss: 0.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3046 - accuracy: 0.5863 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2911 - accuracy: 0.5907 - val_loss: 0.1364 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2777 - accuracy: 0.5969 - val_loss: 0.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2660 - accuracy: 0.5955 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2569 - accuracy: 0.6010 - val_loss: 0.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2420 - accuracy: 0.6076 - val_loss: 0.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2329 - accuracy: 0.6086 - val_loss: 0.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.2279 - accuracy: 0.6092 - val_loss: 0.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2252 - accuracy: 0.6132 - val_loss: 0.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2137 - accuracy: 0.6159 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2029 - accuracy: 0.6197 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1965 - accuracy: 0.6215 - val_loss: 0.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1888 - accuracy: 0.6233 - val_loss: 0.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1770 - accuracy: 0.6284 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1726 - accuracy: 0.6305 - val_loss: 0.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1755 - accuracy: 0.6276 - val_loss: 0.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1576 - accuracy: 0.6351 - val_loss: 0.1351 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1486 - accuracy: 0.6389 - val_loss: 0.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1367 - accuracy: 0.6432 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.1383 - accuracy: 0.6399 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1249 - accuracy: 0.6449 - val_loss: 0.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1264 - accuracy: 0.6448 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1230 - accuracy: 0.6465 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1131 - accuracy: 0.6513 - val_loss: 0.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1056 - accuracy: 0.6525 - val_loss: 0.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.0969 - accuracy: 0.6542 - val_loss: 0.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1104 - accuracy: 0.6522 - val_loss: 0.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757023438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757023438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.0277 - accuracy: 0.3192WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757D4FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757D4FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.0273 - accuracy: 0.3193 - val_loss: 4.1427e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6963 - accuracy: 0.4051 - val_loss: 4.1434e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6023 - accuracy: 0.4364 - val_loss: 4.1440e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5349 - accuracy: 0.4552 - val_loss: 4.1445e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4949 - accuracy: 0.4704 - val_loss: 4.1450e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4542 - accuracy: 0.4839 - val_loss: 4.1454e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4207 - accuracy: 0.4967 - val_loss: 4.1459e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3992 - accuracy: 0.5051 - val_loss: 4.1465e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3751 - accuracy: 0.5117 - val_loss: 4.1470e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3551 - accuracy: 0.5208 - val_loss: 4.1476e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3335 - accuracy: 0.5274 - val_loss: 4.1481e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3133 - accuracy: 0.5334 - val_loss: 4.1487e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2984 - accuracy: 0.5417 - val_loss: 4.1493e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2820 - accuracy: 0.5463 - val_loss: 4.1499e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2623 - accuracy: 0.5502 - val_loss: 4.1505e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2485 - accuracy: 0.5591 - val_loss: 4.1512e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2318 - accuracy: 0.5620 - val_loss: 4.1519e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2212 - accuracy: 0.5647 - val_loss: 4.1527e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.2061 - accuracy: 0.5718 - val_loss: 4.1534e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1921 - accuracy: 0.5775 - val_loss: 4.1542e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1848 - accuracy: 0.5786 - val_loss: 4.1551e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1727 - accuracy: 0.5830 - val_loss: 4.1559e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1599 - accuracy: 0.5867 - val_loss: 4.1569e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.1492 - accuracy: 0.5913 - val_loss: 4.1578e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1448 - accuracy: 0.5931 - val_loss: 4.1588e-04 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.1286 - accuracy: 0.5992 - val_loss: 4.1598e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.1133 - accuracy: 0.6028 - val_loss: 4.1609e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0997 - accuracy: 0.6082 - val_loss: 4.1619e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0997 - accuracy: 0.6107 - val_loss: 4.1629e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0959 - accuracy: 0.6087 - val_loss: 4.1641e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0849 - accuracy: 0.6142 - val_loss: 4.1653e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.0723 - accuracy: 0.6154 - val_loss: 4.1665e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.0632 - accuracy: 0.6195 - val_loss: 4.1677e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0569 - accuracy: 0.6231 - val_loss: 4.1690e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.0463 - accuracy: 0.6258 - val_loss: 4.1702e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0436 - accuracy: 0.6279 - val_loss: 4.1716e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.0316 - accuracy: 0.6328 - val_loss: 4.1729e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.0280 - accuracy: 0.6345 - val_loss: 4.1743e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.0165 - accuracy: 0.6376 - val_loss: 4.1756e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.0019 - accuracy: 0.6435 - val_loss: 4.1770e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.0094 - accuracy: 0.6382 - val_loss: 4.1784e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.0025 - accuracy: 0.6435 - val_loss: 4.1799e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 0.9934 - accuracy: 0.6448 - val_loss: 4.1815e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.9907 - accuracy: 0.6444 - val_loss: 4.1831e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.9811 - accuracy: 0.6480 - val_loss: 4.1846e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 0.9755 - accuracy: 0.6509 - val_loss: 4.1862e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 0.9667 - accuracy: 0.6559 - val_loss: 4.1878e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 0.9655 - accuracy: 0.6518 - val_loss: 4.1894e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 0.9553 - accuracy: 0.6572 - val_loss: 4.1909e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 0.9554 - accuracy: 0.6580 - val_loss: 4.1925e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021756FDA438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021756FDA438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 200.8059 - accuracy: 0.2842WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A4ACCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A4ACCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 200.5482 - accuracy: 0.2843 - val_loss: 37.2918 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 20.2546 - accuracy: 0.2807 - val_loss: 7.0837 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.9710 - accuracy: 0.2864 - val_loss: 2.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.6704 - accuracy: 0.2960 - val_loss: 1.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.1825 - accuracy: 0.2944 - val_loss: 1.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0669 - accuracy: 0.2950 - val_loss: 1.0839 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0009 - accuracy: 0.2919 - val_loss: 1.0824 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9451 - accuracy: 0.2976 - val_loss: 1.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9765 - accuracy: 0.2935 - val_loss: 1.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9140 - accuracy: 0.2949 - val_loss: 1.0920 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9351 - accuracy: 0.2931 - val_loss: 0.9089 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8956 - accuracy: 0.2965 - val_loss: 0.9449 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9009 - accuracy: 0.2928 - val_loss: 0.9533 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8714 - accuracy: 0.2962 - val_loss: 0.8847 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8509 - accuracy: 0.2986 - val_loss: 0.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8030 - accuracy: 0.2997 - val_loss: 0.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8145 - accuracy: 0.2955 - val_loss: 0.9446 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8017 - accuracy: 0.3013 - val_loss: 0.8173 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8024 - accuracy: 0.2968 - val_loss: 0.8708 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7603 - accuracy: 0.3032 - val_loss: 0.8397 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.7945 - accuracy: 0.2983 - val_loss: 0.8749 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.7668 - accuracy: 0.3019 - val_loss: 0.8508 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7763 - accuracy: 0.3015 - val_loss: 0.8356 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.7855 - accuracy: 0.2998 - val_loss: 0.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7865 - accuracy: 0.2974 - val_loss: 0.8347 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7612 - accuracy: 0.3036 - val_loss: 0.8591 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7584 - accuracy: 0.2979 - val_loss: 0.8199 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7936 - accuracy: 0.2996 - val_loss: 0.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7488 - accuracy: 0.2972 - val_loss: 0.8177 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7575 - accuracy: 0.2969 - val_loss: 0.8167 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7446 - accuracy: 0.2990 - val_loss: 0.8379 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7353 - accuracy: 0.2988 - val_loss: 0.8376 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7591 - accuracy: 0.2983 - val_loss: 0.7628 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7216 - accuracy: 0.3003 - val_loss: 0.8474 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7353 - accuracy: 0.2968 - val_loss: 0.8114 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7532 - accuracy: 0.2986 - val_loss: 0.8339 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7612 - accuracy: 0.2978 - val_loss: 0.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7420 - accuracy: 0.2965 - val_loss: 0.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7380 - accuracy: 0.2930 - val_loss: 0.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7355 - accuracy: 0.2987 - val_loss: 0.8035 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7509 - accuracy: 0.2994 - val_loss: 0.8174 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7465 - accuracy: 0.2964 - val_loss: 0.8256 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7576 - accuracy: 0.2963 - val_loss: 0.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7716 - accuracy: 0.2960 - val_loss: 0.8297 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 2.7342 - accuracy: 0.2986 - val_loss: 0.7923 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7302 - accuracy: 0.3013 - val_loss: 0.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7506 - accuracy: 0.2987 - val_loss: 0.7985 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7110 - accuracy: 0.2980 - val_loss: 0.8130 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7610 - accuracy: 0.2949 - val_loss: 0.8048 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7529 - accuracy: 0.2945 - val_loss: 0.7761 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175AA06C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175AA06C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 201.7073 - accuracy: 0.2886WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217606F4798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217606F4798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 201.4563 - accuracy: 0.2886 - val_loss: 42.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 23.4822 - accuracy: 0.2846 - val_loss: 9.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 7.0779 - accuracy: 0.2912 - val_loss: 2.6524 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.9159 - accuracy: 0.2921 - val_loss: 1.4257 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.1953 - accuracy: 0.3010 - val_loss: 1.1633 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0841 - accuracy: 0.2980 - val_loss: 1.1244 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0020 - accuracy: 0.2989 - val_loss: 0.9965 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9678 - accuracy: 0.2988 - val_loss: 0.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9320 - accuracy: 0.2968 - val_loss: 1.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9350 - accuracy: 0.2976 - val_loss: 0.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8904 - accuracy: 0.3007 - val_loss: 1.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9015 - accuracy: 0.3017 - val_loss: 1.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8899 - accuracy: 0.2999 - val_loss: 0.9370 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8901 - accuracy: 0.3007 - val_loss: 0.9391 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8850 - accuracy: 0.3010 - val_loss: 0.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8653 - accuracy: 0.2994 - val_loss: 0.8995 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8677 - accuracy: 0.3007 - val_loss: 0.8901 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8938 - accuracy: 0.3017 - val_loss: 0.9219 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8649 - accuracy: 0.3043 - val_loss: 0.9456 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8900 - accuracy: 0.3014 - val_loss: 0.9403 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8597 - accuracy: 0.2993 - val_loss: 1.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8334 - accuracy: 0.3009 - val_loss: 0.8687 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.8320 - accuracy: 0.3025 - val_loss: 0.9080 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8453 - accuracy: 0.3029 - val_loss: 0.9006 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 2.8359 - accuracy: 0.2967 - val_loss: 0.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 2.8619 - accuracy: 0.3017 - val_loss: 0.8730 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.8318 - accuracy: 0.3016 - val_loss: 0.8947 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8320 - accuracy: 0.3006 - val_loss: 0.8773 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8533 - accuracy: 0.2990 - val_loss: 0.8950 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8033 - accuracy: 0.3019 - val_loss: 0.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8054 - accuracy: 0.3024 - val_loss: 0.8616 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8167 - accuracy: 0.3002 - val_loss: 0.9266 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8128 - accuracy: 0.2983 - val_loss: 0.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8085 - accuracy: 0.2990 - val_loss: 0.8602 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7824 - accuracy: 0.3031 - val_loss: 0.8565 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8016 - accuracy: 0.2986 - val_loss: 0.8828 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7828 - accuracy: 0.3020 - val_loss: 0.8581 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7837 - accuracy: 0.2988 - val_loss: 0.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8093 - accuracy: 0.2987 - val_loss: 0.8881 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8014 - accuracy: 0.2990 - val_loss: 0.8709 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7898 - accuracy: 0.3021 - val_loss: 0.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8037 - accuracy: 0.3005 - val_loss: 0.8587 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7897 - accuracy: 0.2989 - val_loss: 0.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7820 - accuracy: 0.2997 - val_loss: 0.8532 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7919 - accuracy: 0.3005 - val_loss: 0.8733 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7904 - accuracy: 0.2996 - val_loss: 0.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8025 - accuracy: 0.3043 - val_loss: 0.8930 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7988 - accuracy: 0.2992 - val_loss: 0.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.7726 - accuracy: 0.3011 - val_loss: 0.8275 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7914 - accuracy: 0.2990 - val_loss: 0.8107 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175762D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175762D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 201.9559 - accuracy: 0.2873WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217605AA708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217605AA708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 201.7044 - accuracy: 0.2873 - val_loss: 42.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 23.4951 - accuracy: 0.2822 - val_loss: 9.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 7.2039 - accuracy: 0.2887 - val_loss: 2.5303 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.8284 - accuracy: 0.2933 - val_loss: 1.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.2197 - accuracy: 0.2970 - val_loss: 1.1532 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0817 - accuracy: 0.2936 - val_loss: 1.1751 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0212 - accuracy: 0.2960 - val_loss: 1.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9639 - accuracy: 0.2983 - val_loss: 1.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9353 - accuracy: 0.2967 - val_loss: 0.9499 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.8962 - accuracy: 0.2974 - val_loss: 0.9664 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8815 - accuracy: 0.2998 - val_loss: 0.9471 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8928 - accuracy: 0.2970 - val_loss: 0.8842 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8789 - accuracy: 0.2936 - val_loss: 0.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9116 - accuracy: 0.2968 - val_loss: 0.9592 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8851 - accuracy: 0.2985 - val_loss: 0.9447 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8846 - accuracy: 0.2960 - val_loss: 0.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8479 - accuracy: 0.2982 - val_loss: 0.9370 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8418 - accuracy: 0.3027 - val_loss: 0.8551 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8506 - accuracy: 0.3049 - val_loss: 0.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8359 - accuracy: 0.3009 - val_loss: 0.8642 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7996 - accuracy: 0.2999 - val_loss: 0.8979 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8063 - accuracy: 0.3043 - val_loss: 0.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8080 - accuracy: 0.3020 - val_loss: 0.8600 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.7827 - accuracy: 0.3001 - val_loss: 0.8507 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8086 - accuracy: 0.3039 - val_loss: 0.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7944 - accuracy: 0.3001 - val_loss: 0.9036 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7938 - accuracy: 0.2983 - val_loss: 0.8425 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7522 - accuracy: 0.2981 - val_loss: 0.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7854 - accuracy: 0.2982 - val_loss: 0.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7892 - accuracy: 0.3012 - val_loss: 0.8426 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7789 - accuracy: 0.3010 - val_loss: 0.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7715 - accuracy: 0.3024 - val_loss: 0.8832 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7885 - accuracy: 0.2977 - val_loss: 0.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7739 - accuracy: 0.2980 - val_loss: 0.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7978 - accuracy: 0.3018 - val_loss: 0.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7911 - accuracy: 0.3005 - val_loss: 0.8645 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8045 - accuracy: 0.2967 - val_loss: 0.8530 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.7732 - accuracy: 0.3026 - val_loss: 0.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7827 - accuracy: 0.3024 - val_loss: 0.8603 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7724 - accuracy: 0.3002 - val_loss: 0.8415 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7285 - accuracy: 0.3046 - val_loss: 0.8163 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7825 - accuracy: 0.3013 - val_loss: 0.8572 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7939 - accuracy: 0.2956 - val_loss: 0.8539 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7888 - accuracy: 0.2983 - val_loss: 0.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7543 - accuracy: 0.3033 - val_loss: 0.8055 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7363 - accuracy: 0.2979 - val_loss: 0.7779 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7225 - accuracy: 0.3021 - val_loss: 0.8269 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7594 - accuracy: 0.2985 - val_loss: 0.8041 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7909 - accuracy: 0.2934 - val_loss: 0.8573 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.7587 - accuracy: 0.2986 - val_loss: 0.8586 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A943558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A943558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/196 [============================>.] - ETA: 0s - loss: 18.9641 - accuracy: 0.2833WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021756FDAF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021756FDAF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 18.9615 - accuracy: 0.2835 - val_loss: 15.5001 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 16.1303 - accuracy: 0.3662 - val_loss: 13.1840 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 13.8764 - accuracy: 0.3997 - val_loss: 11.2056 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 11.9769 - accuracy: 0.4224 - val_loss: 9.5174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 10.3675 - accuracy: 0.4378 - val_loss: 8.0775 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 9.0143 - accuracy: 0.4466 - val_loss: 6.8513 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 7.8470 - accuracy: 0.4549 - val_loss: 5.8063 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 6.8691 - accuracy: 0.4630 - val_loss: 4.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 6.0226 - accuracy: 0.4676 - val_loss: 4.1595 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 5.3133 - accuracy: 0.4725 - val_loss: 3.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.7250 - accuracy: 0.4703 - val_loss: 2.9706 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.2040 - accuracy: 0.4754 - val_loss: 2.5061 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.7683 - accuracy: 0.4795 - val_loss: 2.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.4006 - accuracy: 0.4818 - val_loss: 1.7795 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1072 - accuracy: 0.4768 - val_loss: 1.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8396 - accuracy: 0.4790 - val_loss: 1.2620 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.6153 - accuracy: 0.4805 - val_loss: 1.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.4254 - accuracy: 0.4815 - val_loss: 0.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.2670 - accuracy: 0.4847 - val_loss: 0.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.1234 - accuracy: 0.4899 - val_loss: 0.6380 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.0350 - accuracy: 0.4838 - val_loss: 0.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.9456 - accuracy: 0.4863 - val_loss: 0.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8663 - accuracy: 0.4905 - val_loss: 0.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8050 - accuracy: 0.4891 - val_loss: 0.3517 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7667 - accuracy: 0.4839 - val_loss: 0.3123 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7126 - accuracy: 0.4933 - val_loss: 0.2814 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6872 - accuracy: 0.4938 - val_loss: 0.2596 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6551 - accuracy: 0.4992 - val_loss: 0.2450 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6630 - accuracy: 0.4929 - val_loss: 0.2423 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6573 - accuracy: 0.4931 - val_loss: 0.2398 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6543 - accuracy: 0.4930 - val_loss: 0.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6474 - accuracy: 0.4959 - val_loss: 0.2347 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6414 - accuracy: 0.4971 - val_loss: 0.2326 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6341 - accuracy: 0.4985 - val_loss: 0.2307 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6264 - accuracy: 0.4999 - val_loss: 0.2285 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6201 - accuracy: 0.5026 - val_loss: 0.2274 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.6291 - accuracy: 0.4985 - val_loss: 0.2277 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6196 - accuracy: 0.5038 - val_loss: 0.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6400 - accuracy: 0.4963 - val_loss: 0.2305 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6308 - accuracy: 0.5006 - val_loss: 0.2312 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6277 - accuracy: 0.4995 - val_loss: 0.2315 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6178 - accuracy: 0.5073 - val_loss: 0.2291 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6204 - accuracy: 0.5055 - val_loss: 0.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6180 - accuracy: 0.5036 - val_loss: 0.2315 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6112 - accuracy: 0.5076 - val_loss: 0.2301 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6074 - accuracy: 0.5087 - val_loss: 0.2313 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6031 - accuracy: 0.5104 - val_loss: 0.2309 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6073 - accuracy: 0.5085 - val_loss: 0.2314 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6215 - accuracy: 0.5041 - val_loss: 0.2349 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6212 - accuracy: 0.5044 - val_loss: 0.2361 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FD11CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174FD11CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.3026 - accuracy: 0.2863WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021756FF85E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021756FF85E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 6.3027 - accuracy: 0.2863 - val_loss: 4.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.8612 - accuracy: 0.3620 - val_loss: 4.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.6801 - accuracy: 0.3969 - val_loss: 3.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.5510 - accuracy: 0.4149 - val_loss: 3.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.4300 - accuracy: 0.4307 - val_loss: 3.7916 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.3269 - accuracy: 0.4405 - val_loss: 3.7219 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.2317 - accuracy: 0.4482 - val_loss: 3.6530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.1339 - accuracy: 0.4589 - val_loss: 3.5847 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.0494 - accuracy: 0.4653 - val_loss: 3.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.9628 - accuracy: 0.4742 - val_loss: 3.4507 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.8849 - accuracy: 0.4760 - val_loss: 3.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.8041 - accuracy: 0.4814 - val_loss: 3.3199 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.7243 - accuracy: 0.4902 - val_loss: 3.2557 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.6501 - accuracy: 0.4904 - val_loss: 3.1924 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.5739 - accuracy: 0.4965 - val_loss: 3.1297 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.5053 - accuracy: 0.4978 - val_loss: 3.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.4329 - accuracy: 0.5028 - val_loss: 3.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.3595 - accuracy: 0.5066 - val_loss: 2.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.2916 - accuracy: 0.5097 - val_loss: 2.8868 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.2289 - accuracy: 0.5106 - val_loss: 2.8284 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.1728 - accuracy: 0.5103 - val_loss: 2.7704 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.1029 - accuracy: 0.5136 - val_loss: 2.7133 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.0428 - accuracy: 0.5154 - val_loss: 2.6571 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 3.9785 - accuracy: 0.5168 - val_loss: 2.6015 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.9153 - accuracy: 0.5189 - val_loss: 2.5467 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.8568 - accuracy: 0.5218 - val_loss: 2.4928 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.8120 - accuracy: 0.5181 - val_loss: 2.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7553 - accuracy: 0.5210 - val_loss: 2.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.6992 - accuracy: 0.5213 - val_loss: 2.3361 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.6435 - accuracy: 0.5253 - val_loss: 2.2853 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.6016 - accuracy: 0.5199 - val_loss: 2.2357 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5470 - accuracy: 0.5241 - val_loss: 2.1867 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4983 - accuracy: 0.5223 - val_loss: 2.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4414 - accuracy: 0.5258 - val_loss: 2.0900 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.3973 - accuracy: 0.5245 - val_loss: 2.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.3490 - accuracy: 0.5246 - val_loss: 1.9968 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.2979 - accuracy: 0.5286 - val_loss: 1.9511 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.2679 - accuracy: 0.5226 - val_loss: 1.9072 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.2234 - accuracy: 0.5223 - val_loss: 1.8628 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1769 - accuracy: 0.5217 - val_loss: 1.8195 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1411 - accuracy: 0.5209 - val_loss: 1.7767 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0949 - accuracy: 0.5232 - val_loss: 1.7353 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0487 - accuracy: 0.5229 - val_loss: 1.6941 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.0039 - accuracy: 0.5278 - val_loss: 1.6527 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9579 - accuracy: 0.5272 - val_loss: 1.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9021 - accuracy: 0.5310 - val_loss: 1.5730 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 2.8575 - accuracy: 0.5331 - val_loss: 1.5346 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.8241 - accuracy: 0.5331 - val_loss: 1.4976 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8032 - accuracy: 0.5261 - val_loss: 1.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7536 - accuracy: 0.5309 - val_loss: 1.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757039288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757039288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.1652 - accuracy: 0.2817WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A4F0EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A4F0EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 6.1649 - accuracy: 0.2818 - val_loss: 3.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.7260 - accuracy: 0.3606 - val_loss: 3.8753 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.5480 - accuracy: 0.3958 - val_loss: 3.8096 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.4201 - accuracy: 0.4158 - val_loss: 3.7447 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.3009 - accuracy: 0.4365 - val_loss: 3.6801 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.2068 - accuracy: 0.4462 - val_loss: 3.6162 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.1113 - accuracy: 0.4589 - val_loss: 3.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.0273 - accuracy: 0.4637 - val_loss: 3.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.9507 - accuracy: 0.4693 - val_loss: 3.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.8684 - accuracy: 0.4755 - val_loss: 3.3672 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.7914 - accuracy: 0.4834 - val_loss: 3.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.7191 - accuracy: 0.4873 - val_loss: 3.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.6467 - accuracy: 0.4910 - val_loss: 3.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.5768 - accuracy: 0.4971 - val_loss: 3.1290 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.5055 - accuracy: 0.5007 - val_loss: 3.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.4368 - accuracy: 0.5010 - val_loss: 3.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.3756 - accuracy: 0.5018 - val_loss: 2.9575 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.3131 - accuracy: 0.5047 - val_loss: 2.9019 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.2516 - accuracy: 0.5051 - val_loss: 2.8467 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.1897 - accuracy: 0.5117 - val_loss: 2.7924 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.1368 - accuracy: 0.5117 - val_loss: 2.7389 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.0752 - accuracy: 0.5119 - val_loss: 2.6856 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.0225 - accuracy: 0.5150 - val_loss: 2.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.9555 - accuracy: 0.5151 - val_loss: 2.5812 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 3.9059 - accuracy: 0.5183 - val_loss: 2.5304 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 3.8533 - accuracy: 0.5183 - val_loss: 2.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.8027 - accuracy: 0.5179 - val_loss: 2.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7572 - accuracy: 0.5171 - val_loss: 2.3816 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.6976 - accuracy: 0.5215 - val_loss: 2.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.6442 - accuracy: 0.5247 - val_loss: 2.2853 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.6021 - accuracy: 0.5210 - val_loss: 2.2387 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5515 - accuracy: 0.5240 - val_loss: 2.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5043 - accuracy: 0.5223 - val_loss: 2.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 35ms/step - loss: 3.4557 - accuracy: 0.5231 - val_loss: 2.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.4037 - accuracy: 0.5247 - val_loss: 2.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.3595 - accuracy: 0.5270 - val_loss: 2.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.3064 - accuracy: 0.5309 - val_loss: 1.9694 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.2672 - accuracy: 0.5292 - val_loss: 1.9275 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.2235 - accuracy: 0.5298 - val_loss: 1.8856 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1842 - accuracy: 0.5269 - val_loss: 1.8449 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1453 - accuracy: 0.5267 - val_loss: 1.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1051 - accuracy: 0.5294 - val_loss: 1.7646 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0671 - accuracy: 0.5266 - val_loss: 1.7260 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0263 - accuracy: 0.5291 - val_loss: 1.6886 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9815 - accuracy: 0.5322 - val_loss: 1.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9469 - accuracy: 0.5310 - val_loss: 1.6130 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9052 - accuracy: 0.5292 - val_loss: 1.5767 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8544 - accuracy: 0.5368 - val_loss: 1.5405 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8295 - accuracy: 0.5352 - val_loss: 1.5055 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.7904 - accuracy: 0.5345 - val_loss: 1.4705 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A7CFC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A7CFC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 15.2398 - accuracy: 0.2834WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217604C14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000217604C14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 15.2379 - accuracy: 0.2834 - val_loss: 12.0838 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 13.0009 - accuracy: 0.3657 - val_loss: 10.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 11.2698 - accuracy: 0.3950 - val_loss: 8.8272 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 9.8142 - accuracy: 0.4186 - val_loss: 7.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 8.5909 - accuracy: 0.4303 - val_loss: 6.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 7.5351 - accuracy: 0.4453 - val_loss: 5.5189 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 6.6459 - accuracy: 0.4538 - val_loss: 4.7226 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.8846 - accuracy: 0.4617 - val_loss: 4.0436 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.2388 - accuracy: 0.4675 - val_loss: 3.4645 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.6852 - accuracy: 0.4753 - val_loss: 2.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.2217 - accuracy: 0.4794 - val_loss: 2.5499 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.8247 - accuracy: 0.4789 - val_loss: 2.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.4894 - accuracy: 0.4815 - val_loss: 1.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.1965 - accuracy: 0.4824 - val_loss: 1.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9401 - accuracy: 0.4905 - val_loss: 1.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7398 - accuracy: 0.4883 - val_loss: 1.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.5497 - accuracy: 0.4940 - val_loss: 1.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.4022 - accuracy: 0.4942 - val_loss: 0.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.2686 - accuracy: 0.4958 - val_loss: 0.8022 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.1688 - accuracy: 0.4947 - val_loss: 0.7040 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.0678 - accuracy: 0.4955 - val_loss: 0.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.9732 - accuracy: 0.5027 - val_loss: 0.5473 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.9119 - accuracy: 0.5000 - val_loss: 0.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8510 - accuracy: 0.5029 - val_loss: 0.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7992 - accuracy: 0.5031 - val_loss: 0.3907 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7472 - accuracy: 0.5066 - val_loss: 0.3529 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7070 - accuracy: 0.5099 - val_loss: 0.3208 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6778 - accuracy: 0.5108 - val_loss: 0.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6550 - accuracy: 0.5097 - val_loss: 0.2718 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6297 - accuracy: 0.5110 - val_loss: 0.2524 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6144 - accuracy: 0.5110 - val_loss: 0.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 1.6008 - accuracy: 0.5101 - val_loss: 0.2222 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 1.5892 - accuracy: 0.5074 - val_loss: 0.2105 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.5706 - accuracy: 0.5120 - val_loss: 0.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5491 - accuracy: 0.5145 - val_loss: 0.1915 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5335 - accuracy: 0.5206 - val_loss: 0.1837 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5323 - accuracy: 0.5189 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5408 - accuracy: 0.5119 - val_loss: 0.1747 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5258 - accuracy: 0.5152 - val_loss: 0.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5221 - accuracy: 0.5145 - val_loss: 0.1668 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5198 - accuracy: 0.5153 - val_loss: 0.1637 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5156 - accuracy: 0.5183 - val_loss: 0.1603 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5028 - accuracy: 0.5213 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5031 - accuracy: 0.5197 - val_loss: 0.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4939 - accuracy: 0.5196 - val_loss: 0.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4960 - accuracy: 0.5187 - val_loss: 0.1537 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4822 - accuracy: 0.5257 - val_loss: 0.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4760 - accuracy: 0.5264 - val_loss: 0.1498 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4696 - accuracy: 0.5273 - val_loss: 0.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4643 - accuracy: 0.5290 - val_loss: 0.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021762A5C708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021762A5C708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.2957 - accuracy: 0.2898WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A7CFA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A7CFA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.2957 - accuracy: 0.2898 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.9572 - accuracy: 0.3623 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.8530 - accuracy: 0.3952 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7900 - accuracy: 0.4151 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7424 - accuracy: 0.4301 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7098 - accuracy: 0.4388 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6878 - accuracy: 0.4504 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6592 - accuracy: 0.4566 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6383 - accuracy: 0.4650 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6192 - accuracy: 0.4711 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6050 - accuracy: 0.4773 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5880 - accuracy: 0.4806 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5796 - accuracy: 0.4865 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5614 - accuracy: 0.4905 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5480 - accuracy: 0.4965 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5368 - accuracy: 0.4991 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5220 - accuracy: 0.5067 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5137 - accuracy: 0.5085 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5040 - accuracy: 0.5128 - val_loss: 0.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4966 - accuracy: 0.5146 - val_loss: 0.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4870 - accuracy: 0.5169 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4833 - accuracy: 0.5194 - val_loss: 0.1364 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4753 - accuracy: 0.5247 - val_loss: 0.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4665 - accuracy: 0.5258 - val_loss: 0.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4571 - accuracy: 0.5309 - val_loss: 0.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4506 - accuracy: 0.5300 - val_loss: 0.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4462 - accuracy: 0.5308 - val_loss: 0.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4409 - accuracy: 0.5336 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4332 - accuracy: 0.5363 - val_loss: 0.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4267 - accuracy: 0.5372 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4249 - accuracy: 0.5381 - val_loss: 0.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.4087 - accuracy: 0.5442 - val_loss: 0.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4056 - accuracy: 0.5467 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4043 - accuracy: 0.5477 - val_loss: 0.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4008 - accuracy: 0.5455 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3940 - accuracy: 0.5507 - val_loss: 0.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3940 - accuracy: 0.5497 - val_loss: 0.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3814 - accuracy: 0.5541 - val_loss: 0.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3830 - accuracy: 0.5538 - val_loss: 0.1342 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3780 - accuracy: 0.5548 - val_loss: 0.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3737 - accuracy: 0.5578 - val_loss: 0.1339 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3595 - accuracy: 0.5607 - val_loss: 0.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3593 - accuracy: 0.5631 - val_loss: 0.1337 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3580 - accuracy: 0.5637 - val_loss: 0.1336 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3547 - accuracy: 0.5633 - val_loss: 0.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.3538 - accuracy: 0.5632 - val_loss: 0.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3518 - accuracy: 0.5633 - val_loss: 0.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3450 - accuracy: 0.5647 - val_loss: 0.1331 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3395 - accuracy: 0.5683 - val_loss: 0.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3360 - accuracy: 0.5702 - val_loss: 0.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A847558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A847558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.2055 - accuracy: 0.2770WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757CB5948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757CB5948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.2048 - accuracy: 0.2771 - val_loss: 4.1471e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8287 - accuracy: 0.3623 - val_loss: 4.1479e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7173 - accuracy: 0.3928 - val_loss: 4.1484e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6497 - accuracy: 0.4132 - val_loss: 4.1487e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6055 - accuracy: 0.4289 - val_loss: 4.1491e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5622 - accuracy: 0.4428 - val_loss: 4.1494e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5378 - accuracy: 0.4538 - val_loss: 4.1497e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5220 - accuracy: 0.4573 - val_loss: 4.1500e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4972 - accuracy: 0.4665 - val_loss: 4.1504e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4820 - accuracy: 0.4720 - val_loss: 4.1508e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4674 - accuracy: 0.4756 - val_loss: 4.1512e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4487 - accuracy: 0.4852 - val_loss: 4.1516e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4335 - accuracy: 0.4885 - val_loss: 4.1520e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4233 - accuracy: 0.4918 - val_loss: 4.1524e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4120 - accuracy: 0.4950 - val_loss: 4.1529e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.4010 - accuracy: 0.4977 - val_loss: 4.1533e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 1.3883 - accuracy: 0.5032 - val_loss: 4.1539e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 1.3803 - accuracy: 0.5051 - val_loss: 4.1543e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3688 - accuracy: 0.5124 - val_loss: 4.1548e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.3665 - accuracy: 0.5109 - val_loss: 4.1554e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.3557 - accuracy: 0.5155 - val_loss: 4.1559e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.3416 - accuracy: 0.5210 - val_loss: 4.1564e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.3356 - accuracy: 0.5224 - val_loss: 4.1570e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3294 - accuracy: 0.5247 - val_loss: 4.1575e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3264 - accuracy: 0.5256 - val_loss: 4.1581e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3168 - accuracy: 0.5301 - val_loss: 4.1586e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3101 - accuracy: 0.5307 - val_loss: 4.1593e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3121 - accuracy: 0.5311 - val_loss: 4.1599e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.3038 - accuracy: 0.5321 - val_loss: 4.1605e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2941 - accuracy: 0.5391 - val_loss: 4.1612e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2840 - accuracy: 0.5402 - val_loss: 4.1619e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2761 - accuracy: 0.5441 - val_loss: 4.1625e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2714 - accuracy: 0.5440 - val_loss: 4.1633e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.2640 - accuracy: 0.5454 - val_loss: 4.1639e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2544 - accuracy: 0.5520 - val_loss: 4.1646e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2517 - accuracy: 0.5531 - val_loss: 4.1654e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2492 - accuracy: 0.5509 - val_loss: 4.1662e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2428 - accuracy: 0.5543 - val_loss: 4.1669e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2416 - accuracy: 0.5563 - val_loss: 4.1677e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2386 - accuracy: 0.5551 - val_loss: 4.1685e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2360 - accuracy: 0.5572 - val_loss: 4.1693e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2297 - accuracy: 0.5585 - val_loss: 4.1701e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2187 - accuracy: 0.5634 - val_loss: 4.1709e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2133 - accuracy: 0.5665 - val_loss: 4.1717e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2076 - accuracy: 0.5673 - val_loss: 4.1727e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2069 - accuracy: 0.5664 - val_loss: 4.1735e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2152 - accuracy: 0.5652 - val_loss: 4.1745e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.2078 - accuracy: 0.5665 - val_loss: 4.1754e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.2042 - accuracy: 0.5686 - val_loss: 4.1763e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.1968 - accuracy: 0.5715 - val_loss: 4.1771e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757039EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757039EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 201.6733 - accuracy: 0.2228WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB61EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002174AB61EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 201.4158 - accuracy: 0.2228 - val_loss: 37.7440 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 20.7143 - accuracy: 0.2349 - val_loss: 7.5023 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 6.6966 - accuracy: 0.2576 - val_loss: 2.8599 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.0296 - accuracy: 0.2577 - val_loss: 1.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3813 - accuracy: 0.2588 - val_loss: 1.2491 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1879 - accuracy: 0.2586 - val_loss: 1.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0942 - accuracy: 0.2601 - val_loss: 1.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0890 - accuracy: 0.2597 - val_loss: 1.0530 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.0487 - accuracy: 0.2638 - val_loss: 1.0337 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.0364 - accuracy: 0.2585 - val_loss: 1.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0203 - accuracy: 0.2643 - val_loss: 0.9620 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9846 - accuracy: 0.2599 - val_loss: 1.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0145 - accuracy: 0.2576 - val_loss: 0.9804 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9588 - accuracy: 0.2615 - val_loss: 0.9266 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 2.9241 - accuracy: 0.2625 - val_loss: 0.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9227 - accuracy: 0.2650 - val_loss: 0.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9633 - accuracy: 0.2629 - val_loss: 0.9289 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9401 - accuracy: 0.2620 - val_loss: 0.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9486 - accuracy: 0.2656 - val_loss: 0.9959 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9364 - accuracy: 0.2623 - val_loss: 0.9697 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9371 - accuracy: 0.2624 - val_loss: 0.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9413 - accuracy: 0.2632 - val_loss: 0.9350 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9206 - accuracy: 0.2632 - val_loss: 0.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9225 - accuracy: 0.2625 - val_loss: 0.9527 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9202 - accuracy: 0.2629 - val_loss: 0.9695 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9367 - accuracy: 0.2630 - val_loss: 0.9311 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9125 - accuracy: 0.2624 - val_loss: 0.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8830 - accuracy: 0.2675 - val_loss: 0.9013 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8927 - accuracy: 0.2661 - val_loss: 0.8963 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8988 - accuracy: 0.2685 - val_loss: 0.9123 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9018 - accuracy: 0.2628 - val_loss: 0.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9006 - accuracy: 0.2633 - val_loss: 0.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9001 - accuracy: 0.2641 - val_loss: 0.9372 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8874 - accuracy: 0.2677 - val_loss: 0.9450 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.8773 - accuracy: 0.2640 - val_loss: 0.8597 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8615 - accuracy: 0.2642 - val_loss: 0.8860 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8696 - accuracy: 0.2660 - val_loss: 0.8683 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8808 - accuracy: 0.2622 - val_loss: 0.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8549 - accuracy: 0.2649 - val_loss: 0.8764 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8563 - accuracy: 0.2675 - val_loss: 0.8593 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8928 - accuracy: 0.2640 - val_loss: 0.9764 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8747 - accuracy: 0.2651 - val_loss: 0.8331 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8702 - accuracy: 0.2652 - val_loss: 0.9036 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8665 - accuracy: 0.2685 - val_loss: 0.8757 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8510 - accuracy: 0.2671 - val_loss: 0.8603 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8724 - accuracy: 0.2668 - val_loss: 0.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8762 - accuracy: 0.2650 - val_loss: 0.8490 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8782 - accuracy: 0.2614 - val_loss: 0.8347 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8753 - accuracy: 0.2616 - val_loss: 0.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8643 - accuracy: 0.2638 - val_loss: 0.8427 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757C425E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021757C425E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/196 [============================>.] - ETA: 0s - loss: 202.1940 - accuracy: 0.2326WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762CA2288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762CA2288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 201.9433 - accuracy: 0.2326 - val_loss: 42.5511 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 23.8761 - accuracy: 0.2340 - val_loss: 9.7282 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 7.7061 - accuracy: 0.2548 - val_loss: 2.9611 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 4.1473 - accuracy: 0.2638 - val_loss: 1.6936 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 3.4630 - accuracy: 0.2644 - val_loss: 1.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.2738 - accuracy: 0.2660 - val_loss: 1.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.2024 - accuracy: 0.2642 - val_loss: 1.1480 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1246 - accuracy: 0.2641 - val_loss: 1.1149 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1036 - accuracy: 0.2631 - val_loss: 1.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0635 - accuracy: 0.2667 - val_loss: 1.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0701 - accuracy: 0.2656 - val_loss: 1.0403 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0525 - accuracy: 0.2660 - val_loss: 1.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0211 - accuracy: 0.2646 - val_loss: 1.0191 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0198 - accuracy: 0.2663 - val_loss: 1.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0155 - accuracy: 0.2694 - val_loss: 1.0204 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0149 - accuracy: 0.2696 - val_loss: 0.9661 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0345 - accuracy: 0.2687 - val_loss: 1.0337 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0064 - accuracy: 0.2682 - val_loss: 0.9737 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9769 - accuracy: 0.2692 - val_loss: 0.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9960 - accuracy: 0.2654 - val_loss: 0.9721 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9812 - accuracy: 0.2660 - val_loss: 0.9637 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9778 - accuracy: 0.2682 - val_loss: 0.9783 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9684 - accuracy: 0.2676 - val_loss: 1.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9375 - accuracy: 0.2658 - val_loss: 0.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9365 - accuracy: 0.2680 - val_loss: 0.9670 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9270 - accuracy: 0.2666 - val_loss: 0.9460 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9280 - accuracy: 0.2683 - val_loss: 0.8739 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9195 - accuracy: 0.2677 - val_loss: 0.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9407 - accuracy: 0.2664 - val_loss: 0.9567 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9392 - accuracy: 0.2694 - val_loss: 0.9472 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9284 - accuracy: 0.2637 - val_loss: 0.9247 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9414 - accuracy: 0.2668 - val_loss: 0.9233 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9116 - accuracy: 0.2708 - val_loss: 0.9454 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9513 - accuracy: 0.2657 - val_loss: 0.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9387 - accuracy: 0.2647 - val_loss: 0.8966 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8905 - accuracy: 0.2719 - val_loss: 0.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.9034 - accuracy: 0.2703 - val_loss: 0.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9178 - accuracy: 0.2687 - val_loss: 0.8795 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9048 - accuracy: 0.2659 - val_loss: 1.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9397 - accuracy: 0.2669 - val_loss: 0.9219 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9183 - accuracy: 0.2659 - val_loss: 0.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8901 - accuracy: 0.2667 - val_loss: 0.8667 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8885 - accuracy: 0.2670 - val_loss: 0.8883 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8852 - accuracy: 0.2659 - val_loss: 0.9377 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8964 - accuracy: 0.2690 - val_loss: 0.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9057 - accuracy: 0.2684 - val_loss: 0.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8928 - accuracy: 0.2703 - val_loss: 0.8703 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9214 - accuracy: 0.2653 - val_loss: 0.9017 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8984 - accuracy: 0.2701 - val_loss: 0.9024 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8788 - accuracy: 0.2717 - val_loss: 0.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021756EFACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021756EFACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 202.3258 - accuracy: 0.2283WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A77E168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A77E168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 202.0746 - accuracy: 0.2283 - val_loss: 42.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 23.8971 - accuracy: 0.2369 - val_loss: 9.6050 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 7.7005 - accuracy: 0.2541 - val_loss: 3.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 4.2498 - accuracy: 0.2609 - val_loss: 1.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4079 - accuracy: 0.2672 - val_loss: 1.2210 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.2306 - accuracy: 0.2635 - val_loss: 1.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1303 - accuracy: 0.2641 - val_loss: 1.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0599 - accuracy: 0.2655 - val_loss: 1.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0384 - accuracy: 0.2657 - val_loss: 0.9571 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0115 - accuracy: 0.2636 - val_loss: 0.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.0217 - accuracy: 0.2662 - val_loss: 0.9823 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0152 - accuracy: 0.2668 - val_loss: 1.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0035 - accuracy: 0.2701 - val_loss: 0.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9734 - accuracy: 0.2652 - val_loss: 1.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0050 - accuracy: 0.2617 - val_loss: 0.9723 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9342 - accuracy: 0.2629 - val_loss: 0.8886 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9387 - accuracy: 0.2645 - val_loss: 0.9479 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9645 - accuracy: 0.2658 - val_loss: 0.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9606 - accuracy: 0.2656 - val_loss: 0.9632 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9788 - accuracy: 0.2663 - val_loss: 0.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9547 - accuracy: 0.2599 - val_loss: 0.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9334 - accuracy: 0.2628 - val_loss: 0.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9482 - accuracy: 0.2637 - val_loss: 0.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9073 - accuracy: 0.2683 - val_loss: 0.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9110 - accuracy: 0.2650 - val_loss: 0.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9052 - accuracy: 0.2667 - val_loss: 0.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8885 - accuracy: 0.2656 - val_loss: 0.8626 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9047 - accuracy: 0.2629 - val_loss: 0.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8935 - accuracy: 0.2620 - val_loss: 0.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8897 - accuracy: 0.2651 - val_loss: 0.9459 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9137 - accuracy: 0.2637 - val_loss: 0.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8896 - accuracy: 0.2656 - val_loss: 0.8726 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.9029 - accuracy: 0.2634 - val_loss: 0.9543 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8942 - accuracy: 0.2615 - val_loss: 0.8753 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8691 - accuracy: 0.2620 - val_loss: 0.8717 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8931 - accuracy: 0.2639 - val_loss: 0.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8748 - accuracy: 0.2622 - val_loss: 0.8897 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8583 - accuracy: 0.2618 - val_loss: 0.8156 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.8570 - accuracy: 0.2635 - val_loss: 0.8756 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 2.8822 - accuracy: 0.2679 - val_loss: 0.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 8s 38ms/step - loss: 2.8734 - accuracy: 0.2663 - val_loss: 0.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 38ms/step - loss: 2.8612 - accuracy: 0.2651 - val_loss: 0.8400 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.8885 - accuracy: 0.2632 - val_loss: 0.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.8707 - accuracy: 0.2687 - val_loss: 0.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8557 - accuracy: 0.2664 - val_loss: 0.8617 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8439 - accuracy: 0.2673 - val_loss: 0.8353 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.8606 - accuracy: 0.2632 - val_loss: 0.8255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8286 - accuracy: 0.2652 - val_loss: 0.8370 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8150 - accuracy: 0.2679 - val_loss: 0.8412 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.8593 - accuracy: 0.2596 - val_loss: 0.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021762C8BEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021762C8BEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 19.3085 - accuracy: 0.2246WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021764DCB708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021764DCB708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 19.3061 - accuracy: 0.2247 - val_loss: 15.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 16.3607 - accuracy: 0.2956 - val_loss: 13.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 14.0660 - accuracy: 0.3314 - val_loss: 11.2057 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 12.1481 - accuracy: 0.3566 - val_loss: 9.5145 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 10.5288 - accuracy: 0.3737 - val_loss: 8.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 9.1615 - accuracy: 0.3838 - val_loss: 6.8413 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 8.0018 - accuracy: 0.3942 - val_loss: 5.7930 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 7.0105 - accuracy: 0.4008 - val_loss: 4.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 6.1712 - accuracy: 0.4060 - val_loss: 4.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 5.4587 - accuracy: 0.4111 - val_loss: 3.4945 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.8529 - accuracy: 0.4128 - val_loss: 2.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 4.3455 - accuracy: 0.4170 - val_loss: 2.4804 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.9151 - accuracy: 0.4139 - val_loss: 2.0848 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.5590 - accuracy: 0.4128 - val_loss: 1.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.2430 - accuracy: 0.4157 - val_loss: 1.4662 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9776 - accuracy: 0.4148 - val_loss: 1.2274 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.7496 - accuracy: 0.4173 - val_loss: 1.0254 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.5609 - accuracy: 0.4196 - val_loss: 0.8569 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.4121 - accuracy: 0.4189 - val_loss: 0.7172 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.2878 - accuracy: 0.4179 - val_loss: 0.6008 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.1790 - accuracy: 0.4160 - val_loss: 0.5052 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.0980 - accuracy: 0.4154 - val_loss: 0.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.0157 - accuracy: 0.4213 - val_loss: 0.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.9603 - accuracy: 0.4188 - val_loss: 0.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.9068 - accuracy: 0.4239 - val_loss: 0.2740 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8801 - accuracy: 0.4213 - val_loss: 0.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8747 - accuracy: 0.4148 - val_loss: 0.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.8580 - accuracy: 0.4130 - val_loss: 0.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8385 - accuracy: 0.4198 - val_loss: 0.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8222 - accuracy: 0.4237 - val_loss: 0.2134 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8181 - accuracy: 0.4260 - val_loss: 0.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8116 - accuracy: 0.4264 - val_loss: 0.2071 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8030 - accuracy: 0.4295 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7908 - accuracy: 0.4320 - val_loss: 0.2011 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7960 - accuracy: 0.4310 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8135 - accuracy: 0.4261 - val_loss: 0.2093 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8016 - accuracy: 0.4293 - val_loss: 0.2064 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7949 - accuracy: 0.4316 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7923 - accuracy: 0.4330 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7846 - accuracy: 0.4364 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7978 - accuracy: 0.4297 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7984 - accuracy: 0.4324 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.8019 - accuracy: 0.4292 - val_loss: 0.2054 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7933 - accuracy: 0.4335 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7959 - accuracy: 0.4319 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7848 - accuracy: 0.4361 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7864 - accuracy: 0.4340 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7865 - accuracy: 0.4357 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7898 - accuracy: 0.4356 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7998 - accuracy: 0.4291 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002176C2A0948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002176C2A0948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.6284 - accuracy: 0.2278WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762C8B708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762C8B708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 6.6276 - accuracy: 0.2278 - val_loss: 4.0841 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 6.0697 - accuracy: 0.2964 - val_loss: 4.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.8638 - accuracy: 0.3292 - val_loss: 3.9400 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 5.7134 - accuracy: 0.3523 - val_loss: 3.8685 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.5914 - accuracy: 0.3698 - val_loss: 3.7977 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.4921 - accuracy: 0.3786 - val_loss: 3.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.3932 - accuracy: 0.3889 - val_loss: 3.6582 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.3027 - accuracy: 0.3993 - val_loss: 3.5895 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.2222 - accuracy: 0.4029 - val_loss: 3.5218 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.1380 - accuracy: 0.4112 - val_loss: 3.4548 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.0575 - accuracy: 0.4157 - val_loss: 3.3886 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.9805 - accuracy: 0.4166 - val_loss: 3.3233 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.9046 - accuracy: 0.4225 - val_loss: 3.2586 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.8329 - accuracy: 0.4267 - val_loss: 3.1947 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.7531 - accuracy: 0.4302 - val_loss: 3.1315 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 4.6884 - accuracy: 0.4321 - val_loss: 3.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.6186 - accuracy: 0.4364 - val_loss: 3.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.5501 - accuracy: 0.4396 - val_loss: 2.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.4868 - accuracy: 0.4386 - val_loss: 2.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.4184 - accuracy: 0.4385 - val_loss: 2.8275 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.3605 - accuracy: 0.4422 - val_loss: 2.7691 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.2962 - accuracy: 0.4460 - val_loss: 2.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.2330 - accuracy: 0.4447 - val_loss: 2.6546 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.1778 - accuracy: 0.4452 - val_loss: 2.5987 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 4.1172 - accuracy: 0.4459 - val_loss: 2.5435 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 8s 39ms/step - loss: 4.0561 - accuracy: 0.4517 - val_loss: 2.4887 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.9985 - accuracy: 0.4520 - val_loss: 2.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.9459 - accuracy: 0.4497 - val_loss: 2.3819 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.8827 - accuracy: 0.4561 - val_loss: 2.3290 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.8302 - accuracy: 0.4527 - val_loss: 2.2770 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7669 - accuracy: 0.4572 - val_loss: 2.2265 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.7284 - accuracy: 0.4552 - val_loss: 2.1769 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.6834 - accuracy: 0.4532 - val_loss: 2.1279 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.6259 - accuracy: 0.4546 - val_loss: 2.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5749 - accuracy: 0.4554 - val_loss: 2.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5299 - accuracy: 0.4576 - val_loss: 1.9838 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4806 - accuracy: 0.4571 - val_loss: 1.9379 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.4398 - accuracy: 0.4562 - val_loss: 1.8923 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3995 - accuracy: 0.4557 - val_loss: 1.8477 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.3488 - accuracy: 0.4556 - val_loss: 1.8035 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.3123 - accuracy: 0.4554 - val_loss: 1.7606 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.2622 - accuracy: 0.4592 - val_loss: 1.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.2229 - accuracy: 0.4582 - val_loss: 1.6763 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.1765 - accuracy: 0.4540 - val_loss: 1.6352 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.1307 - accuracy: 0.4577 - val_loss: 1.5943 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0832 - accuracy: 0.4614 - val_loss: 1.5549 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0456 - accuracy: 0.4602 - val_loss: 1.5162 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.0120 - accuracy: 0.4565 - val_loss: 1.4786 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9856 - accuracy: 0.4552 - val_loss: 1.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.9473 - accuracy: 0.4554 - val_loss: 1.4052 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021762A21EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021762A21EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.4567 - accuracy: 0.2315WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762F5C708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762F5C708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 6.4560 - accuracy: 0.2315 - val_loss: 3.9462 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.9378 - accuracy: 0.2972 - val_loss: 3.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.7326 - accuracy: 0.3273 - val_loss: 3.8146 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.5928 - accuracy: 0.3503 - val_loss: 3.7492 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 5.4836 - accuracy: 0.3673 - val_loss: 3.6845 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 5.3817 - accuracy: 0.3806 - val_loss: 3.6203 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 5.2958 - accuracy: 0.3902 - val_loss: 3.5568 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 5.2099 - accuracy: 0.3958 - val_loss: 3.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 5.1291 - accuracy: 0.4069 - val_loss: 3.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 5.0490 - accuracy: 0.4106 - val_loss: 3.3701 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.9776 - accuracy: 0.4153 - val_loss: 3.3092 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.9027 - accuracy: 0.4206 - val_loss: 3.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.8346 - accuracy: 0.4231 - val_loss: 3.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.7640 - accuracy: 0.4290 - val_loss: 3.1307 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 4.7029 - accuracy: 0.4275 - val_loss: 3.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.6354 - accuracy: 0.4316 - val_loss: 3.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 4.5725 - accuracy: 0.4349 - val_loss: 2.9580 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 4.5085 - accuracy: 0.4339 - val_loss: 2.9018 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.4537 - accuracy: 0.4345 - val_loss: 2.8461 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.3855 - accuracy: 0.4391 - val_loss: 2.7912 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.3302 - accuracy: 0.4408 - val_loss: 2.7370 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.2691 - accuracy: 0.4436 - val_loss: 2.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.2154 - accuracy: 0.4440 - val_loss: 2.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.1512 - accuracy: 0.4464 - val_loss: 2.5782 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.0990 - accuracy: 0.4477 - val_loss: 2.5265 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 4.0422 - accuracy: 0.4500 - val_loss: 2.4758 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.9934 - accuracy: 0.4491 - val_loss: 2.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.9402 - accuracy: 0.4478 - val_loss: 2.3755 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.8904 - accuracy: 0.4483 - val_loss: 2.3270 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.8438 - accuracy: 0.4500 - val_loss: 2.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.7954 - accuracy: 0.4501 - val_loss: 2.2316 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.7455 - accuracy: 0.4487 - val_loss: 2.1847 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.6939 - accuracy: 0.4524 - val_loss: 2.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.6429 - accuracy: 0.4551 - val_loss: 2.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5980 - accuracy: 0.4581 - val_loss: 2.0475 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5562 - accuracy: 0.4545 - val_loss: 2.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.5021 - accuracy: 0.4576 - val_loss: 1.9593 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.4565 - accuracy: 0.4589 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 3.4248 - accuracy: 0.4548 - val_loss: 1.8737 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.3837 - accuracy: 0.4539 - val_loss: 1.8323 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.3382 - accuracy: 0.4567 - val_loss: 1.7917 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 3.2940 - accuracy: 0.4570 - val_loss: 1.7512 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 3.2630 - accuracy: 0.4509 - val_loss: 1.7112 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.2189 - accuracy: 0.4541 - val_loss: 1.6720 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.1756 - accuracy: 0.4575 - val_loss: 1.6337 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.1435 - accuracy: 0.4549 - val_loss: 1.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0990 - accuracy: 0.4559 - val_loss: 1.5588 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0537 - accuracy: 0.4593 - val_loss: 1.5219 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.0243 - accuracy: 0.4581 - val_loss: 1.4870 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.9763 - accuracy: 0.4607 - val_loss: 1.4512 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217606F4048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000217606F4048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 15.5361 - accuracy: 0.2269WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757C42168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021757C42168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 15.5344 - accuracy: 0.2269 - val_loss: 12.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 13.1998 - accuracy: 0.3043 - val_loss: 10.3259 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 11.4411 - accuracy: 0.3283 - val_loss: 8.8239 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 9.9683 - accuracy: 0.3569 - val_loss: 7.5407 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 8.7297 - accuracy: 0.3719 - val_loss: 6.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 7.6800 - accuracy: 0.3841 - val_loss: 5.5097 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 6.7972 - accuracy: 0.3937 - val_loss: 4.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 6.0300 - accuracy: 0.4054 - val_loss: 4.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 5.3883 - accuracy: 0.4112 - val_loss: 3.4505 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 8s 39ms/step - loss: 4.8382 - accuracy: 0.4114 - val_loss: 2.9552 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 4.3689 - accuracy: 0.4183 - val_loss: 2.5333 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 3.9785 - accuracy: 0.4183 - val_loss: 2.1734 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 3.6369 - accuracy: 0.4217 - val_loss: 1.8667 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 3.3459 - accuracy: 0.4217 - val_loss: 1.6056 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 3.1090 - accuracy: 0.4235 - val_loss: 1.3835 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 2.8967 - accuracy: 0.4247 - val_loss: 1.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.7115 - accuracy: 0.4297 - val_loss: 1.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.5479 - accuracy: 0.4319 - val_loss: 0.8927 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.4181 - accuracy: 0.4314 - val_loss: 0.7749 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.3110 - accuracy: 0.4323 - val_loss: 0.6748 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.2124 - accuracy: 0.4360 - val_loss: 0.5896 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 2.1403 - accuracy: 0.4304 - val_loss: 0.5171 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.0704 - accuracy: 0.4328 - val_loss: 0.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.0078 - accuracy: 0.4347 - val_loss: 0.4029 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.9582 - accuracy: 0.4353 - val_loss: 0.3583 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.9216 - accuracy: 0.4379 - val_loss: 0.3208 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8768 - accuracy: 0.4381 - val_loss: 0.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.8375 - accuracy: 0.4442 - val_loss: 0.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8026 - accuracy: 0.4469 - val_loss: 0.2373 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7796 - accuracy: 0.4446 - val_loss: 0.2178 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7544 - accuracy: 0.4483 - val_loss: 0.2014 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7536 - accuracy: 0.4420 - val_loss: 0.1884 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7388 - accuracy: 0.4463 - val_loss: 0.1770 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7381 - accuracy: 0.4401 - val_loss: 0.1678 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7326 - accuracy: 0.4371 - val_loss: 0.1600 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7357 - accuracy: 0.4346 - val_loss: 0.1537 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7215 - accuracy: 0.4396 - val_loss: 0.1476 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7214 - accuracy: 0.4378 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7047 - accuracy: 0.4401 - val_loss: 0.1364 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7078 - accuracy: 0.4388 - val_loss: 0.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6854 - accuracy: 0.4442 - val_loss: 0.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6821 - accuracy: 0.4462 - val_loss: 0.1264 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.6825 - accuracy: 0.4455 - val_loss: 0.1243 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6831 - accuracy: 0.4427 - val_loss: 0.1224 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6773 - accuracy: 0.4438 - val_loss: 0.1203 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6817 - accuracy: 0.4422 - val_loss: 0.1182 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6834 - accuracy: 0.4423 - val_loss: 0.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6803 - accuracy: 0.4429 - val_loss: 0.1160 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6718 - accuracy: 0.4460 - val_loss: 0.1152 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6672 - accuracy: 0.4459 - val_loss: 0.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A3DAAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002174A3DAAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.6608 - accuracy: 0.2257WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A7CC8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002175A7CC8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.6599 - accuracy: 0.2258 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 2.1869 - accuracy: 0.2943 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.0347 - accuracy: 0.3292 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.9557 - accuracy: 0.3517 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.9056 - accuracy: 0.3667 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.8701 - accuracy: 0.3808 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.8418 - accuracy: 0.3918 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.8249 - accuracy: 0.3966 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.8080 - accuracy: 0.4036 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.7925 - accuracy: 0.4051 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7775 - accuracy: 0.4127 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7598 - accuracy: 0.4159 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7563 - accuracy: 0.4225 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7404 - accuracy: 0.4266 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7348 - accuracy: 0.4293 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7248 - accuracy: 0.4363 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.7172 - accuracy: 0.4324 - val_loss: 0.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7084 - accuracy: 0.4390 - val_loss: 0.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.7021 - accuracy: 0.4411 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6926 - accuracy: 0.4454 - val_loss: 0.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6880 - accuracy: 0.4483 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6766 - accuracy: 0.4500 - val_loss: 0.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6740 - accuracy: 0.4510 - val_loss: 0.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6718 - accuracy: 0.4508 - val_loss: 0.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6670 - accuracy: 0.4521 - val_loss: 0.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6585 - accuracy: 0.4551 - val_loss: 0.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6555 - accuracy: 0.4566 - val_loss: 0.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6540 - accuracy: 0.4574 - val_loss: 0.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6496 - accuracy: 0.4563 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6404 - accuracy: 0.4597 - val_loss: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6330 - accuracy: 0.4630 - val_loss: 0.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6311 - accuracy: 0.4666 - val_loss: 0.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6200 - accuracy: 0.4716 - val_loss: 0.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6243 - accuracy: 0.4686 - val_loss: 0.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.6149 - accuracy: 0.4726 - val_loss: 0.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6049 - accuracy: 0.4732 - val_loss: 0.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6000 - accuracy: 0.4753 - val_loss: 0.1337 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5964 - accuracy: 0.4782 - val_loss: 0.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5946 - accuracy: 0.4748 - val_loss: 0.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5920 - accuracy: 0.4786 - val_loss: 0.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5852 - accuracy: 0.4784 - val_loss: 0.1331 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5822 - accuracy: 0.4815 - val_loss: 0.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5785 - accuracy: 0.4811 - val_loss: 0.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.5785 - accuracy: 0.4812 - val_loss: 0.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5702 - accuracy: 0.4868 - val_loss: 0.1325 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5659 - accuracy: 0.4894 - val_loss: 0.1323 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.5694 - accuracy: 0.4840 - val_loss: 0.1322 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.5626 - accuracy: 0.4895 - val_loss: 0.1321 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.5562 - accuracy: 0.4910 - val_loss: 0.1319 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.5557 - accuracy: 0.4895 - val_loss: 0.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A4F0708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002175A4F0708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/196 [============================>.] - ETA: 0s - loss: 2.4879 - accuracy: 0.2288WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762AF6798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021762AF6798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 2.4871 - accuracy: 0.2289 - val_loss: 4.1443e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 2.0242 - accuracy: 0.3012 - val_loss: 4.1452e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8861 - accuracy: 0.3277 - val_loss: 4.1456e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.8127 - accuracy: 0.3492 - val_loss: 4.1458e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7710 - accuracy: 0.3623 - val_loss: 4.1460e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7347 - accuracy: 0.3769 - val_loss: 4.1461e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7126 - accuracy: 0.3847 - val_loss: 4.1463e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6876 - accuracy: 0.3962 - val_loss: 4.1465e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6670 - accuracy: 0.4049 - val_loss: 4.1467e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6501 - accuracy: 0.4135 - val_loss: 4.1469e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6419 - accuracy: 0.4122 - val_loss: 4.1471e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6300 - accuracy: 0.4171 - val_loss: 4.1473e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.6197 - accuracy: 0.4190 - val_loss: 4.1475e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.6105 - accuracy: 0.4271 - val_loss: 4.1478e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6009 - accuracy: 0.4272 - val_loss: 4.1480e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5964 - accuracy: 0.4298 - val_loss: 4.1483e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5815 - accuracy: 0.4359 - val_loss: 4.1485e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5722 - accuracy: 0.4386 - val_loss: 4.1488e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.5660 - accuracy: 0.4414 - val_loss: 4.1491e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5562 - accuracy: 0.4444 - val_loss: 4.1494e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5521 - accuracy: 0.4456 - val_loss: 4.1498e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5414 - accuracy: 0.4503 - val_loss: 4.1501e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5326 - accuracy: 0.4525 - val_loss: 4.1505e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5315 - accuracy: 0.4503 - val_loss: 4.1509e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5292 - accuracy: 0.4507 - val_loss: 4.1512e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5196 - accuracy: 0.4551 - val_loss: 4.1515e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5155 - accuracy: 0.4608 - val_loss: 4.1518e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5097 - accuracy: 0.4605 - val_loss: 4.1522e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.5006 - accuracy: 0.4621 - val_loss: 4.1526e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4965 - accuracy: 0.4643 - val_loss: 4.1529e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4947 - accuracy: 0.4647 - val_loss: 4.1533e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4922 - accuracy: 0.4670 - val_loss: 4.1537e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4917 - accuracy: 0.4651 - val_loss: 4.1541e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4871 - accuracy: 0.4686 - val_loss: 4.1546e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4818 - accuracy: 0.4709 - val_loss: 4.1550e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4772 - accuracy: 0.4702 - val_loss: 4.1554e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4727 - accuracy: 0.4751 - val_loss: 4.1558e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4688 - accuracy: 0.4753 - val_loss: 4.1563e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4591 - accuracy: 0.4788 - val_loss: 4.1568e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4568 - accuracy: 0.4782 - val_loss: 4.1573e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4542 - accuracy: 0.4798 - val_loss: 4.1577e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4511 - accuracy: 0.4820 - val_loss: 4.1582e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4518 - accuracy: 0.4778 - val_loss: 4.1587e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4444 - accuracy: 0.4846 - val_loss: 4.1592e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4395 - accuracy: 0.4857 - val_loss: 4.1597e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.4329 - accuracy: 0.4862 - val_loss: 4.1602e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.4276 - accuracy: 0.4883 - val_loss: 4.1607e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 36ms/step - loss: 1.4220 - accuracy: 0.4921 - val_loss: 4.1612e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4167 - accuracy: 0.4927 - val_loss: 4.1617e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4166 - accuracy: 0.4932 - val_loss: 4.1623e-04 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for batch_size in BATCH_SIZE:\n",
    "    for drp_rate in Dropout_EXP:\n",
    "        for l1_ratio in l1_exp:\n",
    "            for l2_ratio in l2_exp:\n",
    "                model = build_mlp(input_shape=x_train.shape[1:], l1_ratio=l1_ratio, l2_ratio=l2_ratio, drp_rate=drp_rate)\n",
    "                opt = keras.optimizers.SGD(lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "                model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                model.fit(x_train, y_train,\n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data=[x_test, y_test],\n",
    "                          shuffle=True)\n",
    "                train_loss = model.history.history[\"loss\"]\n",
    "                valid_loss = model.history.history[\"val_loss\"]\n",
    "                train_acc = model.history.history[\"accuracy\"]\n",
    "                valid_acc = model.history.history[\"val_accuracy\"]\n",
    "\n",
    "                exp_name_tag = \"exp-bn-%s-drp-%s-l1-%s-l2-%s\" % (str(batch_size), str(drp_rate), str(l1_ratio), str(l2_ratio))\n",
    "                results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                         'valid-loss': valid_loss,\n",
    "                                         'train-acc': train_acc,\n",
    "                                         'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAmkCAYAAAAxxQOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeXwV1fmHn3P37BskBAIECGACJCC7CBVpBJeCWEQUK0ppQWxrrQu4oGDlp1Zr1aqtsijuihuuIIJoXcq+RRYDhCUBErInN3e/5/fHmZsdCCpbPU8+h7kzc2bmzCTc75z3vOd9hZQSjUaj0Wg0pw/T6W6ARqPRaDQ/d7QYazQajUZzmtFirNFoNBrNaUaLsUaj0Wg0pxktxhqNRqPRnGa0GGs0Go1Gc5rRYqzRaDQazWlGi7FGc4YhhFglhCgTQthPd1s0Gs2pQYuxRnMGIYRIBYYCEhh9Cq9rOVXX0mg0TdFirNGcWVwH/Bd4AZgU2iiECBNC/F0IsU8IUSGE+EoIEWbsO18I8Y0QolwIcUAIcb2xfZUQYkq9c1wvhPiq3roUQtwkhMgFco1tTxjnqBRCrBdCDK1X3yyEuEsIsVsIUWXsby+EeFoI8ff6NyGE+EAI8eeT8YA0mv9FtBhrNGcW1wGvGGWkECLJ2P4o0Bc4D4gH7gCCQogOwCfAP4HWQG9g0wlc73JgIJBhrK81zhEPvAosFkI4jH1/Aa4GLgGigclADbAIuFoIYQIQQrQCRgCvnciNazQ/Z7QYazRnCEKI84GOwJtSyvXAbuAaQ+QmAzdLKQuklAEp5TdSSg8wEfhMSvmalNInpSyRUp6IGD8opSyVUroApJQvG+fwSyn/DtiB7kbdKcA9UsqdUrHZqLsGqEAJMMAEYJWUsvBHPhKN5meDFmON5sxhEvCplLLYWH/V2NYKcKDEuTHtj7K9pRyovyKEuFUIsd0whZcDMcb1j3etRcC1xudrgZd+RJs0mp8d2mlDozkDMMZ/xwNmIcRhY7MdiAWSATfQBdjc6NADwICjnNYJhNdbb9NMndq0bcb48AxUD/c7KWVQCFEGiHrX6gLkNHOel4EcIUQWkA68d5Q2aTSaZtA9Y43mzOByIIAau+1tlHTgP6hx5IXAY0KItoYj1WBj6tMrwC+FEOOFEBYhRIIQordxzk3AFUKIcCFEGvDb47QhCvADRwCLEOJe1NhwiPnAX4UQXYUiUwiRACClzEeNN78EvB0ye2s0mpahxVijOTOYBDwvpdwvpTwcKsBTqHHhmcBWlOCVAg8DJinlfpRD1a3G9k1AlnHOfwBeoBBlRn7lOG1YhnIG+x7Yh+qN1zdjPwa8CXwKVAILgLB6+xcBvdAmao3mhBFSyuPX0mg0muMghBiGMlenSimDp7s9Gs3ZhO4ZazSaH40QwgrcDMzXQqzRnDhajDUazY9CCJEOlKMczR4/zc3RaM5KtJlao9FoNJrTjO4ZazQajUZzmtFirNFoNBrNaea0Bf1o1aqVTE1NPV2X12g0Go3mlLN+/fpiKWXrxttPmxinpqaybt2603V5jUaj0WhOOUKIfc1t12ZqjUaj0WhOM1qMNRqNRqM5zWgx1mg0Go3mNKOzNmk0Zwk+n4/8/HzcbvfpbopGozkODoeDlJQUrFZri+prMdZozhLy8/OJiooiNTUVIcTxD9BoNKcFKSUlJSXk5+fTqVOnFh2jzdQazVmC2+0mISFBC7FGc4YjhCAhIeGErFhajDWaswgtxBrN2cGJ/l/VYqzRaE4rq1at4rLLLvtR5xg1ahRZWVn06NGDadOmEQgEAHjsscfIyMggMzOTESNGsG9fs1M8mxAZGfmj2gOwaNEiunbtSteuXVm0aFGzdb788kvOPfdcLBYLb7311lHPNXv2bB599FEAFi9eTI8ePTCZTMeM1VBaWkp2djZdu3YlOzubsrKyZustXbqU7t27k5aWxkMPPVS7vaXXuf7662vbPnHiRLp3707Pnj2ZPHkyPp+v2WPy8vIYOHAgXbt25aqrrsLr9TZb72jP8KmnniItLQ0hBMXFxUdt29mEFmONRnPW8+abb7J582ZycnI4cuQIixcvBqBPnz6sW7eOLVu2MG7cOO64444ffI2QwLeE0tJS5syZw+rVq1mzZg1z5sxpVgw7dOjACy+8wDXXXNPic/fs2ZN33nmHYcOGHbPeQw89xIgRI8jNzWXEiBENhDZEIBDgpptu4pNPPmHbtm289tprbNu27YSuU5+JEyeyY8cOtm7disvlYv78+c3WmzFjBrfccgu5ubnExcWxYMGCJnWO9QyHDBnCZ599RseOHVvctjMdLcYajeaEePnllxkwYAC9e/dm6tSp7Nu3j65du1JcXEwwGGTo0KF8+umn7N27l3POOYdJkyaRmZnJuHHjqKmpafaclZWVjB07loyMDKZNm0YwqFIiR0ZGcvfdd5OVlcWgQYMoLCxs9vjo6GgA/H4/Xq+31kQ4fPhwwsPDARg0aBD5+fnNHp+Xl8fgwYPp378/s2bNqt2+atUqhg8fzjXXXEOvXr1afE/Lli0jOzub+Ph44uLiyM7OZunSpU3qpaamkpmZicnU8q/i9PR0unfvftx6S5YsYdKkSQBMmjSJ9957r0mdNWvWkJaWRufOnbHZbEyYMIElS5ac0HXqc8kllyCEQAjBgAEDmn3eUkpWrlzJuHHjjtm2Yz3DPn368L8WTll7U2s0ZyN/fhA27fhpz9n7HHj8zmNW2b59O2+88QZff/01VquV6dOn88UXXzBjxgymTZvGwIEDycjI4KKLLmLv3r3s3LmTBQsWMGTIECZPnswzzzzDbbfd1uS8a9asYdu2bXTs2JFRo0bxzjvvMG7cOJxOJ4MGDWLu3LnccccdzJs3j3vuuafZto0cOZI1a9Zw8cUX137R12fBggVcfPHFzR578803c+ONN3Ldddfx9NNPN2lbTk4OnTp1avE9FRQU0L59+9r1lJQUCgoKjvlsf2oKCwtJTk4GIDk5maKioiZ1mmvn6tWrf/S1fT4fL730Ek888USTfSUlJcTGxmKxWGqv2dyzOROe4alE94w1Gk2LWbFiBevXr6d///707t2bFStWsGfPHqZMmUJVVRX//ve/a8c2Adq3b8+QIUMAuPbaa/nqq6+aPe+AAQPo3LkzZrOZq6++uraezWarHU/u27cve/fuPWrbli1bxqFDh/B4PKxcubLBvpdffpl169Zx++23N3vs119/zdVXXw3Ab37zmyZtqz89pSX31Fye+DPR+e5ktXP69OkMGzaMoUOH/uBrnq5nKCUEAuDzgcet1k8Fumes0ZyNHKcHe7KQUjJp0iQefPDBBttrampqTZLV1dVERUUBTb88hRCsXr2aqVOnAnD//fcTHR3dbD0Aq9Va+9lsNuP3+wkEAvTt2xeA0aNHc//999ce53A4GD16NEuWLCE7OxuAzz77jLlz5/LFF19gt9sBuPvuu/noo48A2LRpU7NtDREREdFs2451TykpKaxataq2Tn5+PhdccEGz52+O5tp3PG644QY2btxI27Zt+fjjj0lKSuLQoUMkJydz6NAhEhMTmxyTkpLCgQMHGrSzbdu2J3SdxsyZM4cjR47w7LPP1m4bOXIkhYWF9OvXj3nz5lFeXo7f78disRz1msd6hlIqsfwh+P1QWQmVFeB2QzBolEDd5/pk9QGz+Ydd60TQYqzRaFrMiBEjGDNmDLfccguJiYmUlpZSVVXFo48+ysSJE+nYsSO/+93v+PDDDwHYv38/3377LYMHD+a1117j/PPPZ+DAgQ0EZtWqVaxZs4a8vDw6duzIG2+8we9///ujtsFsNjc4vrq6mqqqKpKTk/H7/Xz88ce1PbKNGzcydepUli5d2kCM5s6dy9y5c2vXhwwZwuuvv861117LK6+8csxn0JJ7Ki0t5a677qp1OPr000+bvMAci8btawnPP/98g/XRo0ezaNEiZs6cyaJFixgzZkyTY/r3709ubi55eXm0a9eO119/nVdfffWErlOf+fPns2zZMlasWNFgHHzZsmUN6g0fPpy33nqLCRMmHLVtI0eObPAMly37lNtufZA9u6G6Somq1wu7d4HXAxGREBEBlkaqJqUS3YpyVZxOtd1kAptdCa3dro4zm8FkBrNJ7TeZ4FQZNLSZWqPRtJiMjAweeOABLrroIjIzM8nOzmbv3r2sXbuWGTNmMHHiRGw2W+0Xdnp6OosWLSIzM5PS0lJuvPHGZs87ePBgZs6cSc+ePenUqRNjx45tcZucTiejR48mMzOTrKwsEhMTmTZtGgC333471dXVXHnllfTu3ZvRo0c3e44nnniCp59+mv79+1NRUXHM67XknuLj45k1axb9+/enf//+3HvvvcTHxwNw77338v777wOwdu1aUlJSWLx4MVOnTqVHjx7Hvd93332XlJQUvv32Wy699FJGjhzZbL2ZM2eyfPlyunbtyvLly5k5cyYABw8e5JJLLgHAYrHw1FNPMXLkSNLT0xk/fnxtG1p6nfpMmzaNwsJCBg8eTO/evRtYLerz8MMP89hjj5GWlkZJSQm//e1vAVi3bh1TpkwBICYmnltvnUWfPv3JyurP9dfdS1VlPM5qePvdJ7lsdApFRfn8anQm02+awu5c2LIJNm+Cbd/Bjh2wdSts2gDbv4ODBVDtBAkEBfgl1LihygllFXCkRJXScqioguoacHtOnZlaNGeXPxX069dP6nzGGk3L2b59O+np6ae7GS1m7969XHbZZeTk5Jzupvxk/C/e0+kmEFA9V7dbjdG66xWk6p1GRqlerzCp7ZXVqjfcGGHIWf3OrMWqesDh4WB3gNUCVqsqoHrXPh94fcay0fq5vVUbfgjN/Z8VQqyXUvZrXFebqTUajUZz0gkGlZDW1ICrBlwuJb6Nx37tdnA4IDoazBYlitXVUH5I7TdbICoSklorQTVbwGJWJuZQEUKJqtV6fCF1OI6+T8pTZ6bWYqzRaE4Kqamp/3M9yP/Fe2opUipBDQRUEaJpAbV0uRr2dD1u8NQz+ZpMYLOpnmpYuOrxAgSlGgt2uqGsirqecSTEx0N0lOrhtkQgDV+9lt8fEh9+vPjwGkuf8JNCIoKTr8hajDUajeZ/gGBQeQk7q5VgRUU3dWY6FlJCVSUUl4DPW7ctGFACGQj8sPHT+odIQ9OCEvwewDA1C6HMyVaLarPDAXYbRBnm6R9qJq5rgyRAoFZk60qd+Prw0fj2TAjakID1FEilFmONRqM5S/H71RSd8nK1bDwtJzISomNUCQtr2KOUUnkWl5QoEa4/BltflMxmJZB2R50J2WIBl1v1gF0u8PlVXYvhmVy/hMZmZaOTm8x147ch03JL8eCjjEoCBJFIqPdv6CeIxE+gVniDjaRWILBhwYaVSMKwEY0Na+02GxbMmE9Jrxi0GGs0Gs1Zhc+npuiUlysRlVL1KuMTIDZOCXCNEyoqVE/5YIEqFqsSZLOlbrxWyjpnJ6tNTQ9KSFAiGhLaGmNZ5VSlPiazGr+NiVZjvHb7yR1j9eLjMCUcodyQX9V+0eCnbt2ChTDsxBBZT2RVsZxCoW0JWow1Go3mDCQYVOOsbpfqhbpdRjFS5Nrs0DpRCXBEREMRDAtXJmGLFarsynTtM7yDQ9XMFnVcfALExjY1BTscEBdXtx4IGL3hGtUjj4z8aUzILcGHn0MUc4RyQNKKWNqQgA3rGSWoPwY9z1ij0ZxWfo4pFEMhFz/77Et691YpFBfMf4uCAtizG7blwKaNan5s3h6YM3s2zzzzKHYHrFu/mGuv60FmlonDheuIjFRC7PPB4cPw3XbYuBnWrCll9OhsLrywK9NvyiY8ooy0rpDWDXpmQlZvSOsKa9YsJT39+CkUzWaIjICo1l7syZUEoqqoNjmZeP1vePWtV/Hg5eqJV9emULxh8g04fTW48FBNDRVUU0IFRZSxJm8DfQf2pUvXNK686ko8zc1TAhYsWkinrp3p0rULCxc9TwIx9KQLHzz1Nj3SMjAJU4tSKEokXrxUUMVhjpDHAbaRSy57ceL6cb/onwgtxhqN5qznTE6h+N//rmH27Dls+66M73dCzlbYvFEVd00H7pzxAqNGXkNJCRQeUlN/7HZISoKOneCcDGiTrEqXNBg6rCfvvqtSG0qppv3syYMtWyG/QEWPSm4DS957iNGjR7B/Xy6/umwEL7zwEDExypxss9Xd0/FSKA4dNpQqnOzjMFvZRQ672UMBu8jne/ZTQTUHKGIruxk08Re8vONdnt/6JgddRfx1/sN8xx52sI9cDpDHQfZzmLtn3MWvb7mGN3I/IBhnYvaC/+M79rCLfPIp4gjlbC3dyX1z7mP+6ld4f80nLJrzHDFlDgSCXkMyeeWz10jpmMJhijhIIYcoqi2HOcJhithHATvYzSa2sYUd5JJHPoeopBoLZpzUsJ1c9rAfD82/EJwqtBhrNJoTQqdQPPY9SQkffLCM88/PprQkngP74ji3TzbvvbeUYECZdlu1hqQ2cG7fVM4flklYuInIaIiOg/BICIuEsAjlFe1wNDRBp6enk5bWHZ9PifCOnVBeAa1bQY8MOKc7tGsLy5YtYfLkE0+h+N6S96jBTWx6a+juoBoXByiihAoc2OlAEumkkk4q3elANOEkEU8qyVx9yXjaiyTaidacN2AwnvxqOtOOrrTnHDrSg870kl3YuHIdfx43nW50YPKkyXzz3pfYsOLGQyGl7OMQ7y/7gKHZv6B3fDpt4loxMHswzy5dwBa2E9EnFnOqnQBBDnOEgxRSwOHaks8h8jlMKeUAxBNLB9rRnc70JoMs0ulGZ3rSnWQSKaeSHL5nPwfx4W/2b+Rko8eMNZqzlQsmNd02fhRMv1p53Vwyren+6y+H68dCcRmM+3PDfasWNa3fCJ1Cse6eBg8ewg03TOYf/3iGG6fdhterxnOrKmHjhgIiI9rjcasx2S5pKdS4CsAMlU4j0EU9516XW/Vw3R41lai0tF4DBBQVqX35Bcq8XVKqriUEdOyg5uA2TmZwrBSK0vA03l2wh9btkyigCDdeSLGxefUGtpEHQBh2bFjpQBt60xVTM/035Y0cTitia7f5fD6WvPQOTzzxBPFEN6hfXFJMbGws4ZYwADJTMigpOEJX2uPHTyVOKqikrOAIse3jyGM/AK1SWlFRUEZ72hJBOOE4sGEliwxa0arWoSt0fwAmTMccU7Zgph1taE0CBymkiBKKKaMNrUiiFWZOQYYIA90z1mg0LebnlEIxlBmob98BREV1oiAfDuyH5OT2REcNYdMGGDzoWpYv/4q9ecpjubJCeSRHx0iiosERASXlUFkF1U6BlCpwRXIbJaJd01RvNj4OOneCnhmQ2Qv69Ib0dOiUquparMppqrBQzQOOi1W95k6p0Lr18bMKhab1FHCEHexlE7lsJpd8WUQ1NRymhBo8WDATLhykkkwmafSgM3Zj6k9zQnw0WppCMUCASqrxiwDbyGUT29nDPsqowCQFUYSTRipZZJBEa1qJeJJoRSThte0JeU6b6v2YjZ+WOnfZsJJKCj3oSjSRHKSQHHZSRAlBgsc/wU+A7hlrNGcrx+rJhocde3+ruBb1hBvzv5hCccMGlW2ptETg90NxsfJk3rxROU9JGcH+vYBQ47lCCKKi1PzYVq0gPFxQeGQ1t98+FSlh2o33Y7enkJOzimqnEk63K5/zh1xA+jnNP9fGHsn33tswhWK8MWXp3D7qJcFkajo3t35qww8+/oDWSYlsOLSV8OQo9h3aT3RiLIcoxoaFcOw4sNErJZ3lBz6iN90wY+bDfBfd2qY16OU25lgpFCWSWXPupeDIQRY++wKFFCORTBg5niOFR8jsl8nD8x6htLyUHP9OPBYvm/M3Edc2HjMm2pJIFJFEEMbOlCxWrVpFrNGzPtE0lD+EMByk0ZFqnORzmAMcIpYobNhO6nVBi7FGozkBzvYUisGgmjN7y5/nMvX3c6mpUaLbs8cQ5j33Opdcei3vvvsKQhjBMgxnp4TWEAiq7D4HD+7ni/98S48eg3n51dfo1v18WicO5IVFmxAmNe82EChl3ry7aN+uDCHgiy8+5bHHfnwKxfphJwHDrFtNJU7ufP4+XHjwEWAjOxk0+nwWLnqe62dO4YNF7/KLMcOhNuKUiyogoX8iO3J38GHeMtq0a8sLry/ikVf/wS72YceGAxsBAkZ0KolANEihGNpXSjm55PHS/Bd5f9kHPLPiOfJNh2rrPbrsCdV+TBRTTt/h/Vn21idcNWECXy1axcQx19CdLg3utXEKxRNNQ/ljiCSC7nTGjeeUCDGg3nRPR+nbt6/UaDQtZ9u2bae7CVJKKV9//XWZlZUle/XqJc8991y5atUqOXDgQOn3+6WUUo4dO1YuXLhQ5uXlyfT0dDl16lTZq1cvecUVV0in09nkfJ9//rkcPny4HD9+fG39QCAgpZQyIiKitt7ixYvlpEmTmhx/+PBh2a9fP9mrVy+ZkZEh//CHP0ifzyeDQSmHDx8hW7dOlBnpWbJ79yw5bOiv5Pq1Uq5fK+WmDVJu/07KnTuk/Gz5HpmZOUhmZPSTN/3hQRkWFiHXrpPy3//+XJ5//qVy3XopN2+RcvlnebJLl3R5zcSpMj29l7z00itkwUGnrHZK6fFIGQzWtWvBggWyS5cuskuXLvK5hfPkIVkst8s8eeOsP8p/LZkv98gC+f6aT2SbdskyLDxcxsXHye4Z58hSWSGPyDJ5WJbIg/KIPCAL5Z/vu1Xe+cgsmSv3yyfeeUYmtkuSVptVxicmyEEXDZFr5bbasl5ulzlyl1xXvEWef+FQ2Tmtsxx24S/k/pIDska6ZF5Bnhx58UhZKatlqSyXr370muzctbPs0Lmj/MsDt8udco/cKnfKR955XCa2SzSuEy8HXXSezJE7Za7cK/PkAZkjd8q1cou8dNJo+dDiR2WO3CnNZrPs2DlV9srKlJlZmfK+OfdJv/TLgAzIoKx7OLt375b9+/eXXbp0kePGjZNut1tKKeXatWvlb3/722af4cKFC2u3P/HEE7Jdu3bSbDbL5OTkBsecSTT3fxZYJ5vRRJ1CUaM5S9ApFI9NMKgiT1U7VZALZ7UaZwVl1g1Fn5ISvH7lABX6+rNa6zyX66fYC5WQSfhE7slPgHKqKKGCKpTHdTgOzJgIECRAAD8BAscZk1TjoaI2xCNGMWHCgY0wHEQSThQR2LBi+omCYKi5uT48eHDjbbD0EyCcMCIJJ8IollPo7HS2oFMoajSa/xmCQeVp7HErT+JQ0oLQMuAHfwD8vjpxtViU8Jqtap/PB1XGDCSzWQlvUhJEhKupRlZro7jNRgYfFx4q8ODGgwsPBziAFx/7OIy9XmhFuxFeUSKpwEkpFZRTjURix0pbWhFPNA6aphJSSQyUOIeE2YTAhYdKqiinAh9+TJiII5o4ookk/KSbTwUCOzbs2Br5Q2tOBlqMNRrNSeHHpBv0+YzYyuUqvnL9BAgh5yWTCRB1qf2C1GUF8gbAjEpuEBVuJDiwQ3iEWkoRxG/0TN0EqMKPHz9ufLgM4Q1QF+TDihkHdjqlduK9nKWUUtlgP9R59QYJYsFMa2JJIIZwHE28ekMCHDQEOPTZT4BqnJTVE+AYoogjlhgiT+lUG82pRYuxRqP5yQgEVFJ3j6cuh63Ho3qxIZOvzaaSEthsYLOqzyaTcqyqKFciXGMkJLBaVdzkiCijjpGc3umEgJHmz2xWvdvwcCW0dofEbPcTsHjxCCWuVbgoxotETfM52nQVMybCsBNPFA6j5+nDRw0uqqkmSAArVsKwYcVhJBtQbwXSmN2qMgBZ8OGnimpKKFO5cY0fvyG8R0NgIpYo4oghhigtwD8TtBhrNJofRDCoxmVD4unxGMEs6mE2K7EFlWCgOtA0zV9zSKFGRj1+8JSpGCUACDX2G28kR4iIAKsjQImooIJqyox0efUDQBhnbLI0YzY8hu2E4yCSMAIEqcZJFU6KKUEaoh2GgwRisWLBgxcvXpzU4KVR9A6gcaRkE+balHwOIo3EfGZjPmzdnNjQuh2bFuCfIS0SYyHEKOAJlOVnvpTyoWbqXAA8DliBYinlL37Cdmo0mjMAn08FtqioUJGmAgE11hoeoZLZh3LYmi2qB1tWrpYhhEmN45pMxjQd6rIIWax1x5pMRhF1n2021fsNBbhw46WIUoqpIEgQqzFmKwkAEgGEE0YMUcQQSThhxjiwGxcuanDjwk0ZZZQ2EFRBBGEkkkAU4UQSgeUoX5VBgsZUIS8evPgJYDVS9VmN8WQtrGcuUp7clI8nwnHFWAhhBp4GsoF8YK0Q4n0p5bZ6dWKBZ4BRUsr9QojEk9VgjUZz6gjNyw0JcAPzcRzExCgRNpuVMJeXQ3GpijiFVOLZPkWZmq3WpsEtAgRwUoMTF1YshOHAgf2oAiaRVBoRoypRjRFIMOa7hhNGAvFEE0kkEZgbRY0KOVzFEFV3jwQNBy03VixEEN5iAVUezfZmHbM0Zx4+P1RWq5CkldVq7niY4U8QWjrsYLeeepFuSXyzAcAuKeUeKaUXeB0Y06jONcA7Usr9AFLKIjQazVlFIADVVVBUCHvzVPq+TRtg53Y4dFDVSW4L56SrFHwdU5UQV1WphAWbt0DeXhVDObkN9OgBGenKa9luB2GSePBSQhn7KGAbuWxkG6+tepPxl41jL/lsZxcb2cZWdrCLvRQYwf6rqeEAh9nM93zPfiqpBoJYkMQTxYxRf2Zy1rVc2eNy5k6bQ2QgHDOmFqVQNGEyRDyOaGOM9mSnUAzx5Zdfcu65KoXiW2+9ddRzzZ49uzbMaOPUhkejtLSU7OxsunbtSnZ2dm3wjMYsXbqU7t2Pn0LxaFx//fW1bZ84cWJtCsXJkyfjazxuYZCXl8fAgQPp2rUrV111FV6vt9l6R3uGRzteSsmf/vQn0tLS6NEzk89WbWDfYdixFy7/9WSSkhIZ0L8npRXKSmOzKW/7iirIL4Rd+yEnFzZsh227YU9+3fS4k01LxLgdcKDeer6xrT7dgDghxCohxHohxHU/VQM1Gs3JIWAkJMjbA9/lqEhU3++E/APKg9lqU2n7OnWBXlnQPV3Sqq0fn9XN/iKiiB8AACAASURBVGI33+3ysmmLZNduKKsMYE+oIbF7JSk9KolpW4NweKnGSSFH2M0+trCDrewgjwOUUI4FM8m0pi1JRBJJF1JpQxLRRANmKnFziFL2cJAd7KOQMvwEcGChLa3IoDNZpNOJ9rz75rts2bzljEyhuGbNGubMmdOsGHbo0IEXXniBa665psXnDqU2HDZs2DHrPfTQQ4wYMYLc3FxGjBjRQGhDhFIovv/BJ6zfuI1XXnmNb9Zuo6wKOqf15PU3j3+dunPB2F9PZOV/dvDux1spLXPx9DPzaS6UxYwZM7jlllvIzc0lLi6OBQsWNKkTeoZf/mc1n61cw733zWHrjjJ27Ycbb5rB2PG38OYHuQRFHPf/3wK25sLT8z9h/aZcXluSy213P8ef/3QjR0rU3PNLxlzPP59bihBgsYEwgz8IngAqT5MZhAVsxlBLUEKVE36iadvHpSVjxs01pfHjtQB9gRFAGPCtEOK/UsrvG5xIiN8Dvwf1R6jRaE4tgYAyOZeVqWUwqEzHVhtExYDdEcQa7geHD7/Fg9viodLkYb/LhK84DCoi+Xjx27zx+pP4Ah569u3DlDtv5MaxV7Hw29dwhkczddh1/HbWjXTolsqfRv2engN7sXPjDjp2S+WvLz5MWHg4EkkVXirxcJASCiuLuGLsFezbmUefYf2485nZOEw2BkZmMunmyXz+4QrCw8L5YMn7tE1q2+S+jpVCMcSgQYN4+eWXm30ueXl5XHPNNfj9fkaNGlW7fdWqVcyZM4fk5GQ2bdrExx9/zKhRoxg4cCAbN26kW7duvPjii7VpGkMsW7aM7Oxs4uPjAcjOzmbp0qW1yShCpKamAmBqbL8/Bi0J/BIMwnvvLeHjpasor4LLLp/EmMsuYPotD+MLGPOy/bB+3RoSk9OoCnamqgCGZU/gldeWcMPvMyAsHQ9qfvaufIhMBJtFecDbrWAxqfM4XapXuWknpHa/hENHwG6Dzt0GsOW7fDbthOgIiImE6EiwWiQrV67k1VdfBVR6x/vum82kG27E5VHBWFweeOftZfTul01BiXqGfQdk8/4HSxlz+QTW/Hclzzz7KmYzjBs/iSf+MZvLr7qRlcuXcMno67BbBQMHDKLGWU645RBduyTTN2MY+/btxWGDrLS6Z+Xzg9tbV1wetfSe4kyKLRHjfKB9vfUU4GAzdYqllE7AKYT4EsgCGoixlPI54DlQEbh+aKM1mp89f74XNn3XoqoS9cXr9ykxtkhoLaB1aKfxul3TrQcHbr0fsBklQu0Q0pjAKyko3Mqq/7zKx99+giNKcsdNt7FtwzdMnjGF/5t2Lz0H9qJTRmcuuGgYhXuL2Lczj78t+Dt9hvTjrsm38f4zbzPttun1suwI9hPLtjU5fLttDV06duaKUZeT904OV467khpnDRcPuohn5v6TO+64g4XzFp4xKRSPlRayoKCA9u3rvjZTUlIoKCg4aQ5DHi9U1Kix0Koa9Xs+dLiQcm8y5QUAyRw5UkRZlYowZjGrMdKaygI6pbanQ5LalpWRwoZ1q8lIVWLk9SnxdRhD4tUu8FZA/ZlhLo+q67ArT/focLCafaz89CX+OvcJYqPU+GxZparvrikhMiqWolILLg84/Snszitg227jhAIcNigtKaBL5/Z0bKvWMzNSsFFATHgJMbGxSLOFkmqIiEuhqLCA1nFQU1XAsIHtyeymTtUpNYWaqgKsluSjPjurRZWohu9TBALg8anncipoiRivBboKIToBBcAE1BhxfZYATwkhLKj/xQOBf/yUDdVoNE2RgAwqr1AplWmt/nooIIasJ7q1R1oCYAkgLEFMCBytnCT1KMPit0HATMAH3kAQr18i7W6CMZV88+wbbM1ZR/YwlRbR43ITnhjJrbNv4/PFK3j/3++xadNGYoghEhvt27dn/JCxANx47VSefPJJOt7W8IsxnhgGDBhAn86ZAFxz9TV8/dXXXDnuyiYpFJcvX37UZ7Fs2TLcbjcTJ05k5cqVtVmboC6F4hdffNHssV9//TVvv/02oFIozpgxo3bfgAED6NSpU+1647SQTz75ZBMxDoUZllKJVVUNOL2CDbnKQ9xqNkTRonqbLg9U1kCFU+0zm5UImETz4h0Iql7p4RLI2aN6cqCOtZmUqdUkoFOyEkmrGcwm6N214XlaxUjCHZAYp9bD7GC1CsIdENImuxXaJkB8JBw6AgRV5LIwu2pnyOkpAJRWqvLArOmk9xpGcuehlFQBAkyG2ri9kkAADh6p84y3mAUpSRAVoc5rMkFCjMTthjCHegkod0KlW7Bjn8QfgOoaSIgGh4Qwu6BjGzCbZJPn1TgjWEsxmyH8FDrCH1eMpZR+IcQfgGWoqU0LpZTfCSGmGfv/LaXcLoRYCmxBvTPNl1KemoC0Gs3PiGBQTRWqnnE/VVVqnm/TebtSxWA2BQlKiQyYkNIEpiDEVGOOryYs2ofDFApeYcGLDzce3JTixoOf+jY6gR0rduyESwdXT7qavz74V+xG4nkTJmpqajiSX4QJQU11DTFRMerIsyCFYigDlD8g8PiVmEggvwgOFoM0RZCzR/X+DuarensOqt5ahRMCQcE336xm+nR1T7Puu5+Y+BQ+/3wVm3cpq8Su3fn0G3gBImCE6hTqxanGDRV+cLrhSBnkGt45zzx+N1998RECePPDTRSVQ40PdhcoIa5yKQEvq4ZuVgi3w1/+dAPbvttI68S2PPGvj4mNT2LtxkMkJydTVXGI+IREisuUuIUELyUlhQMH6lyC8vPzadu2bhhASmXG3X0ATBEQGQ6PPHADOVvrUihGhkHbVpDZRbXtvvvm4HUd4dlnn1V/sxKuHjeSI0cK6ZXVj7l/m0d1dTk2u5+gtLA/P5/4Vm3JLwaKlde9wwomRwqb1q9ih+FzV5Cfz9ChF9A7vRUuZzkZHf1YrRa+zatr8/Hu50ymRfOMpZQfAx832vbvRuuPAI/8dE3TaDQ+H2xYB1+uggGDweOqE19HmCSulcQc5sMd9OP2BfG4TcgaO0GfBQJmsPohtgriKiG6EsxBAkiqgepG17JgwYGdWKJxGMEw7IbkhhK5Xzni14wZM4Z7brmbmMTo05ZCccOGTbg8UOOBbburKS6tIi4hGbvFzzvvfcywoUNVTuLNDVMohpg7dy73zZ5LlQv2HoZefYbwyJOvc8noa3nrtVeQEgrLlGc4KAGLsYCrAg4d3M83X3/LOZmDWfTia3RJPx9b/EAWvbUJIVQEstiyUubcdxe/m66ctlZ/8ym33vEgMZFqjNVZo3q80ZGQHA/xUdA+Cbp3UD3ehx+aiz8wV8XgDqjxWVACLAQkxipBTYhSwVR8fnjg4edJiof4WPU3Mmb0aP6zYhFTps3khfmLGDJsDHuNAUYh1PGt2/Znx85cvtueR5dO7Xj99dd59dVXkVKZlQ8eUc/AbIauHVR7X37peY7G8wvns3LFMlasWEFYWN04+KrPlzWo98sRw9m27i0mTJjAM48uYvy4MXRuq3r4Hp8q5w0byeOP3EV8eBmRYbDuv5/y7NMPEh8nGD58OG+/rY5ftGgRY8aoCT6jR4/mqaeeYsKECaxevZqYmBiSk49uoj6jaC6V06koOoWiRtMQv1/Kbd9J+fIiKW/9k5TDzwvKuLCgDEPKMKT8dHmO3LLTLTfvqZYb9pXLtbsr5NodTrl2o1+uXSdV2eqRa/PK5JYjRXKfq1jWBF21qeuCMij9MiB90ic90ivd0i1rpEs6ZY30SV+L2/lTpFD0+6WsqJbyYLGUL735uew/aLi86JLxsnNaurxq4lSZeyAg9x2WMjw8Qh4ulbK4Qsp5zy+Wvx4/SebskXLdDinXbldl+TeHZc/MfrL7Ob1k57QMOX7iH+S3W31y3U4pBw0ZIVu1SpQ9e2XJXplZcuSoX8m8g1Ju2V13/IbvpVzx9R7Zt98g2efcfnLO/Q/KiIgIGQyq9I6XXnpp7b3Xv6eevXrJS391hczJdcqtuVKu+07KtTmqbNgu5f/9bYFMTe0iO3XuIufNr0v/d889s+Trby6R+w9J+criNTIxqZ10hIXL2Nh42b17hnS6pKxxS+n2SOnxSun1STlr1n3yb397RAaDUr72+juyTZt20mq1yfj4RHn+0ItkeVXD9I1SSllcXCwvvPBCmZaWJi+88EJZXFwiXW4pc7YXyOEXXix37pVy43YpH3/mI9mhY1fZrn1n+ae/PCDzCqT8bpeUf3v8HZmY1E7abDaZmJgoL7roomb/HiZNmiQXL14spZTSbDbLzp07y6ysLJmVlSXnzJnT7DE/NoXi0Y4PBoNy+vTpsnPnzrJnz55y7dq1tcdMmDBBtmnTRlosFtmuXTs5f/78Y/+h/wToFIoazVnA/n3wzddBvlznYu26ILkbwvA6DWOVzUcwxknQbSfgCiNogk/e306rVoYnrSkINp/q+To8hEX6iY00E2cLJ6yZxASng1C6wS1bc/D6lCm22qV6hjUeaudkOGwQEaY++wMNS+PZRFYLajzTXre0NQrQ0OBablVkPVO+2aycdaLCVO8QaXjSGr3gUCIKs8ko5rrlrt17Gf/ry3jvkxycrrosUWF2ZcINlcZtOhpSqudRVqmKt/lpuU1QY6qQmGDcww9ESnXNGrfxezGWFjMkt1bXOFMiVLWEQMCIX+5Sv0+rBcLDVLFaT/x8/sCPc+DSKRQ1mjOAggLYsROiolQpLoKNmwJ8uqaCdV/aqDwQCZiQdgvBlCJk+xKCxfEEK6KRWImMMpN+aRHp3SGhrZvwRCe2c/LwWmsQZkmciCaBWKKIrTUjn2pCYuJ01wloaOrMvv1K5DbsrKtvMinhTY6HyDD1+VhfdlLWnddsVs5OjQkG1RewxxCyUJjNaMOzF6n2hYQuEFDm3kNV6rz122YSatzzaH2UgwXq/qSExHgl6pHhahz4hyBEnYCnJCkx9PoMRzzDGS9Y3xlPqueVEPPDr9n4+nabKnFGnsSjeXxLqSKrlZQp5ymbRQXNsNsaLm31Iq2FHAgDAfVcA8YLlj8AQWNb0CiB+kvj92IxnNws5qafTUIJbo3xEuFyKa/yECZTQ38Km5GzOiKsbmkyGYlN6pX664EA9OlZ52h2MtFirNH8BPh8KlBGaank7aUu3lwMW1eHIQMCs1QdWcMNCUkcAbsf0aoai13gOhIB+e1JSAxw3igvWb84SJcLDmLtUkC+OMQ7LGUNm7lo+zzahMXTlrbEEX1KYh77A1BaoZyQ6seL9hpOR06XCpwAgFBflFbDEzgtLZWV/8lR2ywQYTgOnUhPS4i6qSdgOLC56xXDkelEDHxmY1pPbLRahsIgWi3qeiHhqxWQemLSrWMq3+/IOSlfzkIogQhZCU4XjX8/LpcS4JIyNTZtNquxY79fBdMoLW96DqtVvUgc68WmPiYBJiMtptlUJ+YeV13e6mNht6neb0KcWoaFKfENBA2xrlFLZw2UVxz73kMvJxHhanmq0GKs0ZwAUqpoVa++V837H/oo3GfDXWkl4Ar9r1XpCUBlTAEItikm0H0/wY4HCbYtAqsPR3Us9sp4LH4bEQM3477gc0rO2cQHAj5odM0s0nmUu2hHG7rR+ZTcp8sDRSVQUtGyLEugvkDt1jqBC3ntWn/Et0wgoKIgVVSr3pjLS61522JWpuqkBLW029TTl6h/avMz1RMDu61OdI+GMKYTmUx1v8OfGz6fEtmSMiViQkBMlBK7mOiGMcaDQVXf46vrVfp86pjQFC1zvWIxzP4mc53wHu8FTUpjrrwRrMTvV0LrMP7OjvZyZDFeHKLrRTf1+w2BNpwha3v29uP/bZxMtBhrNM2gEhI4iSESn1/y1teHefm9KtYsScCZl4AU4cgBmwlmVWPa1ZnA/mQkkNCriJiRWzlwwSf448sZ0S6VQW1bk0oiQQKU4KOEckrIo5gyqnESTyyt6UUiw2lNPIkk0Jp4WpNAIgkkoCaBbmf7yb1nqUSvqFQFaQiZUM0WNf7qD6geTFS4KhEOdVwwqEyrLo8q5ZVQXK8nY7U0FOcwh/oSNR/Fsu72qHZUVCshllJ9YUeGQ2yUMQboaPm47M+NQKBlAgd1Y8ZutzL1u40IWKHx8PAwaN9WeWgfbczVZKrL1nWyEKIuH3Zt25HN+kZIJDXUUEkFfnwEG/9YggSjVDFjJowwwghHEkYAKxKJH7+Re9pPIomnxAdDi7HmZ0+AAN+zn018z1q2s5octnoO4Pwkk7B3RxD8cDCUJiOtrRBp+USeV47VHUvJzix8LhPtU+CGeyVJk77ikQ5/J5dD/Iqh/I17OYfU03Zf9U2tFsvRxS8QgOJyJcIeb126Qm8AqtyGWTJCTb+Jjjj6eepf1+c3xNldtywqbdpLDTOcsOw2ZXYur6ob93PY1bhsTKQS4hOIGPmzQco682u1U1kPQjkXTKa68dUGvVKz6rm6ParUt3xYzOBwQFIrlTM6/DSbzIME8eDBjbvJ0ocPgajNBy0QBAkSwE+QIEgwIWp/gIaiKsEnfDipQYqSJtcWQYHFYycuLA4bJ99ercVY8z+PFx9FlFJYr2xjD+vZxvcc4DBlBIz4fmJbKuanr8Dy0qXYqyIJmAMETBCwQFBYYU8nYtsF6XGOiR4XQvYIiM3O4Tbz43zLVjJJYzn/5JcMaLYtUkJxBeQdgr2HoLQK+nWH3mnqSzMYhJJyOFSsoh0VlighSkqAKIsSzpBJLhTdye1V4uf1G44nPvVlGwg0Ha8LOTfVJ1hvzBcTBI1Y1QkREGM4upzoOK/NqkpMPfOglKp9IXGuMZbllXXHRUVAUrwyiZ7K8bozBb9f/S6h4e+u/mefH5xOJb7OevPOrVb1t9I6vs7xLeQsFfCD21e3brUo0W0doZYOu1q2ZEhBIgkS/HE+C0EjEbYwESCA18gK7cFDFVU4qcFn9GrrY8aMHTtRRGHDhhs3blx48SKNsQmTFJiMCK5qm3p4QgLSyKEtVbFJsHmsWN0OTJ4ITJ5wTF4HJp8Vk9+iZLy3/5QopRZjzf8UXnws47+8xqds4nsKKaWUyqPUDgJ+IqpjifznJDzzLsOT10p92ZgEjvggAwaaad+jmtL0TWzKWMq+c76lONZNGIPpywhe4VteZRlJxDOfu5nguZSiUjNfF6voTQeKVFCJvEOQd1h9drqMS/tQMQSDKn2azQw+r+rJNscn/wBvyPwoGgntUZxkQlNyQoOpkkahM40wmVarEsDoCOWBfDLi8QpRFzox5LkLsGLlKh599FE+/PDD4/a6m0NKGDlyFIcPHyIQ8DN06FCefvppzGYzjz32GPPnz8disdC6dWsWLlxIx44dj3vOyMhIqqsbh0U5MRYtWsQDDzwAwD333MOkSZOa1Pnyyy+5+eY/s3XrFv7+j9cZMqxpTG2A5/41m7DwSH4z6TY++3Qx8/49m7y87bz/4RrOO6+fmk7V6OWltLSUq666ir1795Kamsqbb75JXFxck3MvXbqUm2++mUAgwJQpU5g5cyagUijOnj2b7du3s3rNatL7pVNOOWWU4cGDCRN27My6fhbZl2Vz+bjL+ePEP7J53WZsVhsDBgzguWefw2K2IH1epMuJ21tNjXTz/YH9TJ92K+Xl5ZzT5xweWPQAZoeJoJC1f6sWKfjwxY+YP1dldJpyz2R+NekyPNSwJy+XOyfcTUVpJRl9zuGpf/+V1l4zkTWSW+5/lI9XfU24w8Hzf7uPrB69CAbtTJl5L5+sWkmr+ES+eWsjwYBFvXnWez2V9ZYSiRR+TG4/RJ58qdRirDkr+Z49VFJtRImysZU9vM9XfMBXlFJJAjH04xxaEUkhReSxHx9ubFgYRBYX+y/As2AM7/+7NTu2mKgMQlBA63bw6/GCq8bDgP4moxcaCZyPxzeEpYV7eCl3C58dyuf9w4WYis+jU/HvsZe05fYSE1OqmrY1OgLaxYPDBB0j4XCN8lAGYxw0DjBBtRvcoLySbdCjMwzMUIK+8Xtqe64SFZHJJNRns+EBGkqKHppmYrce37QbmkpiMZ++8dfa+bzHaGvI9O0xTKuhpdujett33fcmkZHRmE2SO+8Yx4KFi5l03YTaFIrh4eH861//4o477uCNN95ocF6vT3kMuzzqOUSEN9+GQCCAuRlPIb/fMBPXqHZZrVDjLOW+++bw9TfrcNgF/fv3ZfTo0cTFxanpYDXKIuDydeCOu17g5RcfJRiE5CRj3rDxuxDGP/GxEBEJaZ2A4T0Zfek7TJ8+lTaJal9zhFIozpw5k4ceeoiHHnqIhx9+uMk93XTTTSxfvpyUlBT69+/P6NGjycjIIKNnBi+88wJ/nPpHvuf7WnNvFFEkkIAfv+qRSonb7aPyiIeLLxrLP+6dj9XtYPqM63n83uf47a9vAuxGiccMPHLnPfzxiju54qIJ3PrgNL64fx2Tx92IJIgQQUwiQHlFMQvveYH/vPoFwhxg2IQRXJd+JdEJUcy++T7+cN0UJowaw613zeKjf6xkylVTeO/Lz9m+q5R1S3axdvM6fn/XX1j+wmoArhz5B64fO5Pp911HwGcHAcIGJiuY7GB2gNkRxCy8mILViEA1PunDHJHW+NGeFLQYa84q1rGF2TzBR6xEhUp3GMWMkiYP4KaScpbJXDiYRMqugVyQO4VWuX1wfteOzevN3F9IbU8xqR38+iq46Sbo1An2HYaNufDXF2HPQcOkfBgKigVSdgG6AGA2S9q0CpKUYCa5PYzoowLqt44xpoOUQu4++HYTbN+i2p8QCxf0hV/0gwv6Q8+0hoJZUgFf58CXm1VZsEyFPjyvt+pNdu+oHKd+qvHT0HSloxHyqpXScLxywJtvvMw///kkXq+XgQMHctddd/HLX/6Sb7/9lvj4eH7xi18wa9YsunXrxqhRoxgwQKUb7N69+XSDAJWVlYwdO5adO3cybNgwnnnmGYQwERUVyQ2Tb+bTZR9is4fx6ONLSEhIatDLjo2GDu2iEQJKy/y4XF6KywRbd0CrNsMpKoFoL5zbdxCLFr1MUbExlu1Sy0AQCgrymHWnSqE4eMgogkHYngubN63iqSfn0LZtMjlbN/HRRyqFYu8+A9m8eSMdOnTj3jkv4ghTE5qtVonfL1j68TLO7ZfNoSMq/d+5/bJZ+MJSxoy9mmqnqgOS9qkpdM/08u4HPiLaleJvs49KpJHRqu7H76jG5whSEr2LyH5gQuKihv3sJZpIjH6cMssiCCeCd5a8w8pVKwgQYNykcYy6YBQ3PnwjNdQgjWtsXrOZtmltoTMc5CCjJozixSUv8ruM3+FJ9yAQ+PETISPo5GtPZFUYgQozfpeZoF8VR0kMcQVtab0vlbE9OhKs8RM0B8jK7MOB0r24IqqRpiBSSBUvXQT4cv0KHvnXEzhFMePGjeXvTz3M76++GoQZabKBsLBi3SouGJRNdHQHZBAu6D+S5cu3cMVFE/jqq9XMu2cJgTILV468iYfnzeY3l8/kg89WcOXFNxDw2emTMYSKqnIOFh8iOSmZ84cNo6BsLyYbxGaC2bAkBJB4COIiiJsAboK4ceDGhgT6wCmYRKjFWHOWsJ6t3MWjfMpq7ESSSFeKqMCEoIc3jW67BhK1/RyKtsdQuC2GI9tjKf8+Hl+NlRLgK5ToGFZh2rWHURfD+OvhYBVsyIXf/VOJcJnRuzWZIKU1pLaBEX3VslNy3bJtgsDlMbNpB2zcARu2w+v/gW176uZFJsTCL/rCX66DC/pBj7Rji19CDIweogqo3mCo17p9e6M0bxf8uukJxv8Kpl+vJlZe8pum+68fD9dfBcUlMK5R/OdVKmuRlFBVDUdKVO+tvjk8b8925s1/g3nPf01UpJU5903no0++4E83z+CGydPo3Xsg7Ttm0KnrReTuUekGb5+5gD/dOoS5cybzwNxnuOUvtxEVobxvQ73xNWvWsG3bNjp27MhFF41i3sJ3OG/IOJxOJ53TBvHRLXN5/LE7+Orzedwz655mPanrp1D8003jqHGpIBVlFVBcCn9/bAF9+l3M/gL1ImV1+LHE1RB0VPL3u37Lr2+5hEuvvpw3n3wHBASEj8oqyfp1a7j97Rzap3Tiu517+f77ndxx5wLuvOc8/jrnBt7/5DGuu/03eMLK8Jn9IKHo47UkZTig/R7w2mnVPp4DhXsod3kg0gnR5RBVQY0lQA1QY6qizPgJOSIFCRriCpVU4sNHGXWTev0EcEoXNbhqRVs5MkHJ/7N31nF2VHf/f5+R6+u+2bgRIcQghBBBQgJBipQiQQI/JFC0QCktBfq0hRZKIXhx9wAtBIJESEgCxN09u1m36yPn98eZu7tBipSHp0+ffOf13TP37r0zc+/cmc/52udLHdXV1dSU1VJDLZRBTU0NTbKRkONDkwJXOFTt3ENRRSGtbhMOkkh5hDUL1pFugPx4CcGYn0A0SGR9KYhiol4K1L7u3EzAx0VqEinASju8/o+X+P11f8UXD4IUSBWtpb6pjpxwHjlNijO6PKs/lXtrSFr7mvi7dldRWtQFy1ZQWFrcmT01e6hpric7KxdhGDgCSjtVUFW3By0i2Nu0h659KqDUxTIcSruVsy1nK6EhuThIKrcnSOkuq3wxHDpGd9rXDMBEIxedINrXRYB+cNkPxvvl31ZqaeQp3uJBXmE71aifaw5abTF5j15E18VDSawrY/tmnc0dmgx17gKD+0OPw1QHnk+XwMYtEIrA5DOg1xBYsBWeXgIPeZ3y/D4Y1ANOG6tcyqkEVFWr+G4yBXu2wZb1XvPxpBrjSdhb1w5WJQUwtB+cOA6GHKDWu3X619y//0qN7ncVy1J1pbX1yvVr6FBcqBKCdEOVvHz43kds2LCEM356MNKFRDKBP1DMxVNv5YUXXuXJJx/m5deWk06rhLTy8s4cO3EUmgannDaZJx6bxim7r2v7bJGwsryHDTuEYKQH6zfDqDFnMmf2fMYdcRo+n4+fTz0esVrVRAAAIABJREFU04TRh6sWil+V2GVh8crMV0glU1x09kXMXjCDo8cfTU6hBlLwzBMvsmXz5/zhvn/g5mwjajaQFBIDgwJyWb1oOR+8+S6u6TLlktO5/7Y/key1ArFrM4MOGcSAkTlY8VbMWAulncoZdmYutm8JR08dwcvTXub0yEQEoCOQQqLpLgGfoCTfREcQybUIhBIU9qtCR8ckhEkOBgamNMh3c+gRL+KgmlwSpkNT0KbJTJDywN1vQW4c+lbrCGGQEin8NmQnIJgWpAxJUqS+lJ0XtIQq1ckk/QkHx0kgbR+uHUBrDWHGQuRv6oWZDJC/Yy2RphqKtvb0NiVB6iB1pGGh+VIEAml8YYeEP02TL04iv4H6HluoHrKM3Cjkt0qu+sXvOXLEAZx4dCEEd0EgAoEI0vRDjUT3Q+EQtfnELjCDgsLBeKwujdBSSzBYqV7Xqx6C2YTKIBQS5A/03j8UhAaxXRItANG+SRJBm11lCQoqYgCkDUmzT9LgJYIlvOmNi7qb6G2TC4GLmqzbSGwkCSSNuBT/CJnUsB+M98u/mTg4PMMM/shTbGa396ykJxWcsOc0au+ayHt/K2RXQtC7D/TvByefDP36Q98DVB/XZSvh4/nw9HRobIR+B8CUy6HWhOeWQnI1dCqCKcfCwX0hJwi7q2D+MvjHuwpgAQrzoDC3naEp6FfkAQGvJCfgU2CbAd6yoh/5y+pgyWZoBh0H7Cg4Tghn+us4jrq/ZUgsNA20RtDMAsQ/XkcTXgZ3IzSuU9uKhKG8BPJy97XizQiEQ5ILppzH7bffDqj9JVMQjcZpbtqN3wc9ukQpK8si6HcxDEFBaRKA8lJJbo4g1vwpl19+Ca4Ll079Hf5ANomUYE+Vitfm5UJxoaBvT9VC0TS/voXi+BPHc8nvLqGZZnWbDcCQE4fw7FvPUjZeWV6ffvQpd911F4/MfYTmop34pI+nfvMUc9+Zi4bG8uXLEQhiIupl8NoIlHXkChdflkFT3lbIA8vaC7qL7U+goxMmTEiESHya4IpLrgDght9dT9eKrsyfM486qgkQoHp3NePHjacb3cCxkckoaauFpBMlSoKE08xeo5bVBXXYOjxw04N88vZ8dBeWvfcK+Uk/YV8+gcAgpNTwOwlM109Zc5A+u1Wc9fwbbmPZ2g2UlBTxzpPTKM8vIGuxTWFBD/ZUNVOcU0rn5YPBzkAQ9NXqeWvHm4RbVUbd3urdlBWWowGaz0Fmp3GDFi19drJ7sEACt075HRuWbaCwvJAHZtyHqZmUiDIG6ENIZktuvftWdiYd/vb84+wxDHQEZ06YRF11NUOHD+fBRx+hqamJpJvGMA22791Jaacy0oYCTNeXi5uTS8GgIcyb+zHVuVnYuKyv3MHB40bTWBKmvqmJ5W4LUtNZvnsz2eWl7MWhoKKc6l17wKOHrd5dSZfycoowCKERwk8QjaGE97mUHAdStldzbUuSlvfYBq2CL5cg/DfIfjDeL/8W0kIrd/E0D/AGDUQBCz9wDpO4dOu1PPmnPJ58Sl00Z5wNv7gRevWGlatg/gJ4412YfzNUVant5WRDv4NAFMPSSli3CHLDMLIX9OmkmgRs2wnXv6H6yAKUF8MRB6tY7thh0Kfbv2bVJpMK5HKyFcj8EAlSrrtvXWks/u2bC/wz0XUoKlAaDHz964466ihOOukkrrrmKrKLs9jTvIfa1hoevuthJkweT1nXUs646GdMe/uv7GYPO3fu5MWFL3DQyEE89OKDDDx8AIPH9GXFqiVtpTHvfzCHdWs+I+LfRp+eXbl6hmqhmOmpvIsdRGllNzuJEqVa38v05dNpoQUbm9poLb5WH33L+mLbNitnrOTQ0YfSgx4sX7KMOy/+My+++gA9RD5ZOyGYTjPtgvNJTb2AliBsTizlwMMG8OBLDzBp8nFMf1ZNcvLTIYrTOYTcAJ2cUpq1KD587N25l9YFrYwbMYYHn7+Pow4dzehBB7F8/ixVsuM6NNTVcu+Nd5O1w6LJH2PW+7O48Pbz2ZBagkSSCoLbAQ/SOgjLpHB3Gb5UiLvPuR/O0nEdQbRaI9maj26Had2UiV6GcFI+Whu70dgwFJDcfeNbIFR9bWutxvhRp/HY87O5+vwRPPvq4xw35idotgbCRtOUHjqsN9tu2UB1ci2dunbnrbkv8cwTL5BzIOh+HQjiM0y6GF05kCHEiPLQkw+SJk2YXHSy0AjTiMFykkx//Ene++ADHvnoHRoNcFA/zjtnvqHM0bjOumoYfPAR3PPA6xxzys+Y9tDTDD3qeFa3WGC6qt5Il3SfOI5bfn0z6xprAJj7/odcePstRIVk2BGjefe16Rx7xk957+kXmHjSCZRjctqJJ/HE/Q9x5RnnsPTTzyjJyWVMWQ9cL1Fvb0LHdmF3nSr1StuqFHDfCgaB5pXnBbxyQ20/N/V++U8VB4fFrOQD5vMaH7CC3YCJwOEgOnMexzNq7c945PYI415UYHH0RBg8Amrq4PJr4NPPVb0lQDACZg6EukNKh2YNFlUD1e37bIrC7GqYjXJLdyqGiaNUMtXY4dCz878GmC2tsOBz+PhTyTuLWli9PISbVpRBQnfwZycJZaeJZNvk5EhyszSKcgw6ZUUoyDHIzVbA3XEMBWHNBli4BI4bqxrMZ9ziPlNZsQH/l0kd2tSzht1M0wGv8YDrtpP4Szymra+54bi4JEkSJ0ZW/zCX/f5Sxh4zFtd1MUyDG+7+BSs/X8Urn7yMT/cx6/U5fPTkHEYfcTh9+vVmztMfc+cld9G5d2cmTT2WLWxGIPATwIePerOKwSMH84tbfs6GVRsYPmY4vU7uyUqW4+JSTx1Bwl56XpJK1IxLQxAmRDqWZsqJF2ClLBzH4YgjxnHlOedhVjfwhytvItESZeq51yE1nfLOpTwyfRqtZoq0rgL7AUvj9ttv5Kopv+LNO1/htAlHIiR03hVlS20zZjJJ6Y69FDlBxI4QB/ToxfP3PMEVyy+nZ5ce/P7i39GyEaT0gxRomoVfL+GXF13FhDFnIIBbfn4J/WQuzVJy/y2PMGzAUE4Y8xOWf7aJc644i+aWRub9fSH35z/OglfW0HF+peKy7W7Ud2a/wU13XUF9Yy1nXDOJgX0G8+p9M0F2ILcw4dqpv+SC637GC+88RpfOFbzyzBPk59dTWbmH/3fV9cyYMQP0LO5/+EFOvOAnOLbD5HMvoEu/ATRbMPPNN7j+F1dQW1vLpEmTGDT4IF6Y+Q4pAkRxqcMF0sRxsZH4gDsuvYrSrp05b+QRABzxkxO46Be/gagBcUMV/2ouV9z2e3596WQeuvdm+vYfzEmTLoYaP2tXLWb6iw9z8x2PUmAGufjy33D+kHEATL3yZsoTFYg9cOO1d3HtZWfyyK9+T/+BQ/jpjZeS2OtjxNATebf0fQZ270sgGOKPf3mSVduVlfvrq89kyWdzaGqsY9jACi6/9jbOnHwh4UwVggl+QzXA+J+oLtjfQnG//Giykz3M5GNm8jEfsYAmYqiyIT9h/FzonMjpKy/j8YdCvPsONFeiEmlMSEO7q0gDfKhKiaCnHk1e0COLryiBft1h+AEq5lmQo5Kp8nPU+g/BLFRTB/MWwbxP4eNFsGKtxHUF6DYMWoJ56CK6d3OIRjVam3USrSZ2cwRacqElxxu99Wj2P92Xzyd595l19Op9AMGQSyjsopsqyUcgvpR9+23p+ySSGFHSpD0CQKuNCDDzN2OhgiJdCBEiRJgQIYKE8eFr25+D08aQtGn7Js45/hzeWv0WKVL7bOeLIhBtyUr/TMKEySEHE4MkCWJESZL4Tkk2uguRhIq3ZiXA//WHheP6SacLSKfycewAOyu3c+Y1x/PJy6tBuGiaq6xRIXBdgZRe7RkCIfc9B9JjnOj4fOa4baGs46ShJpOZlwjvBZl3ZB67QqkUHdclaFKl/gqJEAJdqIe6EBgCNA9hXLe9u5b1DU0YhCaRhlRWqykRhosw2nO3M2UJGgIfGiYCw9VIxTUScYGUAkOX5IYhPwJZQfEloMtYrknLa2dpqeTFjjzjGajah3v8KzjIOz5v6gpo91Hjx+Og3t9Ccb/8W0iUGO8zn3eZyywWsZVdgKCAfIrpRvMel8DMw+n99hlEl3Tmsd0aj3ruIgk4PjALIa8AtADEbWhOAAZ07gT9eynAHXYAHHogdO/0w7Q6UwAVo4UWggTJ9jok1dXD3IUwewHMWaAsVgBfwCYybA3u1W/BoXMZNczgotBZnMqFRIjss+0ECeqpp4466qhmLyvYzGbW25vZ0FrFptYaYs0GtOZAcy56NA+t+1bSBy4ivfUtasrj3+ozdARmE5NccsknHz+KQNjBoYF6aqkmRarD+wQGJiYmfvxEiGBgEiBAiBA+/G3AmSZNjBjVVJMg0UZRmJFqqtuYmvLI87bavhgYuDi00kqUVnwes1JYRhCug+OklLppHDeNz3IJplxwmsC1lUtYujgC4n5ImW04qEZNR+q6GjUdIXRCdoCgFQBXQ0oN6ROkDIHrajiOhtAFwtSQaQO7VceJefHqMATKIBAE4Qe7C9itGsQ19FR7g4q0gccCpeaMmVEdljowF4ljgOWHdEjiBACj/Q1+TdWOG22jAlJDU+sWLq2OJOq4xF2JdAQ4YDoapqMhXIEjBbaUOBI1BZJSkctINW3SNBCmSnwK6MotjC6RusTVVQKTtARYGtIWYAlIC4jrSCm+cvLjourkk95j04CibMiLQCTwZQDe5/cqVA5GwAdfCOf+n5H9lvF++cFkK3t4gFd4ifeppgkHh7Y5vQSxvhva+4egvXQM+oreiEQg8y81w/eBmQ/HHQd/uBF21cEz/4DXP1RZzT07w7knwDnHQ/eK73eMEskGNjCPeaxkJQ00tJWUdFy3saExDxaNgU+OQCw4CrluIABaKE7eIWsoOWw9u0Y+R+ug2VT4SjiP8zif8+nF9ycJkEhqqGGjt2xhCy4uAQJMXDeR7v26t1nCHTl3v0SGj4uD0+ZijqH8+SFCmBgkiOHgECZMESUECWFgtHH8flEcHGLeEiVKjFibpauhESRIwFv80k/AMfCnXfR0CtJJsFJ8LU1Y205scC01wr5JM191IxcChKFSvXUDjAAymItDEMcycdICJwm2p/IrYutf3KzooBJlsVqaslodTYFr0AIv1whHBzcIIgI+j8IzQ2CieWBqCZdG16HJcUi6EtvntiP0V+z/u92RZZu2H7vAj0YADT9CJaIBFpI4kjguEnUIom0rEhe8/2SORRJEI4RGEI0gOkGpIR2B7YgOr2tfabPghXL3/l9v5LHfMt4vP5pUUsvdPMeLvE8lDd6zafJkhC7rR5M9ZyypOQPZ8kEZ8UZVIiABMyQp7g2tfqgxoFsvuP5M6F4Mf/8kxeGXu9RWBcmKuJx+rOSCE3VGDfnuF7eNzXKWM89b5jOfWmoByCabQgrJI4988ilp7Edi0cE0LBjEnoW92bu2SLnYAhblh2yj6KTpZB+2FGPwMlrNBlpo4TgOZAr/4GiO/kH6CwsEJd4ymtH7/G8d6yih5Httt5lmKtlDjHbLOkyIPArJIlslFZHCwiLtLR3XO1rPAQLkkEPYDRGxTQKWQEunIJ2AdIMCXulmPtB3z0TV8NK/Fci6up+0FkIaPnw+E83nQxh+XKlhxyBdD1aDwvEvIlkbVHnH0QZY8qsPS2ogg2piKCUIG3yekvbeFIZALoRyBcbXJLulcWnAoQGbGC7oENY1SjEIINAQ6ChPhIYqsdG8xxJJEpcmbJpxiOF4VB4QRG8DWa3D5/Oc4G2axCWG01bSkxETQRANyyO66Ph8FjqhDurrMNlrEwF4cdX98sPK/q90v3xnqaGBP/MUL/Mhu8l0O7HpThHHrDiH1ntP4pMZETZ6yVO6ASkXtCAMGAZ9R8CSvYKNu6B3OZx8INTVu1x/l0M8aqpsykM/gquep/XIN3kykOTvFFDuLWXeYmLieEvGEuy4bGITC1lIFMUx3J3uHMuxjPaWgoY+zFskmLMA5iyEVevamaYOOximXgdHjIKDB5v4/X2APsAp3/j9pEixmEXM5SNqqKYr3elGjzbNI/87f+eZdm4xol5kV0Flhkx/3740HTvVCJIkaKUFDY1SiskihyhRGmhgh7d8UQQCU5qYjh9fKoeIbRCwNAJpiWbbYKfBbcYSimJbINGE6wGKqdY10E0fwhdQ/J6iA7G2aEdHqd5NGh8p1yTpGKQcjaQlSFmq5lt4IUu/DUEHAraK/bZbdqoc1hXgyHYA1nXl3jW9xvWaroxpYSisFx0f64oWUXSwWiWSJhxqsIm6juf+Vv/TEJh0BFJlWaaBtAeRPgR56GSj4UdrA1AH16Mml8ptjcTxHsc8FigAPxrFXkVyBB3tO85sXA90kx00hUsQjQJMwp7F6/s6U32//Giy3029X/6pSCRb2ckilvEqH7GANdQSRd2uHXpTxjnyOPrOPJun/pLN7A8V+GohVXbjaiCzgGIgH9BUQklptupCtHG7SnrSCqtxx/yd8NjZnDWihDNCJ5AiRaW3VFG1z3oVVTg4baxDOvo+6zo65ZS3Ae9IezQN6zrx6VL4dBksWgLrN6vPGAzAqENg3EgYOxIOHvzderO6uKxmBXP4kI/5iIXMI04cDY088qmnbp/X55DbBszlVGBhkfRirkkSJEh4KVAJ4sSpo4Zaanhx7QyKenWCVAiZCkEqrEYpEIa1j2KkEboFRgpdcyhIByi0QhhCRwgFhhJB3LBo0RNoDpA0cZIGtmWStH0kZYD0D0B4kIlRfmUCDmA6ELEUuOod4q2ZdeHua8Vm3ucKSJvQYkLMUDsK+lSji+wgRILf3O7x68TCpRqbOmxspGe9eixT+3yyjmNHcfmSmf4NonvWcgCdHHRyMAj8KESM++W/S/a7qffL95Z6GnmfeSxlNYtZxeesU242/Hg2DwPpzDkcxwWpn/GPZyP8122wd7dy8dk6JLyYWedDYPgo6NoFWppg+25Yvk7V9e5pgvABG3Evegkx9h2O6V/IFO08TuQJAnzZ9+e6sLsSNm5Vunm7utFlhQWRsCrxiYRoXw9D5V4FvA8ugQtXqvpcULW0hwyVnH6qxZGHaRw6WMfv+3qLQyI9S7KO+g5aRw1L+JSPmUWD5yHoSz8mcyFjOYpRjCWHXKJE2cE2trOF7Wxt0zWs5EPexcTnxVyD+Am0rQfiJcQ+H0Nw40HkbO0Nx8Zwff0BL57nh1BYoGlg2Tpp24cVk6S/0InGAvZ4qt7ronVQyCNFe3cCgUtApIhoMYLUEiSOkcmE1g0wg2AGlPqCik+YfcumHOmtOyDT3kG4tLWuQ4KeAi0NmtOeeEVmzAC3bHe9SkDoEn+ewJ8PZpYysMs7lGh9sduUOncuLThEcTEAHxo+RJsKFOtSqsPrrA5bAInhuXcDmBgIDITKGu6gGWYnX1scv6Plq6xUF4nqwdvups5Y1j9GA/v/K2KnIeH1z9ZN1QxCN9pH8W/oCNgPxvuFJCne5iOe5Q3eYQ4OoHt8NZZXDTqeg5nKaRzDCNas1bnySvjdxypO5wqwDYiUwfixcO7poIdg1mfw4SJ47T21n1BelMChn8DIl+HQD6goDTOFKUxmOp3oBKiLZ81Wiw+WRNm+2c+OrT62bNXZtE2QTLYfcyAg0DVlff8z0X02RQN30uXstfiHLoGhnxDtspyFop5PcJlGJuHFj7+tB5SfAAEMDJppop460qS/cvvldGICxzOGoxjLUZRRDsD2anjkE6hugiMOjDB2wIEMCB34jefCsuH95fDcHHjrU0ikIeSHwd0hElhHt2L1OGAKNNeCZBQSrWC1qpgtIIWG5c/GMrNJ6yFsYeI6Lq7j4Lou0nFxXanUA7t8GgmKOEES+LU0muFTrmXDD0ZEAbA/pJ77gkgJTkrlXTlJT1PgJCXOPjVp+yZIZTB33rI5PPDcXbz88NvKk60rdTVJSneJ6y5pzcUKSqwsl7DQCKMRQSOMjiEEkyZNpKqqCtu2GTX6cP7rgWlEdXjw7r/yxmNPoRsGBUVF3PLEQxR37fyNNuuYSAmbovVke/zEBlpbb13tW7p0n/uWLRSvvvpqVq5cyUsvvcRpp311C8Vbb72VSCTCddddt09rw88++4zhw79kZAE/bAvFjvuxsUl6OQQCuOT8S5h4/LGcfNrJXHD2FJYtXoZpmm0tFE3T/NI+77//fu655x62bNlCbW0thYWF3/yFfsNny83No6UxyUX/7yJWrlyO49iccty5/HzKr768AcNFMyTCyLhilErN/ZJWFOeg/1CdWf6J7Afj/0MikUxnNp+wkgZa2MxOtrCTGhq9GbuO9OKZGgbHcRiTmcix7ijefTvAzXfCT5eCE1cXoaNBYS8YPwkGHQQbd8P85S6n/0bVFuqBJKFhi9FP/TvOoe+R7LWO/tpgLuZojuRxCshju9zGfZvf4fOFITYsLKd64QDs6hIgDwwLresWtB4b8Y/ZRmGPHWT1rCS3RxXZpVHiIkq920BjIokTCyFjEWQsArEIMpqFyGvAN2AV2f5scimkwNN8TqGAQiJkYWORJEmKlJem1D5apMkhl/x93tu+XkAhOeS2WTSV9XDvAtUsYlGm7MmAu99SFtvIvnD0QTB+MBzcu92KkxI+36QA+KX5UNsMBVkw5Sg4eyyM6AM6NuvWpCm090BrK1gJZXZCO9bpmYcuPqsJn9X01VUiutdnUTcVuOoZ0M1So/7VabCu5VFtJtvVToKbYp9mEkKTuH6JFZDYEVWjaroCX7OGbmm4usTKd/EVQk5IIyeqMpHz+in3cKOX+BT1wC+I1lZWriNIeBZsRvwI/vTKM+Rm59Asba4+7Swef/VFJpzxUw4YMohnF3+MPxTgtYce4+4bbuL2l5/CRNXEGl5euro+IIJOIQYaUIQgRpQqYkSJ0eq0ous6WUTIIZsccgjw1fGMhoYGbrvtNhYvXowQgmHD2lsodpQuXbrw1FNPcdddd33ldr5KBg4cyPTp07nkkkv+6ev+1RaKAwcO5LXpr3HxJRfTQCNb2UGcWBsQZ6SJFvZQyTo2cNjZh3Pdc4rw/Tdn/Zo/PPZHLpp6MVlECBNCODpWAob0H8VbLx/PcSePI9ECqaAXs/c0Y7m6jrJyM+p44y1/uIPhA47iybt/yf2P38Gvrv0jN/38T7z17nSSUYv3XltG3IpyzMkHMfHioyjrWYxrCaStoVmGpybC0RGOhrBUSZhwdYRrIlwNIdUvwy2y0X+EmPp+MP4/IvNYxnVM4zPWYqJ76U4WGhqdKKI/vehPTwrIoYJiRlSP5tlHs7nuGZi8TWWVCpQrOrvcpeeoKG5JnHWrs3l6VghmgRZpRQ5aiBw/H4Z9jHPQQmK+NAaqyaEBbIquZ/1muHdFE/aCcdgLxyJrSwHwl9bS9bBNDDz0U4aPSFDQo560GSVOjDhx4iSI4yNBEXHChOlBnlZAfriAgnAheRSQ/wXtCJb/HVLbDK8vUCD68RoFSoO7wx1nW5zeaztlzk4+2ajz4aYcPthZyq0vlnDLixo5eowjwsvorW/nzdhYNqU74xdpTsxfzOS+c5iYuwRfYxJejUP1JmipgovfgawO9TmGT7mJ/aEvJUc5tk467iMd8+GkdYQmVA2tocgohJcpLOOq5Ee6XgK07DBm/K5SqnWPieKVGc/x6MvTsOw0wwYcwjUX3MTJl41n5hMLycvO54SLxnLdhTfTs0sffnrlRIYNHMGqDcvo1bMP9z/6JFYnH82ag+OV4+wkTV1LM+NPPpEtGzYyZMwobnrwHgxNcFiklDOuupT5b8/EHwxw11svUlBS7H0B6nhSCMgOU4uNbaex0mmEABOXw44YhcDBJcaQQ/sy87nnyaIWEx2jrZjLYM+23Vx61iWkbYvDJx6Oi8tK1rBkzmIeve1vlJaVsmH5Bp6e8QynTTyFASMGsGHZerr36c79zzxAaaiUCOE2q3nmzJmMHz+evNx80gkYd/h4Xn36PU44+kyEpuZBugl5ZjcKSsG1NawkWEl1KqXHkCZVvRF2Cixd9VDoVtYP42tyGjL13zY2b7z1Bm/N+Tu11DHxvOM4ddzJXPany7G9eLZAY/lnS+nUqwKzh58a6jjuZ5N49vUXmNrzcjhAJy7UdbeXGkooI0yIAvIJEiRTb55NhFJK6EUPeh7XHQDXkRw6eCTVG+tp3aWTSEiMpIOeVjPGLtlDVM21DQ1bIVOIEU/E+O2dV7B+8ypsx+aai2/lmLEndfBkSDAkMz96kxeeeQ+LNKceex5nXHwEv7rqDmTAIWG3YgYlIu3g0/3k1vUioucTKYBIgQSfg+3R2YD0MtpVuaAuNdyURqpVqElCDHTx48DkfjD+D5cVbGQqd7CQNZ7h1IKDxQRGM5mfcBLjCaP68m3bDrf+Ce58DRL1XvIMoOkSX0Ua2aWF1kQONbaPmvXZEK2Fke/D4IWIwfOh51o666WM5HAOqbuQnCV/o3JTDus2STZtMti2KUR9ZXsPwMLyOCNGp5h4WJIJIwP06l6EED92t4VvL41RWLNT6eqdsGKLw4KNGo4rOCC7jlu7z+dn+uv0bZgDL+xRd1MNjhJKbxdQ5y9mlj6BD9yj+SA2jjedwxlnzuPG8O851XyVHKdRUXh2oPFE6JBbqlzF+RUQyIYbfgsrVrW9RALSBumoG5xU1TSEhHo7eODaUb8gdp9BxH9xp/qnh+ttNeAeIcSG7WuZPuclXp0+F8Nv8Jubr+DDTbO46IrruPKeixk+bAR9B/Xj+Mnj2bFrO5t3bOCuJx7iv8Y8xI0XX8p9L9/HBdddRQC87GFI4rDss895ee1iyrp25sqJP2H29Df5yWmnkojFmHDoKO75w2385oabmPvoU/ziN9e31cR6WIUDTJ5wMis+W8roY8cw/rSDSLO57bMFCPD24y8z9tixuNjEPEYwx7Owr73qaiZNPYH0rvnNAAAgAElEQVRJ5x7P6w+8hkDQmU7Uspd1n63l1dWv0L17d7Zv3872Ddt4/PHHGTBqIJddcBkPPvgQk687B03q5KTzCMVy2LhmF3mBzuxepr7O/FAFO7fvwbE8F7wD6bhXjgWkWqB5D+xd/dW/vVg9EIf6Le3PpVqhdotLZY6FE0yR9seIB1ux/AmkJtlbvZd4SYodcjeUSmprammiRdWS2zoiabBzXQ0l+RWktoTRkn5K7L4sX/05YlUZYVFCJODgT4TpVNOLXvUDMIMCw6+sV8dWkwQt5UM0hHC25WCnlLcklbSY/uSb3PKLewnXFCFMifRbWNnNpPwxrEASzTZwNZdUMI6tOQhXZ9oTf2DkweP483/9jeZYAyedNYrDRo0h7M9Cc7wsPVtQV1dDebAHMu1S0beAhpYaug7WmTrgDBYsfofBh5cTj8f5y1/+Sq9B+UTroXEPNO0RBLIMQjkG/rC6TqwEJGNqdNLquUwYRUedI+07JHR+X9kPxv+BUk0tL/A29/Ea26gFJCYWxzCcn3A0J3AUJSjQa2yEPz0EjzwMTXtA836Imilx82ysiIkMCRIBF73XJrodVMmIQZLywVtZUvAGS6p2Y246iMFzf0vpY8ewe2MOH22ClxvajyccggN6wbEjoX8f6NcbBvWH7l1CCPHlRvP/U+I4UNcKexuV7mmAtbtg9Q4Fvnvq21+brUUZ4K7iBmZzBi9xYMsqhF4KheVQVg4FYWjYoe5MHaSQGk7nWU7XX0QGc0kEywjl5UJOKeROVmMHdYKlpNwyUi0CJ7GONKW4MTCSApFGWbBOu8ca1M1eM1G9ZVGJVMIB0YGoAS8uq2Xis0LiFjvUDU8S7VDXGvbKcnyeM3fRnI9YtX4pP/nZoQAkEglye2Zx2a1X8O6Hz/PMcw/x5vK5bM5qYWtTlJLOFVQcOQwLyQmTf8Zz0x7mwuuuaquzFUDI0hg0dDjDOvUmomtceObZrJ7/OfmnHY/P56PP8T3ZyEZKh5Xx2Qefso2tX3n+7p75F6ykxS1n38z6WWuZMH4CQS8d7sXnXmTT4o08NvfRNhYyAFdKUmmH1fNX88K0GQT2BLhsQk/uu+FespqK0eNBDh5+CJ07dW9zmVZUdGbEAUdgV8I5R0/lkSemUTphEG5aQ0iBjQJK2870JFZpcgiBFlAgLKWKBoSKIJgFwVzILoP8bl59syaRwsX14pa+AgszK0WgfzOWtEkmHVyfRcIfI5m2MVpC+GQEX4c6dM3RKVk6uP134ejkLxmIEO1l4P6afIxEkHAiF8MPgWyBPxvyukrspIaV1MAVJOp0GrZ1iP1r7dtItSqLPd7oWfMSfn3HZRw8ZAzDh4zGlij2rrQf0eonQE5biqZwFUOcVpBAhlN8vOIdPvj8NR5+XXUFS7kxqnKWM6Bff0zXh2n70S0ToUE4D3RTA+lHutCwBRZ9/hl2TGfFh5U0NjVy0nmjGdLpaDqX92g7624rRFvxCh73FaF5kRovcqOZqgTux5D9YPwfJHNYxK+5iwWsRxE2awykC7/iPE5mPEHvEkil4PFX4E9/hu3rQHc8ADZcnDwXO89A9txGcPAKBgxqon+FQZERpKbSz+adOh/+Q9B49zjkpstwo1mAar6Qlwv9e8NPJraDbv8+UFG+byu+f1VcF2qaVXJT5uKXdFj3HifT0JpQ2hKH1mSH9QQ0xRToVnngW9P8xe4t4Dcl/QujHBlcz8Cs2QxsncOBrKKiUw7i4OOh24EQvwAq18C6WVC7VL2xqDuMPh96joBIAYRy1d0jlKvUH0YIwRenIlJC00bYOQN2vguVcwBLlfoMfhdaMuRUF93Z9p5vcsJLIUlFXBJZDomISyriIL/mfISQFGOSjUakrVV9h/9LjSnnncett99GJbU0EEXiozHusHt3LQ6C6miKwiwLSStCuEi2kULgUotGmvXvf8JNV18PruDaS24jEspBT+rIVX5aNZfGKpumeILt6T3opk6OyCaHbLronVlrr6av04tRw0aBC8ccfQLXXXYbdkLRNmo6TBp2FrOfXsixvc/G8cO7Cz/k97//A3NmzwXLT0sT3PK7X/P+R+8gJcx4fjnShdReP46h0xpV56F2MzTuAt0NU7lSff6aSpC2oGGbepxoBukIFi9ZzE1/VDHcay75HSXFFSxaMYtEYSNWOMYOaxUjxxyK7FeJz9Gxm03cRj+t9UFaazViLS710RjbzR1YoRjTfvtXPpkxD4Tk+aUv0+irI+kLsSOkJiKBcADhd4hU2BQPcAlKuOC8KSxbtozSknJef24GxSUlJIwqSorL2Lu3iuKiYrJKAKlAxgzAwGgFb87aRekANaGrbd5DeVknlUESBCMEuh+yO0FOZ2UlXnb1FFauWUZJUTlPTZvh1U0DOgSz4Z6HbyPu1vLM04+o0JYLx50wgZrqaoYOGc6D9z2mPDdeykLnviaFhREggk8YvPb6P+jbt+8+v7spU6awbOkySgrLeW7aDApyS9ixqYrS4jJq6qsozCvGTsBrb73AkYdPxB8yKYsUc+jBo1i3azH9hvRQiYGaUjutch+lhEAWBHPAF/6fZQzbD8b/AbKGjVzB75jNcjTCQJgjGcaD/JK+dG173a4qOO9i+OR9EGmvllOTuD2qsUMBXDeXcP/VlJbWk24M07xgEMteLmdZct+uCoHSOvr2SjPm9CAH9m4H3uLCH+7H3BKHbdWwdS9sq/HGathaDdtrFND+KxIOQE4IyvKgPB+G9oDSXJcyrZbS9DZKG5dSVvkhXStnojfEVa1WYQX0KIHwAequtOldmPsX5a/zh6HfkTDhGjhwApT0+qdfhpTQugFq50F8DzQsh+b1EN0hcRMeXYcuyXbaS14EHrGEIXF8KknK9UssU5LUXVxNInXw64KQrhHUIKm30qpHsYWFg40tXYRlYCSD6MkAetKPljJwAymMUJrskEleIIwpdFxUXa0LpHBJ4NLnqJHcedLPOOKaKeQXlhKtckjWx3n23ns55aSz6F7RjbvPvYbnn3kTWV3A3p2V7H6liaH9D+OD+6ZxSLfxDM0/hveeOQaJyl79ZMUHLF/7GVsb1tA1vw8z3n6Ds06+mKKVAxGuRmhtN/RscOr9WM0GLauyeOexlW3fZVNllNZ4K6XFZaQTNh/OnsEhQ0YTr4PVG5Zx+S8v4dlp72HtKabGe8+1U/7AtVP+0LaN4YNG8fb7L3HKcZP5+3vPA2D6FVhoOvgj6gT4IrBn707W7FzIiBEjeXf+ixw++nDGHTOCT45ZDo56bcxq4J4Rv6YoG2IIPp+1iOvuvI4qakCXaPkaer6O7hiYLVlgOmjRIKFN6nq9+dRH4VTv4JZCsKqMcFOYwiWDFQuoJhDRANbmPJoDYZo1uP1XT7alDiRicMyRJ/LcS09z9c9v5IXXnua4iSehe6Qmrg3xVuhRejDr123ik3e2UVTQiReef4l7/usF6jrwwFgJ5eJtyFG/wTtufFL9IgWYPgXquSVQ3g+eeOoxZs+byUcffYTpa5/xffDBzG91XU6YMIH77ruP++67DyEES5cso3/PIfzl10+SbIaMy+aE40/kvaVP86ubbuTpO57mlNNPongg9B3chc/Xz2Jqr8nE43GWrlnEDTdfTfZX0OfmfKsj+vFkPxj/L5Zt7OZCbmY2y1HVkxGOYxQ3ci6jOAiJZFNTEy/OS/DEtCwq54TRbYGGxO26l/Qxs3DWjYXKCrBaoMUlNn8Q8UgLgW67KexdTcVRezigq8ngznmM7FLGoM45BALfrQzh20hNE8xdA3NWqXHNzn3/nxNWONi/Mxw/HLoVK0AVGYpD8eV1v6nIH7KCiggiy1uPyBb02m1QtRl2rYWda2DjGti7HjRbXRWZK8P0VNPAjUG8TmU8BbOhoAsMOk6Bb+/D2sp+EiR4m7d4gdfYwjY6UUYnyqmIdqH89UMJvdUbfX4+ora95EOiXMXxLIemrhbVvVIkutpECgRWZ/VcWYlN7cAkrtYxVqoIKQwyXMOSuOvSagFpDT0ZxEhE0FMCM6Whp1XWaNt+NYk0XURLACEFCSCmSZyggx1yscMOdthBuAI9qdE5ZyDX/Pw2rh7zU1xHYhomv776btZ+tozbHrsfQ9f5x6tv8PRDzzFy+BH06t6P115+kV+tvILuXXpzwbmXES6U+HIcyEqR1tL4W+IMPWwo9zz+azas2sDoUWM5/eyTSbWoY0zHlSaa2qmrNa/c2Z8FpGKcc/qJpFIpr4Xikdxw26W4Fvz52utJpKJc9pufgoSK8i689Mzf20A2U0p130P3cv4FZ/Hc3+/llFNPRWhQfiAU1CtwLTlAHUvCD/369ePN95/mhlsvoXev3lx26VRkCpJNKmSQqAbI58rzbmb4QSNAwA2X30b/2CFoaZc77r2FESNV1vLnSz9n4slH09jYyJw57/HAk7exaO6adlIU2W69BUKC7BLB2+++wY2/vYL6hlrO//kkBvYbzEtPzGxL+HJdFfu8ZPKNTL3+dJ594XHKSrrwwB2vUrcDqmsrufH3/4+n75uB4Tf442/v57wrJ+C6DudOvoAxxw5AWvDGm29w/W+uoL6+lv93zSQG9BnMC/d1AFUJblxl1ceqoXolTL3sUirKunLwkJEATDr6FK677Lf7XswCHn12Gvc/8Wdq6vZy4IBBjB93HPfd9RhXXXAzv7rtagb2H4R0JZ1KuvH03W+jGRAuhlChOu83/+5GTj/9dJ548nG6dOnCq6++CsDll1/OlClTGDhwIFJKpkyZwqBBg77Lreh/TPYzcP0vlKWs43L+yCLWAxpZBJnKKRxAPrN5nzW1TWyfN4SmuUci5x6OsV5HTwFCYh++CPuwpfDuGVBb4M00XfJ6NJNdKrDMENVJE01TDbY14XV4waMTFKoby+DuMLo/HN4PRvRVta/fRTqC75zVKjYLCmAz2+3bCXqUQvcS1fnlO0lTDWxdCtXb9tWabdDqBbQ9nl2ywkBa3emFgE6DYNhJMPh4yO8MoRw1/e9g6UokrbjUYlOPTTVp5jtr+LRqC3t3xMneXkzx9goq1pXReWkexTuChOO6xz2sOukkDZeq7mlWT2hizYlb2D16Bb7AbiJUk0sdEdIECdKdLgx0BnDYuoPp3Ks/CVsSt11sGzRboFkCPaWhpzS0tEBzxD7W9A8hHbNZ2ywzL+asGwoE0vH2FxoB2Nu0nbMvOp4Vy1crNszvcTBSqu3Gm9TjQJZyQvwYzd6/SrZv387xxx/P5/NWk2z0ANhrPh/IBV92exKdY3l1+FZ7D4xMnNUMKWAJ5v84MckMSEtXuaM1r7uUnfAaaXQYO+YfaDoYQU8DajQDXk5Cx8/pfb7M6KhEZW/nX8gXlO3HJF1vO94oO4aJBARy1Pfkz/73JOr4JtnPwPUfKDY2L/MBt/I3NlMJSCoo4CyOoI6NPNz6F1reOxHtqVtwt/VExMCocdCTig3X9oOdJWDTSKW6JFgkSWQLyNZoNPIIZsHwXtCvwjMEM4xKcl92pXgKFm+BW15UN0vTgGE9FYCO7g+j+qlWaDtqYEetcit/cb2qUX2uSAAO7w/nHgHjBsLQnmp73+9LsmDJDPjwCVj8jrqrCNQGc4sgHIbSIijOUWZW3DuIrCw4cCIMOhYGjicZzmEXaXaSphKLKpqpcuqoq3VpqZQkKgV2lSBYaZC/00f+dh/5O4JU7DyMbtbhGChj2gB0j3HJDri0DkkTHR2jeVI1rQOr2VBSx94GjVAlFO81KH+pJ/qe/gQ35BHckkNgdza+hhBaymC9pTP03fUkkz4vsaqjqLtbewmXRDMlZkBghsAX+hY3sg7xdryyGlvaxNNp0mmJjkZA86MLrf0m6t3YHUvdtLOKlRvXH1HxwNR29bz5L2SiCqHA1/8/1FZPSmVlOimVOdy8U4FW4xYFaMF8COQpC/3bgIVjKWaoRJ3aVssu8Od2AJwvTFgyhCpWQgGlFVfbyMQ+v047nqMMyHVUO6Wez4imml4RyFdgmwFfzfz6SVSG3/vrmmV8H8lY99JRn+PHSp76d5D9lvG/uTTQzK08wpO8Q5Qk4FBOFsMp5zP7Y/YuHoj290tx35kE9QYiBUari55SyfkybCPKJEnXVH5ME8iGol4w4gAFvsN6Ki37jv0LmqKwYD3MWwvz18FnGyH9NY3aTQO6FintVqys3rEe+H6RwvBbSUsN1O+ClmrYtgxWzERuWczWvBSzDvIza1CQFr9D59o0XepdujS4arQK6eTrRU2XwSzpM4QdPYewM6+IHcJiByn2JC0Cn/sZ/FY2g9/LIdCi44vq+Jt1hCu+xDgczW/Byo4TESa50Qi+eh+4ymoM94fcQyB3FJidYed2m0WbkmzZ4hDdohHeEsDXaqrm755+sa1dOuxgB110AyY/s5nOpX1BuLjCxRUOUkikaWMEJVlBP1nBAKZf/K+0Ir6vODgkiOHiEiH7WzNkdRTXgXRMAV4GeDNjxxOuGcoCDuSrScd3+Z4dHFppxsAkSAgnrpOoU+Ds2moCEyxQo5VoB+CO1qIRUJm+XwTXjpqRNjazrwBrw99u6RoBtc9/VSTSa9Fi42Bj4sPA/Leh+cwcn+01XXGwUNXuiqY081d6OfCZ9XK6fK/fFHw3y3g/GP+bykJWcj1/ZSFrcQENmz4U0sIWKrcG0GZegHjnXJxthdDgosc0fDIB0aDKbvRJrDIB2YAf9CwYczCcfTRMHAqdCn74Y06mFZPUJ+vU/atbcTv4lub9ixnV0QZYPxfWfqSylivXAVCZK5jV32BWP4OP+pvsLFQ7KYv6KEmF2JWVot6XAEqAQcBBwIHg0W+G63R6LQjSd76fXvOy6fZ5LgFH45vuTbaQ2FLgg7ZOPFGgxdMofKF53T+XcLGksJ+kaIikYIhD1gCHYD8bJyTpS4hsjC9d2Jm2hzo65jce8XcX6Sor0Ep4tcsO/9S1mHFbZ8ql2kajPWmoTZ19H0u7HfNE258OkskJ0CToElezcXQLW09haWmk7iB11c4p4g9R4M/DJ77eJHcdSEch3eppXJIhNRGaRA9IdL8HWn6B4RfoXsnLd3W3p0lRTw0N1LXVNQvAT5AQYYJuGKMpG7veR6pZbVwzPJdwSMVIM67ib7qG2mrJxZeP08Ym7THMCQQmJgY+DI+H7Gu3ifS6hKXaGmoqQMuAWgbadFx8SPzItgYjso1/W0fD6EC2EkQnBx8+tA4g2L5Iz78tHYFjC1xL4FgCx1K0sbYNmiHRTAfN5yBMG0wLaVo4wsHF3mdxsL6RBlWdG7Vkeob3YQD693Qi73dT/y8VG5s7eYppvMJeVOpgAUEmcTAr5GxWfBLA98x0WD0It95BrxX4YhI97RHTiyCOAXYB0EUQyIdjR8OZ42DiEMj6by7pDfhg9ACl31fsVCuf1r3BgvgHJJu2Y8WqsJMNWG4CWwe7TGB1EiSMEJ/11FlfoczqfDeHI7Sx/JLRHMkYzEgXZgWiLKyJs7oqSaJKI6fSpKhKp6zS5f+z995xdlVl2/937Xb6mTM9mWTSKymEkBBCCFFaQg1g4FFBBUSq9REUERAQEBGlK00ggNINICVU6SWFhPReJnX6nJlTd1u/P9aekgIGHvT5ve/rnc/K2qfM2fucvfe61n2v+76ukh0eybVRUquq0QBL+FiALjUKSDYj2IYq2bCAKKpYLITERK2ni5BHNuTTFPJpMZQYgOYJhA/4au3WjXhkBhYQg2wGDNI5aEiEA/tEMAzR5aFUDoNISSfNAHTxWv4TE4i9imp8EfOc7jCokwc3p9igdh+9hNjN2+pJXego8O6qe/60kU8EoN0Z5gyBtrcwtOzhzUgHR3ZyawuEoyMKOrqfxPA0JQ/W/Wc0CR8ZsjFDglDYwAgJNBOcbCf4Bm8UEhktYlenKSbSuNEcvuHuMRnQgn8mJjGSxEkQI/GZGtY5MjRRTxq1HFJCKWVUIfHJkSVPlnbaaNGaoAy0Mo2IkyAio5imRURECBHZZ51sicQVLo7opnXNY5PHxQY8DCRmcAV7CNrQKCIoBMsqpgJoN4R0DBwzj6PncYStgLHHCdSIAGEkcVxMvB5gbiIIIZBdsqY+Lj4OHuAiHBc9GyJtQ71XQPN9hOejeb6qhfc0RVPpGgjHZK91eEKR0Ai3533T45cwPaTpQbSIEc8TSTiYlsAQRjAZUBxseiDToQXw2y09+u+3fQJjIcQM4FbUKHGflPKG3V7/CvAsEFTf8Tcp5TVf4nH+X23rqeNifs8LfNilDXsA/TmCYcxlDg+tfBvuvBnmHYbbYGPWS/SCunB8oWjyvAjIXlA9Go77Cpw2Fb46Bqwv2WFqp53neAkTk0oqqKKCKiopp2yfBw0AHBu2r4HNy2homM9c631e6rWBl0cWaO2z681nuhLDD2N6amZtSuUJjpEjOEeewOFiGsO1/XiHLHOzHbz2qGDYXR61i8qZ6Fcwcbdde2FfyeIVFedxDPClxvaQx6rBHawfl6FjUB4v5TLkgzJ6v1qK067j9nYxTs8z9AyP0fub1AYS7614tOLSikMrLi1B34pDAoMTqGAkqf/pT/+lWNcaZK4beJ0eTFAQ1KBGIF4SeGVRFcbsBOB93U+XBx14z5rR7S1/lndpUyRDBxnaydCOGyhGWYSIESNGnChxwoS6Bk4ZUCu6BSgWHbKFAk7RwytYOB16dwa5kBC1cao7yCdacOIZ0EMYlOBTikU5MSAU5Kv7u3lsRQq00EAT9QggQiwA5iQx4ggEaVppop4cWXR0KuhFOZVYPchGEkFhjfI67YDyNUvezNJKPV6PuIoVaHl1NgOzy0t1Al/VCbjUPUw84kgsJCY9swuUPKMgjIGDTxYTF5UZ6SGxsgLZGMZrjnUBoCEkhukjTR9pSFzTxw+atHx800NYPmEDQkJ5uyF0zACcfR/cvMDJCtyMwM1qyOLu44TiL5eaAlip+0hT4od9pJlX+zI9dFNimBLTkIQMMIVASg3f0fCC5tvKe5YOSFtDa43jNyUpAq4licQFZhz0hI8M+9iimw5TLRPJLgUtdW58rH+TjOU/BWMhhA7cCRwFbAXmCyGek1Ku2O2t70gpj/8XHOP/lebg8CjPcx33s4adgEYYjQHo+KxjBfNZtGUwXPcgvHMo+g6J0Q6aZylvQRN4BpjVMP14uPR8OHjUF1x/3QfbyjZu427u5kHa6djjdYGgnDKqqKSKii5ZhU6W6Aq/lPLtjVSsWEn5x/Npal3KS+M0XjzQYMGhOlITVKclMxc7HLvC4HDrGFKjZqGNmY6IJPd6TOsp8hJpLifN8lWrOehPFRw8uxfD0gZOfxtnXAHZKhAtOuEOnZCvwFcltSnLA5uBJsAt6iRWJBi3ItH1uhWDsV+DCWfA0MMNND2x+2EQQ2cvZYz/1KRUJSHRys+fHeziUPALFIo2vivUTF8aqqEjpNYl3uC7gacbAG/XuqJQyTqhZKCKGFWh0P/J+qGPr4Q2RBFbL1DUlQiHi72b2rTR47EKk+bJkqGdYiBEYGASJxm0xC5gtrsJ0c33HEqYJDHx8UnTSousI+8U0RwLL5xH6joGJUhSOJThIykCEQyyeLQHSXdJIqSwKMXE7DEg+4Fnm6GdLB00Uk8DO9Gkhu5ZOEaBECFqqKWUis+cpAoEFiF038LPJHHbJWEDUuUerlmgQI4ieQrk6aBtj2CDgYmFhU4SmzBO4N1F0IhiEsUggk4Yowsgi3hB2FiQ9z1aW33yDRpkDaTmU6wo4sYdNFcJKGhBE7bAyJlozq4SneqLSHzTJ2N5dJg+vuGj5w30nIEIoha+6eHFHNzKHF7MwQu5KhtfE2gBr7rynWWXJ65+H40QOhY6ViDj2tkLIRCmjzCLCLJAAUEBVaTnkpYRmgqlOJkYeoeJ22GSaQlg1wA/5NGTNUh08r/Kzq8lqB3jEdb/9YC8L57xQcA6KeUGACHEY8BMYHcw/o/tg61hA7/nAR5mLvmAAbUXJcRpoIGl5J3e1L95LM4froKVtRjNAiOrLgpfg6IBMi6YNBWu+CnMmLrva7HLWMFDPEY7HUxlMtOYQt9g7fTTbAnLuIk7eJSn8fE5lZn8kPNIUUJDIHvfSFOP7WYaaGQ5q2jyG2mhDU/z1cJq36AdPQQ4CuRaDt6S5po5bRy7xGNcydFoh32X7MnH07DOoiUL/rvguJIdrsNG12aTY7PWLVLn2hQ7YPBHcSa8248TNobQkUhTEkVibLZgs+IvdhDYQA7oCEkiNZAYKCgZAdWDYEgn/V0gZKQHQkZWFAYc8uVn8mYbYcnDsOg+aFqpPNHSQVA2FMqGQNlQSWKoTXhIFtEvzfqWOtasbmB/awB1W5qRBQOtEEIvBkwUwKfkzXWb5iOjRWSFjYwW8SNFZKRIUVOjjhEM693NxMQKwniB94kM0l+c4H+7a7tb6aq4C2AYGIFfF+sKWhYp4pENApg+899cyOybHuFPz99KjATlVBEnSYjwPocMZ8zollCcOnUqd955J7qu8+c/PMh9992HMHRKKkv51f23Udm/Bhuw0ClDAXcCCxMNH0kGh97xMj7I1JGmyGYghkkKixJpYTo6ejFBpJDAKECkILGLPm5RAykIWx6RuMaTzz/E72+7FiF2lVBUYg4+7UWXN+a+wzWXXcLq1Uu5+brHOObIr4EU5LcZUKqTrIzSJ27w66uvIRaP8f2LL+LJJ5/khqt+y6qVq3ht3rv0ntCfLA4GGn38CKliGEPTaEu38M3TT2HTpk30H9CfO594EK80Qg4HYetEG6OYTRHefus1rv3Dj0A4nPW9U7nwF9/DA5598mVuvPo21q9cy4MfvcghEw6gCpOEDOO5Jq5j4NqCcy84k6O+ejzHHj2L83/4bZYsW4Cum4wbO5GbbvoT8ZRJKCYxLYEQSi/rj3fcyW233LqrhKJURX/SyZDJNZHVBY4VwjYtbOHSAdgoMoF0SyuX/QLluj8AACAASURBVNf32LFpC70H1PKbJ+4jWZrCdXSuPedyVn28FM91Ofbbp3HWL34E0QJaZZ48IIo6VodBOKNhOhq+EHhC4Auh0gaERAiJQKIJiRbohf2rbV/AuA+wpcfjrcCkvbxvshDiE2A7cLGUcvmXcHz/11gzrZzMRbzDcpTom844atFZzzpex2rZH+fm59g65xhEg4GZBT2vomqepvSCI1XwwwvhF9+H0r07i3tYC608ylM8wF9ZyGIMDKJEuJsHARjEAL7CoUxjCtM4hP70QyJ5nbe4iTt4mdeJEeNCvsuPuYCBPRi99uu5o1y7Is+oWwablsCyLbB5A76AdO8Kto4by2MTDuKJIWNYVxLw5wpozOVZmy3hBYbx5rtltN6mk9m8++xC0CkJbwEjgXFAKd1qUGbgzTgOtBqQS/lEhgj6TRH0GQtVw1WLpP531oOkDxteUwC86hkVFtYnb2H7757Ba4qwY10fwmv7EXtjAEZOBUohhK+VoPlKCYeXVmLopRB20aI+RlmRUNhAN1FJNMLFE0qPxhMurgiSbHQHaTlBaLhnDbLakkCBHO5eElzUOqmFxMfFwd/tHcK2MNOl6H6SSMqmNKRjEe7Shv5niS8ePltpIUSMUobhIcng00YBl3zXeqOLxEAjHgBnHJMIRlc48fEnHieSjJOTLqfP+i/ueHI2R3z9JOIHDOK+BXMJR6P87U8PcsfPfs0Dj/+FJCYhdJBClWe5kHfBdwW4FkJCzdZSiq6kGNR0txY9Mt6upClCSBVdCOskUirCUczp7NzWwvW/vZo5Dy1A0+Ckb09g3PhjiNbEcXMCLW2iF0JUiyHccPX9PPDo74n0cuk7zqdg+7Q0Sbwmg/YWjbawS0vGRYt6hGSIA0eN5f6nZ/OD83/MNjdHdVpQnQmjZQxy2RDZwBP97W03MG74Efzptz/jrtk3cNNPb+Vnl1xHuZB4WQsk2PEsv7r5Am5//TGqa3tz5sQZTJg5nX77jSA1Zgw3Pn0fN55/MUNoZkgnDAgwTNWI6ljhVhJlW6gesIbvnX84xxxzLUjJN8/4b16YewsXXHBmjxtB/XZTD9mPE4/7C1/56tdArgO5E6QNwkeYkCiBPWJQEiQ6DgY//80tzDh8Ij++dDY333APz/zmdq787XU8/cQLmEWf95cuJJvLMW2/8Xz/G2cybMAgVZaHJB0q0hDK0lap1maEhBgaCQRxBDEI0iE7r/V/D3/+voDx3kav3e/Zj4H+UsqMEOJY4Blg6B4fJMS5wLmgdDz/X7GFLOVIzqMNlzAJjuFAmpjHEp4i0jSa/G/mkn7uKESbhpkFI6/SIV0dXA2qB8CVl8H539m3TE4Xl1d4gwd5lGd5ERubcYzhVm7gG3yNMkpZwnLe5F3e4j3m8Dz38wgA/aklTozlrKKaKq7jcs7nbMoIdFilVKC78RPYvFSBb90yaOjBnxezIFkCtdWsS0S4a9oMHpg6nbZYggkfNnPFn3O4y0eT2dAHvV5lXbYA64YVaDy4g8JMh17rQqQaTJKNOqWtOsmMCjNrdJYAyS7e5HwIjLGCAafB/t8TREvgy6C7cIvda6Vf1NJbYPEDsPh+SG8GvaxI00V/563vXkXb6OUcyCFU0pswMSJEsWSM8I5qrLV90NZWIzZWUF4ZZcjwCiJ9oPdoDSGsvezpf56L2Z01a3c1G4d2JKARQxCRBnP+/Bz33HEPxYLD2P0mccFZl/Gdi6byxP0f0Kt3GSd9dxpXXnEFI0cNY8aMGUyaNIlFixYxbNgw7n3ofmTUJItLFocsDlvI0tye5vSTT2Pz6vUccNjBXPrHG9E0nanx/nzjR+fyzvOvBhKKs3tIKPawhEDYbbgFj0yugJPXCDeHOXbUcRhpDb1Z44h+R/DqumewV0VocBUAe66617Zs28h/X/FNPNdl6uQZSAmt9fDhon9wxz2/prKqmpWrlvCn2X/jvDNnMnrigaxauoR+wwdxzew7KY1GiUuHmCwghMlbHz7P5GMOwzrAQM+aTJ58BG889xonTP8mppAYCZ9opcfkUf2xwgN4+nmDVMwgrOuEIzqpWvBqJM2tLh2NQLtBztVZvcmGqkEkshZa1iC+poSQUUIRSSiaJ1HRioy6ZKTBa+/P4f4nX8KtyHHq6bP45teP4+pLL8f3dBJVaUoqsyz4+BNGDhvA4YNGkkPjxK/PYu5zb3DeqP35ysgJlBHmViJYDEVVITg9mqua1INQb45jjxkHNIMGB00cxNata1D+2652wAGdZJQBl5xjQMYm25rnB1fcwtI1G3E9j6uuuJiZRx6i1CiEi7A8LEvy4rOv8eZrd1PqNnHB6YfxlSPP47brvk3S34bbUU9Zfhl6e46wJaiO5dH9VhAxBCFSIkyKMAVcPCQRdDTPUzwFrqsoxWQBKIBwIFH+5bHnfIbtyx28Fajt8bgvyvvtMille4/tF4UQfxRCVEgpm3Z73z3APaBKm77wUf8fZLfxMD/hVnx0JjGMFFt5g9swto8he/WbpF+ZCnkNvQhWWg0MjiFwNRg0DP7wW5h57D/fj0TyMZ/wOH/jEZ5kBzupoJwLOJsz+SbjGLPL+w9gLAcwlp9wIT4+y1jBm7zHW7zHTur5M7dzOqcqhRvPg5VvwYdzVGsMuCoNE/qMgBFTYPp5EI3BO/fg7lzJ84d8lT9Om8Gr/fuR2hjiyFtrqHqmF9b8KB1A06g8DTPaSY8vEBnvUFUwGHxDGQc+lyKR17pqbjtJMzrN18BPgKyUJCdL9r9Io88kaKaRZSzkAT5mGR+zbssOvE1Jwl6MkB/p6kNetKuPFUqpaRhJWf1grIZycvUa2Qa1jpttUJm3CLWmGi5R9aWhEtXCQS/9IBEqq3o7273tZCG9RZXMeEctZ95vf8eakx6lT6gPZ3Emp/Ad+vaINIDaHzVBm7brSytX7tx1MvaV6XteCKedAheeB7kcHHvynq+feQac+S1oaoJZp++66zdfxsLClBZSQsF3aZTtFHwPI2Mh0xarFm/gydnP8de73iNUqnHVb77PsvrX+ekvLubXt5zHmOGT6F+zH0Orj2Lr+g2sXr2a6+6+ncun3cIlZ1/IVX/8Pd+6+AIEAh29K11m+bxFvL5iPn369+PbM05m/t9e4ZhZJ5HP5ph08MH84rqrufFnV/Dy3Y9x0cU/xysI/LwGBQ1R0NAKBmd/fwZLls/jsEOO4YT9vgUbdWzARnmwsx++n2lTZuAJVbvtGC6u4SENn2suv4jTLzyL0751Og/ddzc8DvHxWWIdNkuXz+etx+czYMAANm3awKZ1a7nhgZsZPeVALjv7Jzzxp/v51sUXkRMGBAlRG7fvpHf/SkpTjURSNsNHh3DMhdSOPAgzJNH0MCo/30L5YQHTCgRsHBl0LU1VeTtV5QWSFY0INMzWEDRHEJqPrkGi0qNsmE0h5tChF2kIVlwNPJqbGpl4QD9imIjaYbS0NlETaYXWZmiR0GGybeEm+pVWkdzZTtK0GFveh48+XsR+Xgq61kkl4CjPFVtlyXlZMBygoJ73nSCjPQEihuPoPPzIq9z6h592r6GIOGgpECV0UuKACds16MhAzOS6u//K4dMncf/sy2lra+OgQ87kyPmPEEtF1N84QM6lvr6F3mYvaNHoHa6hoaEV0iazjprOs3PeoXftdHL5PDff8FPKSorgBbnFPmBrUNQIF4VShtE9dRpCdPf0+Oq+DdqXyGzyKbYvYDwfGCqEGAhsA74OfLPnG4QQvYB6KaUUQhyEGkeb9/ik/4fMw+M4LuJlPkagUU0jq5iHXD+RzJUf4r9zEDhCMWEVJKQFni6wddhvNNz6Ozjy8M/eh0SymKU8wRye4Bk2sAkDg2M4krM4neM4OgjsfrZpaIxlNGMZzQ9RyjM4RfjkNfhgDsx/DtKNikpp3NHw9V/BsIOhZigYJr5rs/SdO3hrx9u89V+n89aoCdjb44x5qoZvP1FB2Ty16NpwYBb/+kbGHaJxbDqK9kIpjTdquDsEur8r2YVV4xMbaxMZXUAMz7JlWDPLhjWwsLqZFaLANjxC+KRoRbAWVy6j15I4g5+ZwtBnr2bqon2rr9oJbNc8ipWNiKoMkWqP1KAQw6pTVJYlcQuCYhqKaSgEfcdWaFqhHgtNJT5ZMTCiEmI2dlUHhViaTLSZTYM+ZMG3b8Yb2MCxnMqveIWDmPpPSQSaKPA2O3mPelopUsDjfFIYpAPiEUltj5XizpVdDxcNFyuAuc8yKZUz4Dlqe8fHPVi4ADCwKOu+ggyf95e+yrK1CzjpvAOVGlS+QHhAgnOv+hl/feYxHnrmjzz6wZsU3CzFZknv6lr2jx2Jv8pl1rSzmP3wnZScUI4nVXjQQCO1qYRxow+if2EMrIaZ085g4bMLOWG/b2GZFscMPhWxUjK24mDefv815Io4Gio6YoZ8jLAPyQKPPPs0WSfLjy84h3/UP8NBR09Tmbm6ZO5fnmTxpve5a/YcGkONaFKSkD6lQEIKlsz/kFee/TOmWeCH3zmFG355Jb2lTZlvM+mg/ZnYXwe5mixbqK2t5r+mVANb+dEZh3Hr7Y+z309PJodJhhA5LKT0sYVGiwhTAngIhOYTigS8nqS7zwPg04pNHRm5EomHwFd64o6B6AhBziUebqNfr60UbUnOyuOFHOor0mxIKnrXKAZVRElikZAWGhD3PSVO3tGiQN5qgoEhxWvr+8ikA1YRQjvVwXj1CK8VMovAFGBIkBnw1oMXoFSnYkmOANhMyKegOBDCUdB1LjzvHA477AimTvsOkAe/FWQreFuBrSBiiiFIOlCVgYoU4PDK62/x3POvctPv7gMJhWyRuo/bGTlqEMQSEIkFYKmBG++RfCUgG2HeghXovsn2d9+ltTnL1DO+zpHDZzBoQH+Ci0ZdeKAyxn0R/K0AXw+8fC3og9f2+zeIGbMPYCyldIUQ3wdeRk1l7pdSLhdCnB+8fhcwC7hACOGiElS/Lv+32ET+l00imcPf+RbXkQMEeaKsR2uvJX3OR/DeRHUBxCWGBeE6geuoKE3NYLjnNph+1KeHoyWSpSznCZ7hCZ5hLevR0TmCafySn3ISx3WHlD+v+T4sehnemK1oJfMdEE3ChOPg4JNh/DEQieMhWUwHb7GDt/J1vJdLY8SmUZ0+kd63JJn5eorkVlUQoKdcYgMLlOuCA+vC6FdEEZ7omql5gKv5dAxI03zq26z6xqPs3FBC+dzjyFRASz9orjFIlxVIRzO4op4QG0lRh3RTVL5zNP2ePYZhzw6gdFMCKSRtk1vJ3riZ4QdYTDTKSWrWLrWxnQIBWsinsWodq8o+Yqk+jyXMZwWLsYNs3hRlVNKLJKmulgj6aLYS4/2hFKq2s3Xs22wUq9nAKjI9Ms1jxBnDBK7kSo5hFvE9V8G6rDkA3zfZwSveNrYv1yh7r5rS+RWgS+zyIs7JkkKThjQkGJJ1c59Sg6Uu8YUMVIgBWhFRQejNRwljBFrEgRIUgJ/FdZO4t76EdDX0hIeMeHiiiCd8XE0iRYCWGorlK+KhxXzkOzannPUNLvvNNRgIfCSu59DRkaFx604EgqyXIVITI1dsBwuMXg6yQ8fzFS/3osXzuOqqixDAJT+8ingiiqb5GGYW0NF0D82Q6IaDYZroegaQhCMFdLODyr5rOOzoExFCcuLxU7nmqvN3+S1Pn3kg8+Y+ztnHDqMgLF5+dR4PXn8rf/nHU/QzBQkvw/WX38iLL74NSBYv+AvgI/zN4Bngd1K2bAB2EovpQEcnaiKEUGsjRR1aQ2gFnaXPfMJ5l10LwDU/upAJkRJeW7GQeFGjxYqxclsbB06bwhoxCIEMSCi8INCr0UKULaKEVULdu3/85W9494XXAfjr4tdoSCXoiMdYUtM5NQrhC0ki5zDIS5DQwpx71ndYtPhjanqX8+Jzt1BdVcKOrW/Ru3cFO+wmqqpKoUzrwaqi03dQDVv+0qgUVSRsbW6hpl8vsKzAC/VU34SKkTpw1s+vYdGqNdRUVvLi3bdB0YW2Nti0GoCr/3gvjRvWcfetN8GqT0AIpp9zAfXNzUwYux/33XY5xLLqa0ggbUFeQF4i85Knb7md4aPHqchbMQO5LGedez6LVq1W+7z/XqorKtjRUaB3ZSU7Nm+lqqwC2mP89fFXmDH+OMxMLVUhmDLmEBYsXM+gsv3p3uFuJlADriYCwA56XSjE+zch2T4tNEkpXwRe3O25u3ps3wHc8eUe2v9ZVqTITVzLH3mC7SRQpUptFNlA9rXpZC98Cjoi6KU+XlhQ1SDo2KacY5mCG6+Hn5zfDcIFCmxmCxvZzEY2s4FNbKSOJSxnLevR0Dicw7iEH3Ayx1PB/4BSq70ZXrwdXrsb2ndCOIQ7fAJ1U2exYfKJrI9ZrCfPejawoZCndbFOakEJVR8nqV44jjOWxYj6IiDGkEQQRJGEEdBmQJuBH8z3i6jShY5wnjWHvsuiS29g+xHz8DPjGfng9xl92p8Ytq6UQtLGzBno7q7+nZFyiPazifTySS+IU2gR6CFJ5VEO7uX1rD1+Kwuqd7CIZrK4aAgOoYrjqOU4ahlNaY+wt0Y1wxjNMGbxLQBsbNawjCXMZzmLaKWZdlppkvVsWuHjzR2MOfcwYm9PRbPVjNkdfBSRWR8yY1Ydow+MMUSMYDAjqKYGgAwOLdiso5lWirRQpBWbFopsIcs/svXUf2RR/l41Ze/1ZfAH4xnRHszGK4toBvhNJsZXVhPZtCegS8PDKbFxkkW0Eg/L0NDRgsQsj3aU3qT0wWoME9oZQXN03KRNoSaHG3fQg3IRO8hxTmBSSZRwUE5iBH62fsTxzJw5k2su+CFVYZOWus10tDZzz4OPcPb0o+g/eAi3n30xf3nxWWwRZseWLbxR9zpjD5nA3//wMIfNmMys08Zy2ml/B9qAIm++uZDFSxdQ0N+if/8KXn7zfs793snUDPkEIXxq+q+BAqQiDYS0HCWinU9efUQpVOgGmcYiHXmb3n374mLw4itLmHroFCx9CMsXLeHSC69i7ksvMLR6GOCB8Lj++j9w/fWueozDlCkTeeyp9znj9CP5y2Nz1Q/rapATUEDhMsBmqKvbyQdz5jN5/DgefeJ5Dh03nknjJrH4lZfUMbkOLU2NXPnbP1D28UpSAha++AZXXfIjnGIOgUR3fSzPw/B8DM8nVrCpynQwtKMJEZLcfPX3kFefhy9iSN8kJS2ihKglgYYgiUXM06hpbaGsbQ0kBQ/c+2NAgB2CFpsTDz+M2X96iUsvvYTZj7zEzJmngjl+l2tn4uThrF13BRu3ROnTpw+PPfkP/vrII+DUQmsjZNIKjL0oRHpDVOOBW29VPAGKEg0MCy8aJ5cq48+PPs7z8+bz2FOPsCMaDpxQyYNPPxSUDUnqPaAdQkUfPIFsTEBlLRhhph96PLf/+Vluv/gwhBAs2ryOAw4ezwMPPK1q87IFyDucOOUoZv/pr1z6nYuZ/eDzzJx6AhQT9OvdnzcWvsMZx51OLpfnw2Xz+fE3vk9XNrQmQfO7e88FV4I01ETM/V9SIOE/dJhfijk4fINTmMMqfMpQV+96atv7Efvlg6x66kCwJFQIknYBZ6WF9DTcEJQfXceM2ffglTaSJUcjTWykju3s2IX1JkSIgfRnCAM5numcwglUsu9ShnlyzOERHuJ2dsgtDCj0YtB2ycBV9QzamGZgPdiyH78+6Vz+sd9E0uEYEo3StRF6fZSg14dxes2LUbE4SspTqslWyCdieiSyBrrsLn9xwj7S1vB8VTcoeufRpzTgHlxH7uA1bB+/iu0Rgxb6sWNLBZW3D2f8vcOJtIXITGqj8iftHH1KnFFaKbmdQhHq10HbZtWn66B9K1SNgeEzYfDRSqCgp3n4zKeJF9jCC2xhUeCL1xLjWGo5lr4cQQ0xTCSSdmx2kGEH2a7W2OYQf70Gb24ldXMjtGxV37F2lGT0DIdBR6Up1CVY+FSYJa8rcouS/h6pWW00z6pj4UEbWKulcZHgQ3hHlNiGBNENCWLrk8Q2JEisTJH8pAzN05Q3OqqdPlNsDpkS5vApcXoNFAihonErV6xk6JCRQeJRoJjjQiErybUHmcBIvJijwLmkiBWVxKWF3hTC3mnh24JIQlJaoxSQOi1NkU2o1I8BJCndndlLSiWS297G4489ym/uuhffl5ghiz9c/2t+fs11vDfnIXQvzynnX8IJM6bx1a8cxLH/9X2mHjKe9+ctYdjQvjz88DVEY+HA29BAarz5jwVcc93dVFakWLpsPYdNOYA/3vRzNKET7zOVTPo90Dyeeup1nn/hHR584KpdDq2+vpnjT/gJxaKD53kc/tWJ3HzzTzAMgyOPupClS9fTu7earPbr14vnnv3DHvfHxg3b+ObpV+A6Ll+bfjjX3no/mXlv8+a8hdz04CM8f/cdYFhs2rGTY8/6HodNOJD3Fy1iaG1fHr72GqKRPdcU73/mOa7/8wMA/PKcszjr5BMBuPLOu5gwejQnHnUE85ev4OSLfkRrup1wOESvqiqWf7wALAdIg0wDLlddcy/xRBkXX3wJc+bM5Qc/+imNjc2kUgnGjR3Gy0/criLfHSinPllCs2Zy2tnfpa6urktmsKysjO1bt3LOOd/lxaeeANvmxZde4sdX/ArP8zj7lJn88hxVgjXnH+/wg+tvpLG5hVQqxf7j9uepl18gi0ceDwcfG5/LzryAQ48/miNmzeRgo5Je/WuJJuIICUfMPJ6LLv0ZuicwXIhnBLGsxn1/vovfP3QLO5vrqSqt5JgpR3PvlXeSc/L8900/54NPPkL6kgG9+/H3m5/cI3+qsb2Z0y77Dlt2bqW2ppYnb/4L5WYp2UyGs645nxWbVyE1yVnfOpNLfnoJGEK5nnsLOboutKehow3a29X8TJgQSaibpE9Jj/Xzz2f/4ab+N5qDwzSO4wOaAR2NHOcwjf1e/xHX/fcQGhuEqsGJOxirXYz2KFLzsfv4yF//isi3HyQuosSJESdGKSkG0p+B9GdQVz+AXlR/IbLyHYXVPJz9NY8m5tBm5Ri1LcS41UU2VcHq3uVsKp9AgYnkOAyfMsqXhRn6ZIreH0aonpcg3KaS/J2YjTWgmWH1MVJNqq7KjzqkCyaOD2bEQ8srQfptYxtZefRmNkzeyaZJjYT6CBKE8RC0UCSNQ5+PKply82hGPjUAIQXVXysy/ScWAyfv/Tu6+CylkQ/ZwUfsZBEN9CXOofRhKn2YQC/CnxHo2U6WF9nKE2zgHXZSCBiOTEDaPtHVcRLLSkkuKyW5rJzksgqiG0sQUuAkizQetRltRgP9pucZXRtnIKXUEGctHbzLTj5p7iDzXCnVT/en6pU+aI5OsU+W3NhWzE1RIhuT6IXu45Oaj1ObRR+Sp/Zgh6lTIhw7OUUy9enneG83Np4LUiI1g2JOkGuHXFpSyIKqQfHxNYlm67hxm0JNBi/hEBKKKSmMgSd9mkSeqDQYTIyQF8j6OAVF1+UXwcuB7gf6zpoa3IREcX/2sB5j3aZN2zn+hJ+wbOnjwZdGJfN0JuJ2qm50tiLgx1SmXDyp1h87B0/pAJ0yQ7uPWT44jjpeuxAQahcDSUy61wp1A1xPeUIe3c1FrQ3qFoRCEIpAJKrWJ01rl0L+TgnFZcuWBYciAwHhgCzZ6ySR6KQgk7s231cL9Y4Ntq16x+FTTYAfE3glGl5Cw9M1fERnPRpkAccMZNU8RZtWWolnaLhIPN/Dcx08z8H1XTzp4wnQPR/TdTEdD8tzMaUi1zCFgW6YyEiMXDxGVnjk8Mjidt0z0FloqGEhukk4pEakQ2I1eWht3h6Xxt6sc1nW15Sed89lXF+HoiVxDdA9QagoiOQ0jECwxY5IQnkV53JMSXuJpJgCmdCI6AbRIKqjfZ5UaN+HbEaBc3ubOj+j9lfXzhew/3BT/5tsLXVM5hs0q7uZcVRwf9vdXPSrIvc8MQRCEmoFWnwT5tv90DwLN+mjTdjB5Fsuo2bMBsKMIkSYMBFChIkSp5JeVFJGJTHi6F0FJ6HPYCACoJiFuk9g00IWtT/H/YM+4KWxWWQpHL0QTn6nlDZ9PG/sdxALKiaxulzxRmmeZODfE0y8vYJeb5QjNQ9jdD0VpzYxcJJJlVlG270Riu/2xq4ssH5MI/bycpI5gyhqfK4b3srmiU3s7JfF6DCJNiUY+lgZo++2iDSHCbdaWB0mVtbALOronoYX9vDPaqDs8iYS/XVWEaaBMGWE0RF8TAMfsYOP2MEC6skHCUtVRBlPFZto58WAgdVC5yB6cSh9mFzsw+jGGnItGh+3t7C0vY1V7e1sTOcotkcZ2D6CcDpKYmcJkeUpQmuSaEE43Nd9ssPTuBM6kGc20fHVerZO2k6zWSCDw4f4PLHHzS2h3IOztrDxrEWE2kyGPj+cmqeGUrI5QXSkTelxjfQZpDFokMHowRGG94tgWQn2Uk25pzkObN0AhRw07YRiADp2QQEACnPCukHYMCgLG3jREDk3Qc6O4vk68V5pRCJPUZcUilDUHQqaoENTpAdVfoa+tKnpnsaeWaW7fF1f7VGiQrmOrwDNQ3Fd6iFF5eVK8A1ojEGuoBIjhFCA2AlAoYgqg0skoTT26R6IMOms/lTHIHcFPWGCHgbTJuBCVGBXKKgB1XPYRY3CtFT2f6pEAb/1zxMd935cQh2zroP1zxN9JBIXGXA1K7pFR/q4vofjq0puD3AFBDTNyE9LIDH5lMsn370ZnEvNExi+ji4VjUsxrJFFoDlg2YJQEaI5QbggCNnq3EqrgGFB1IKkZmAKDVMILKGhd02SUOc54yltVS/YZ1hX28XgBzcEJDRI6qqZIhCzEF3zpU4ylCJqAuCiWLQNNEyU0IQvBTIDWtojnPPxUxr5FGSiPrlg4pDHCTjVun8CxfcmMALmMSNoYXRSmF3LMGiauhYTSajpq66dLwjEn9f+4xl/AbNxuJGHuZK7yWxpwAAAIABJREFUglByB2dwOB/P7cWKn50HTZVQKqDSp0+xieYPq0FI7BrBwFM/YurVt0OyhSKFPVoHadpo2et+SyilgmoSlBD3osSzHon2AvHWduINjcQbmzE8+PskWDwEYtkQE5aOI9IxmY9GHMrivv2RQpDwJMO1CPVtBSr/nGLinX2JbAqRrPQxxuVoLc3SES1iNWiMmFdOZVMEV0iyMsgKRd047SmbguUhWkMIp3sQlZrE01XVgOupWaxHUFGoSdykQx6f9rYwPpAZ0krDUZtpPHozjV+twy2xuz7LQmc8VUySvRnX2JdBdb0xt8RoqhOk66G+wWVzY4HGRo9Mg4ZstDDbP3tQFJokmoREuaB2P+g3BmpG+3ijO6gf1sSqUCvLaWMtacIYlGIFtIghSrEIo5PFppkclYQYRzl9iFNFlGqilH4O5qg9zHFg7VJY+hEs+RCWzYO6teB5rLz5JUb2qlCDgxUCPdCLkgB64AX6YLiq7MT0wJQKWD9lPJESPF/D8JU2mOIk7pRbMhXICVOhQt6D9gK0Z7vB1AqpgSueUNmu5j5yado2tDRCcxOu79FWlsQ3TYSUiABkhS8R0lfP+d1p3p3LNxJAiKAH4UvCtkuoaKP7UgGkaalEIMtSxxaNQTQOhvpBfCQFPAr4FAKaSEUfqQfif/t2Hl18ikHrJClxAtB1dwPgvZkATDRCnkAXAqF1A0dnM1yBlZfotvIcO5ONOrelANHegZbOoUkdXRhomokQCnq6IhOeVBMob6+HsssR7vrtRY9nOulidnd/e1BlRjVI6VCiqe3PK3f1Bc1Hku8RSndRyY2d58HrcV5kcLQlmJRhkVIkm1/asfwnTP0vtPf4hLP5NWvYAhTQaWUsg1h05zS49mpExEdWapT1zmIvyOFtq8S3fOQwj1uvEpx3ivFPr0kbOyCV3Kma3EFjxzIa04tpKm4g4zWT0fNkIpAJ09VLDWyGEsodTtg7kvWxAdiawJSwv4gwihC1GHy4pIPwtZWMeLYSy9YwYz4iJ9ClULxPhkeJqxFCAWkBVcXQ6fy4QDHqEeoFhqXRkRfU74RMUUUaY1UK4KoGQvVAqBrQ3VK91ORTSti2Gha96rPgFcmqNzXsjEDoktKxLZQMXU/c74dsraK5TqN5i3IEe5puQLISSiqhpEptRys92qs62FbZglbmMLqkhHHJUqpLQkSTEElCOPZvGxf2sDweG8myngzrZZambBPj1m/nkA8WUvPhu7BqPpQWoB8wIgajyqAiBCGHld49jBxaoULDnaFX6B4XRY/nQLlWrgGeCb4ELZCY0yDvhmizo6SNKNlomFDBJpktkMjkSWTymK4XZJgGg6sXlFEZhvIk4wkFwvvgDX6aZXFplCqhzf+ST4gpBSGhE0Yj1MVtrFEMgDeP1wXCn2adwBxBC3odDUEBjyI+hcCLKwYD++7W6X0ZaF3bJhqGFFiuIFQQmHnQCxKRl4iCBCf4nJBQnq+GOne2D/aXOVYHv7cpIKRBRIOYDtHgsS7A9SHrK68366l+958rrEGZAaWGWr7o8dHo/zs3metDwYOiF0i4a2Boqtd73B8SSQ6PZmxapYPjgfB0Iq6F4el4nkbRE4wtVwnWX8T+A8b/Amsnw8Xcxr08i4Kkdiwy2DJP9He/Jnfz91XIqAaSvRdh/20U2CZuUjB2huTR3wqGDfgcO2zcCCveUNq9K96AdFAHWNYXeo2EYhE2rkC2NrGjdz+en3UBt06ZxoqwCrdFkOi45LHxcIjusJj0u34c8GANiVaze8zWfEKmT4mtEZFal8i9RLI1VWTVSdsIf7eFkQeEKPtHH9IvpVj9hk7dquDPNRiwPwybDCMOUa1qwOcEOylxli5hzV3v8clLNp/UH8yGwnhK9AYqUi1UDo9TMbEvFYMsKvpBZT+oqA2Icb7M+11KYDNSfsQrcg33ixAxTGpFlFpZTj/Rh1qGUCtKie/makok7TJLExtpknU0sYMmmtmKwXpqWO+EWS99tu2W5yN8HxmsSQ4oNnCIv5pDXNXGuJsxWnVocMGWrCx7iZHDKwO+BNmjMLvTNQoWYTvXYB0RRCwlfkLQoUVo8+Kk9Si2oViTYq4k4UJeh4wh8IJRJ+z4JGyPRMElUXTRTQsnkcANhXCF7PI4Or09AUTRiaLW6j7Nu/CRtGDTSJFsILxXhkUloUDXdlfPt/Nx5yjV81O7aT27P7snSHb2e/NGw2iEA4BVnrB67PXwqgp45APg9vbyGVYA9OEA7MM91k4NB4QtFYA6EnK+iizYgUe6+7jbVVZDEN7ffW9B6U04WK/P+93ADWAJBeCWCOqDRVCaE5Tn9Awrg3pPWHwulJFS4mR9vA4PaUv8lIER07B08YXB6ouYlMq57wTdggcFt3vb/Yy1ak0oUO5sEvW3RU8GV3HnG32E7hE2YHBMJ/wFxdj/A8Zfstk4HM0PeJtFSLKotMUccRll7NV/4/27J0IS6COJ6h/hvzZJVRjUwKU/E1x1wT5E7/IdsHQuLHlJAXDTZvV8STWMPBwGH4zd3sEbLStYZjqsrO3PihFjWdarhozRuXILIWwGo9MXi7Imi+hjSUrurCC+KhzMzCVWwL8aDdZkOi9B1/DJ9C1iHOhwwLWSci/JJy8LFr8My99SOTFWGPY7TLURh8CQiRCJ7+0L7d3m0cIVLGclHRydjXL8e0s48oEHiC9frLyuKcfA8Wcg95+CeO0peOpu2LBShUCPOwNmnQsjxn2e0/fpJltBzgc+AjkPKefxkujDNdqpfCSGUSUzGLjsIIncjRMzJYvUOlmk79JkhmnSorhi77HgXrKVIexksLeTwYV6Brs7GaypPunlWawN4H17OO/pI3gvMZwdkTIA4k6eSblNnGgs5BuhN2ha8zgjR1aiuHJjPVpo10QnmQOZw5M52oSkVURoFxF8IdCAJCYpTEow6TEt6/IUOnBpxyGD+xl+o7LO8KofhAA7LYIegLNOLADnZmyasPGQhNGoJEQ5Vvd63b/IPKQCZdfH0jVC4tMnC3sz6UrcnIuX9RBFlcemy07datmdiOYHiWFdINkzOy2wzjpWnV3rWqF7VmEJiOgqtBvS1Lprzod80HtSvRYLWlT7Ur1QX+4KbnlXeZkFT722NzM0sDSw9O7eEOr5zl7vzPvrcaidwOr4CkSdHs0NvqorgyWvoPf2cgyGppapwzqEDdWHApZOx9+zde5LiD3/ztIlGU2VI3bgMpaSLxy6/g8Yf4kmkXyTK3iMV1Eg3IbA5of+Bay89CxeeXgIpIBqh+TGNE5dBZ4hKZsgeOx2mLbHT97D2hth0XOwcA6seE2hXawURnxFAfDIr0IuS8tbs7knluH26ceyvVyVM1X4JpYWYwfqvj4QjTHYtLYW6JgTp3R2DQPe6UVEiq4hO053CoyPCim3ANuR2DWQHCSoGqhKB5e8Ds0BpWzfkXDAdDhghgLhUOTz/45LSXOF+wnPGo1U5l0OXb6JN4b1Jp2MEbJdvtrsc3zJKI6PDqZ/Dw1WpITF78NT98ArT6jkpdET4WvnwjHfUGuA+2JSAptAvtvdAuExCbwgZnKNdjzzRSn9pc5lchTfkRoh6WNjs50tbBE72CJaqHNa2JJvZUs0ie77VOQ6qMy2U5HvoKLYQYXTQYVopyKcpro0TcwsKm9WQw3WneoWeztMoI4K3mck72v786YYyTJRjSElr60axJgRo0gJ6zM9z3YcWnBow8ZHib2nAgBOfI41Mb8HOIPsSqTpDLuadMuxdybf5ILkmxwu2SAJp9MEkMKkihDxQOThX2quhA4P2n1o9xSoaSjvMiy6+4imvEpNqOsk50Pag0zgzfYEVxF8k87lU0EQzg96AvRwg7/RgYQBJTokDQWu/z8yKRXQZhzIupB1FPj2RIXQbmAV1pVX6fhB9Nzbs98bYHaaHoBzJ1Du7a2CAMBFd98J5rpQ45cnIWFC0uqOkH/Z5iP/R2vI/wHjL9F+wZ3cwENABmigH6V82z2Ru38ymcanvgaloJfaxBcbFHMabhxmfg/uvepTlJUaNynw/fgZWPOuCi1W9IfxJ8OBJ8HQKVDIwtt/Zd3Cp7nlgJE8cMQMcuEwB+ehXzjBJ8JjDWZwETdRsj7HoOdqGDynP/3eqybua6SQJFBEHEGaDw5g97Gp/LrDiGMjFHyNxs3QsAkaN7g0rC7QWAeFvM7oiR2MOynOASdFqfwimh5BItK6TQv41f/H3nnHSVXd/f997r1TdmZ2tjd2WXpbQJCOXRRBoxgRRcCKvSQosaCxoLFGYhKNLdiwY0dRsT0uiIUmiMDSy8IWyvbpc+89vz/Ond2lqIlPkuf3vB6/vo7nMjvl1vP51s+3OMYr/YsIhqLcMGce0178gECHbiR/NZnFp5/G/DzJe9SwiRAA/QlyEgUU4SXDaXGXgUFGOEbGp++R8c4LBNd9j54WwD5+PPaw0diawI5F1YhHsOMtuNL3ECysxCjaAUXbwOdQECZ90NATGe7Pu5kncldOPt9qYTpLH7+30jg/9jHuxOtgbf7xY7Q4uLOaBTR4oNELzQEIZ0GiCxhlEBgEhV2gsBBym0BbBXIziCygAMgHke9sZ6skKmANTbxAJSdWJMnq0wUdQRYucnC3ustDmNSTpIGE0+FIvSfbec+/HfgOISmAbiBOFIsMDPxOY8b2+1NeXs6sWbOYP3/+z/6dE8eeRE11DTJpc8yQI3nspr+gxwQPvfQwT82bg+E2yMvL45k/PkmnnFKIpWKw7ZLChGzF28AxRYQW1bT9iOG4gXXRZgXbh5gB0lXG8Jx3X+buB+8F9m+h2F4WLVrEtddey+rVq3n11VeZMGHCIY9x5syZBAIBrr/+el5//XVmzpxJRUUFS5cuZciQQ2v89fX1TJw4ke3bt9O5c2dee+01AsEsBboO8IaT8MVnC/jTrdOwLYuzz7+E626Ygc+ASHM9F06ZyI52n8/KUgxh9913H08//TS6rvPwww8zZoziSb/597fw/PPP09jQyObGPfikB2xd6SftrNsj+nZm3sLlWPEo111+Pnt316JrGhdfchnXXjsNvZ0FLaXSid55fwG3Xj+NpGVx+rmXcOG0GerSaErfSXdBQJfcNH0aH374AT6fj+eee45BgxTRydSpU5k/fz75+fksWbWGeKrKzRn2AdumlFgSyjJoyx7/J+UXMP4XyeO8wVU8iAq81VCCgZGoZ8+VLxP54EzIgXSvxFql2rDZRTD7CTjvtANimdUVsOxNWPEW7FipXivpD4MdAC4dqD6waRlywZMs3vsdD51yKvOGHYGGoAsGtVqMkFPLICyNwm8sur/ho/ubncjZGcQNZCDJQ+BFNVewUST5ns6SHlMFPSZDRlEIdmyCLWudsU7Nu7YeHMcC6NQDyoZA3yFq7nO4chkDhFugegdUb4eaHVC1XW1XbWNXSw1/uPBUnj7jBNymxbRF67mh2k12jyHKss3IbvuNcAh2VbKxYQfzXfuYn2vxRYkfU//XqLt+O0pGPEKwJUrGvggZeyJkNEfY2LWI7/p1oVtVDb9f/z7nFi3ClRdRRY+NZRA7BjbXwObVULOl1SOM3wcDR0CfPpDZGbRS0DuqWStsBdF/tayrqKCkT3eVcOJYvR4nzprARkNZntm4Cf6Ls0L/UUlgESZOiAQhEkRIHGT5CMCNgQcdDwYryr/myVmP8P78+RiH6hub4h82nUSmuIS4jYzaWDEVTw83NZMRyEBKyYSbzuPMk37NWeMmsHDVYo44YiS+TD+PP/ck5eULmfvXF5ARC6J2ay2sLZwKAEOieXWyBxQSqml0fK7KarYsC/2nyB+kBCGor69nyJAhLF++HCEEgwcPZsWKFa1glpLt27fT3NzMrFmzOPXUcZx0+gTlPqXN4EZI7v3DHXgCaVw4/Ro2rV9PUHdz89XTmPXgLIYNPRiMpYTrb7iRQGY2l103gz//8X7qGhq4+tYHWt+TZoBXWJwwuCcfLPiEbp1KGDZsKK+88gplZWXceOONZGdnM2PGDO6//34aGhp44IEHWLduHZMmTWLp0qVUV1dz4okn8tXGlbToCRZ/8xWFnYoZ3+MYFoUUPaYfN5l4ySQNr6MYdu7cmeXLl5NMJqmpqWHQoEG0tLQwePBg3njrHbr2KiNsQosJLUlImBZnDu/J7Lc/oVtpCeOPG8rzL75Caa8yWpLOe2z48pMPeP2pR5jz9gds/HYJv79+Gu8uXELcgi+/WISRFuC2q85n7uI1B54xRIoCVthIYbduH+b34v4PxIx/qTP+AZlHuQPEcaAGHyHyovmEp64hUt4D8iDThPgKgS3A3Rs+fhVGDEA9CTu+g+VvqlFdob60+0iY+KAC4ILu6rV4BD57DnvB47yd6+X+syazvNtkdFtHCIEl3GzGha82i16fptHv+RyKv8jEE9NxOTHfdCAHRT9pATEEZMTpM+o7evf4LzKTy2Htdpi6AxraNdIyDOjUC/oMglPPg259oVsZycwsXBu+h7XLYd1yWLkYPnxFfUYIKO6i2GqaVAmWBHYV5FDRszPr+vZm1a9O5tWj+2ELjatW7uGWZQ0UNsRVZ4W1b8GrL0FTA1TvhKpKaGwAoCcwHZiuadiFHQj1z6FpWBpNfXWautg0FyRpMjw04aPZzMK2AmgmaC0RtOYQWkKi+XPQ8rsgfLkkRDZNViFNMptmEaUpGKMpmKSpm0WlkKTZUZ6re5Yp7g8x+gLrMuAFD7zdAE1rgDVqVexeCi0uFfif/iCcfcV+RBD/KRGoeG8QF6X4aCRBvepJRDFeMh2b898ltpOw9cKLL/DYw38jkUhw+PAhXHPLdM4+cRxzvn6XtOwglx87gUtuu5bePXty+djJDB0+jDUrv6Nrz+787akn8RgeZEL5OLWEjbvKJFTbxPgTTmfT9s0cM+hIHrv5IXQ0AkcVMe2cK5m/eAFpHi/zZr1KQU5+6/kwAIlGelYm0q0RlXGiJDDdEpm0OaHnkYh9AvbFGJE3kBe3vYhVnyDiswjnWUR8FrZPsLumhmunXEbUjDN87LFIAWZQsLh8EXfeeSdFRUWsWrWKDz744KC2kM8//zxeXxp1hGkRcYJ4WfDRh4wePZrsbKV0jh49mgULFjBp0qT9zmmHjp3xJyBkamwLweYmDiGCprhGmuGisTGdvMKhgLJq1zeAvlc6cVmhLEqUJfnGO/N48u1yasIw9qwLuPTXx3HjXQ+o0IUTY129bCldu3WnU9eu6BpMnHgO8+bNo6ysjHnz5lFeXg7ABRdcwHHHHccDDzzAvHnzmHDO2TR6EiS6BMjvXsL7Sz9nyMhhjBpxDBnSi4agp1VAMzGaRYwqQlTRglvoZOJFIglbFoHcfAqz8tkatolLPx269+GLDVUkilS3dJdu43fbbP/+S3r06MLggfnYxDlt0q95/f25XHfYDWR6dPKljrR1Hv70HSZMOZ+QKcjrN4K6hkbWbq+mqEMhg446gl27NiM0G9L3gWaBZqEJJ/NdaE4oRndCMRoG+qHUw3+L/ALGh5BP+YYzuBHlc6zBQ4Srw5ezcNIsNi4zFBDXQ7wKLB1yh0P5S5IecgXMfV0B8J4tKvja6xgYdZWygrOL236kaiMseILQ4lf404lj+Mudd9Loz3TqPA30kEbxwjS6f+an+yc5eNb5cNHWcE0APk2QK8ErVf1vGJtg+seMLriR/LTvYTOw0wsdOqvRd4iaO3ZTwFvaozWzLIzJXHbxd3sLS7QK0odBwWE9KYh0oyB0BgX1zRTU7KZgVzVZe/awIy+DitIC1pXmU9GliJb0tgbcOfXNTH5jEbc/9Dqdd+1VL7rd4E0Dj1fNwQwoLoWhR6o5NTp6Ie8tNJ4nyHcEgY64gcEgjgIxQg13aZv7IQjIbfDS/bD9WRiQpGJ0R4yMMD3koWu2AeU2WO2BDV2gbgDk9oRBneGkDqAZUFsF856CNUvgqJPh9iehsOMPf99/UPTrryPnu1U/yEjeFuU8tOdr/zxkh4xiwGGEZj1AspXq0CQpbbSoioFawmbzhk288PJLPP3Jm7jcLv4w7WY++fQzLrnuGv548S0MHzSMwV36c1Xf8ezYtoMtGzYx5/bHOPL6EUz9/ZXMvWM215/3W1prsDTwJ1ys+P5bVixYQlFxMWdeNIFXvniHs044g3A0zPB+Q7nnqju48eHb+Ps7c/jdb64n5Dex/IJ0nxe/14umCcaMGcPSpUs5+eSTmTztfJK6pF7GCCVjJBMmf/r7Mww64xjWD4yQLjyk4ycXNwY606+9hN9ceTXnnn8e9z/6EBLJWnYTIs7SpUtZs2YNnTt3YdPW7WzYsIE/P/Y0f3z8SH5z+UXc8dAjnHP1tUjbC7aPet1k2ZZK3PmFbIskyNANCjqUsHNXlXK5mtCYgMY4RJyKMVNKDFcCLXMftp4EqbqpeaULLy7SvSZBr02noCRhQVRaaJpEuONIV4KkLTCljrDbaqPr9+4mt6gIBGQWFVG3bw8JqWLASQnhOKzdVkWwoCMVjhJgZZVQsXIJG5slNbt3E0rPY2M4gZ2RRe2ePayONbOqcgt9hw9mZ8zEsNPoUNCVlk1x9LJC6m3BHlt57Dc2poha2phJEsAeIGkLNjXpZBoO1Amb6l2bWP/9twwb3Je8RAiXJbEMC0u32bVtK7mFhewLh7EMG19RDt8v+5ZKGttuaB221W5lVI9TcGfuwWu7KCotYHd4JTmZTqMIXwuakJS6vfhx48VAP1QCoZROXA8I/Gc8TL+A8QEyn485jVucf1Xhw2J+4j1unjSKpctQrukdEG+GpAf6nmzz0aWvU/Dsg7B9hSp+7TMKTrlRWcDBtkboMSvBqopPWb5jCV8FDD4+awx1Uye3gkpwm07/ZzPp+WkWGUuDYAk0TXlL0nDKDr3gNiAnBH6nSiImIvTOncXhPV/Ec9opMPBWB4A7QXb+j9b/fE8TTyY38AKVNLsEvbdWc8v7XxPye9mdm8nuvAwq8jIo75pJ/ZABwIDWzxY1RijbG+PCjRH6xJOUkU6ZkUteRh84djSMucsBYM9Pc7vK78D+M8hXgCSIX4G4EcRw9ZviEPWsUoK1BhIfQeAjNl+ymrnewbziLmOtSyW6HbujkiuWreWMDfvwkAGuPPDkg68D2EGorlWu9ervoOY9RVXYXoJZcPccOO28/7HiZImkhThJrNbZQwLDyXaW7eKe7UuD/lmJEGUn9QgbgiGDrEY3GY0eXIm24/70taVsXLaGC4eeBkA0HqU3HZh52S2MeeF95sx+mlUvfYmoSUKzScfCEo4cfAS4BOdOmcLDzz3G9d29yjSzgbhEbDYYdtgQ+mb1hGbJeSdMZPk3S5l43ATcLjdDzhrFLl+cwtG9WVReTlVZgiLSCbSjCJMS3vvgI8LRGBeeN4X3FnzO0aNGI6QLn0zntVeeZ83Ktbx+XzmZsTQ8usr4TSUyfvnll7z02ptEkoIpEy/lnpvuQIYyqQoJ+gwaSkN6Z+r2SqobJAXFHcnrdyQ7Q3D8Gecy96m/Mvnq6/C5BF4hiFoGmqWRMA3qQm7qgD1RaEawcp/ElirRy62beDwxNC2OrsXxWQlKm7y4XX5cfgMpDCK2IGJC3DRoSGjsCKeuhYFtC6TpAcuDEBKp2UhhqQVDs0CAK9CMoUlcunLD5mY1YaAjkVjYBHwhXO4EvvRm7KSG107iSUjS9ykXvnufhqVp2ELVARn1QUTMgx5Jh3CWYjW1NSQ6bk0QMFrJtejkT92/bZEGiZMUJSDTG6ejESctJkjsC3PZpMk8+pu/MGRfh4PuzYLaAMFmL30qCgBYWZnF7n0BBq0rxvLZJH0Wcb+J29bJiHrJqvNiRDU8cY1OdZn03ZOHWzfY2ZzAbevkR/0q38MG4ra6CeI4IRBnTuUADHRSw//N8gsYt5O/8leu5TkU7O0igMZ39rdcckEpS5aBCELaJodONh1Gn7CBNwrH4J+7Azr0gXP+BJ2HQbgZ9u2Edx9Wc90uvgp6Oevi31DdrwD6jQNpKfIGImiymTNnd6PT9N5YUUFuL4iUQHgHpNsqTBnMhWSTJBhTSVkWYBs1HF5yF73OjqGPOweG39LKLPRjEsHktegmnoys4ZscDY+dYML8b7j83WUcVXAY4vizITffoYVzqAr9ARII9hKnjgQdSSMr060yyX+uSBvkApAPgfwM8IG4DLRpILq3e58J1nY17G3O9mZIlrOLZuZ6+vBq4HCWGypR4yhZyiOJMsLxZp4szWJSp1Ly8DOVoVzGMLr+kD1pWbC3xgHn7cqlP3Yi5BX9Nw7yYImSZDHb+JhNLGEncUws7FZmIMsZpjP2ESZCkg85nQSOp2HWLU5Zke5Q/WkOU9OB28LhNG8D6gPSlgBwWRrpTYKBWyV6k42wUCuqX4egk85qgUzTuODMc7lv+l1O4hIgJZFohF37akAThHwJ0jt4ATfC0JAFHvVZXUNYgiUffs3lM68BCXddfhvBQLqy5jJ1SBNQ6EI0uXAN8ONyu/AF/MiQJDeUTnqLm8KqLEaOGYwt4Pix47hixl3ErdQxeTl81DheeWseHYeOBmDJwk/564P38eTbC2my0mhqgcfu/T2LP30fgJc/X4UlYW2jwNAh1CyREvx1XrKaDLJ1Pz1rbNKSkqwaC7ct6Fxvk9RhawTSTJ26T1dywW2XI4Dbr7mLQb5SFq79nL77bKQtSW6u5IjBx9J/p6X6FAOaFCg1O42MJjd5u9PI3aEK0X//2G3M//JDbAEffvgtRlISCEg6+5V7WRcQMKBnEAZnK1rJiy66hBUrvyWvQwFzPnidvIJcwg2VZBflU1VdQ1ZeLi0tcbwxRUfrTuj00DrxzoYaeq7zoZsa766rpYe/mMJ6QWFWAa71uynNLaJmXw2FGfn0qYbDfCWwdieDqkH4IVK1i2EdO9A90KavCiDPm3qsLAYPHgwWnHb8adx1+Z0YSeh0XLU8AAAgAElEQVS00SA300XSTHLWdROZctpkxk8eD37YWbeTcROUwnf5JVcwYPgAdn2yE7oBFuyK7aRDpw4IJEa9wNin6sW7eUuJLd1HYZYPKaB2Vw09KSWt0umFWO0A79pD0I9pqCQ9D+qe96DGfygi9QsYO3I5U/k7y1F1JzV4sFjMp1x9WSmflytmQM8mqchwcgUX9XuaJ4JXYHQ9AfJ+rZJ8/n6DIhpPiaZhZ3XgtxdfyWNHjEaSBBoADUSCjiS5ubYP4pKj2PC+RkZvSDaCqIBiwIvEq0mErcE+tdhYgMuznq7j5tF8XSmLB01jjifJVsJsYSHbCGMhHTICff9ZanjqG/jWG6fJ76ZXVQ1/em4pF0TzyBk1Hp556EctWDdQLL0U27tBtss03c8SiwBfocrAVFNFRKou1qeeXvwgl4L8M7AZZC7Ic8EaDDIG9pNg7wV7B1jbwN5FirsvgsFqI58l7j686ZvAF4Z64gdTzIMM4GwOo1RkqZ11ww2cxids4kmWMItFPEA5J9GDKxjBafTZP2FI16GwRI1BR/3o/dJAhLXsBqCIIEWk4+PQ/MYSyRpq+ZhNfMxGFrGNGCZudIZQQpbD7aQ7ZUO6E69KzTn4KCSdHPz0JBcXOi7n7z8rS9qSijSiycJuUQWkwrTbEXk5NTtSqCKCUNs9fULfYzn92Ylcd/Y15OflU9/SQEukhVnP/oUpp0yktKCUS6dfyfw/vwnVJpW7KvnmrUWMPGw4r774CkeWjWRgn+EsfGs5YY9Gk0/ji6ULWbJmOe/XV9G5uBNz5r7ORWddRmw1YEPGljSkAHeLGz0iCNTorH5uVes+Na0P0RRvobC4iAQm9370AUOGH01mElauXcn9N1zO399aQN8u+WhCZfPOnHkP4pa7MaJgNNqMHHAEa595mfNPnsLsuS+gSeix16YqJHFbkGZKbAdFd9ZUsvGrLznisJF88sbLnFB2BKO6DGHFK99iaqBLSWNDPbf/5RZitapb2H99/SkPXHlva3czIcUB/gsNibIwAe6+6h7uvkr1RxZ1NpnNEn9SkrMmpSWBCIG+wQbDRgLP/OaZtnKrlZLxw3/NwnvfZcaFN/H2s09x9ohf03tD9n6/OqrjSK7YvoWdO7ZRnF/M3E9e5aW7X0BgM+6YU5nz8bPM+N0M5sx/jnFnnA7dYdzkcUy5bDLTr5pO9fpqNm3cxDDfMFgF0g/4lBkst9oQAS0BK59a3sZRE3XuJwMkFpf84WL6dO7N7yZMg90WeASlng6semdFazMPM26yacMmtn+9meKcDsx941Ve/sMLiIj6LukS4IJxJ43j0ZceZeLJk1ny3RIyAhkU5pa0C9so2ljp0toY60S7UjUplGs63voB6MPPecr+afkFjIHFlDObr1HBxz0IwrwmX2LGVf1Z8L4DxLukyk4uEcw87B5uO3IhomUYfPUp2B9Bh55w5s3QZQDklBDKLWR2dj23as1ECKKubgyBxYl4eJCB8GY2r12m8prS3VC8XunJSiySWMRtt4IhTyP1Z1bw9rQmlg2NYLZajmtxIeiCn674GUk2brRWyr64w7kbb2kitm098WiIU+vCXLrbyzH9TkRcd82PJyNJC6zvIbEIks6Qe/d/jzLR2saBd678gW3TOS2JfcCLzgDwgJZLSOvCKu8ovjUKWKEH+FazWSfC2KpJKn3I5y4GMJEB9CTvkLuvoTGGXoyhF1U08TTLmM1SxvMCmaTRk1y6kk1XsulGTut2MRnoaMRIUsEevqeW76lljTNXOe0G20s6HopIp5D01rmRGB+zkRpaWvf5CkZwEj04hq74DwTwiAU741AZg8o4VMUhw4BOHiq67CFoutmv7uNASRFPpNgSTBwGKAsZtiFmI9opjBrKuE3qGgldJ2FoWJrAEgJbw5kFSR2iLkG8dBAX3XYPR//2dGxp4zJcXP+Hh1i4YSVP/elL0mydl8rf48n3X+Wkw4+jT5c+PLXgVS5+YBpdO/Xgnim/xbA8BE0IRqGwEXbsEww9bCTP3jyDdZu+5+jDj2HK8DOIOHzLmwoh4YWafGgOwo7O4LbAZYJuQn1NmInTxpGIx1ULxSGjuGH0FRg1cMWtN5BoCXHzpLMAKC3oyLyH3gGgPRw+eu1DTLntPJ548RHGnzBe3aouHelWXgHNp5PQTaKZFr179GHOwhe54k9X06NLd6686kpl7UYkrqREugR5HbK59drfM/TikaDB7XfeRu4J6h69/fbbGTx4CONOG8eyJcsYP+EMGhobeO+r95j53EzWfLlWHbhTQiWTINOEw64Fb3/8Fr+ddS17G/Zy6rWnMbDnAD56ZL928wDcfP4NnH3LJJ6Z9yylRaW89ue5yHSN6r01XHr7pbz/+vvofp1HnnyEMdN/pVooTp1Kv7MHQEwyY8YMzr54Is+88SylBR15/ZG5iLhNv6FlnD35bPqOK8PQDf724CPo2QKiFjfefROvfPQqkWiEjiNLufj0qcy88jZIM5G+BAQi4I+Ay0R03cpXGz/hhQ9eon+fXgy8YABIwb3X3sopI0+FsKEYVjRFL/63O/7EmKtPxrJtpp5zEX2P6w9pgideeAJ0wRVXXMGv+pzKh98voMdZPfCl+Xjm8WehhwATJl8yifKvytlXv4+OY0uZec2dXDzhYpyb4cfn/4D8ny9tSpKkiO7UUYBqBlrLg9a9fPibK/mvt0EYEm8V2AiSxRazj7iDqYn7lAVc1B2OmghHnQ2d+oMQbKCeP9rLeZ4GTK0zoIOMkhtvZGrFPm77Yif6XpuXX/81azcMxItNKRqZgIWJMGppMTtgoxFDog9uYOnfKnll+BakgBPJZxCZdCNAN/x0w08Jvh/Ooq2vgwdvg7efgA5BuOZKOOUU1Vknxb8nUjx8upplAyQXO+C7GNVTFdA6gesYcB3haJIrQCwFsRaEBTIb5DCQQ0HmAVGQUTUTc4ZSSpABEANB5IKWAyIHtBzWaBYvs553xDrWs7fVkVpIOoMpZlDr6EBHMn+WZWhi8SEbmE8FW6lnK/XsoBGrHd+UC51CAlTT0vq6G50yCuhHAf0ppB+F6AhqCVFDM7W0UEPLfrMbnRPpzkn0ZLTsTsdQEGpNqIjA542wKgR74lCXhKakqn/9Aan4MIM+uY4SJkBqCpQlOI0UcJq5txfZ+v+U5ZvUBQlDObLdpo5htT+HP3Q+1etSQMKAuAEJXc1xQ/WkyImAz7EoEj7YHt7OmReeyvdr1hzEukRMKqs7DESkskYMwAvSoyi1k/IA1iShEiYtTWDqqsWe1Y7ByhCQqUkyExJvxPneKAiz7aRIlTqrlMaUSzJNOEkZQvXI+JFb6qAWivudaifO+J/gZE7VNac6sLTOTnDWLZSTTwdkAqww2GGwQmBH1B80j0pCSQ3hVa8dwDZHTEKDhHqpWMBA9WdPijblWgDuOLgjSHdCNSxJC0Fa2DmfmlPy1269aV13hLMt2r0u1AHZcbBjIOP771Nq/1M+ZJEybVMjtVMqSq1uuhRdrN22jeYcs8eZ3c558cAPMOr9M/JLadM/IbdyA3VkoS7OHqbGL+WtaVfw9bug6RJPNdhSEC+Ep3pcxtTMcjjqJjjybGUFCwF7atn27H2cehys69oDRB6IbiBthq78ir/e+jc29CjmifNPYsW+kfT94zH4Em46IclFQ8NGM3bSYHYiaRayF41415W8/+xq1h0TIK8hxA0fV3F5jYsuJV7o2xUKOxy8apjrqI39lWxzC267Dpp3gl0P10pVM0QTcD+03P+PnRy9N3gmOgB8NGjZtMhX+Vi+j8V6/CTwk4eP3+HXTsTPIHzCgx83vv2INn9cdtDAK6ziZcr5nlp0NE6gG+cwgEEUM5hiijgUg8rPEwOd0yjjNMpaXzOx2EmTA851bKWeKprpRCb9KaQ/hfQg99B1sO2lzoSKGKyPQ0UctiWgNgnVCajZqroVkWR/8mFnoXK7FeF+QIdMN+S6IMflMEklwR1HenVsWyItiSqFbHMvp3rDpgBaGVcaUoClO7FlU8NlCVxWiom3LYL8QyKhlbpRCNUZ1JPAaTzb7o0ulHPJq4imPI02mCB2OA0GnD7GIkkbQ1V7MYFYqg6Zdj6D9u89xD2lo5BYsn8zBY9Qibx+TTVA8IH4dybiCHEwCcy/S1JUmgeu4FI6gBuGZEi1VZVmagdB84MrXwGSHQOrGcy6/b9DOEAkHYSXNqRbkC4h7oGWTIj7IBADTwy8plJoHHAXmk+1rDRyFMjzI56cf1SkrZQKO9YOoBPO/rE/2KoPtNZ8twF+ShlI7YvzDEoTrAbAZH8xQHODt4dyj/6b5f+0ZbyVzfTiBEwKgb0c0TyS5ukvsOZDgS4l7j1gWxqJbLhp6GPcd38PGHCiupi2DV98Bi88yVtyE2c/cQOWqxCkD4SHno0h5i6r4e3uPp4otnDPK2LM1QMp2OsliKQA8CKo6RjBqPWgJTWqEVQfFuazv3zLzuP3cPQ+myu/3MH4eV/g+f472LWjbedz8qDvQEKDDqd8dAYf9dzKx17BRiObDDvJuJqtnFmxlpOakqQNGQt5vUDLBJGlNOBW7bD9sNTrIg1cI0DLBymRfM0y+3lmiypeFd0JiZ/u/RrATTdy2g3lBu5ODh3JpIEor7Oal1nFYrYDcASdmMLhnEV/8vgnCK//JyRkwZIIfB+DdVFYE4MNMahP0gpwBpCBAuCQKlfBJZA9/NAlg0h6JrsjGch8Az1fQ8sFPRdcueDJVUnfejYs3wvl2+DI9AoKC3vjMSVeE3w2eG2J7sTVhCUPYRkrUS+rRch0gZ0mMDJA98RBj4GerkzNVjc3B1tepmxr2+XM8pC/6byQ+kNqjUmBlaHcrcp6E2oh9wplCkedEXHi2imdRUhH0wDcCUgzFZ2l5gXLaFtHfaIVeDGEshTD0qG2lKqnbqZD5CEttbDLuLPAx9WCvZ915D7YUvx3inQaAv8z4CVtB1QbwGyktTei8ILuVwCs+0FL2/9YpBPGSFgQT0DCdDgtpVK0NKlAP4Vn7bm0daH4MX0eSJUnSQvieyFRC7apjsGVBe4CMP5B2tqfKzKlVMo2YJY2yCRY7QDcSihLP+FWsQ9LV32wdb9zbiznGphqlhaU5v5sb8cvDFz/gEgkAzmM1XgAi7TdXnJvWMTOcgM9YePeJ5C2IB4QnHnCKubO6YK2t0r133v7VXhpNlblVn7zwBQeP3c8kIWGFxsXR5LETYgv7GaKXi1m1A0Dyav2OAxZkIFA6E3Ua25IptGMZM2YehbfXEHdMXWcJ0q5kq70I2P/nW5uwq5YzaraZXxkbOXjrlG+7JlFUtfx2QmO276L48ojrPNJ5p3ci4YMNwHp5leiN2fSn1NkZ/xEUU9XFqph+w+doD00yDm8JD9ntlbAapGPT0omUsqFnEyO8BMmSYQEYWdESLZuV9HMFurY4liZiXbNU13o2E5pRV8KmMLhnMMAupD9w/vzPy2boooM5L+a4bsQ1MZx2u/wY5aldAnoH4QOWcTNTJo2B8neAoajDEVdNi5TYuz3FQcG2dXisv7DnfTJ7XXAu37MxawsZFOHaAC0LPAF4+iyGcxmMENtVpPmBl8XMA7Zrf7QYktosaHeVoAXl/vvuu64Sr1CuYATjjs61c3oh0TgtPILg7teAW+wAOwA1MVUDmTUuXfTIhBsgUxb1bAnNQjrEHGpmGO0nanqstXfAXwRSG+A9GbV/1ntMPtbV6n9cbcDaC9oAdB9/GymNSnVebdjYEWdOeZYfQn1O94ScGX+MCgfEoB1MDLV/mk+Zd22d98mBDRJNeLONTjUZXDc9W16uvzx29wFuE0wQuCKqiYX/gwwwxBvUq088YPIBLxtyp7ACRk4ypnRbtZwwDCpzklqtpOOhZxUr0nHBS1xPDVOooHUFJOe6VbWfNKrwDdxgCGhp9zW0GpBHygD3L+A8b9T5vAUFzILyACzhqKrVrP7kyAiLHE1aAhLEk+DwSP3sGjgrXi/ehNCjaRSmvd2LuWE2dfwfXE/VH2PGxUTrQULOr5YwsgZ/Sio9RMAsoEC3UKXUOcy0eIebCHZfeoG5KML8RULDBHEJo0I0JzqniPiNBOnhTjNxKihhQbVF48B5h7GmJWMifg5stKFp6ESrCrolEWyUz6f6wZvikzeFkXsFWmkySRj5TaOkFUESOJHw4/XGan/glTTwtOihTdED2LCxSDp4VJGMVmMIIj30Cf0R8TG3g+cN1OHgcZZHEZ/Cv9HeJOrw7BqXxsPbep59lbGyFneTOaaEBkbIwS3hvHsi6NZbW5lCZDlQvT0QZ80KFLuZRk0sFpcJHbqJDbqGBsMvJU6uiUAC1NTNHvudiz6tlDthk0nFmoJtXbZQuUpSKAlTaM+Q8N4fBulJb0xDRUztVKt8TSVCK7patZ1VeHm0sHQTFxWA5rVAmaLWsRAga8RVOArDIhWKuvBUwDe4h+2Bm0JLRIaLGh0ksQ0lMWZsnA9zmzggE5ELaCazwEJob4nBc5xqaxit2PVGk2QrFSLrasA3B0OBr6YDfUm1FsQc/bVMFWwGUDYCqjTIpAWVrNuQyJduVmbAyrYDcr9mqWrEIGBs/CnLOZEm+Us4+pvKdF8bVanHnDcu4e4l6VUQJtsBLNJAbBsV1ojHAtfd2K3yQb1HiMA3o7KqkyBtx1VbugDAdjIAtuC+G6wIqkvhqgPwkGIpEPCqct2x8ETp5VFyK2Dx6WG2/3DCZ2pmLiNuu4xW1HiRhKQcEEyzQni/4QIUn1aaaejH/AeW12vg+DJOb/SUTBS8ZifEu8BXpjUrAl1bWPVkKhT95mnULml/gW0tr+A8U9IHfvoTF9CdALCdH/tRjbfdgFag427QaBZNjG3oLh0J9+6B5Or1alFQ/dBn358PbCYE6efRCStLyrzQ6LJeqQZYfBfc+l312EEQhm4AL8nTGHcTzaSiJBEpIYBbDhqC3NfeZ764hCJAxIFhJQEiRMkQTpJgiQJSosgSbJlmKPkNkazg0LCBxyZQWuTATJAZAAZWAT5giBvam7ewqJa/NAT0CbpUjKFXlwqxjKI4p98///vYktYtQ1WfA57v7IY+HUDfWsaSUtG8SVjuM0ELtvkwIITU+jU+z1sz/bzXUmQrztlUpnjo6QRBlWb9K6x6VQnKWi2Ccak83l5kHqxN12ws1SDXjpdh2pkHqZBLw06/0j7Oymh5Rvlt/Z2p2L9+oMe7B8UK6YW5mSd0vw1lwJePV2BsH4AiYq0ILoLEntBT1NWsu5r01IOBcCZGmRrqiZTE07sLeIkCjmzTBywY7pjVaYpz4zEAb+kWvxkGGRUAZ2nkwK6n5KoY53HbQXmAQfUW4HRmQ/MIotKaEh91rnuBy7WaaKtoxOo/bTDTkJUSM2tvnTDOTaXE3N1EpDMKMR0iAQgFlTth1zC6TfoDBfgcs6rnYBoPUSiTiabB5IuZ7hVOCHl7jd00OJAWNUQuYS6ziEXtOhKqxOA34T0BKTHVbZdSsGwYgcoBqKde153Rir5qt22HYf4HnXNXRngKVLKQ9KxumPOsaT6KeuAbAJztzpvwlD3pBV3NFHDGR6wvWC7wXY5v9duIPY3XtvlgO3XEzrlWvcccP1+TKwoxKqU0qS51DG5c/9bYYpfwPgnZCKn8xrbATfuWh15zkLMtR48jRLDNgnrBv6OLazwD6Fnv2yYeDUcdxoyGGSWWMGN1KJAT0elgzZw9HvQY9LxpIWDuIDsor0EpUV6bQE+BCFU/oqvBE54FkpOxIltNCKpxaSWhKwFGvARRxBXC5O9Eax1TgehmPpNfSC4TgbRAygCUahmsn/yxpFImokRbudSPnB4MDiF3geX3fwPS8yEb3bD51Ww5bs4yXSd7CKD0gB0DEBpOpQGoNgHxgZJ4sMYe8ojiLVRgrVR0mMhVB10cr/nWaLhpNeilCsfquFkOvs3nTRJBUxToK0Uc42wV1CfIdiTr1FTKtjbRWDlCIKlglFjDPI7/JPWf2QtbP0NNH2u/u0qosI7lz59eitAPZQVlkreiddCssmJ2eUoLV9LUzdgaqGMtxsJaG1UK53/STjIZacDQQsyk+CPqUwsaTpgekDGq3BcujhNZVMWpjRbvaZtv5f6cqvtNYljLfrUvus+x0Xs/u8nAx0o7YE50u78tBePrWLVrji4bZXF5pbKshS2cx5Sx5gEU4NwQI1IepvF7nKUE9N1aItOs9pcre3FMJWb3etSbg/TctiHbOWOtQw1pw7JJRAZGmSINtKWHzp2abaLqTrucpl03MR2W+z0QHFlgKfDPxcPllIpMIk96ju1tDaPgOYFTZ0nmXrcXP/6y/2TYoYgtkvNmgf8PQ9WXv9B+SWb+keknE95k5VAEch99LnreVZvc+FuAsO2COsutMIk75/wV3pe/wb0PAyAMEnG8iGLyQQ6oO6UWoahc/ncUSw+N52gCVldWjhiyhxW//FichNeBIIwYBTByDug1wVgpDy9QsVuVbO7PrgE6mFOfArxNyAxD2QDiAC4zwDPmeAeiyLO+HkiEGSQRka7iub/tEipGpV7f6KMJGnBsj0KfP+rCiq2mIz/ppELl9QzpFK56rcUuFlS4mNPuo9m00tga4yi3fvAqsODSYpJWvWxUsQKdm464sgg4tRsqor9rI8ZbNkHu3ZL9u4Go1mSGYG8kGTYrij9tpukh9TiHM0RRPsZaAMNAocb6MM0RE9IR5JekaTT8gQsT8DXTbDaUgc7bCuMjcDpedBnwI/HZc1GqJwJNX9ToFt0vXKFRlerXs6RnWoht7xgp4OVpiwJK6ksMMsCmekoaB61qJtSJei0xxeBcgt7BPhFO5YhB1isFrUgawKQ4I2AL6SSesBJmBJtVqDmAXxO7C4JZqQNnIWmrG096MReHatLJkHGKC//nFl/eYb5bz+j3NK26bhjI2pBtOv33+/Ud2ie1nnsaedQU7sH07Q4+uijefTRR9F1nYceeoinnnoKw3BaKD7zDJ06ddr/nItU0pdzEmyTQDCTUOVGiCaVGzzpgbgXQsEDgFKCKwlGQgGt5odoOsQ9zJn/Anc/cz9ocOv065ly8dk06wIXFj4RQbdhUfkSrp1xG6vXruXVR59hwpjx6hx7DJUg5RbgSjLzjlsIeOH6aVN5fd4iZt77Fyo2bOOb9xcwuO/xEHUho05CFioBq6GpgclTJ7J95/aDWiC2P/YFH33GtGnTsCyLKVMv4eLfqdaENNdz8eR2LRjnvkJWZhCkzX33P8jTz845qIXi73//e55//nkaGhoIhUIH399CIPUAncv6Ub5kOfFYlMsvPIvdNbVoaFxyzmX8duI0pTOn7lcnZL/g6wVMv3salm1x8fmXMP2GGZiOU8VOAkmQScmMO6fxyaIP8Hl8zJ75HIPKBiEEXDpzKh8smk9+dj6r3lSlacIDItvJa3WpxzWhBQh7ehHW40Qtmx6a+z8SSPs/ZRlHidKb7lRSCEj6zB9JxV2Pom8Ad7MKIdk58OKDe5hyXhundBKLjnzMbvJwfHbksotX5fHsvbMj790J+UDvUz4jJ3c7dc9PJYhqYWgWwogHocc5rUpfm0gbrC1grQJzFZgrIfklyGaV7OAeB54J4B6tMiP/l4qUsKlJgernVVBeBbujal0NuMDvUnPABX5DzaaEb2ohFpecVNHCtSvrGbWiGSMpsXqmoQ3KgHU2bApDtAVBFGX6SVTikhdbuNGkhUBHmTDpKCawAxN1DnBntt/uAIzQYbAOZUJZGiEbQlI1rV+fhGUJWJlQVhWALwHdVkKPChXzW9gLqkrU37qvhqO+gzHNMKwYAr2UlRDZBo2fw87tUF0EOzvBzmKoKYW6QqjPp+KZHPrk9OIgcVq9IaRygWp6W9ZrKj6Xctd5hXIAuFNu17BK5rIjbbHdVtEcy8hxXaYuZipjNZWR334NEUJZsbq/bda8P6p1qX7GDzJ//vuHfkMrODvlLHbCseScbaC5OUQwGEAaQSacdz1nnT2JcyZN4vPPP2f48OH4fD4ef/xxysvLmTt37n5fL6WEaAwZUe5nQYT0roNpqfwG3D5wBRBGEAu3aqGY8jCkRqo3ciqnLyCotxoZ8qsRfLVsGc2WxgkjBjNn0QqC7cAwTYOGndtJhpqZ/ZdZ/HrcOM4aP0GBSsoJY6rtOx+Yic/rY/oF11CxYSOG6eWqe6/ggWmzGNJ3SCvRnXBI7GUj3DTzRrKD2dx4xQwefPl+GhIN/HHWA+2OG0JJi/69e/LU/E/IzCvh3OOG8vDfXqFHzzL+cN+NBPOyuWHGDJ750/2Emn64heKGio1oMZ1vFn5DaVYnep/Ug8avQ2A4IGdA0oCIDiENjhzemXc/WI67KUnTrhqGdxtES7iFYecP5oVH3qF0QBm2y0maT4KIWfQb25MP//YJHfNLGHHBUF68+xXKuraVJ9oC5n/9AU/MfYTXn/qAZWuWcNMfpvH+m0tAwtdLFxH0B/jNDeez/KM1ip8ogqJDQCU51gehPqCcDAKln6Wo1H+O/GIZ/4Dcy+3sJAAY6C3N1D1xK2KnhSukY2s2tl/jjtvZD4glku584gCxCWzmGrK4PzqFxy+Msvw1KNIsSvqvIrxwGGnhE8gATF+cYY+8R4+zdyL0dDCDYKWDXd0GvNZ3IFPaow56marr9YwH1yilDv4vlW3NbeD7eRVUOeHtDn44sQT6Zqs2b6Fk2wgnwLMbSjZKDl8T55mN9RRXNqDHTaTQQWYiCaBttBAbo6i6aZXIYgmNxsx0kkU+MlxJ0jbF0F0R6LEHmZ0gEc3GqslF3xvH3exC/CNJHwDVwFvOOJR4YlBWCWfVQ891UPg6FG6Ekoug190qIUpK+H43vFEJ7xfCnH7wnAZ5VdB3KTTnwO5jYfdklf2ZEt2GDknoEIfOLSruV9ACRhL0JOhxMGJObWuq5shQrmkjV1mjB4q0VBJRvEnNqS3PM68AACAASURBVJog4VVJSFqak5iUiukmVCxZJlAECRovvvoeDz8+h0TCZPjQw7nlxt9y4q/O4evF5WTndeDY447ntttuo2fPnowde9RB7QZ9Pt9Bu9Xc3MIZZ5zBhg0bOOaYY3jsscfQNI1AIMC0adOYP38+aWlpzJs3j4KCdjkM0gY7SdAfB6sFM1xDItqAiO2EWBXHH3sEaB6kDcMHjuDF517E3g0yJiFuqTmps21XLefdNhnTNBkzcixIDWvbYSxcUc4fZt9JUV4Rqzau4q0nP+D0K8YyZOhwVq9pO6aA3zkmKYlJwdyXPmPIqNHs8ioe9BGjRlPx+QIuPGcSVhwSMRUuzXF1xgiAaNYwt4O18tC3mQyrcEg86aNjz4FEPRDzKH0t2FuBhUuo9suGAJEO73wzjw/eKMfU4dxjLuDEy4/jrkseIJ4JMaF0m1XfLKVbUXeOjnVF3wHnHXcOy96Yx6iLyvjyvXl88mQ5meth/FEXcPqFxzHjdw/w1uvzmHjWObiiHkqNLnQr6s7XLy1lZP+RDCsaoSI9AmQGrZariCm2tAxbVfsZJnSohczcIqKHF7HXB3FfOqX9+7BOryKroAxTwh6pqkhXL1lKQa/utIzqylYbxk48h9dWz+Pak8qQBkgXSB3eemIe4y47n4augi5dRtBwcyOVrhpyCoooKzmG7du2EzdgXTvCPm8cspohuxlKqqFYKOeSkQMi+N8KGf9T8n8GjNewmlk8g6QrEOa4267is52FuJpA2JK4SzD2TLjjyrbP2Ei68iGV5AMmflbzljyWITX1zDx9K5XLu1HqjRAMRPF+dzhZaAgkXS6dzdA/TEfTwjiJz/uLCIA+ADwXgjEQjMPBKPtfY/1Kqdq/7QjBjhaobHFm59/bW1SXGoD8NDi2AwwvgGFhm06fJAk+nCBtc5J4mgRMRCKJEUvijiXRpAkkENhIbGyhYyPQZByoQhJvtV+jbo11I3OIT86n70kZ5CxcDe8uh687QqQTIGB5CcKdwJO/B/K3QfcqyN0FuZWQsVvF2pJup/jWrYZ0EmWShiI08EuVLRx0Q0YA0g2VJBQQkLEDIoshtoXWTvUALU/B6gXgKXGIFgIwxQ/n+6E+Fxb1gk9KYdVxkFMJfTbDeB36DYBuLuhiQEenBU5KKiqgY27bv0cfd8CFMeH00XDRqdC0AyZNd9zIuhPTNOGcU2DSqVDXAlNvVi5moatz9Un5wRdbeMDfrd0uVDD3nc/58uvluFwurrrqKhYuWc9NM27himumM3z4cMrKyjjppJPYvl21G3z66ac58sgjmTp1Ko899hjXX3/9QT+zdOlS1q1bR6dOnRg7dixvvfUWEyZMIBwOM2LECO655x5uvPFGZs+eza233tpu/zQVz9M9jDn1LNVCcfSJjD9pEnY1yERYJUAn3Dz156cZM+hk7J0ohihXHOGOQzpMv/lqrrjqMs6fchGPPfGo0jtKVU+SZeuW8vkHa+jcoQu7t21n05YNzL75aUbccCQX3TOVe+97jHN/dz3SAyCI2rChsoqSgo50DUMgAf3SSwh/V4XHMeRa1RENpJPAbPqgrkDddjhDOCNaoPKjrD5K93JL0F2qKZpLcxhPbUi2463YvWc3zV2LWAO4C4uobdyDlQD/LuUfkkDzrio6deiogMcLJYeVsHTlEvR+sLtxNyWHFWFFobumWjCmV0L12iqG9xuBvVk5TYoKStgeq2JAF0j6lfVrC/iuQP2ISDlTnNPutlQIvaYbNBc6zK3Azu3bWfvdSrr+P/beO06q6v7/f55bpu1O2WULW2HpTQERECSKYi8oamxoxN5ijH5siQ27iSbRRI0fS+yVaCyIBSUaKyBSpPeyjV22Tp9bzvePM7O7FI0ak8/39/t834/H2XPn7p07Z+7ce97n3V6v0eOJZr+HV4DfgFRTHdXVVYS8ygGVX1PJ8gXz2ZybMtVUwpa6Og4qr6LDVdepuKKS9bV1GCVliqApl9yVy+YGUgFoyIOGMoXUWdAOkQ5w27JlyMPA+GEh4+8l/2uU8YXMIEUFIOj7WRHzVl6CqAM9qZL5/GWC5//Q7U3rJE1f3qKNasBhH9nEPGnQsuhmrpl2L8nWAvoXJPBFPZTs6EUIiZbvcvinGpG9LwAuyE6AMZBR5XqWnSCKQO//n1tu/UgipUqeemo1zNoArbug0/l0KMtT9I4+L5T5wDWgfJvDoDkWR3yWZnh9HGhB0oHAxrs7vPNOIlBlgI6h0VnqJzYoSGp4CWJQAG9/H709XsZ8lIZH6uHiGLjF4A/Afq3w842w10ao8UN5IXhKwBwL5tHdLlcnDW3vwI7noW2OyvLUwxAYD76RQD5El0HHl5Dc0j2wvEEQ3heCI6B+EUTXQWQcDJwJgVJIroPUOtVn6pUr2GrukYUbhwlxmOCqmbbsF1B1s8py/ldEGOAphsDeYG9DxQ5TPf6vqbitfzAEUtkEq+8nH3zwAYsWLWLsWEVwn0wmKSkpYebMmcyaNYuHH36YJUu6SRyqqqrYf//9ATjjjDP44x//uJsytl0YM3YcJX36YQk4+ZTT+PjjTzjx6JPweDwcNe4YnFoYXT2G9z+ei7OR7iSvHu2tP7xLqj3Fz26YzgevreaQ8YeCx0aYcZ5771G+Wv8pH97zJHpwCXgCCLNA1fJqJp8tms+rb72OZsJp55/Jtbdcy6p82JQHQ/cdR/F+NfgNFVKprKpi3HH743bCWUecwUPP/ZFBx1+FbaqwsteCsiZJOgOhbagb2QEREGgVQBZ9EQ9K4Qp12/lLIK9CKVadLLYGKuIQ0FSL9JixPUJV1Q3s4QBxZTe4mQ7s3cMJoWlgjlAef0NTY9A3SbRVoPdRStHygWUI2rMY87Ksx3pQB2cIpPMk0TBs6QMxH7TnQUNIsNZLd44jdOXj+TRF/pWnQ76mXhsaVAWhKDv2WCzGjDNP5KH77+OAshC56r+ce3ixIQlqMMij5qKvdKg1BIM93cnauoCQkAz2wsjsI56vwWCvYB+fel+BR0VqRnh7YNrIbjh3JwRuCJpdMKPgiSowvP+E/K9QxnXUMp8moAKsNsK/fxBjs42IehCauvn+cj8UZOfCN1jDCSzCYRDgcpSM8ZZzF1+81pv7znqOYMRhSJ7E2JFHCVk+ooFw2CcavpIeHywMFfv9l3gG/2dlWxSeWQtPrYG17WqVOq0GxhRDaQCaMrA8Ch81wYaYpKRNcnCrwyUfJBmzIEYgngQSSGKotF0JwsDqVYgsNxH9TIwhhsr8jEuoa4KGHdBuQUk55FeipzVCHZJQuwtvu/CCDe2d6gnSHBi4Fk5fDscOgEMGQP3N0DFPfYGObOspelhBAjpRsBoVSEKvaVA8HSJTyGHSply1MhcCRWbRsQjav1TKufUfUP88+Gtg9ItQdjIIgS1hjbYPS4GlLsQMVYo8PKBacQ6HQcps5q3cszv5u8ieLNmsyHA/eHMBsj2DTLkInwk+o8v5IoqD3/r+bzyvlJx11lncddddO+1PJBLU1tYCamINBlWSmugRK1ZVUoK5n87nl5dciCvh0utuJeIN4WQEqfXgscDZBjQLnBVg6iZym1A4DkmdTNIm2e4w8fQxABw9eSo3XHYrCBXns8p8TD5uKi8ufp1BMw5F6gafzlvArY8+wPNvv01DcRma5uHem29k3jsqRj1v4RIksMMWxB2oS5BDLabUhNJQHjXZ69YiQBMCfxFQBMYm0EKChc3zufjKC5ESbvnlrVQOquSjhR+iDwe8UP9ILZP3moy2CxunK6HTUWkIm21YnQ3ZP3Tz9XySHd/z85fQ6ECHDYtSSuloQNyFjZayvHXgV+efzcoliyktL+fpN+bQq7SUFXUNlJWV0dzQQK+SEqJSWcC2VGBblFayass2lqTVvsVbazFLy9lgQbiklLmbG+hdXkZnYwMFxSXs8EHZgEoaY9sgolzITQ21FFeUk2+qPDhfNlVhkA8COgg3S6EITJ06lVtvvXWna2BZFieeeCLTp0/nhBMUSUdd7TaOPVZRKF500UWMHDmSbdu2Ze8p2F5fS01FOcFdbJrKysqu4wBqa2spLy/vep+eHZvvu9hCvbLtPyT/K5TxW7yJk3U1H3rP0cxtHovepCoVMgaM3h/OOB6aiXEes3kDCxgCuEyWjcx2zmLeU6fyp/P+zKDhcUJbBJ5YPiWoXJjSI+GAVwX6/ze8zHsUV8LGGHzVCis7YOUOWNwIG7I4JzVh+Olgh1F5awhv2Urd50PYvLmUPo1w3A6Xm7bbVNQnMOw4yjevahOkomUCQBbk0TC8mCUFebgJGNzmUL4ogzHH6YHIVJJtkPRJ0sEYMqJhFvoJFGlofTvAWANiMdR8AfvHYdTPoegiqL0NVp2pLMx+DyrlareA1QSZ7arvaor+kMJpuAXHst4KsDQBS7fBsgQsjcPWjLJGKj1Q5S2iynM4Vd7DKaoAsxqkjNHq+qlN62xZC5uSsCnV/VVMoZJ0OntUhfQyYLgfhgcEw/w+hgagwgNlJoR2yS53toH1jkqe1/uBzO/OlXLIEijI7ipXzQY9Cnqn6oUtAC/SANEjIVkNLmudZfkBRDib/PNPZMqUKRx33HFcccUVlJSU0NraSjQa5d5772X69On06dOH888/n9mzZwOwdetWZv/jcwaOncBDT7/AkFGTGFI5nn+8tIS8lIodfrToQ5YuXUDzxo307tOHl+a9xKnTL2BLhXJ3rhrg4hhQt8qlPQirB2v8ZVG39b04FiMZi1Lauwzp2Mz5eA5jJv6EpICVXy3m+p9fxMOvvUOgtIaoVNgYZ994B2fdeAcA2zIwYvz+PPrci0w97Qw+feU5NGBoALYbuxV4sXXrVj7//HMmTJjAiy++wKQDJzHhyPEsObJ7TK2trdxw769pT7VBCt57772uBYyTzf1rc6HDVa/TUpU09zOVMrv/rjtw77yjC6wqpCnFVqp3I5TmOC8EKqds5iNPdGFyNDsw8aipPP7kU8y4+jqefPIpJh59HJt6YJYIYOCYsWxdv47Ylk1UVVbw0V9f5Ilnn2eoB6YeO5V/vPAUF159Hc8++xQHHnscDTbsdeRUbpxxOlMvu5J0Yz0NG9YxfdI4PMbO5w7lXuv6Tt6SniKl5Nxzz2Xo0KFceeWVXfurqqp2eo9t26xbt45NmzZRUVHBiy++yPPPP7/b+aZOncoDDzzAqaeeyvz58wmHw5SV/TA+chcHixRe/s1Qnln5X6GMH5MvgDDxNsDnX9yCb2sGoh5cA6QX3nwW/soyZjCHOBXAYJAwhE2850xnzWdn8eeLHmTvPi3oKyMEpE4RqgJ18DUw6rZmxI7noPUN8PaF0E9U8/X/HyiS++fiuLA2Cota4bMm+LwJVrdBKgM4ksodDpqrEiIqTPAi2W+5w8ErbA5eUUHfljLUlNCZVbYJII3ARkXaBYg0QlogBG5egFggQofmx10v2EukcDwum4o8fDEsQP0BGvWlBvXlOrFyl4o+GoUVHpa5jSy0wrRqBSDBsDP0TXVSmikioB2PL3ApXm8vPO0b8NS/h0eOwCx4HzM0HkP48bSAlzBepx/BRgjVQt428NeCrxbYATt0aNQhmk2Isb0wKh8m5oOZB01+2OaDBh/M98G7AejMg7gfFfvPiaCLdSgX77Oyibe4qkzVcCBtw8IUfBqDHkBcgJqE92uAqR/BAfOg5uud/y/fVqWlGRPSJqQ9atu0IRhXnmdQYZf2PIhmm2WoWJ03ozJT/dnekwGzXSXWUAu2H+wCcCPZMGx2srfJIiQKGDZsGLfffjuHHXYYrutimia///3vWbhwIZ9++im6rjPrr69w/2NPMGLSQfQbNJSXHn6KxeddyKDKgVx//sUEmsHxuqTzXHb4BdvKYcR+E7j88evYuHwZ+40fz7SjRpGfXIGGy16NXwGwvmUTKxI72Kf2K5KeAEl/kIQ3j63xTn558klkMmlcx2Hy5AO5+ZLz8Hgll990NZl4jOt/lqVQrK7mjTfeUNczG8e0JPzmvvu56MzTefnh+zl62olIlOXp7vIbAQwdOpSnnnqKCy+8kIEDB3LxxRfvdkxhYSE33nhjlzv/1zfehBsuZH0GfjPzJobssy9Tjp3K1q8WcslPp9He1sZnc97kz7fdzIoVK3Y7X76mWqUJf/vb37jssstobm7m4uOPZtSoUbz77ru7vee+G67j5JNP5rSnH6equprnXppFgQfq6uu59ILzePutOQhh8N8PPsA5xxzeRaE4dq/hAMz8tXr/rCcep7q6mlmzZlHghb1GDWfVySdz2uhhGIbBnx98EE8Wn/qaa67h+eefJ5FIUFlZyXnnncfMmTN3v4hZ+fTTT3nmmWfYa6+9GDVqFAB33nknRx111E7HGYbBAw88wOGHd49z+HA1zocffhhQFvRRRx3FnDlzGDBgAIFAgCeeeKLrHKeddhoffvghO3bsoLKykltuuYVzzz0XUCiBFgnSXQC/Caxswk8lo9D/A6ryf0Vpk8/tT1orourqX1H/8TGI5QZmXE1ol10FV9/ZQX8eJk05ShELerORNc7ZWFsO5ur9n6A45iUYDxEBCpDoGox/4CtqJt8ObbNVfDgwAjIN3SwoZplSyuGfQOgA9f9/Z6xYSlj6MfQbAaGdcZ5tB55YDw+thuUtYOfA/rM/f3WLzbkLY5w9P05V067sJTlxUMAjuTKiXU7SQ9qqYsw6TeOeI/ZmvU9lvwqPRPq1Ls5jv5tkoBPF4+ZTn/JTn1ELl+F+OCAQZUesjk1Jmw2inDbxLbjVEgo7oG899K2FmjroWwdVjapVbFegQz2lJQwtERXf82bAnwZfSr3+LuJqYOVDphe45eCWqSSbeG+Il0JHKbSXQkchRD3Q6YO4UMkncVe1dltBXIeWwZFz4ZgPYOgGdf4lw+GtA2H2JJUdO2o7XDZ2FYPKhuLJZBOqM905Y26einelghD3KQyLlOyGH84Vd+VikEAX5TEWhDpVRmlOoccC0BaC9mAWdhMVv/MLRSrlFVlmJpHlY0B9n1ZboSNGOiG2ahOnXnwsS176Gidgk/TZdAQErUEvji7QpEMwFSPkpAnhKvdmDtdTy5Vo9XjtumCld2kZyKSRjk2nP0R9pJy4Nx+Pk6F3RyNFyQ40XVeEuIapsOUDQTC9pKRguwMtWVKpfE1dm0SPuKtAeTfysqXITVs3c/LUY1j+9fJvXWdLqaIuHVnrN5H9nUyhgMsKssr1uwBD/Wji2JCKQyoJeSHw7Z7V/p8Sma38/yHi4mYBgmMINHRMNAwUL1mu6V3nl7i4ODjYuNmW27ZJkybepXgBNGnglX48toknreHLr0L7gdCY/6+0qYdYWKSFF77cj20rj8fcJtHjKpsvVAz33AIn8CZpSkEOAjTy2cJC6xJ8LS63/fRmvO0hwmkvhUAIie6zOOi+EykZMRuipVD2SyidAYHhqtQiuRo6/gGdH0PnP6DlZTUYPQIFR0DxGRA5jB+VlmvpW/DuFeBdh7sgn3UjLuJLMZHPO/rzTnMNG2P5yGw5jyEkffIy7Ovv4GdLW9n/bUmvr9SDKU2BxJ+9jR0kCbqJZzNddH0KQMPAIY/WQD5begdYV+Xh68FeFu7lYUl/Lx35Amna9A3E2SdiMtjnUmG4VOou/bxehnr96Gk/znpwN0HTMovGxZ3I9T7CjXk4nv7YfhuZJ9GCNmagA5+xmjzPZtJ5PmjOx6jvh17fFy2687VMlUKsGhL7wbpK6KyEtipoqYSGCmgNqCVFWFOTY0SDiA4RCYUZCG+rJbJ6BaUFA/CE+iE7hcrB68i23HYTuA3gLlH9bgilPcXMuoJzNaFeB9mWwd3uR2ourSNamXtpG28c7PL3ASU0BAq61jkrBfwsAbXlWcRDVO+1Fc9vTFMTvgRwlRUb0KAgqyxzi4Bkj3WTL6sQ/F5I5sGWUgkpQaQDCjokVY2CykZJMl8S90PSEFiGoE1X1nYOVEpDIiUE44KiDpdgTCCkYINtYxuSlYNdMqYJGOTZKUqcKCEJeR4PWiT0/bxHnj2ntQrHIWxnCNkWUauTet3H1sJqGlyb3olWiuMtaMk4sn0Hnf4Q28O96fSFEEgKcSj16ASymlFmFzHxbIZyXCrEzGYJ9ZZa5HyVVglUueYV3aXbna5qOYWeL1wqpEU4k8CfjiNMD3j94A0oIPF/h0gJ6aRSvskYJOOqnionLRqU1UCwYLe3JukgTawHxtxuJ99lr9ztb04FKjqYXXsHiYuOBx/5eAniI4iB9xsVtItNkk4StJGkA7kTBemeRKBjdCnibxJNGnikj4AVwZMCT9xGT6QQdlRBZ5ug+Su6man+jfL/e8v4H3zEgfIKuOg1IkvLSCwx0TKQMuGFZ6H4p+s5hNkgxwEeDBpZmPkvRsYH8MeLb2fBy6MZJlyKpUYQibdXPYc+dAjBvYdDyQylXL+NhFpKSG9RirnjQ2h9XVnOZjEUnaoUc/7Y7+3Olq5LS8syNqz9gI21q9hg9GZjph/r04NYmtyLTpljfJKgC0qM7cxc/T4/eytDYEup8sdm/Ah0JDpgIjDVYybSIFPklK86i07a9LGlLMhH48K8NTmMcAzGro0xZJ1Gvw0BKraYGPYu38OTQgQ6EPkpRGEYURRGhARkwFkN7mbo+VxpxVvQqrei989DegZCOqgS0mPZWsuYRHYmIe4gitPogyJo/Q30/qBlm16jlN33klQCFn8I899WrW5D9/8q+sP+U1Xba5KCI/ym3yWqSsndBtVkC8gkClggCTLuwOZtyM1bkY0tCGlhFLyHp/ANNE8z6AbkhyEQorm4L8vLh1GXTLPdF2LCIT+lbOBgLNOLZXiwhY4F6EJ0MQfmaZKAdPFKG+E4KkDqOsoqchxsKYmjEddM4rpJ3PBhawaGa5OXjpGfjpOXjhFIJ9BtD67dC2kVkK3b2fm7CrB1iaO7mLZAdzQc3aU1ImgtECR9koBrk49L0NAImgbGfyhsI6UilKrPJkeZAgo1SYcjSaFhujbFsR0UdzRiOra67oF88PiyVrRH1Q5lLWoptC4k0RzpVBrISElGKld3LrpsSJeQlSCc6iQcbcWwema0i51BUjxepZR9AdV7/eoz/9l1ktngt5UBO6MKenPbVlrdz272wdIN8OeBP195BkwPNGxSCrq4EgpLQQgs0rSxleROGY+ix9+d9+W2xR72iyzinbJQs73U0BwXYdloGQvLlKR9Do6mxqljdilmH0EEGknaSdBOiigg0TAIEMFPAT6CgMSVNo6bxnXTqpcZHKksXyElmiPQXZXrqTnZ3ApHotkSkckgctdJCJyAj1RQJ+2XpM00jrApF6PRfiBR9f/Dpu4hp6VP4MV2B858Hf1LiadNYJkwbBTMn28zkPuoFcOAUpBtzNlxDUeuXcwbL/2Sp//0B0abSXpZPsJAXp+tHDHnXTwDT1Dg/T9E3Iwqp2l+VsWYZRp8g6DkTJVw5KvpcawFTgc4nTiZDt7cavLCxiBr22FjooBOV6V/a65kv01ppq+IcdjyDOGYAw7oUuKzHXxuHGG1I7CRGAj8yCwnkOyiTrGzmGFKLN2griifj0aHeeKkAqJ7b2OYtoTR6cWMTC9lkOFSXjIJvfc0CI0GIZAZcNaBswLk9pwV6SIb1iPr1yA7dWSmAmn3A9OPXrUJrXgeevGH6NWb0PcZjhh0BvQ68N9f+mVb0LC5W/ku/lBZDl4/jD4I9jsKRkyEVQvgk9fhqw/UZBcsgAlHK8U8/gjl8vxn4rqw7BOY+xx8OAuibRAugoNPgQNPhOIKCISUEvbsAa3KcWDDMlZFMwztXaQsHVv506VugGEiupTuPycB6UnvJDUDxzDRhYbQjex+o7tp6rV0ActV2B8ZiWMJUo6OZetga7g6tIUlTgjydUFQg7wsAMX/tERdqLdVH9BUElSBpix6rAwko5CIqd7K7Kwsc5JzdQstu8Bxu3tURUYs3yTt1fG4SZVFrhsI3ey6lkI3QTMQrkSzHLSMhZbOoKXTiLSF5qrYvhTgGALXFIo7QRddPAqWx8XRwLAkZlrF+/WsktEd0DDRhQfNm6cUrz8PzD3gmLuuUsjRNtxILzpLPXSKRkAQoZwgJQj+tWdQSnCsDHYihpNM4GRS2FLgaAa2x4dwXbVQ0R0cPzh+ieVNI7U0ogdJtoGXgIzgtwJ4UyAyKQUNm0kpGFjH3rMBL1D3r1BgNXvqXdMgnSdIe21SegJbqIWThoGXIF5CBCj8f8r4x5DCdB/avjoFzvot3o1qX1qHz/8Bc8c8xk2GBnIvEA7Xt7/I7e0+lnyxH7edfhx7BxyK4zoRwFcuOHqpIn3/0cRuh5ZXoOlZ6PxQ7fPWKFhCpwPcFG12hMdbz+XBlkvZnKmhzKhntG8ZVW2NjFgcZsT6wYxaHiTS4ZLR4e/DfMTzdYZFbfps3I4vEc0mVnmBXkiCpEyTVZV+1lVaVLa2M351B4YD74/J4+kjC/j7+Dx69YVpBQmOzksx3LTxawIQ0NkGHW1QttceXVzfKK4FtU/B+tsUXZ+ip4HQPlB1LlScrmo+v4s018HK+dCxI+uGy7riUvGdX6cTykJIJbq3c73TIy5eOVAp3/2OhJEHKIW8qyRisPA9+PQN+Hw2dLQoC6OsBvIj6lrkR3beDhYoC/uDF2D7VmX9TDoeDp0OYw9Vk/v3kK4HW0pl/SRiyGQUHKdHrDWraLt6Y+dt/Z8Agv8ASbkqgyBP/IdjoN9T7Gz97rd+fSnVvWFbu7SMmvhdCbqOqwtSPoeUxyJlZrAMtTgSOWo/ZBbC+l+bX12p4+DFlV4c6cVBeSi8oh1TRHFcD7bjx3H9Xb3jevAbMXp5LQr1AKbw7dn9KyWJzo20+duwPRBwCyjQqjB+IEGM7Uo6UhYdlkunNLD54feakC6GsAk4afLSCQLpTgJWAtOxFAOn14sVMNCFBx0fwjC6PRl6dnuXX+sskAAAIABJREFUe10isUl3UeSkiWGh6CYFGl7y8RLCSwgT/49C7fqjK2MhxBHA/ah7+TEp5d3fcNxY4AvgFCnlX7/tnP8pZay5g5GP34hx5RmYMUXpefw0+N0TD9Hf244jJgEBCpxNNGjTaN1gcM04qLCgMgYFgCcMRy6B/L7f8kHpJoiuUJRbgX7fj8kEIL1VKeXYErA9rGgr53d1R/FC+0RS0kM/UcdwexOTFpgMX1HG5JWQl5Z0+AXzxvj5ZIKfgRsNps9OEEw3Ac2omG8+UMGOYJjnj7N54ZgU47+Ci2a1MnRTmraQxryTAmw9r4zhIwJMTDWSv/lrpTyatmb7bd19z7hTYW/oM1S1vsO6t3v17n4IMmmId0CsQ/FBx3ZA+2vKdC6aBhUHQa+yb1ZMtg0blsHyT2H5Z6pt37r7cYbZ7YbzZ60CX0D1OTdgzhWY6yPFsO8hyg39fcRxYMXn8NlsaNysLN1Yu+pz2zllr+sw9nClgPefqlyh3yC2q2pJ2y2VDNVuQZsFOzLQnIGDk6voPWAodjYemWsqht8NR61BjuYYTSgXbdiEsPHDMXb/J0RmXcFxqWLeBoqx0burkSch7qiEtLDxo681cHGwSatkH5kgJTrJZJMDcpO4jxA+gngI7DaJyx5xVAldcdOuJh0cXGzp0uF6SUoPtmtgSw0XrWcYVrGFuSDdnLu7O5BkaGk8moUuJDE7gJQGupYk4GklbKbwaT5MPIrLA5s4bWRIoLsGoR02PsuDKOmDMH1d593dSZ3dli62FSVhpelwDGIyQIo8QCCEo9gWhY2hpTFEElNLoIs0mnAQwkYTjkLlkh4MGcKQYTQ3gExb2Jk0tmWR0QwSZh7pHoxJOg4eI4mmRzG1BB4jiq456Hgx8GLgy/ZedLw4ZMgQ6+Kkc7OIJEJqCLcAzQ1iEsDAt5snIHfZg8YPX2T+qMpYCKEDa4FDgVpgIXCalHLlHo6bi0q3/cv/Dcq43tpEhXk8nPUivmeG4prgmpJVn93FpYO/5j3PKSCqgBjvLm/lJ4vqufb6k7EbIwxxTAqRmIbN4RfdQqRwnUrOChdBLz9EkhBoBb1OkT1YjTt/uLcMAv0VlGBgQPe2lIqeK74Jmr+G9rWQrKXW9fECx/FK8kRWJIYTc7IIJB7Vxm1O8/ijOxhRa1NfqDFnUoCPhwcwUz6O/8jlkMUd+GQ9kpas+9kPBOnM10mbDqG4ha8HB0DbGA/6OfmERqyEzV/C6oWw5ktldeZECCgqh5IqKKlWfWk1FJQoxbxlFWxeqfp4DzitnLs11rGz8v4mEUKds6hCxbCKK5QSXbMIVs1Xliyo/SP2V+7j4fshiypJevKIe/KIYRJ31KQcs1UfMmBkCAp+xDy57yRSKus81q4WBj08CGkHlkZhQTvMb4evo9CaVb5R+1vOCbzTexXlA4diZBWskW2aUArJZedeZvu02137nK+r6xExwPstnrdcElPKUZavkz1fjl8+t60m9u5t+S3bpqawk7sysbMt58rOoBRvTvn2ZArOJQ6CIrfMzxbUxm2IOd3/82pQ6nEJezI4Io1NqkuROlg94pg6GnpX5m2uqQzbTNd7bDK40iZtR0ikyrBdP5pw0YXEFAJT6OhC7P5bZK+T8w3bPfd9H9tZQ32OmYWcTGkSqQk04RDQonhEEx7RiYtGMlNM0irCdvyAi26k0UwbqWmYIoZfa8IQ6e/ljJZSI2MHSdsh0lYEJ5tLoGtp0AWO7kFoLvnCwkEniU6O3duDS56Q5AmFJCtJkswSutrS6YoIG+SjE0BIHUukycg0acfBdg0cx8R1PbhursIadM3B1NMYRhJdj6IJC4GLwEUXKTThYEgfwo1g2WFSjp+4rWN9R3z6UUGFGPZD5MfOph4HrJdSbsye6EXgOGDlLsddBrwCjP0hg/53yMPbroB+JuLLfggJjpRcOuNN1vZ5nPe8V4JU9bKTln/EIe/M5DcvvUpbXQH7oFMAGMJh8uVHEhn0KUhDUZuFEwqrGNTs0Qo0AtuBVh3CfoXsUJBSNSv5C8Gb3uP4mjNF/DV+Es849/K5MwEyGrhgaBZFkWaMYouMXsBNjya57KUo9UU6159XjC/q59Av4KQ3IEArJluBjqyF5EHixwpAsqweypNESnx4Ij5Y9BpuejPOhBIKYu/Ci5u6B1M9GEZNhiFjYeAo6N1XKeLv4kqVEloakJtXYW1ZQ2bregJ2Ai0/pNy1eWGloHtuSwk76mFHHTTVqr65VsWxvv5EWdMDRsHR5yrlO2IiVlEVf28VvNIIbzYoo/S7TGTVPqWUR4VgZFBt9wt0r3aTDtSnoD4NdSnV6tOwXc0v+DQF9+nLQvl5NUm7vopN2vsEdMlAfW+G6mPopYfI0yGgC/L0fALhfNosWFCnFO+CdljSmUv2gTIvjA6pFjGzSjKrKCM9tos8qm1YA0O/Q4h6Tz9P0oG2rLW9LQXbUCU7kazFbGePSbmQdJUS3jVfVfRsotsaz22LnbYlSIktJZYQuEIjpXBgdpNFH3/Isw/cyx9mze4yvAyh6q49QuJLp/DGOklqJu3+IDHNIJZVz7pwydOSXHTCMWzf3kTGglETDuC63/2B/EAHzz1wHy89/hqGYVBUXMjv/3I7lX3KcUllLdPdByQQDM3/CRujS8AuojNVQNo18WgupR5wMbClqte3shnqjmSnnF2B5K0XnuKxe+5AABdc/SumnXEGQnMxcBHCRQiHhZ98zB1XX8/a5Su44+nnOebEg/GKdgyhExAh8kQEU+jcfstMgvn5XH31VcyaNYuZM2eyatUqvpi/gEFj9qVV6rTLCDEZQcvmGnd0tPHr06fSsHkzZdV9ueuJlwhFChGag60HSGol5OsOX8+dzfVXXI3j2Jx16lT+69IzwZ9Hy44WZpx7FZu3NVBR3Yff/uVZPIWVSKHx5O/v5I1nHkc3DP7r9/ez3xFH4Acevel6Xnmmm0LRzS6sYkBcasQktEmYOqAvT3/xJamkw8yzL6BleyNC05h27gWc9ovLe9y8ASAAGnw29x1+d+XluI7DcWefy4yrrgNH4Dg6jhUAK4CUhfzuusv5dO4cfIEAN//3kwzbeww48Mn77/K76y5HOg6nnn4GV597Hj7XptV2mHHJhWzZuoWK6r7c+/zLeCIFtLS0cN1pJ7F60UJmzJjBAw888L2fve8j30UZV6Ce3ZzUAuN7HiCEqACmAQfzf5Eyfj70BbSNRmtSqzePL8VVl17IOP8ZwDAQBsJt5MWGh3hl2Y0s+fJ4xiHplc0rnnj73ZQeZIG7t6I4ERqERkL+SND6gV0KHTHovR3am6CtSVmIySg0RGFDFBJRxZCjt4M3SmegjNcqz+H5wmnMZTBuOovyjkCEQfYBu8TE1AuY+k4rN9zWTHmTZElNPiVNAW54zI+Og0ETgm1AQk1LwgPVSeTEL+C4LXimTEMvOIA1CQ9fdsCiTljUOoElbRZx3U8vq5MyLU1vv07vSD698zz09ioFETKyNaO10JpRllvP1mapyTpncWVcQcYtx5Ll4J8Cg9U5RodgnxDsE1b94PxdOM4HjPzmH891QdNIOzB3B/y1Ed5Ypj47X4ejSmBwXg/MW2P37eYMLO1UCnBpFN5q6lYw+TpU+ZXCbd1DbXFAh1KPUvYpN2chSlJuTu0My7bvJvk67BuGK2pgfCDDuAXvUPHnhxCffQKjx8Dkg1UbNx483TG7FDFMvOjsviiSUrmhHNntntboriXOuWuFgIChWoVPWefttrqWDWnVcuIRauFR5FFWptBAasoS9wmFabKry86NRyEWQ0tnsCybVp+flmCYRCAPpCQU7SSUaEdzXdBNHH8+ti+ApZvYUuA11Hi9AoQEV0pcKUlKSAhN1YMF/YDEIxLk6S1gWjiajzQFxMjn1pf+SmEYkA6//Ol5vP/6Kxw67QyqBh/Fsx9fSygsefG/n+Cmq//IfS/8GU2Y6BgY2RpVDQOBJIAgKAwEGi2xQSRcdR36+iVhzUEzwCGJg4VDJtvUti1tMlKgiSTtbe08/tvreevLpxFCcPSYMznulL5ECkJd1jnSpLRfNTf+5Rme//1vKDLbqfSm8NALH5Gd3N2a6P49R4wYwauvvsqFF16IJrJleShru0NCVCrS0CfvuZsjp0zh2uuu4w93383bD/6Gq277DTsyOsnsPd/hCK649L946LW59Kmu5LQDxnLIoScwsH8pt9/3MCMmT+W3V/6aJ/9wN4/+6QF+dedvWb92JXP/9hIvfr2Slvp6fn7EISxbvZaQoXPq1GO59rKfM3DgwK5x5wvlzcjdsxmU4qnUwPEY3Hvv7xi9zz7Eo1EOHDuG0w6fTP9hFUgsfDIPT0zitrZyykXnM+/BP1FZWsq4s87mkkkTGNKvHzKdwbYsYoaXNz/7grp1q3n1y7UsX7SAu39xMU+9/zkuNr+9+lIemDOX0spyZkwYx2HHHMXAgQO55bZbGX7wFO659lc8+du7+e977+LGu39LJOjj7ttvY93y5axYsfw7P+s/VL6LMt6TLb+rQXIfcK2U0hHfErARQmQZFBQSzr9VpGRzQQAWD0aLqQFfesYDPOIfTKNnXxS3bYprNz6DN3kwrz53M2OAIgQeYJ8/CqovuwG44ds+5TtLcwquWQIvbFblf2ZK0bQKHWSVIFQN08ugyoWVGxxOvaaNoz9LkjJMYrKQIVu8eJ0MsAmNBgQZJILOXnm8c3k5a6b4CLzxMr41G1n30UAWbQ+wpK9LPPsLB3QYHTI4t79BoQnb0yEa0gp04pOogoNOf0PpXsSAQg8U6i6F0Rb6bt+G32PgKQjjKSjAEw7i0QSerBvSFLAlCV91wsNblaWVG8PIoFLOg/KyvOlaN/WbKbpdmR2WxuvbYXazct+GDTiuFE7sDYcVgU8oZf3P5IgeVGlJR+FoL40qJV2bcjmoUKPcp5RUmReCXjBNSSrWQVtLC3Zpb5yAjw18xle8SqusJd+tYqh7AlXufvRBx2Aly9yPWenMp9FuxnYDBO1hlDrjqdL7MjKSYFBeGmPNOrQ3Z6O//S6iPUpjcW/k5UfQ3rqMttqZtP19Jm2bdNqGR2ir1mktiJHWlYvedUs4Q76M7oawpR9L+rHxIr/VyeiiZd11Bi6mkHjQ8Akdj6lTbgq0rCtaCqV006j66zaZRQ+Dbj9z9sW7zz3Niw/8CTuTYuS4vbno1+cx47BzePbv8/BU9uXCKZO55NrrGFXTl+knHs/o8cNYtmQl/QZVc9/Tt+AP+NBc8LkAGnmedaQS9Vx95kFsWLOFcT8Zze1/vhZN0xiWfwAzfnE68976GJ/fw6Ov30ukVAEGa+josgnLLSAeipB2PWQsm0xGIkwd4XUZc+AUcAXxuGTQ6CN47dnZRK2Knc18oG7zJm4883Rsy2bClMNxgZS0WL3gVR668x5KyopYuWQtT825jzOP+AWjx49g+eI11Ayq4TdPPoTmLycl85BomNj8/e1nOfCQw+hfsC+60Dns0CNY+k4dp582GYGmcKVdiPSBIQLeMUzCopCwVQqpFFht2XKlbDJZawvE4/D1Mobm8hFiMVizSq1wpVrQFGQbhs7cv87iw6efwr9hHWdPOYjJp53OPVdcTqlu4EpJyoWPvvyKmpoaKvv1xZIaB51wCs/N+4yzRx3Ie+++wxNvvotPtzj27DO54LCDueSe3/LW7Nc4+pRTGej3Mn5ADUMGDGDllwuYMGEC++2337c+j0KoVFINKNKgqKIMynuDbRH2GAwbOJC21eso6FUCiQR0NoDj8vny5Qyo6Uv//X8C4TCnnnUWr3/2OcMOnAxkKbsdh8/vvoNLTv0p+6S2M3hIH+5q20HZ1q/Z0tjI0P79OHBAHxJC55hTT+P1Dz7gnH3H8fc5c3jlzdn0r93MtePGcMh551Fz8YVQWEjN/hOp3bD+W7/TjyXfRRnXAlU9XleiWF57yr7Ai1lFXAQcJYSwpZSv9TxISvkI8AiomPEPHfR3EWvTApyaACzcB81SiEmjDtrCWX2OAapBQtjayG3ew3lw1gyGuYJi1I0y9DoYdNmPMw4p4aUtcPF86IyBsABXoTeJKphYDUMMaEzC64sld/wuzlXz2jAclwRB4gUa4ZYdmE47gg7AQqKxtqaIC27qx/IKP/GMQ6rdgAMuhgMgIG1GN6/n3A/+wpg1XzCmZQNDxgxDn3YCjJmyk+XVc5ydtrKSOmwoyCrgiJPGmPcevDgL3noDOjrA64V0D3MqPx+GDYdhI2D4CNUXFUGeooVbY/tYZPn5ygrwVcLPUx1+YvKflwr0MiWnBDo5sXMNB6/5go6/1/GBP8zPq/rz8fBRlCXjTPKbTBo2mAkBD+Fv0UsdNLBZ+5IVwbUsDCT4ulc+jXY1i9wKMnYxSbeAmAjjWjpYArQIFEeUKR0D+Em2KXm9x7lrtOEc5xnOWXkXMdBYxwrxGkv4G5u4la1IutLNhmbb1bkdjcArKlFJFhB3KyDWDyvam/Z0Ca3xCqJU0uKMIOr25QR3FZ1uBQKL6pmXE1ixBCFyEVwAobRqTy2T3Xaz23Kn/6l35tJjEsNH0TzzPnxI8oWDLpJAJ65oQyJwpI81K7fx3qzneeKj9xFmkLsuu4yPPqzljKtuYOblVzFy3HCGDivn+GOHsHnzBtatXc89f7mBx/Z/hEvOuYKXH5rLpVeeQ9qJYok0juHiaC5LF6zggyUvUV1VxvSpl/PBy59w3CnHkIgnmTRhInfeeSszr7mL2Y9+wg033ICOqRJuBOSqTg4//HBFoXjkkVx96sno0oVMgkQ6QwM+Xn/iMSZOOVKtOHaR3/3iF5w043yOOu0cZj36JwBcv0lcFLNkwSrmLpzH0L4l1G2tZ8OaLdz10KPc9MhBXH/hBTz20Gucd/kvKUon8Dk2UX8em+uayavsz2onTEhAUUVfamu3g9Sod6FeqnSQwRoEHQuRSkF9HSxbuvPABGCayieuaxAMqmzh3P5IIZSU7v6FHIftLS2U9e4NlkVZwE9TczPUq6lbAwJCEF+7gsGFYUY1rqctGKayqozFixaBH1qatxPuV4WRTDLUa9DR2MiwNSuQXy9ln1GjKF63GnSdynCYuiVLoLq6q2QOgJYdaty5EjCnR2/bsG4tNNSDZSnjqb6exYsWMf6aq6GuTn2/gkKIRKjbsJGqQYOhl1qIVVZWMn/+/J2/s65Tt307VUOHopeVEQKq+valPmNR1xmlT58+FBgqBDmqupIvvpjPKB3amrazz+CBICXh4mKa2tohFoW2NvVd7H+SzPEjyXdRxguBgUKIGqAOOBU4vecBUsqu4lghxJPA7F0V8X9aXl5yKfTzwAcTEA44uuS/D0visjfgAdHOs3I0tW0jWPGsCoz7gb4/g73v/IEfun27stYKCsAw2BSF4z6Ar5tQsTIBhMDTCwryFDj8p9tgvgP3P5zilVfb8LpxMoYkGnAJJtoJNEuUYyepYsL7liNeqWFQtcmHtbVw8Xkw912cgw8l8cBjxCuqKfYY6GIInFwN7/WGv70Cr7wETz4G4TBM2B8qKqG8QrWKCkR5BeHyCkKRAux0GvP9d+HVvyoF3NkJkQhMnQYn/hQOmqJW7ytXwIrlsHK56me/Dk8+vtMlMYDh2faz7D5XCFrzC7EME0tXLWN4SAfzWXmkj/mnSdqrU1RlViO/mshLnYdw3ahDWXr6aAAiiRg/qd9Co25wd5+hOGkDkXLZ27WYFPAy1owRMF6mVixgmR1gjV1CnT2cHfa+JKRigtGkTe/oOoL2dsKexWj5zRj+HfjEDnxaM35aCMo4thGlbFuQnzytM+i1VnRXIqREVFXjDhvB58NG8vrAEfx5wDDuMz0URks4etEIjvu4gemrO4lpq3BwaRo7idpDjmfb3vtRa0aoc/3UOXk0ugGa3QDpnnWMWcCSYLqdyvY2Dt+2lb23zqN48BBGbF2Hmckg2joV7iQghcTVFWWl2+M0OZAD4Sj3rzoWpCZwdYGrCaTQkEIgcPGLHRRri5AiV5YDujTxEcSbMjFb47z9/BzWzf+K8/adAIZJIp1mQGkJ1988kxNffZlXH3mGt5c8R4I20qQor+rN5P0Px0M+Pz1jGg/98WHOuOpY0MBDgKAbple8mHEjR7F/r4ngLWTG9AtY9sUyzjt1EB6Ph1OPORuBYL8xk5g7dy4GuwOQALz77rukUimmT5/OvHnzOPTQQyEUIhCCz599li1fL+LR+z/C8HRnoucgQb9e8BmPv/gqBR6HX51+Ig/OvI5B7c1sSCQYvu9YvIPGsxFo0CSlVVX0n3QwvliUsw4/lCcffZQRUyYjNA2kpFRKyhvq6DRMeiXjdPj8tElIIljmKI9DIS7VnW0YLS0Q7YR4TCmpsnK1uDVNBS5jZNPDi4vV/r413V/Y64XSUvUs70k0DQYO6n6t6zB6H/U5mqq1lRs2wqrVaAMH0Quo8Bhs1gU1hlrjjDZ1hJkHPhMhBIGSYvD61IJeCKVIbRuRiMP2BvU5haAA2TerhY+dncIsTQGnu7pa/WvZxYVpEMukOPHcc7jv97cTGj8we/PqoBWB5kXuweO6Jy/snhKShRB73K9pYufMeyEgL0+Na6+R6nfp7Pz3oaTtIv9UGUspbSHEz4F3Ub/PX6SUK4QQF2X///C/eYw/SB4Zth4YhLakj8KXLergk/ABqOiKxT4tjRzjGcfMKxU/Ux4QHAnjHvuepRFSwgfvw/2/Y/H67XwxaD8+7T+BtwYeSzsRNfvpQESih1wcUyMjBdujEqTgktfT3PF0O5F0FDfLdmTa4LG9SHxIT5sqcj+gAPHUIOjrV5/57NPwX79QD8P9D6KffxFBTWOn/J5AAI4/QbVUCua9rxTzsiWwaCE0NwNKOS4cNZZXjzyBV445iW1llUzf2sKVGzYyYtpJSgFPPnhni9rrhQkTVespTU1KMUd3ISvu8TBoQJFlKTdUIo6T6GRZv4XMm/gRtUUWDU1ns7HpdF4oHIU11otGhkrjM04wn+AoM5/jC8fTq2o4uC7bP32Td9d/wLziCF/sNYlH9Ak8mA4C52QbgEuhvoq+nvco07+kzPiSEmMpZlGSwngJI5JHs1fe2UR8Q2lmPU2so4l1dFDPPpzEsJrDETcLuHQHLF4EXy1S/Rt/ZcRLT3O+P0CsoBfvTZzM6/tPYfa++/PM5CPxWhn6RDvYWtCLVA7EJMv3WiqgRoexRhShfUxCm4tHW0elpnGgdgiHaidQIAqVdT6wBjiAVatW4e2nYnE8+GzX9RRSokkJto3r2qRllJQWI6UnyOjp3QNNEjSpoUkNITVAYumWOs6V6LlMJAMQFilaSflBL4F4scbJ55zIrb+5eadSko7EdrbWbsTFJhVLURHsTycSIQTtKGrFODsQQrB+fhNXXvgrBIJbb72VUKgQ4fNBcTf/aG6iNU2za1vXdWzbxnG+mZLP5/MxdepUXn/9daWMgffff5877riDjz76iHBAKfLrr7+et95SFIVLlixBA2ryBIah02nlA4JQcTGloXxKg/kM0yQdtoMlHTzAKGmjBfPYVlSEEQqxwLK58KKLALj1uuuoGjCADz/6B33WrlJkFCuXs/eUKQQyaQo72+nVUKuCvB4PlPaGcAQqqyBL97fr+L6LnH322SxevJjy8nLmzJlDaWkpDQ2KQrGhoYGSkpIuJZyTXSkH6+pq6VtRTi8NSktLaWzMvr+1lZLSUiguoXLIELalMzBoMAC18TjlE/eHUcPA2gwyAQgwImBmcHwJxkxU9tvUow/g1psuyQaNHSjqxMokOfGEK5h+2hROOGEU0MC2Lds59qQrALjo/DMYOWrCN1Ij9pRvolDMZDLf+P49XichIBRW7T+EGvedsKmllHOAObvs26MSllLO+NeH9S9KrI2F/UIQC6K1KAWSnlT/f9g77/CqqqyN//Y5t9/0AoQQEgKhJDQpAgoqKAgWVFRULDiOvTGf3XEs4+igI+Po2P1GERsqiqKIWEFRkSYgHQRCSQGSm55bz1nfH+ckJBAQEJ35HN7n2c+59+aUvc/NPe9ea6/1LqAjVoXsEmb0u57lu16jqm4WuQAIx09XBy4XHQ7DG6/DPx+lonA7E657nlcuPReqscIrRYELXOkR4tz1BBKSSKss46KPXmHUwo84dnUqevABnBEHQgiIouFASAXdj+SVwvoSVLITHs+HsensEMUPOyuIPf0E6rtvURdchvqfm9EyMi3rx7CILkVBWw1SmwR94PHAKadZDcsi+DoY4Z2qEO8qN9udbhymwYlbNjB01RJeP3c8k8+/jJOdcLMHTnKCSZQVTON7XsGJj0TakUQWiWQ1vo5v1Ra91bADuoUGMZbxGp/LP/k+1o4fQy+xqmIUIaeDLulwgwuGOQ2ynQvYomayhvfZwAYeAVpTQFCrpmzINqJDrMCiE4ChER1tY0+iRcNpVZrCUV/OJL9wKb44F+aggciAAZh970ScXiooZKV/Ol/7X+ErJpNEe7pzDj04h6O5EG3P9di0NBh+stX2QBwwxm4xga9jMCPiYps/ndM1aK9HSNK24dNWoukLqVTfU8oKqilCQyefMxnINXRk2MGLDSj7i3a50HDhxYeX1o33OErQFsi381pVDFMZjdHEgomXNLwk4Nb8FvlFo5g1QWKxWmJmEMOriHo1jjt5MJeccS2X3jyGtFYpVASqqKup57lJr3LWhaPolN2Nu654lA9nfkg8IYq2lrB1fi1HDerBZ1Of4aTBozhxwCksX7a7Ks/cuXNZuHAhmzdvJjs7mzfffJMrr7xyn8PV9yjJV1tbS01NDRkZGcRiMWbNmsWQIdaSwtKlS7nqqquYPXu29ZC18eCDD/Lggw82vj/22GN54403uOiii3jttdf2uqZPU/hcDsJuJ9u2bWPB998zaNAgpr71FoOHDGHAwIHN+hQIBPjjpL9TkdUeamv54ttveeSTGZE1AAAgAElEQVSG60lZs8KyetPSLRes3299dw0W8D76dyBoWqEIrInKlClTuOOOO5gyZQpnnHHGXsf0799/n6UJ93X86NGjGTduHDfddBPFxcVs2LCBo/u0g8gaKwjGmQso8HQCQHcJy5atBDMEYjelQOmISuD31/yFbt16ctMt94FygnKR1Uln2bLhYOwCo4xYNMiG9avYvGEhme27H3QJxfT09IMe56+N32ShCHnvUYIX+mF1F7R6Kx8vcloUxAOqlstVOm1f/oC/j84lD8GFoqP7SeJumg3d8qFLN+hqt6Q9VKHKy+F/n4Vnn4TSUj4682ouu2cSpRU+K71JAR5FUhaQCJWGizZeF/e2gZNTW5PKOBLfGoOjSgPCCDVYa3lJQCq0WwiBIGqtn109CplxfpC5nnq+XZPP5taZoCfDDfdYiWQNqGn5PriADM0i5qZtkwHvRWCXuPC4XIx0wkQ3nObUSUrvCsDDJjwbgidCMKIGOuq7OMozkRz3k6SrLBx4+JFPCe9xcYVGPG1IoC1+WhFHK+JobW+t135aUcQS3jZe5uvwUNaE51BhtiVRCZe6FZe64ejGZ5MODKE7QziVSWxlEV8wiTV8TjUVCOAnhX6Mpj8X0JljcKz8EP71HATrYcQouPoflnuuhYCvo7mCeipYzQxW8jbzeYKveZQEMslnNF6SMYjalV6iTaq+RO20GLHFAiwtXoWGUgrl1BjiVNQTYAcrKWEDxTRo8LpoRTc6MpQMetObC0hg71n+4YCOA52DzIdSWMTucuEisZke0+D8Dkx8oI5LR9yGYcZwOB389dF7WLloI89/8ypO3cmH73zG5MmTGTp0KN26deO1KW9w3VU37rPcIMCgQYO44447WLFiBccddxxnnXXWAXe3rq6O0aNHEw6HMQyDYcOGcbVtpd56663U1tZy7rl7l1Bsiscff5xx48bx+OOPc/bZZ+/3egdVQvEYy3N0z/33k3LsYIhGuecvf6Ff//6MHj2aRYsWcdZZZ1FRUcEHH3zAvfe2XEKxKZqWUDz11FPp3asnH3/0lmWRmnWWxK5yc8fNlzB23HW88MK/aN8+m2nTpgFQXFzM5ZdfzqxZs/ZbmvCOO6wSii+8sLuEIkBBQQFjx44lPz8fh0PnqcduQ5cdoKdw2x+f4vWpb7ZQQtEFuguw9RNwgKsT3yxcyyuvvWOVUOx7PNC0hKILHJmgZ+BwVPDkY3dz8innWv289HwKuuWAmDz73PPA/ksotjTObgVdMYhw+x23c97Y8/YaJ0BOTg7V1dVEIhHee+89PvnkE/LzDzyL4mDwm5TDXHxfa/rflwH/uA3PzeMwFERXL4POUfxqK5WcxdevanxxMXQBlNPgvMsmoC+ZB+vXNQ9Oat16NznHYlZ1iWCQ6lPO4qYrn+CFukxUGYiBVag9FSQFcIDuA0kG0wfJFSZvX1LJ0O+qgRimFkI3DQQf0JptHcvRjA20K3RR2F5x+T+68vnxlnWTESjjmB9XM6hwA33LS/GcNw7J6bBbWIHdQgwmUG5iBYk0NIFiUygyhWrR8KsoI51hxrp8nOrS8O/DEKummLnyNC+EK/g2dDVlRg/SVYgbPS4GOzVyNEjTqqhV26hiO1Vso5JtVLGNWnbYbSe17CQsigojj4DRmYDRhc3REWyLnYBCGO6ES92KM11Wib49EaKG5bzPEt5kNR8TI0IqORzF2RzFGDowcG8r9hARooo1fMAK3mY9H2MSRWss0dZ8a6XDNCh8m03a7vceEmhNd1rTnTb0oA3dSSXvkOqjtiQg8J+MwsJCTjvtNFau/OXTQn4t/NvHJBFLLreReOtBmuTmKS8oz24LtDG4TwfNB8oHmhcr2C9mNaL2Nrb7M6Ws8zQ2+7zKLmIhBsSKwdhhfebItqrS/dIw68HYCUaA3YmKjkaLunFLw3u3vbWeD5YkZi0hyghTYZ/D0lHTcaHjtl+7G18fqi41/LeXUDRNnjipDnCiZh9j5S26TMgzQFXzBD0wQxrTJsBRWHbXoNd09HPthG7DgMJCK2Vgrd3WrYE3X4dgEC64iM+v+BOXVnZgezFQa6WEkASkg8RBhyTonQ5ZnihxsQAnPRBmyGMK3Yhi6iF0I4pmOhHSCaRVAz/QfmOMrZnx3HZfBl9d4eDoOCe/d8MxDmifkobKOw447ieHLwhVbGMHq9nBKnawip2sZierCVNDRHzoRNFVlBX42EFXWpFPawpoRT6tyCdGiHk8yjJexVQGYz1j+Ke7nrVR+HvIw912FSIAnUSytERytO7k6JCjWa0e2GDAOgPWG8IWk0YlHoAOWi33e2Nc4tbI1vcm0jB1rGAmS3iLlcwiSohk2nEC19OX88ih/2HRjt0THhI5ios4iosO+7mPYD+QKBZx2FnSh3OdzgyBUQ5mlX1eh+VOxYFVca3J+6bR5o1daNIXaSEp/WDQOE4H+y2GImLtKzbhNhDwnsSrJdgE67cJswlxiAkSbHJsve323SOHUTlpvBfKa2mYY1pkbgRoLmdi530TtSYGejo42jW/7i8JzQdajnVNs8rqQ2NruF97Rz+bykVI1wjrUQxloETDhR+rFKxh1zsOEqVmd7SjjWTpga5aDho8nPjtWcbz3yW9+zWUxWejZ32Na7uTUEENsnI9GVJEsRrN9Idgw53QHtDawnlFP3lWEKE2FOP2jU6eXsdua9gNtAaShfEpa5iY8CIZshgiG4h+3gPzjsdwB7yYKoySINYP2w+uGjACKEODwdvhdxuIjKzAlI146mdjRSMeBfEXQvz5lrsGSye3mmIq2UIlW6lgC5VsabZtED8HiKN1I9k2EK6Gzk5Ws8Mm6Z2spsoOsmmAEy/9uIzB/A/xtOVHvmYNn7CaT1hrVBA0e6KMAUTMXtQZHQmYGewwEigVR5NrC7l6iLZ6Gan6ZuL1lTj1+cT0zzFVSbPrNcgRKnR0HEQJYRAlgTb05Vz6ch65DDpsFvD/R/x/s4x/EmYYzArrgS/1e/xRtx/wTbdu0OKspn6imIHEwKgAsxzMWuszLZ5GixBj9/agoFlEoKcf3IShqSXZ9FyNk4ImW4na5NmEVJS3iWVrbw+FAEVsi1nZE5GfKOYgAkSbr/dKEBDQM0E/BEm4A+0nHNqkTEyQKEKEqFQSUlVEVMiKKTPBZYBhB3a3ePger5OlB9ohkvF/t2X89kTKByRA2I2qdFhu3FFVgPD7wEtUFz3L3Lvfpy8OQBg558C+7GU1irMWOSksYrc1nCrQRtE+YRfvek6hj2MxhNOIbRpB5PYncX+fhIMY4guh1YcsmXgVQUkAcemo8e3g2kzIPwGgcW3OiG2nsu45ysNvURa9hfKaWyjzpFDuchLQyjFV85mfnzSSaE86XcnjZNLp0kjAflJbHE8OxzZ7H6KKnaxlB6sIU0sberOZRbzGtWzgK6KEcOCiI4O5QB9DnV5OifMrSniWqqZp55KAxxyCUpWE1HeI2v2wS6IdrelCa8aQRFsaCn83tKYC+g5c5DOSPIb8LDfRfz3MMEit7arzYD3wf53o0H32Z08CVn57sqljWWQGFkkau19LFMway0UJ1ni0OFDx9tZjn78GzDKLiBHrc0c70FNaJnAxm1wn1iTqf89Hsr01dkJsqzUGRzZonp8cshhVGEYhhopiOL24SMQh+t6TAgnb/dCtPPdG4vUeGvHuCTNmKQmaYdDc4GihtOKeUIq913v3AzGQWBBDquznnd6siYKIqiJMJYiJAy+66cRh6ugGOGIGygiDEQYEHHHgjAdHPDh8+/QmWJZtCIMgMRXEUEFi1CPEUDjw0Bo3KURVgLBjJwqF10zEZfpAKVs8RzWmUAmWrquljfjriNv/5si4OLgU0brCmq5oIYWpgOG1QIQrzGze/Otx5MV03ICn/yISk9+C4GjwHGPPFPfGtxUwfB7Ul2A9IzwC7RQqyeSPcX/lL65JqMRLMeumErw3F/3lCnzUYvpNCAZR9WGs+sHVSEcf/CEPdXFrSzMSqKGUDXzKBj5lOwsJODZhJO52RznFgT9WjRmL4VKKNlp/8hzn0I2TSaMTLg6sQlSUENv5gXIKG4t2t7QtYxPVWDP4thRwHNeQzwg6mX1xRwohugX8J9uWBgSpooQ1lLKGErWaUn0tTtrShjtpTVfa0JXWdLaLgR8GmGGoe9eapWsp1oO2Ybuvh+5/GowyqHkTIqsg+XZwZh/e85thMEos92wzYrEtTOWxHsjKY73HZbspD9DzIGYT92BDMmlToZE9t5alKlKPqcDQPJhaMqbmwlAGQi0uUnCTvu/lh0a3a63dakACTcal2W5cHfQ0qynf/glH2SKiytlYXWm/yx9aonVPY9sgstoOMGrVeA0ruK/ealKHQTWGZjQKkyBBwgTxGsm4HTmow+neFbHI3IzsJl0jZLfw3u5bpVtE50wAZyLoB2n9iQGxIBj1EKtDYvVEHEHCHjD24K+m8S2Nl1cQlVqiDRquTmsHTRQO04lu6raLvdpOCVSguezmBk23i4EEMZspuSgceO3gw0RcJBEhQB0/IiqKizS8ZKIpJ/9JjrbfFhlvX8e/RtiL9++djBYDQwf6B1FSh2vT+Wx+82gKUEQRzn7tQaiaDZV/tx7mnkHgaAN6a+sH5mjNF9VdGLWoF5ES+wfaCmiraJ9cyOfea+mUNBoSioh8GkfozCD+UDEaBka8oNVUAwbR+BqcNQYrbvqBlQ+vI82RixChis1s5zt2sAIAH6nkMIR8ziSONlRSThGr2KC+YpezHCWK9JiL5foilrEIJ/fSkWPpwjC6MIxs+jUGBsWIUMxKtrC4sRWxYi9hfKtOShJekvCRhI9kuskIuhg96RZOJTlcBOHlEJ4A0Q00/pycudDmdfAMwEsiuQwkl/1L4f1sSASqX4LAg5Z1si8ov0XKjnbgygdXt91bR/sDJ5zDDTMEdR9AzStQ9xHWE0aH2mnQZhr4TjgM1wiDUWqRPVjuVD3Ndn2GbOsrZK2txSwis2b/NpQDK/jFbg2vMXYTr4St1zYMZWUsaGIttzXV+DKx6oeHdSyhERr+GLKbZXkoFBE2E6YMP9k4aMHiVJr13Wp+oLVNPrblb9Za5OBItq3KfX/HVkS8ZUUZEsIUmzyVgRKFLh50FYemeRoD8rAD8izvrobS01BGFcg2xNiBqXuJqVAzUtAEdAFPDPQI6OJFOfzUOwIEXRVEoxX4oinorjaW1fdTEBOxyVWZUatGuEQs8jWj1nbPZUfNCboHXMkW2eoei8yMEESrrRaptPbV3TYxJ1hkJzHLmpaYTfIx20PRQPhW4IgoCHs0wgmCqYFuuvCZ6WjitGoHq2oMLQwCLtONK+ZCNy1VRFMHQ5kYWhSDqC04I0S0JiXmpOmLsNVUjeX4MEEXHad4cYgXp0pA1xJQdqBZjDpqWIdBHQ78eOmEY3/Gi4j1G4rVW+MzQhCX+6t4k35bZDztr7x2gRdwoM8+xtIwSIhBskn7+k1MubiADlgi6m3OmY/TdxWkPgXRBVA3AyIrIPy97QozmFl7Kmduno6x0/4iOihoK1yX+hGPJftxeD/EUDE2vLmYrHFdSDBriLiiaBEnek0VMT1GKGk7rno3L732GD+M+44wdRhNCFFDI5G2tKUHHRiEYLKc2WxhEYIQTzrdGUV3TqGbGkGcMqnfdiwbnNtZl34G6xyrmcFdALiJoyPHUEcFRSwnhvUP7SOZbPoxwphAdjm0MnPwtT4Dn0ppXn819D1UPQm108F8Zfd9dXYEVy+IHwfunpblufM62HYspN4HyXceHjeaEYadX0HxbKhaBdnnQc44KyWp+mUIPACxQvAMgFbPgauL5e40AmDusTXKIbYF6mZCdRNVMOUDV1eLnJ15u8lKT9291VJ3ux8lagkZRDe20DZZLlJnV5vwm2xjXqi0JlkkaFA71SJdswr0tpD0B0i42LJMi8+AopMg/TFIvO7QfvhmxLaEG0g4DfQMYppBzK7jKsQwMZEGtWoBIYoguMWPz/RbEpISbULeDQFH2ATtBi0eUU4imkFE1RGjvlmMk7W7blOYAQo0ceBQfnR86LjsKFUXOi47iEYIsYt6iqhkFT4y8NKGPWvMNkNDxC8ea7z7QZRqQpRgEETs319TS223iqhg0CRCkd07qMaIXNOadTQ+PSN22+Mr0azpVlgHXAqlIkAMJbolgeowCTsCKAmgTFvXU2lWEQtxoZs6uiHoMQMtFiKih4i4wXDbAlUmaKaGJg50caHhR1Nea31T91jk2uR3KZhEqCTEdivbw+1Gk1bopkKPRdEiQbRwOYR27eN+a9ZkTXOA7sJ0JxB2Rgjr1YgycBCHlzY4tDjCBKijBJMwGk58ZOJRaWi6k32tOondQ2uiFEaIWJMhZS0lNGYr2BMDIYapTEQziBEkRpAQAZRpK8+JRsxpokyFL5qAy4hDaXWgwrvHIUYT4rWbNAlw0z3WZET98q7q31YA18WJOF5KxdDT0Vt/g2ung9DwCuSTjVz/0kdk/O5uOgBBLcbvXvaiGlxryT0hfQgk5oPuBc3FGzWZjFs/BCmzJO7oCAl5YaalFnNsnI+l2jt8x8u0erI/591wD26CCG6gCkWIinZFxO90Ut22jFffvY8dvQtRKFLoSDaDSaIjGh52sZkdrKWUtQTYAkAOR9OdUyhgFO3pu3fQUnQ7bB8CZjW0+5Iad2vWM5d1zGEjXxNHGu3pRzb9yA53Im37ctS2d6HkE2vWB5BYAN3vhqzRlsu36kkIzbcsj/ixFuG5eoG7u0U4e8Kogl3XQs3r4BkMbV49NFdrzSYo/ghKZkPpF5bLS3ODry3UboaMBGjnABUAdz9IvR98Iw+OsIxyS5AgssZyLTZsY9v2fYzyW5Gqxg6aFRNUXmty4uxoeQeMKgguhdgGbBFr+5pYhp8DK8hPnOAZCWk3gndo88mLUQ07Loa69yHhd5D+9O7JQDhAw9rZmvWb9g7gMiO2JWw9QEVPI+ZIJKJqiVCJQdN60spOx3LaW4ctNGMSphwAD2l4pQ26aE2soQigIUojpkJEtCqiqgZRJpq4cEkyDvFiECKqaoiooPUAbVD6wrJ2UKCbTlxmIi6VhqZZghdz585l0qRJzJw5E4MIdWwjQgU6HuLIxilx1gNS7TvKeuTIkZSUlBCLxRgyZAhPPfUUuq7z90cf4X//9Ty6A9LSU3jyf++jXXYrDE0aJxC66cRJIk4tCV0sqzEpKYvSwDfEHDFskTIchhOlHMS0kDUeAUcUHDGrVoPSm7hjlZ9XXvuUhx98DIDb/nQj48afDY2WNggGX305lz/+zyOs/uFHJr/yIGeOOQlTA0OTZtKmf7v3efzxXq6/eTwz35rLQ/c/w7o1G/li4av06te56a1A4cCBn+pAjEvOu44thVvJymnLv976KwnJHnsi5LAJL8bns7/lrgl/xzBMLv79Wdx0+5U4xEVtucFF465ly5atZOdk8/pbk0lKjkcweGjiI0x5YSq6rvHIP+/jtJPPBXTuvOtWXn/5bSorqimqXYKX1rhI2mtSlZOTw+LFiwkGg1xyySWUlpaiaRpXXnklEyZMoCXMnj2bCRMmYBgGl19+OXfcccduApcIptRhmPXc8od7+Xj2l3h9bp5/7i8M7JaPZsaY/dnXTPjj3zFMk8svOoM7JlwKQKCiivMuv4vCbaXkZGfx1muTSU5vS3llHeecO5ZFiw69hOLBBHD9dsg4WEflHxJIfrYrGIk4E75BDypCT26G63ZwV2onOgXScAOdnoL+V9ZB2QLYOQ92zYNd8y0iAJ51Xsk15rNQpSypqjzFyDbvcq7/9xS2qaDcZz1rT77zz5z+0OXoRLA0oMqAGHQuRq33wcBKeHQLpDotkte94G0D8XngbbvXgyVCPTEi+DiAfL3IRouQEWg3D1ydmtyLUtj2Hmx7B3bMsR6qvvbQfgxkjYH67bDmHvD+CK11cBiWlZh4HSSMP7h8wepXLVJGg1bPWpHf+0O01rJ+Sz6xSLhmvfV5XEdoO8pq6X0h+DHsuhOk2KoyX+KG9Cugy/9AfO6B929/kIhtRZdZhG2UWdG3De/NSqKONGrdCdQ63dRpIWqjG6iNraZWbaXOUYEWi+KvB189+MMafi0FnyMFv+7DB3hjGlq5gs3LrTz1pJ6Qe4ll8XszmvTFhLK7ofKvIO2JlRdQGVpKpbsUzbRKYlckf0S33NZoaChdIbqBqRuYQEz3ENUdRFUQsSOENVw4cKE1cYCJnZEudqCUSAwraMqyOwz7memMgTtiWV/KhJgTIm7LrahMcEbAFbEskJgDIi4Iu7AiVqPgCVvHKywLxNSUZdm5xFpPFHBGwRV18s2XK/j7E5OZ+fZk2zVqENHD1HrCmLrgDoG/3oq4x5UIziTblbp7XNXV1SQkJCAinHPOOYw5dzRnnHccn835hD4DCvD5PEx+9m2+mbuEF19/GBd+nCoVp5aI1kKATlxcHLW1tYgZwYjtIioBQtSjOXScUQ2n4cYhPpTutV2/HqAGzEpwtCVQGaZfv34sXrwYpRR9+/ZlyZIlJCcnN7vO5sJN7KreyKOTHuOU04cy7rQz0QxFxC2E9XoMLQIo/nbfi8TFxXHdLZewZs0aNA1uvuohHpx0FwP6HYOOBzAxCWMQIkYtd9/2N5JSErjxjkt5/KGXqK6oZ+LDD+KhFZYaeYSIUUdB57689+lkMtolM7T/eTw/9QE653fgz7f9k6SUBP5gH19VUcN9D9/A2tWbuOKCPzFv4UzKig1OPukUFq+fiakHWfzdSjpmd+OovBOpra3d6742oIGMo9EoJSUl9OnTh5qaGvr27ct77723l7CGYRh07tyZTz/9lHbt2tG/f3+mTp26136zZs3iiSeeYNasWSxYsIAJEyawYMGC3cd/PIt2bdvQf+Bgpr7yPPnd8rntrvtJSUnjjjvv5KGHHqKiooKHH36Yuro6li5dysqVK1m5cuUvTsa/HTf1R88ws4/bcics7o0WVpgaMKSe+I0m6YE0PEClH/pdg2X5tBlmNbDWXMJl3P+jh3tXJVuFQQ3Quphc0u8P+BOeYiHWbDoh4uf3508h792jUSoK4kKxE9EjqIw1sD4LTpsK5/7LqpO2qYX+OvwWKcfnQXxnSOiMKz4PV2I+HEj8kasjZH4G24+zXJwZn0Lxd7DxX9YEA7HOm3+bRcAplpYvwa/AmAGdCgEFtV4ossPDu6dB4kEGWSVcBN5joPRCKL3AWgtt9WRjcBdmFMoWQulnViv7znrg6h5odQJ0vg7aDABHidW34L2wZSlgWJZ56tMQ6QDBf8CG52D909Z4ut0MCd3s9bI91s0amjvNIvl9WdHKZcUIONoAFlFVsIoS5lAqC9gh8whpFc0P0cFfB3FBBxlGOqY7ibpEk51ptdRruzBVGdakzIKGk7iO2cT3O4746ijxpVuI33ELCZtvJd4/DEfrU6kLLSFgzCfgKKQiHQKpW6nO29pYrKEBPdZARVJDdDHNXcON66+7Y1IUUdstbQUpKbHCQ5UYKDOGEtNKqVQ6oukoJSgxMZRJ1AlR5+71XwXopheX4eaN12bw9JMvEYlE6DOggD/88XecfdJ1fPH1NNom53LisDO5+09/onOXrowcNYoBAwawdOlSOnfuzMsvvYBfxYgQIOKooc4Vpc5TR2VNBWecP54NG7Yy5Jh+PPPon0kWD/FtenLFjefz6Ydf4/V4efOtR2jVKgUVxlr71N2gedATHNRSQTBaRW1kF/WqiJAqZ/DQvjgMcEQ9DOl7HO+++iUpep+9/hU2b97MuHHjiMVijBw5svHzL7/6lj//+c9kZGSwbNkyZs18n5GnnNZ8TC+/jM9nu8uxanZ+/PH7DB8+nJSUFACGDx/O7NmzueCCC5pdt0NOLh3IxaW9BEpR462077ag48dPBi5S8JCOhziSKWBgty5EqUFjEgYh6uxy8zoenCTiII4YYWbN+JL35j6PAy8XjT+b0064lPsevpYwu3M5Fy78gZxOGWTlxqOhcc75p/LpjIX0zh/A7Blf88HcyQiKseNP48wTruYvD9/NZzNWcMH5F+Fy+0npUEZ2pzYsWriUIYNOYsTA3s0mfz+FjIwMMjKsSWl8fDzdunWjqKhoL5JduHAhnTp1IjfXmoiff/75zJgxY6/9ZsyYwSWXXIJSioEDB1JZWUlJSQmFhYXW8Z0sPe3zLxjHjFlzye81iBnvz2Tu3LkAjB8/nhNOOIGHH34Yv9/P4MGD+fHH/5wSiv8/8PEz/O9NHsCJmjoGZYLhFCgI0edeH6lY6zdDp7f8bA5rES5aG+btNRlQK2Ao3Pm7GDckF5dei5cUejGGY40raHtiV1xfV1gFeKOg2IXEK5Q3DIFseLMrnPssmP+0IxntQACjHuqLoGYDVK+3rMKKpbBtup3SgLWW0foEi3CyzmxuPe0Jdz4kPgeBcbChK6w2wZsHPe+DrLMtt7tSEN0GFX+F6snWWqeWBEk3QuK14OwAKe/Aivvh24usbZcbLAte91mBJbp392uHD9HcKDGbEJ8Bcc+CegpqXoDaz8DoA9WboHojxMKWp9ffEbqfCcn9Ib4VRBZA8DnYZbullMdyj6f8EbwnWK0hEGfQZOj1IKx7AjY8A1vf3udtiTjhxw5Q5wdP1IvXkYfX2xOPfwDexKF4PF1s96xQySpKZA6lsZmUavMJ6Za8Z1wdtNsBidUQF4kjTs8nztsfb/xxaClHQ3r2Xv9I1rpnGfVsp44i6tlOLVuoYRPV2kZ2JW0kklRpVSZBgM/RY59jNPkVuk0fDnQ81DStDohu6Ghi5Ulaa4sO4sb8ngZWVqKhiSAnnwjnjUEFQ3DtTaiGCOmGQJwzToUzR0NNFP5wsx1BbY9j+tzGfsSop55iIlQitsynoQVZv2Y1b017j4++eQWvM4mbr/0zS78s5c7b/8Qt1z3CgAEDyC/ozoiRo8qEg6UAACAASURBVCgsLGTdunW88MILHHvssVx22WU8/ez/csstt+AlFQ9CjGp0bR2LF69i/uo3ycrO4JyRN/LqZx9y1jmnUVcX5NhBQ7jnrzdzz21/418vv8fNf7rcdvU2rNVawTxjR97A9wtXceKoYzhzzIn4wz48qi3KmQAOjVdffpZTRp3a4v/MhAkTuOaaa7jkkkt46qmnmv1t4cKFrFy5kg4dOrQ8pqef5pZbbml2TFFREVlZuyvPtmvXjqKifQsaaDjx0A43rQETF2n7DDTScOAmGR0PCXQiiQKiVBGhmhA7AUHDRdmOSvIzTkTDQVJGAWU7q/HTCYM6rCULFxVFa+iQ1ZUk+qDQ6NjuKBYsWICP9uzaEaBrxvEIJvEZVZTvrCBCNYVF6+g3sDtBSnCRSE67TlQXufHRZp/jOxAUFhaydOlSBgwYsNffWrqfe5VQ3Md+RUVF+z1+x44djROCjIwMdu7c+bPGcaj4bZCxCNRuZlGHdoCG44t+VvBWZhh0OOb1LBxAIB66jNj78CDV9F74Des3jLKko2KKVgXrGXdcV+JVCucwmZ6cg9QJsV4BnBsrMH0uVH0tijok2bRK2mX64LNe0MNeY9XddrpA4u6LJeZDxvDmHTAiSN2P7ApPR6p+oPXqZbDoWlh0HaQNtIn5LIjvaO8fhq3vwI/PWS7fBB26KOjXEbK/A0eKFblb+5ZFwPWfAGKtVabcC3FnW/mLDcg+F9qfbbm2V94Pi1su5hzTYX0BbOgGugG+IPjqmrRa8Av4WhXjdBVbqmTNPN4brRZ62zLktHhrvTn+YvAOsdaEtf2kV/jawlETofsfYctbViSoZudAKicV7p2sSfycH/1fEdNCaOLAVEHgB7vZlY4EPFE3oinCDksMIC4MWTugTZmbjGgf4vzHQWp/yOsH/vYHtEatUHhJx0s6qRzV4j5hKqhhI1WsZ7u8S7k2n5iUgwqhAw5NSKQHyWYPkivmk1z9A74Y6M4urJFkklSvJsEkTb5D23xVnkyI7wZSsjsyFGgQ5sedDsm9gEr2VxXFgY8EOhEjSJBS+zM/iz7/khVLNjKi/6UABINB2rbK5r777uPtae/w7LPPNiuYkJWVxbHHWjntF110Ef/85z8biUuhcJKIl0yOPnoAPXJHYBLi/AvOY8HXKzjznFNwuZwMO607EKR33y7M/XQhmjJtHXAnSnSUKWhmjHdnPUl9NMTV4+7n+zkBTh6x+6H+6quvsnjxYr788ssWx/vNN9/wzjvvAHDxxRdz++23N/7t6KOPpkOHDgc0pgbsq5Tf/qCh42tWOv6noew0HgdevLRpzLd14KMhRqApXHv8KHXxoNCbrenu2U9LLDIZ0EilN05JwEUKyfSwJSNdaD8zQ6G2tpazzz6bxx57jISEvfOZD/R+HkwJxZ/6Pn5t/DbIePFsgl4IOq2HkxRZLlJzeBVg0HqLtU6T1YL2vEGEWyvPY/2PsyAkEFW06/ENFw4ZTB79OYPnSaM3ss3A6LULZ0UYM8mLqixDEYK4MKoiDNe0hUkdwXfgUcWWdOUytuqvsj1hKiFKIB06dryenlVvo7a9b1nNS2+1WlJPSO0H22dAuNwKue/9EHT8HRjLoOR0KDnVIrWa12xhgvaQcjckXGpZwfuC0uw15TOhbou1tmtYOYQSq6PI/TkrkqYQdATIrO6Fy4in3lNJTXyAHY4ye21rN/xmFukMpZUcQ7rZH7f4mqTFhC0idvU4tChsZzx0+j1gRetu4wNW8yQlfI6Om1wuoBvXk6r6EKWGIDsIxjYTqp1PsH4ZwehagsZWxAzSuj6bNuZg4uNPgrSjoUMXq47qLwQFlPMZG3mCkComTuWRxqkk059k+pNAgfUA1YBkA5zTwdke3EfD2rXNozqbWLJ7IbUTvL/ImriZYUs8oekDMzVt/8fbcOAlnt3/N5q4GD9+PBMnTmy2X319Pdu3WyputbW1xMdbv8G9HuxKsWDBAq666ioAu4RiAkopm0B8uEjCpZJIoBtOp4sk1RuDEH59JcQ8OI3WHNN3JCCcMnoYf7z/OmK6oHCRpndmzBnj+OD9Dzl5xCigeQlFt7vlEoot9bUBfn9zC/VAxtSuXbtG1ydYJftOOOGEfd7nPfGLlVDcA/sqOQgtlxZUaGS368jObTXodl3pfZUzbMD+Sl4CRKNRzj77bC688ELGjBkDwLZt2zj9dKv2+NVXX02vXr1+3RKK/w6IyL+l9e3bVw4bXrxHPnnAI0gPIdJPXC5T3EqEGetFC30p/0LkdUR2bmh+WFTq5GnJE+9HxcK/RHhKpO3cr+XPkiBvSAd5R5B3BPlMekp9+/ViUiix5CIxWS7CQjH1OWKkzZHK97+QHfKZ7JBPpUK+l3opFkOi++xurWyWNfKgfCLd5B1BpotTvpUzZLtMkx/kZnlHkG/kVIlKjXVAzSaR1Y+KfDxYZKpH5MuzRYo/ETGN5ieumS6yXhfZ4BYpvkCk7tO99zlIVMoP8qWcYN+H3rJL5u21jymmBGWHlMsC2SZvyVp5SL6V0TJD4u17qOQz6SPfyAUyV86X6dJD3pM+slMWHnK/glImy+VheVOy5QVB3pAsWSYTpV52HvhJjNghX/9gUSM/ylK5Xt4Tn7wjyDw5SUpklphy4N/P6tWrf8EeHhhWrVolnTp1kh07doiISHl5uRQWFsr1118vDz74oLz66qty6qmniojI5s2bBZBvv/1WREQuv/xymTRp0l7nnDNnjng8Htm0aZMYhiEjRoyQt99+W0RE/H5/437Tpk2T8ePH73V8TU2NFBcXi4hINBqVsWPHyhNPPCEiIt9//73k5ubK+vXr9zuu008/XV555RUREXn66acbrztnzpzG8RzMmMrLyyUnJ0cCgYAEAgHJycmR8vLyfV5//PjxMm3atH3+/d5775VHHnmk2WfHH3+8LFq0aJ/H3HLLLTJx4kQREZk4caLceuute+0TjUalQ4cOsmnTJgmHw9KzZ09ZuXLlfo9fuXKl9OzZU0KhkGzatEk6dOggsVjz31LT760lZGdny65du8Q0Tbn44otlwoQJ+91/f/1sipkzZ8rIkSPFNE2ZP3++9O/f/5DH2YDJkyfLddddt9/+7Qst/WaBxdICJ/42yPi6ETJubqIgRwkf3iIeJeLURChdJgVvLJKXEZlM80PCEpBXpasMKx4rvGwRcfz7W2S6eY0EpUpERGplo6yXv8vmCS+JsFmi7nVi8r2YfCPCHCkd8Tf5sDilkbSbNyUzpZV8Kj1kngyXRXKx/CA3y1wZ0rjPXBkiG+VZCUvzH+lGeUamiy6fSW+pk20Hdy/Ca0VigZ9zNxvvzzK5QaaLLh9IimyUZ8SUgyOvatkki+V2eVe6yWTR5QVBXhBkiiiZIh55UXRZKveLcRDnjUlYlsvDMkX88oIgs2SobJZ39jv5Odyol2LZKM/I13KKfCXDZKFcKD/ILbJe/i5b5TXZKV9ItayRiFTKLpkn8+UseUeUTBenLJLxUiHLDum6/wlkLCLyxhtvSK9evaRHjx7Sp08fmTt3rgwYMKDxgXzWWWfJiy++KJs3b5Zu3brJVVddJT169JAxY8ZIXV3dXuebM2eODB06VMaOHdu4v2FYk5QDIePS0lLp16+f9OjRQ/Lz8+X666+XaNT6fzjxxBOlVatW0qtXL+nVq5ecfvrpLY5p06ZNMnDgQOnXr59MnDhxv2R8IGMSEXnhhRekY8eO0rFjR3nxxRcbP7/77rtlxowZIiKycOFCyczMFJ/PJykpKZKfn9/iuZqS8fTp0yUzM1NcLpe0atVKRowY0eIxZWVlMmzYMOnUqZMMGzascTJQVFQko0aNatzvww8/lLy8PMnNzZUHHnjgJ48XEXnggQckNzdXOnfuLLNmzWr8/NZbb5XMzExRSklmZqbce++9LfatgYznzZsngPTo0aPxO/rwww9bPGZf/XzmmWfkmWeeERER0zTl2muvldzcXOnevXuzycqhjDM7O1uSk5PF7/dLZmamrFq1qsW+7QsHQ8a/jdSmkkJSE44n4G+Ne9yTaFOPJuIzMeqWcuPQHAbOTaXGC1faUrhBSpjF8XwuG3j+gzqMEi8AUy78Iz3j/JhE7RbB9X0aPfpdiCKIJtUI9YgjxvZJq6i8oQKXloSLJNwk4yKOKFWEKCVEKWF72/S1n1yyuIgsxuEnZ59DKmU2CxmLg3iOYSZ+OrOJ19nKBzjw4iYVNyl22/3aQxrxdDpkPecINaxjEpt5kigVdOQa8vkLLlL2eYwg1FNMFeuoYi1VrKWEOVRglZnz045MRpHB8bhwUcG3bGUqFewgCiTQgWFMJ4Xe++1bEZ/xHTdQxVraM5o+PEAKPRCEKBUEKSJIESF7q+EinnwS6Y6PnP0LSPwEatlIMe9SzLsEmA8IfjriphUhSgjZAgctwUkyuVxDLtfh/Rl1i/+/FYr4t5cb/AXwWxzTEfxy+K9LbYpmZBLADShYYIW6m93rAZPs75JRQJJdF6GWjXzBMOaxjfmbJmIErKTh7r1nEot7iO/tcyocOCJ+zjh5AZqEUFQAQeqyd/Hp+3dQ0XPvfCWFRip9acuJZDCM1hxrr4MdPNowkuP5hq8YwSyOJoabGHXE0xENB2HKCROw80abw0sGuVxAJy4mhV4/WWqwnmI28BSbmEolmxtViRQO1jGT7SzFRyY+MvGTiYd06thOFWupZC1VrCPWRPDCgZ90BtCfR2jHSJIoaNaHLM6lO3+jiOks5x52sp4ZHEUWx9OPf5C0R/BTLdtYyE0U8jY+2tCN8TgxWckNjeRr7KmYtAd0fMTTjQQKSKCAeArwk2vrsTUvDtAgyhCjhh18RDHTqeIHABLpTTf+TFvOIqHJuKwJQVUjMVuTrxIcJJLFBfuX4DuCIziC/3r8JizjBSxjIBeC+HEkfoejRiP0121wxxae1QaTCPSdBemjlvMVw5lHOYGYmxffr4EdGspjMOeSGxigP4CLBJRdND40NoRnWjFCAEUtclQyfFNAzBsmTJldoLq8cVtPMaXMYxcLEGJouGjFoEZyTufoFgUG9oRJjK18wFqeppjPAIUToYAJHMU/mhCASYRqwgSIECBEOUFK2MIMtvMhJlGSKKAjF9GRC4mzIzUFgwAL2MJUCnmHakpsSlckk0sWZ+KlPfUUU08R9RTZqTpFxKhr7KefLBLpShJdSaALSXQlkS74yPzJCUBTFDOLeVxGHTtwAm05mhzGE6KUQmawkxUIggcaplx4yMRPB7xk4iETL+3wkmm3dnjIwCBINaupZhU1rKKalVSzygqUO2AoUjmWtoyhLWfiZz9BcL8w/r9ZxkdwBP/t+K+zjAOUYgnua2jB3ZWaWq/T8GDlFyeOmMdnnMpC6qnBZN6a96DC0q+76diNHK8/0+yckfdMnNN2IVRZRJzuQ83rDl4dJw6c+ImjZfnHKLWUMo8SPqeEL/iee4F7cOAnkc64SLbd2ntuU6hmPet4jjq24yeLPjxARy5gJTdRyONAkFQG2VrDBtK43f26Lb1IJYtyVlDOapZwJ0u4Ey8pxJNmu3PrGhWyE+hAHuPpyh9wN03D2gOW9VdNkJ34aIvzMFl7bTmFc9nOUu5lOQ+xne/ZyULCWOnJcbQmlzNIZxDx5BNPV5wHUM5Nw0Uqg0hlULPPIwSoZjVBmhabaF5pSNlJI6kMxkPrwzLOIziCIziCfeE3QcYL+RJw4Xn7dIgpDF2gZ5DRV+biAEK68KE+klUEqUXQQz3ZsGY4hMGfYjKpc5dm5zNLwDy/EhcBhGrE6UQt6Qn+A1uHdRJHFqPIwkqtCFFOKXMp5gvq2EKYCipZTZgKIlRg7LHW2JbhDOQJsjitMU9wIO+wglv5kX9QyPM/2QcNNzpe4vESRxYhwtRRxU6sSj1eWpHPZXThymapK/uDQjWWJTvc0HDQlwdpzxnM5UJq+JF4OjKIJ2nHyJ8+wUHARQppDD6s5zyCIziCI/g5+E2QcSVWQUzn1DHEADPZAJdJpw/SrTCmrhWspp5aIB7Fa8vftHSnlfDWsOZBPWJC/Rlh/OESoBoA9XkPyPrpIuL7godUcjibHM5u8e8xgkSoIEwFTuJatLgVOj15lDxuwSRiJ+rrtktdt4X/dfu1u8VgJUEoYzGCQToDDsqV/GshnaM5k6UU8SlZnNKYy3gER3AER/Bbxm+CjPswgGT5gvpVHdAAc3ANECUuYJc8+91r1GINtrzyZEp+7AJRSMkuItDqDN4kDhfxZDKEHhNvwbdoG4pKBAP1ZAEM+WmX6M9Bg4KO7wAibX9ONK5CkU7/Qz7+14KTOHJoQaHlCI7gMMMgSox6otQRI4gTH15aHXI2whEcwaHi31Rl/fDiYkYTqN6BWeG2ypedH8BXH8GDQhC2XfIXBMgjhze/fwdqAF144Ph/4CcDhaKaLaz77l30P+1CYxcQhfEd4Lr0f+/gjuAIfuOYO3cup5122s86x8iRI+nVqxcFBQVcffXVGIal9f7oo4+Sn59Pz549GXbiMNZv+YFaiqnkR3axnF0sp4IN1FJMlDpqKKKMFcTF+a1azD8DU6ZMIS8vj7y8PKZMmdLiPl999RV9+vTB4XDw9tv71lu/7777mDRpEgDTpk2joKAATdPYXxBsIBBg+PDh5OXlMXz4cCoqKlrcb/bs2XTp0oVOnTrx0EMPHdDxEydOpFOnTnTp0oWPP/648fO77rqLrKws4uJaKLvaBDk5OZSVlbFt2zaGDh1Kt27dKCgo4PHHH9/nMZdddhmtWrWie/fuCOZBfz9LliyhR48edOrUiRtuvIE62UkN21m7dTHHDx1M76N60qNndz6Y9R6mXef7V0VLyce/Rjusoh+mKT+uzRW3JuLSRNi2XM6/b7O8jMhLypQbBblKkDuLSoUplsDHoC+bnyJWYUpF2k4xWSDCHIn1XH74+ncE/3HYVScya4PIml0ikV9PiOtn4ZcQ/YjERMrqRML/xnuwp7DGoaCqyhLqMU1TxowZI1OnThURkS+++EIq63ZJhWyQh56+XUaPPUlKZJHskhVSKRulVkokLNWNwjNhqZWArBef3ys75HupkaJGQZk9Vab2h/LycunQoYOUl5dLIBCQDh06yK5AkYSlVKJS1ai8tnnzZlm+fLlcfPHFB6zAtXr1alm7dm2LClwRKZdaWSNB2So33/o/zZSlbrvttr3OG4vFJDc3VzZu3NioTNUgbHHrrbe2ePyqVauaKXDl5uY23pv58+dLcXHxAStwFRcXy5IlS0REpLq6WvLy8mTpqu+kRrZLhfwoAVkn5bJGdslKmfHli/LpktekS0GulMgiKZFFEpD1EpQKMcXc/xciIv3795evv50nNWaxDBt5rLw66zEplcVy4RVnykNP3y4lskjmrnpT2mVnNJ5/hyz9WYJCByP68ZtwUxOZx5NvX2NVanKZ0C5K7ymZ6EBdeiVRwGm4eWhZilUb1yNMHrASId/OM4XgFcb/sXfecVZVV9//7lNun95nmBl6lyIqIAoqINg7FlCxoYZYYu8tGjWJMSGWxC6Kih27IoIoCgLSexumML3duf2U/f5x7swAEkWjPs+bJ+vz2bPv3HLObmevtVf7kdZQAUSIp0he/OZkTuRtchj0P9ixX48SJry+FGbMhbWV8NtxcONxkPEfFh5bF4Y/L4bHlkPYcN7TFOieDn2ykiXTAYxfvB40FQJe8LnB6wGPC1wu0HRAhYALCgKdJbA/8JdJkhIiCfC59guH4keTlM68Wja4dVCVzvfDBtRFoDnaGWWd4YE8P/h1571YAsJxCCdAEeDRnfLmqy/y2KMzSCQSDB8+nFtuuYVx48bx9ddfk5mZyZgxY7j99tvp3bs3EydO3Afc4J6x97YNLa1BTj7lFDZv2sTo0aN57LHHUBSFQCDAVVddxXvvvYfX62XOnDnk5X3Xu70dXMA0TRKJBEIIEoQYcmQXopShoDJqxBHMeXEBuQztUEPbNoTisGbDDqZfcg62bTJxwsQkplEKnyx4l4fufoqigiLWrtzMBx98sF99+vjjjxk3fhxpmR5Mmjli/DDe+ehZTj97AuD4gGikUdQ1g1KKUZT9V1LuK7zNliZBo5pQ3CRhZOLSw7z99pt8vOB5EtRy7vnncNQR43nwwQf3+N33QRPOmTOHBQsWICWcec75jB97BNOvf5AnX5jD4RPOYn2NG6F2I69LT1569xuGDBtJoMsIGi2wJVQ0QZYfvP9ifUskuQWZpBe4CLKTREqI7v0K2FS1jIL+KiqdIBYabsaMPoLysioUNAJJUIw4LazctoBbpv+J5vo2/L5UnnryKfr27YtlO/dVBFRWl9MSbKLXSD8hqjjrvFOY//ZKzjnmSnwiBzuYQhb9oLWZosIifGRgEcW0LYTy6/jW/Gcw4/jTvPn27x2kpmIDMPDu1FCA0EmvYQOfb38JWaODlIwZ+jJV7snUkEoah5K5/mS6vH44giBSuAiu8WG5E7zCKI5jNt059mdpZsKElqizUG2ZBNXZq2gKZPog4P5lNuh2smyImVDeBE8vhBe+gLogFGfBwT3hjx/AY/Ng+ni48mjIDTibeXlrnJe3LMMj/BR7u5LvTSfNA+lep/xSjOXfpZoQ/GkxPL4c4hacPQCmDoLqEGxqhI2NTv3hWjAbIIkyxw9qqlScpyhZ625I90N2ChSkOcKMYULMgGiSuQWjTmkOg2GB3wVdM6E0E0ozoCRjtzrTGXvX3k/qg1fDppWOWWa39SPtPddTO0WS3UF0dikHKFBAV8Gwoa10CBsv+SsKznXaUxBoihNiZtuwY+sGnp45m0deWkSKT+e+W3/DnA8/Z/pVN3LRJZdx8MHD6d2nP0cedTQV5Q7c4JNPP8HwUUOZdsEV/HXGY1z62+uIJpJjYsCWWlj6zTe8/ul6+vcq5eLJE3n9jTc5+dTTCYfD9Bk8gouvv48H77yBRx5/knvuvG2fa2zChAl88803TDhmHEedPogmNiY37kJ85HLP009z7DHHkzBUglFojUBbzBmnm2+4irPPv5wJJ53HS889ii0h3tqTgLWVld+s4+G1t9G1WzE1ZZVs2rSJx55+mKdGPc60C3+zB4SiRGITpaxqPfnFbsKsBynIzS9l6xbBzl0HgpAoioEiEiiqgSIaCSVi1EVCbGkKIRTw6uDXBR5Vx70PdC3TAtOG+iBsqjEJx8G22xGfJJBLbU0LQXMU22vbcHssautqqYuEsW0fthTYElZtqSIjr5iyFmcc9PRCVixbzIb6GNU1tbSSR025xLIdaMGGsE1dTTkHHTKMjEAMpEZxlyKCTVX4Pck148C+UxeE2lZHgMsMOIzZpUsMwtiYNLIOC0edLVCoLmtm3YotHDL0KMLN+SRMFV2LoyomimKgKgaxWAJb2sSNZlTFxKMo3DjtQe6fcQ/5pd1Z/tVGpl58Kf98eT6GqQASTbXYuK6MrNwigk1d8Ws+umRHebNiPnFDcP1Nt3HS8cfw9xmPEg5HeOb1N9hZXYBhurBtlfQuJrr6y/sQ/GcwY+tEarYXoAL2CS24jAQ+23lam857HtPWWb/2FIiBSBW8OHA0Gi/Swhe08iW+M/qj0IBEoeXDVrJLR3I2S5jDCczhBI7grwxl37CC+0Ord8ETX8GLy6A1tn+/0VWHKbeXLL9TZ/uhRzb0yoHeOVCUBj8kVLdGYU01zFwJ722E2rADQUwoWSQOGl8RVPigwgBKoK0BHngXHvgASAF0CaYbGPXdm0jABmFLXFKS4YUBBQoDu0BmCqCCISBiQ9AChHMK7ZcFfbOha1rnye3foWgCttbC5hpnDEty4fkN8I9vJQkLThtYweWj5lKYtYyYXYc7kkFKVjaRVcNYsewwzF0FuHSDvOIgut8G6UPaXkxDwTAcxmqYYCaLZTtQ1DIBMuagOtbXQz2w4Ycam4Q9DAtY1wgbk4zSluwZ9iydsXn/PIjudN4uCoJvP9dSO8mOP51kWk4BhwFjSSdOXwhQJC5N4NXBrTpago9XzmPL+uVMPflgpIRoLIovNZdpV9/F7Fdf4x///Aez3lvJqgrYVQV5hcX4ikaxpkwwfNx5zH5+BkefeR0gURVQVRuXy+CAoQdR0q2Y5pjC4UefzVsffkH34aeju1z0O/R4WmMWpX0PZMkXn7KqVpLuEaR7IMXlnHwQknc+fpWG6E6mTf4dn839kgnjTka3M4klVJ558UW+/HoZT83+nLUOuBRu3RGa0rywbsUi5n34BqoKaRefyyN/vJGKJiir9zBo6HD6FEzAsHYRs2opLM6j/6gcGlnPcVOG8/SM2Zx/3VgUx30UsIhZbUQSHqrq+hKN+2gJfYDH68KybISQmKaKxIeUAikFsYSHtlCA1qDDnFr2mrldLRKfIfm23AIpsG2FaALq2yS5cVBUG12PIxQQSGxbAwG21AhF0wlFMrBtQXmtv3NtIWlps4nFJQ3NzqKLRBVMUyMc8jjItHEFoVi4PXGEkBTmbcHjacbnryOQugXL1lC0NlzuFlzuFmzbjW076qG8dGeficRhV7NTXK44Lm8EWwrCoXw0PR/TUmltjTH1pIu54ta/0xjut0ffd2sw1Q0qhulmR9UBAETCbSxZtJKpZ1zf8R0jEUeKBB6vicRG2iqWpWHbOi2t6bQgqGyCUFywthJmPfU6R598IVMuvpbV337N9ZdfxCsfrUFRFQQC09bRfwV/vv8IZmw1tUBIczaR05oZ+0oOGmAhaT30a8qaz4UGAQKuGg5d9C7AZPKZjPmljbp+KRCl4cztrJlwEZkcTW8eYRIL+ZDJzOdKmtnMETz8HXzQdmqyF7OoYQEtbf2IRw6hLpjPl1sEy7Y70qsQEEiBFJ9zCklYu51cdpfyk5KlYUOzDW1hqEwyTMuCuOEwgHby6tAz2yl5fjAT0BCC2jaoDTp1OLHX9c1kAXwp0KcUhnaF/gUOk9dVofCRRAAAIABJREFU2FALX2yFLzdCQx3QAkKzySwpo0ePClqiadTUFdHWmIWMqhAHLJAI4gJqolDTAPPW7HvOhArSiUgDFVRdkhmwyU+PUpzVTElOLfkBg1y/Qq5fJ93txa0GcCkB3EoAVehUNFlsrImxscZgc41ga42Lykbvd2+mSbKyqhjW9RvaWpq54600KhuuoqKuB1ZMd7CVkwICXrB9NnEtjNdVh1uP4NISeDUvfi2NgJZFQMvBo2m4VOfUKESyJG8XiUvC8RhtsThIjRxvgDQPpLhBFRA3HaEhmnDUxGXNUNEKNW3O/CJBB1wKiOQaScqWHSfhikv+uufaEXu93kcd0CHNDW4NDMskaoaJmxaWpaEoFopqki7qsaWCYbpJmB4Slk7CSjZCCloikomnns9vb7ofl+pcy6VCJByhvrYSAURjbfhTUxx8ZQSyHbpRkQhFsHb1Yv5wy2UAXHrNPQQCqdioGLbuuJQqIIQCFmiajjAEpumE75kJk3jE5uixDiTf6HEnctm19yT7mAL2IA4edR5vvLSUHn0vAQlLvvyUh/98H/98+XPQ3CDgsT/dyqL57yOAtz9biS2hvFmgatCSSGZ5cwNCorn8bKn2gOhOTbWCbbvZVT4EISRNdQ3EY2l89G4b997kCOzTrr4bl2c4a1YtIBx2mGtddSXDRox20tdKCVJFSgUpd584iYINQvLIn25j0WcfAjDrgxXOp1Jg20mu0C64qgIpNCwb7rjmAjatW0FOXiF/e/59MrPzaGioIievgIbaajKzc1FUu0PjAZBXUERtdQVCdTaVutpycvILQJVk5uTRUF9Ndl4BVZWtpGflUVnXB0/qYFavg2HVDkMsKwui+gZQ05IOQibdZqEm6DBSyzI593gn4dTosSdy2e/uwbZUmhuzkTIN0zD53cWnM/GEKRx19GlgQ82uCq65xIFQPO2cyzht8mWdD8Buy11BkpKWzutzv0UK29FMSEHCkEyaMKJjjZw+5XJqayqdBxCoq6skJ68QFJjz2tPMmPkRqJLBh4wkkYgRjzaSl5uLqjjr+9eg/whm/NnmISiGwBIShkUYc2V/NCDijWIpkvXbfwsGKOlw9+75LaREjN+CIIrUUsmadS69CLOd21jCQEq5iWOZxVfcxXIeopktHMUMMuiNYcGyGoMPytcyf2eElZUDCcdHOEwuisOcJKi6TX6+pFeBSmEqpLocBurTwat1Fp/uvC8lNEWhKQaN0WSJdP6/qw2iccCELAU8BlTugg2bnZPa/lBJFkwcAtmZsGoXLN4JKxY5nwXczgm8vBmEkAzv1sLxRz9FzLWGRR9fTcX2A/G0uQhF0giGHTtddlqQHt3ryMptQE1vJigM4lo1qmUTqetOVXkf6hq7gg3ZKXV0y24g3WMTjls0hjw0BVMJhlOpb/VSXxlgDQHYL5B1FfCDYqNoNlITzgleSxbbwiMjmBEvjfVdWFTbpeOXfg+kqNAShoJ0mHIYTDkUijMg3etGiBIssmjlK5qZTzPzaWOpE+6GTirDSWcMAg9xqklQQ4JdGFQTpxpJuwQkyOFkSriRNIZ/twt7Lkc2NsLcHTB3Oywoh1DyMooA1QUpAfBo4NZMNDWEojajCokgHWGnYksN0wZLOkKbIR3JK9Nr4dKSkj4NJKjDi8RFLi4KAIFBW7KEMYhiY2GabsKRHOKJAIbh5eAxY7nugpM4Z9rV5ObkUlPXRCgU4oV//pljTjmH/C7F3HfzJTz8/PugQ82uctauWcTBIwbz2YczGX7YUA4/ohcfL56HEDYIk6+/XMD6VUuIRz+mpFsun899mnMuOoOc/E0IIXG5QyQSPtrTsKtC5aX3OjF+I8EQkXAb2bkFmKbJovkfMPTgw3BpFts2LuePd0xj9ltv07dvAFvGMS2Ne++7F8O6j7jpCMaDDhrFSy+/wrGnTeH1l19EAglpIRUbFOksNRuQUFNVzsql3zBo2Eg+ePsNBg0bTb8DRjPr/VXtU04k2MTjD92CYjejKbBs0Sfcc//9pKW5aIk5phIFx06f5YWsAPTIFRzYVUEiefKR2zGYjkkzNsvJSqvG7zfokd+KYdvYSj0eV5Su2WEGFTrasbdfebZjTGwR5eRTj+LLuX9i+k1TeOPF5zjxtMPoU1KPm3QMQkSoJa9I5a7r1uOyltCzaBBffPQqL730EgNKBGecciLL5z7HlddfyVsz/86EE47EF2jkqGMncPPlF3Du5VfTUFtFRdkWBh8yDE0zk3KFwzFd3qgzaLbgtU+/wTQ1pNxN/SUkUsC9N19En779uPGGa/AmfRsGFBWzZvVKFBxBVwIRA8yw87nwOIcZjzuVguJufPD+G4w74QyklGzbuIq+Awbx2mfLEMIRCAQQSElh89qvGHzQCD56eyaTL76C9AB07VpC9bp5HDd8Khs3bsA2Yhw2IOdXN7f9RzDj2QuHISTYfgleE/daNyoQHL4YgLrywQBM7Aapu/XYurwZNVaDRIV3+6OoOsVcQS6ns5XrKOMeapnFQB4hTfbmucpXeHrnTGoqzmBjRV+ihhsYSknmNg7MDFJVncL2ZgWXZnLU0K85btS99Ov+CUIopHIQmRyNj36o+FDwoSaLslutkfad/NWWDTsbYFM1rK6E99fA8kpobE/cpQI+yM+GwcWwvhUq2iDHDxcMgguHQJc0RyhUkjbC3RealLCtwWHKX5cZ7AzWceHRH9Nv4AM0pmwhChRTyh9GDmPR0hKeXVBM12w4vDeM7gPdclIRIhXo2XHNWpazgN9RxRdk0Z+Cpt/w5ZqefLi6kOXb+2PLTnEzK9BKj8JWClIbyPGpBDQv0YSPHY2CimaF+jaVWELtVLEK6djdNImq2aBYCCGxbZBSwbY0pKnicsXJK1hLYdEquhdW0z8jh8z4QdRXDWHFDg+tUbjsSDj1oH2ryFX8ZDKeTMYDDnBEK1/SzHy28TZfcR/GPtaj8+irKCh4SaWZj6nlLTI5glJuJJMJ+0y4IgT0y3bKlQc79uSVtZDqhm7psGWzQWlWNSYtWMkc4U7CV4lNExKBSgoaPixs4rRBEkCj7TttdIBAErQAQSxiHaEcKi5cpKITQNf8aKle4tQQlZsozPZy/T1XcdW5Y7EsUFUXV9/1MOtWL+WpOV/gcRt8/vHrfPHOUxxx1CH07tedhe8+zEO3rKdXr97cfs3v8PtS9mjLDnceI0cO5693PMHaNes5fPQoLjjjUlRFRSAYWOjFtmFzliTdC73zwZYS0zYxZYxqs5Lp555DPG5gWxYHHXYUp154OQlV5f67byEUCjP13MkIJAVdipkx83USlhtbdm4G1/z+b9w+/WxmP/cw448/EQQEfGFSvAYuDQoznDUiI9CrTz8+e38mf7zjMkq79+LcaZejexwbbru2y5edyYVX385J45y4/guuvoOYK5N4GJ556A5GDj+Is087kW+XL2X0KafQ3NzMe+++y5133sm6des69gZJETYRVBFAKHFUzxY+eGs+N1zxEA31zZxx0iSGDBmyR3iRM4de7rjpXiZNmsQrT59FUUk+T772R9qoYMuub7n24nuZ/cE/ydR68Ogjj3PahKlYlsWFF17IgAEDALj55puYNGkSzz37DCUlJcx+7RX8mZL8MX5OnTyKs8b2QtNUHvzHNRQVOUAqv79hBm+99DGxaISJQ7sx9eJzufeuB1DQkNLxEwglnH0oL01Qu2MR77/5AgcccAATxziobX/4wx849tjv+ulcNuVsFixYQENDAyce1IXb7ribqRdexGuvzOLK6Zfz8qP3YhgGZ511FmeNHcLekbvPPfk4U6dOJRqNcswxx3DpWccgBDzy14e45JJLeGTGwwgheO655xD/A44v/xFAEQPPgG2vQ7wI1ClRHnnQSxqw/vFLabz0CR57zoaY4Iuz4bD05I+WxJAjVjmn4m4liO3dv3PdJuaxSU5n/tYePL/gUTbXdQWgIHc13YsXMrjLetIbzuOFecOpqBEoJuSmwrj+cGQ/GNHTpCB/Kc3KxzTxCUGW0CHe70VSQmtbNjX1faivHk919aFU1PSlrDqPbXU6caNzcfTM62SEI3pCk+mcohbshK+rYFAuXHEQnNp3/1QsEptmFlDDC9TzOhYhgvjZSRwVD0fzFL0588dNCo4zyxbeYCHXE6SMHpzIaP6M0daL5ZWSXa2Cyhaoak2W5OuGJBaF3wX986F/nlMPyIc++QnCGS+wQvkzTWwEQMVDPgdTyKEUMopCRqJZ2ShCElS2UMYn7OQTKvgMgzAClUJG0o3jGcQ0PGTsd5/iBPmca1jL02TRnz5MQsGFjeXYpzryhDtxkBV8Ri3L8JBKDpBOkDQGU8KN5HLGvzR72JgY1BGjjAY+oIG3cG14iB79slHxo5GORjoqXmxMotQTpxGDWIfMoqElmaqHBPXYGAjcqKThKPisZLstNLwO88WP+i/ATCwiRNmBTRSVTAR+EjJExIojpUKaloZP5CAxiLGT7WWbOfP461izdjUqPz2D3f6QRCKxaLfzGJYkakLUEERNhaghiFsKumKjqyYuzcSlxtHVOJoWRVejCCWOgheNTHQyUPiua/z/JISi08MwYKOS8pMy6JlEidOKhjcJivPTmI5MjnN7/d33HKHuf2OWv1+T/s8BRVx4Elz7DtADui3zdGwl7+pHkrPBCzEBLhjRnlK50UKO2+4wYvyIr/cN+LC+Yiw3z1/PlxUKhRnbuPGE8xjZcz45yjE8/cV4nn1mMtGWDLDApdlMGqHQFIb3V8GLXwFoZPhHMrLnSA7teReH9Ayj6o3saLApbxCUN6qUN+hUNHqobPARTXRugqpqUJCzneL8jzhlUAV98m36F6QzuKALhanpqKSikYZGKgouDi2GW/bhV/V9FGIdNbxALbOIU4lKClmcShmNbOd9CjmUY3mZVEp+3IWTJBD05nS6czzf8jeWcC/PM4AhKb/lyH63/0smGE96nef4O53TTOKs41nmcz9tlJPHMMbwEIWMIpehqHtvnKrTggx6k0FvhvJbLBLs4mt2Jpnzl9zEN9zHUK7kQH6Hl6zv7U858/iYCwlRySHczAjuRPuBdJ0SSQWf8Q0PUM6n1OAll0qaOYcUbqWQS5AYxNlFgl3E2UWMKsLUEkN2mLN1utADNzZpWECcViTNSCws4kic/N4estDxIDCwaMGmCQNHYPFRikbaT94gVXz46UecKhLUohAhRXQnTWu300sSSfhIgYqbLii4fnFGDJ3AHu3kVp2S/p3pSTop4Ib/z2AtnR5+fzKNH6L2bH8/R1v4P89qf176jzgZL/tWcvBdDfC7Ni67uJQR21UkkgvOBzIFZIKaDrPHwUF5kpJTd8GCrQgUosf24dN7c/lwLTSGoUsm6C74rAqWNkBuCtw5GqYM3UF5dCmPvn8izy70EA8DEnKzmjls4u8ZdtizDPWdwEAuosAexdYaja+2wtdb4astsH7Xd9udnQKlWVCa7dRds53SpwC65hgktLW0spggiwmyhAib9tl/Bc8ezFkjHZ1MNDLQyOh43V6HWEUNLxBiBQKVTCaSz7ko9OZDzqeBNRzEDYzi3n95SvopFKaGRdzOWp5GxUURh1HCeEoZRy5D95lP2yDKGp5kGX8kRBUFjGAEd9CVif/2VlDPapZwL5t5HR0/Q5jOMK7BR+4e30sQ4gtuYBWPk0EfJvI8BT9g/90X1bCMpTzIFt5ARSeXdFKowwIS+EngIookQhhzDwW4wEUKh2x4ne79ChAoHfGXIsmCXaSh499jTJwwmwg2CTTSf9at06SVKGVITNwUoeIjRjk2MXQycVO8X3Ch/6X/0n8y/ZiT8X8EM95GIz3ZALj5m/8gsiKC8jSTW07XSB4LENkgVbhlYQv3fbURSQybTFyTB2J/X0yN47KHpjvezNJwbHtH9YfbToAxfSEialnGn1jFY5hE8ZBFD06gBydTynh0fDSH4ZvtTqxmabZT/D8SA8GgiRCrMWnBpBWTICatWMnaJIhFKwbNmDQn6yYk3/XsSmEY+ZxLHmejk8M6nuUzrkDHx0Rm0i2JOPVLUD2rWMfz7GQujTjqPg9ZlDCWUsZTyni8ZLOKf7CMPxGhliIOZwR3UMLYn10eb2AdS7iPTbyChpfBXM5BXIeffCpZyMdcQCs7GMbvOJR70f/Nk0Uzm1nKn1jP89i7MV0vOWQxgCwGkJ2ss+iPhywE4n8dnrGdVEebyUAcBTceStH2A97yv/Rf+r9A/+eY8aus50xC6DGTv3kPJQPYPP0RPjuxhs/f/T1EBJhwRE2MeZ9sRqEJ8HHH0F78fmQGuCE9A9ocXyBG5UMPPzS0QU0rNLZBc8hxzpg8Em4+znHo2JsStFHGx2zlbXbwPnFa0PBSytH05GS6czxesn+WPu8vtduZzA4G3YSLAvw4sJFxgszjcjbyEsUcyTG8SODfAKP4sRSimnLmUc5cdvIpYRwVgooHixjFHMUI7qCYMb94W5rYyBL+wEZmoeCihKPYwYek0Y0JPEcXDv9Z79dGFTv5hDS6kcUAfHx/HvT/bcwY2jGum5DEcZHXkdHuv/Rf+i/9AjZjIcRE4G84xpanpJQP7PX5ScDvcbyTTOBqKeWXP635P54+JAooDPnS36EYC02azaRDivh8s4AGKNxp8trnVQiaAR1TT2X6gnQmBmFZNSzd5YQY3DASClO+52bfQy5S6M3p9OZ0LAyqWMhW3mYbc9jGHAQKAbrgIgU9iRTVXre/TqGYHpz4k+20e1O7nUnbR7hQDct4n7MIsoND+T2HcPOvjlYToID+TKE/U5BImtjATubSxEb6MYWifSUY+YUok74cw0xGcDvfcD+b5GsMFpdzOA/i+jdtdfuiFIoYyAU/+3V/TXIwrr/f1v5f+vnIwsLCQMOVTDLy46ndweq/Ft//XfSDzFgIoQKPAuOBSmCpEOIdKeX63b42D3hHSimFEIOAV4G+v0SD90URp6Uc/2RpMhxQEjpkKfO2vQsKuPvB9k/rcRm1OHpnH+pLReSlCvJS4dAu33f1n0YqOiWMpYSxHMkM6ljBNt4hyA4ShDBoI0GIMDUYhDAIkaANizjzuYI8DqIXp9KTU8j8iUMpkdRRyQ42sIP1lLGBsmReqDQkEb4mn0zO5iN6JMN3fg2ysTGI495L3SsQZNGfLPr/YveWSBLESRCjNZSgdqekZifs2qJQtlqnepNOU0UJoYYnMaNP80Ga5OVeCv2Gw/CJcMh4Jzc1QPkO8PkhO3ff9zIxsTBx7+XA1NYMaxbB6oVQth6yCqCgG+R37awz8/edVtRuT1OZTKcqJajad7Ow2RbEohALg2WA2wcev+MPsft14zEItTn98Hh/oRzZSTczx+VHSTpb/f/HCIyEM957jyG02+et5Jwb+6iNjvWg48KNd4+yL8YqsYkRJUaYKBGihEjQmXZNRUPHhYYLPVk0dDT0ZEuMjmLEwQjpWCEPMuQD1ULxJVC9BrrXwuWV6KqOnvy9Cw/aL2TzlxJiEWfNujw/bs3ZNoTDFsGgRSwq8fht/KkSn09FE9p+HyZkcsaclbhvocbZK6K48e3z85+b9udkfAiwVUq5HUAI8QpwEtDBjKWUod2+7+eHM/r+rDSToUyinppP0lCBSKCNFI/JC1udOKbTXSbuRbVAAghgZ6WgnP4Tj7//gqSEDSsgNQMKS/fcHAWCPA4kjwN/8DrNbGErb7GFN/mSW1jILXjpQRrDUOlCK2FiRIgTJ0EcI/nKeZ0gQYIIUVoJ0kwTBp3pt/ykUEgJISpZS2vSklzPe0wgkzwyyMKdCCAruuBuLcIdLMDTlo8ezEUNZqMEszCDPhJhjdwMH8UFPrLzBTkFkFMAWXmg/4vnN0qIJeYnfBH+gGXhrwnFoqSbReSY3ck1u5FtdifH7Ea22RXdDKCikZ/tIyMXgplb2KwsZSur2clGqimjkVoszI7NvT2UyMbCjCuYjanQkonWlo1sS8Nq82GW5SNXDkRd3x9tS2/U1j25aDKjJxZge6LI3FYSzRlsXupm61J495HkQ+ySmELQGhckgPximz6jW+l56jpSjl7IrsAqdrCenWxCIum5awJ5X5wJC0dR90UJ5WudmEuhgOoFK+H4IuzRFiGxlWTgUTKP8IMfgAx3PlwdYdeKjSuQQHUbYAusiI4ddbF7Zqf214pm4/IAQiEWh8Ru2dkUVeJyg+62EK4EpjCwMLGEiRASTVXQVQVNUVBVBaFaToy3aqGo4FbduIUXFZ04USKEiBEmQhhr74hsW4G4B6Ievpm7kmcff4LHHn8DIQXso0gpEEKiaE4SDiGks4lLAbbgomknUFdfgy0Nho8awR8fvxeXR+XxvzzBi0/NQtU0cnKyefyZx+hW2g0VDRUNkE4fMbExk5u0JD9QzI7aCmIhhXibjhFyI03VGUXFQvEYCG8c4Q8jvWFsLYFUTQdhRHFm5u3n3+Mf9z6DkILLf3cVp5x8HjLmwdTjhLwh8NazfOki7r/2z2xevZWH//4UE0ZNRia0ZEIMCcINws0j//g7fl8KF0+9ho/mvs7f/3EPW7dt5M33P2Hgwf2IuCLYrlZwJZw4/JiHlnKLay+6il0VlRTld+Ph+18lLS0NoUowQIYDmFIw/6uPuO+hq7ClyemTzuXiqy+FlGqiRgO/O/tGKst20a1rN1599VXSMtKwMHjw/gd5/ukXUFWVGTNmMGGCA4Bx6623MnPmTJqbmwmFOtlCIg6RIISDkkgQjjiuG2/MXIYhw9x4x/k0NtWgagqXXDKNyy69ikRMYNkSxWUQtxJEIzbXXvFbFsz/iMyMXN6ZvQaEJNGi0FqFM/apLShpIbTUCLqLpPOpszPYWKxevoYbpt5GLBrn8KMP5+b770ARCg011dw47UZCrSEsy+bOB25h9LHDidKGjUVXhiTXyi9L+3OHIqBit/8r4buupEKIU4D7gVzguJ+ldftJbhROjOTxZIsDQ1V/6FcM5QhCzYCAe6ojQAsSHwId8U7Bj76HRBImiH+v2Dzbhnlvwz/vdZgxgNtnU9Cvjez+9bgHbMTsv5ho/y+IdFuGVAxUdNSED0LpKG2ZiFA6SlsGIpQOMQ8J4kRFL6IUkhAxhzmIIJZYh0QiulShdKmEtNZ9SpW7ZZnERWdCKkEbLaxDAimGRmxLTxKLRmF+PZL6tQNp2NENpTEbIRUs2KN0REerJvgi0LaPsBBh48puxZvfiqJZJMIaRtiFGfZgh/1gnAqc2vH1GkhGCu/jUuwm0ak9kYF88I1FemKgG0jVRA2EUXwRJ8tOSzqyKRO7MQuSKQhVnLSS7aX9HG7j+PVFk7X0GHi71+EdtRzPcW+QGPM2anoQkn2Pb+xF+E83wPvH46rNx50Q6MhOC2+FwtZZGWyddRiSUdhCInQLdyCBMFXKgx7KcTQ2BhIDx5Zj2JDM3dHRXgUnnaAqBaqldsyhkhyT3eX+DrxVW2AHPdh4nPc0E5HRipoZRAskEKpFLKhjNWRgtaVghrSOdIKu3a4jLTAjYEQc5AuJl3ZGLhGYwPenw07eWzPAZYOuo+gpKJofVYAMe7Cjbki4wFI7niPRUg6Whhrej1Ajo3MOd7srD937GoGUFLDhqhvP4OW/fMGxx55Gl6xhzHp7Ct58g1eef4FrrrmOPz/xCDLhBkOHhAtp6GBqSNONIiRCCmwbGjZk7JZ2EUzLRNGFI0hEPMiIB9noxEt2JrWUKLqkta2Jx26dyeyZK5AonHnuMA7vN5XsHD+m4ce2sxBAQZuX+68/mGdffAg76HOYeiCIkM6JTZUaGjq6S6C5wONR6N93EI/95U1uvfsyzPp0rLIiYLcUF0KCFDw94wZGDpnAxX+9iSeee5B/Pv8A11zxACKZchMFzITknj9O58lH5pKf14Uzzz+YIw+ZRK/u/Xl0xpMM63cMj//1ap587gGuv+UOrrvjJrZt28CsWa/w1sJ3qdvVyAWnT+GjLxahCp1BBx/OSydNYeKRB7NxfQQMDUwNkcy8JXEETXDSFUtL59rpDzGw7zBC4SCnnXcQPQqPpnv3/kgc7CyBCwGcPOEiJp9yNTfdeZ4zTy4TaWjOfFgasjkTmrOcbL+6gUiJIHQTDB1paNw+9XzuuPY5Bg04lMuvOpaFz23n8FHH8Lf7/sTYEedx5lmXsL18FZdPO4W5Xy1D1QNo0oWVb/8sefN/iPaHGe9LifCdk6+U8i3gLSHEaBz78bjvXEiIacA0gJKSn8cm2k6VixwmpwDBU9/kbPNpZ+fQodtbTclvqdg9UlEO/eGH3iBBJZv4ls+Yz5us51tCMoQiBDoqiqVjzJ5E+L4bMNf3x92lgsxzFiKzGjCiXqp3llLx2QCsF44HHOB04Y2geOPYIZ+zGeyD2h/8dmba/lrDiYxsT0UvAVuxkL4IpAZRs5vR8pvwFDWhoGCFvFghL3bETSLsJhbVsWM6Mu5GtKZDmx81mdZgjwjdlDaU1BB2fSbs3sZAG6LXZmTPrVhZjTB8CXafTViqhVVTgFVdgJ0soZp8kALhi4A/jOoPo/kjaN44LtuD3piHXVGAUZ+K3ZSOaElDhAMoUQ+qqaN0bGvJNNqWhtWajtWa7ki5wsk/274FCiRut4XPI3H7QPEYGGEFM5aEyXMliEqIGC6iWhx93KcUnj6PnkMa2Lo4m+YFI2n+fAzWkyfCkyeiF1WSdsQCsgZvofnTI2mcdxjS0vAMWIdyxd/xnPUKsqgKa8lwxJpByPISKCvG2tIHu7II2ZqOSOgYTToSh3/EkZj+ECK3DqW0HLXPRlyDVqMU7ULk1aLk1aLn1aL5oh3zjQQZd2M1ZMOubghxPxTUIhPtTEQDS0XaAttSke3jYerQnI7RnAa6iRQ2JNx7BD0JbxTFFwHVQpgaGDrC0MHQUSyN7ya47qR3PniRF2bPwDASDBo4nGkX3MyF08fzyjNfk5aayXkXHMXlF90yz0aTAAAgAElEQVRO15JeXHLlMQwaOJwNm1bQtaQ3D949E49HBcVGqpYjWAWChBINTL/1WHZs286wYaO49eZHUCw3ww9PZfJZV7Hwy/dwu7387c9zyMzqhFBsb50nkIYpwbAMEkbCEWlMnREDjkMEgSAMyTyN97bOR93R4zt9qqzawXW3n4Nlmhw+cmLHdRcvn89jT91Nbl4eGzev5JmXZzH1rLM5YPAwNqxdS9eS3vzhrpl43e1hZQLbEHz++VwOPWQ8WalZSCSHDh/HosUfcuxxZ6AoAk2qCKnQpbDUGQcVLARmxA+Rzv2pXZ8QjymoQqE1qJCX55hxbOkIi+2xEh0zJgUSmPf5HJ7+5wJMBMcffz4XXXoEV17xIJid2/6qdV/TpbgHhb3zEHqEiSedwLxlL9FjyPV8tnAOz/9zPmrUxyljL+P8S4/k2ose4dOXX2DimPMQu/qRDxQX9GHl3HKGDhrBoOKjk9oNEBGfo2dQbGzVcPYtW0Ayv7aFICO7kIycfExh4Uvx06NrPxrqq+jTvb9z8GjfCxSLg4aPpKJqJzYQkwrEnZ2rsnIb9z84neaWejweH7+/9Ql6dO0HTWnO/QXUN1USCrdy4BG9wVPJKRdMYMHXz3HUhd1QU9uIqBUoGU2ENjaTm1WEqM9GSsURnLMSuH5k5MtPof1hxpXs6fnTBdhH1KxDUsqFQogeQohsKWXDXp89ATwBjjf1T2jvPmkpHzJrdhUHcDEAxlELeXDbE2CDHgAWtya/qSLm7PtUvIVvWcZHlLGGLaygjC3EsLEAY30/2m5/nvCcE9HSmgkoEk9rGi7DTYpqogobUVkML00GnEH1BNoQRXV4DtuAT09DNzOIh70ouo6W2YjhryGk1BNuMxHN6SgN2ag1hRDaU1BQNIklIGI4JxPdZ2JEVFQEmq2iRwIokRTYVYRc3Z788LskkKhCgiJQNIEvD3JLoMcBMPCIEOkHbybedSU1njU0U03AyiHy7WCqPhlE9ZJiGjakE9o0FGvFgWgIxD9+46RO0CWB4iiZQ3eROvYbYqd9RGPfz/AYWWStmwCLD6X+85E0rc4hXp4OcUePreAIAc6pX6J6bbw5ksxcm9wilZwCMCLQVg/NNdBQhaPpQNmHKCggrmEloFU6m5PmhZgbmuPgdrk46nibwaduJDTx72xIeY9aymkAsoZB1+lPUiz7kbHhBFoWjKH8876snXsOm2YplHSDs2+Ak8+GfgcMIM5tbON4NrOUzWOW0TRmI2GWEKKZEM2ECTo2wqYMQvOPwKrPITBsJV0PqCDLk0om+eRQTB6laHShlQCpHIiCRSs1tFBDM9U0s4sWUYvliSc1IdVoGyJ4i2pRUFFQyb7wfHZnltIWRI48kdZjL8ZosCm8a1InwoSQCNUmcsKpxCadiNJWT+a1V9JuPRMotDwzGx0PuuVBMTxguIkEFSIhB9FJUSRbdqzlowUv8+pbH6G64c7br2HZ1ne45LeXcddfLmDw4IPo2acXo8ePprK8gh07N3HvXU8y5IDDuPXuC3nh9Uc5b8r1zoZsq2C4MEKprFm5kjdnr6OktITLph/Doi/f5eSTziAaDTN2/Aj+9vf7uO32G1jw1RNcf9NNmDJpi5WOitmUJlNOOptVy1cxZvyRnDRtFIJapKFiR9zImIs33n2S0YcfDe64Ezah2iBshCL5w42/4ezzzuXkyScy66UnQLGh5xYoa2DtuqW8fvdyinL7UlVVxo5tW7nztqc48J6DueOOabzy/kNcMH0aCBtsBamZ1CTWktcjHSu9GZFwkV9QSH3tLjTDhRQ2tuIoT21bRVoatq1gIzrwShRF4vJIhDuO5Q4h0lpQ0mL4e5ejomGaEuEywBvFwnaeC9VET4niSYmjeU2aWmvoM8YGpYJMxaYlWEPmgZuRwgLDDTEf4ZVbKC4txKW4McI+clL6sGbtEhLBNBoa60jLKiIBZGUX0tRchwrU11cxeOAI2kW2gtwu1NdXOWKxFB2HhQRg4zBfBQWXR6K7bTR3AkWT5PQMUlCko2lgC4NtZdvYtGMpw0/PQZVV2IaG8IdQ/BFUt4WCSiCtGs0bJ2tgGXbChW3B5decz11/vZ+Srt1YuWwFd//hYp6ZNQcRd0HMg2Lo1FXXkp9dAg05SGGT6xpEXdlHuFq7cN1vHmTKuccx66mZRKNhnnn0U1RNonrjCLeBS/t1ksPsDzNeCvQSQnQDqoCzgHN2/4IQoiewLenAdSDOPtv4czf2X9FGlpH3zjQUwFAsSnvmcMu7zmfjUi1EUxjQkKUZKAP2dKbZzDJe5G4W8x4GoOAjTBTbEgTWjaHt1jsJvzeaFM2i0GNCU3aHtGYLm5hUiEqFGA42hAZ4AHcoBfemFOxNnao9G+moyckH8gHQhURLMckuVCg5UiU9D8rKYcW3DuoRlmD4aJhwklNKu2sEg5LZS1/m0yVraVg8jtrFh9NU7+A3+5KQcpF45wm63XcSKTr1zrXJshR4JoDHcyB5hQeSWwBuN2xYA431neNU0g0GTIABQ6CkK6xb7JRdWwS12320bO+J8kZP4ByE4mzeVR39dsZGeCCnD/QcDAeMhL6DoVtvyCsQKMoPO160tUDNDti1HWrKwJ8KeaWOUJFb7DiDbF4Py75yitvjjNlhY8HtVnB8Ch8FHqWNRqrYSCG9nUSVAuifLL9xfADqaiB3L0cqN176M5L+jPyX7UwQI5TZQui0Fsf2TdefZHOysYnQgoqOhwAb2UgJu4dJ7BXvrIDbnUZGTg4EIuAXHU5eiuIouX3+DNB6AGmwl2NKPkkUlXa1jMdBGuskwbtzP2fDxhWcNekoAKLRKN26F3LrXTexcN7HvPHqTFauXElKigfdrVNcXMw5U52QsCuuPpcZM2YwaJgDd9fetoZWOOSQQzj2pB4IARddfA6rV39FYfEkXC4XZ551PELA8OHDmDt3LgHv3oYHhxbO+5xYLMbkyZPZsWID48d3OiW++OKLbCv7lmee/xy3293hcNXu6LRy5RJe+ehJXLqLaZdcyF/u/Atd0wuozN7BIcMPZuKxvbFN8KZAcXEx500djUTym+nn88iMv9OrKIM4ERJEnfiFgIpbtyjoGccigi+/DbfXwD+wHJ/LTYqSjo7bwaK2ndDKgi7QvbfjVBeLCqIRQazVi217sVrTMQ0/oYpsEBI74sdO6GDrpObHyUjXSPVrCJGCg5bi6IyKvEW7zZ5CsdLb+SepEstO85IS0OjT1/FjWLoCKqoEpd0dv5fS3bIECwWyikF3S1we8Kc7zoMuL6RkCbKKcbQ5OM9MUVfnGXS5QdNEMt+zAmioiiAnkEq67qj5Q6EQF5/2G2b89REG5A3pmB+FnD0crGxS0HDTxdMVPM7vVixdzg2XdkLcxuMxSruqxGhDJYpb+qgLm2gupz1GXEFJOFqgeE2AN155gpOPncr5U67l29Vfc8Od5/L6K2tRDDfgRnQO4S9KP7hDSClNIcRvgY9xHtFnpJTrhBCXJT//B3AacJ4Qot0Ud6b8FQOYx4Uu5K36XDSgsdsOXhVf0dQkQQhmVEdwZDQP8rrO4OAtLOdF7mZR7BNi751KeNY7GKv7owTT0INpaAmdBI43mh+QpophQmYRnHABnDINcro4iyQcgvpah3lpmuOV6vGCy2sT1HexsaqK9eva2LFaRTN8ZLsK8BqFNDdplO0UbFqns2EjHQZUnx+OmOAwkrHHQeZekSOpqYJLxp7N+LGf8AGnY0uLwTvepH7xUaxa6jwI/uwg/4+98w6zq6oW+O+02+/0kklmJj2QQkggEELvBGkGYgMpAlIUFZWmAlJELKgUBZ6AGEAkBIg8qijShEBCIISEkEIySSaTTG+3n7LfH3vfNjMJoT5F1/ftb597zzn77LrW2muvsqnyVjKVr7NX5Rz2rTqZikqN8krpvKRtK7S2wLaW4ry1RbbniOMk4Z0yDSZOhZLS4jrMPS1/3dUJby6GV5+B5S/DljXSSUr9rjB5H9j7YJiyx2DC9kEhWgbR6TB++vafmbibTKee+z5lUcmuOzCb0jSo/eCqBQD4CFDBMCoUw/VhQUcnQsX2H/jD89u/FwzBH54vOMscAOVVO35/OyCE4PTTT+f6668v+j+RSLClWbJfsViMaFQRhAEDrmkaixe/xrnnygG65pprKCkpQde1ormRfc+yrNy1YRg4joPruuy5pwyhePzxx3PNNdfk3gsEAhx//PE8+uijOWL897//neuuu44XXpCEGODyH13OE088AcCyZcvQ0KjQhmFioiP1BYJEsPARCUfQ0dFNSVg0LasPrmFgoGsGb772VlGbJtRP5Pnnn6dczYHu5hgHHzyD+kDx8ZymgWEgFeD8EC2R6Uc/+lGufq8uWkZpOfgtjZAVwPUEpSMEoTCMHWsyql4yJV/72td48803GT58OE8++SS1tbVs3bqVuro6tm7dSk3NYLX/+vp6Nm/enKvLtm3NjBw1nLIKGDaslmQ6/35tbQ1VtbDLpHqS7mYaVFyYzu5mJk4eTnX+9ABNgwrlUsF1XaZPH3q8AGzb5qSTTuKUU07hxBOlTknz5maOO06GUDzvvPM477zzBtUdwPM8ysrKWLZsWdH/ruuy/56H5L55/vnn09bRzJgpkvl55a1mGhqHU1ELjz59F08+8TQNjTB+6iyuuDZF5bAOqqtqJCP7aVl7CiH+X9Kee+4pPi5YdLsQtyLE/Qhx6ZwFYu/uqOA2T3CHJ5rnPCsEzwmPJcLrd8QasVRc4Z4g9n/uILHHWXeJSdEeMRUh9gknxGElGXEQQhyEEAfgiQNKY+K82THx+6uF+NsjQqx4XQjP+9iqXQQdbUK8/JwQzz0tRDK58+/1iA3iXjFd/EogXhFXCU+4Ypt4XfyPGCFuFmGxRjzyyVT4XxQywhadol80iTaxTXQLT3xCA/YJQ59IilfEOnGneEncIxaJJ8Xb4s13louUyAhHuP9v7Vq5cqUYN26caG1tFUII0dnZKZqamsQFF1wgrrvuOnHfffeJY445RgghxIYNGwQgXnzlRZEUGXHW2WeJG264YVCZzz73DxEIBMSa9WuF67riyCOPFA899JAQQohwOJx7bsGCBeL0008f9H5/f79oaWkRQghh27b44he/KG655RYhhBBvvPGGGDNmjFizZs0O23XccceJe++9VwghxK233pr77nPPPZdrT2GbXnnlFSGEEGefffaQbers7BSjRo0SXV1doqurS4waNUp0dnZu9/unn366WLBgwXbv//jHPxa//OUvi/476KCDxJIlS7b7zkUXXSSuv/56IYQQ119/vbj44ouFJzwRFylhC0cIIftr9OjRYv369SKdToupU6eKFStWbPd9IYRYsWKFmDp1qkilUmL9+vVi9OjRwnGcom8XjttQMHLkSNHe3i48zxOnnnqq+M53vrPD57OwYcMGMWnyJNEs2sW7YrNoFd1in1mzxIMPPiiEEMLzPLFs2bIh350xY4ZYtGiR8DxPzJ49WzzxxBNCCCFmz54t7r77biGEEO+8846oq6sT3seE6N95551B/wGviyFo4mciUMSqJmlrXA6sXziXzMKTGDtMIzHRJbzYD9g4vhAXN13Iy/eNIPWnW6C5gYAvTW1QnriQ9NOny5goNYe/xXU3Rjhg8mBFj08KKqth34Pf/zkPjzgZeknSR5JeXMq5k5Xcwm/4MwHexMcqdiXI6TxBNbt/4nX/uEHaR/fSRh+d9NORS3100E8nMTrop48E/aToJ5nLMwNcfxro1FDCOGqZwHBGUs1IqhhJNaOoZgQVmAU6yilsNtPFZrpppY+xVDOVegKfkM2li8c62nibLSxnC8tp5i2aaRrilOcpTsVR6hr5II0aJjph/JQSJEoA432cQXh49JKklwRxMmRwMZCKiQFMfJjK8EeqRGb7x8NjxKRRXPaTyznsyMNxPRfdMrnk15fz4pKXeeDlRzEMkz8+fB/X3n0Dexwyk9ETx3LjvNtYfu7XaRg/ijPP/z4r2IyOrhT0PNbSypRZ0/nGZRfy3turmX7g3oycM403WY+HYBnrAdhCB2lsPLwiu9x4PM7xxx9POp3GdV0OPfTQ3E7q4osvJhaLceIXTsLFo76xgYf+92HC+DEKxv2mm27i5JNP5qabbuKkk07aYf9NnDiRefPmce655zJ2/Di+ev4ZdNBPGhsbFxMdX4XJ9664mBl7zQA0Lr/ycioqpJTjyiuvZMaMGRx//PEsWbKEOSqE4mMFIRSHAoEgQYZHFj7Cpd+6iI72do455pghQygCXHaZDIF45113Utc4gt8suJ1lNLGtZSs/OfuH3PPkfKrMKDf/9maOPOooXNfhlDNPpXZyA+30cu5l3+SsL57BHXfdSUNjA/cv+DM2DrtOnsjcL85l4qRJGKbBL373K3qMBA4eV11yBX+5/yESiQR19cM57ewzuOqqH+PHl1PMLISXX36Ze++VIRSnTdt+CMUMDl/6ypf45/Mv0d3RzR71U/jG1RdyzFkncvmffsoN51/LtT+5Fsd2+PKXv8zuuw/Ge7fdVhxC8eijpcvfX/1KhlD8zW/+G0LxI8OdP+gg+bMqqoF5hiDpanga6JrDc95iNDwWa6M5S4zAr7kES2IYvaWAIOXL0JvxE9MdRh2zjB9fU8rh08YP+oaLy1tsJEaKFA4pHJJkSOGQUHkahzLChPETxCKEjyA+lVuY6PSToo8UXcTpIEY7MZX3006MXkVQMri5XFoQ53+LwRpMQ8IoKpnFGPZhDLMYwxSG00YvaWzqKCdKkAwOLfTQTA+b6WIDHWyjlySOInCyvoXXCTJUE6WRchqooJEKGiinkQoqCdNODxYGtZShodNNgh4SdJOgizjb6KWfFEF8BPBhoNFPkk10spF2mmint9DmpwB8ql8D+PBj4cPAxiFOij4SpMkAgighDAx6iav+kqYi+Z7L/xckgIGJjSA1hB9vHY3hlFBNmDAmOh4JkrTTh42DqRSqPDQ8NGwEGTzSeNg5xwJ5j0f5HGxcbGWokzU1ypBCYKPhUUmIOGmSODy16gKqJo6gWPA8WOtZKseZhLCIEsCHSS9JYqRJY+MW2B1nny8O7JnXNCi+HgoK6yLLlUTcYFtTC+cfexpPrngBD0E6N38Lny/8RmFbtCGeyYP8homOpgJXegjAzKm36SqelY09xJjKduuKqMsyPAQWBmHl8sKn2BobhyQ2aWw2N23im8eeycIVfyODi1fUcxoWOg7eEGtUU1/TMBSDY6ErNx26Yqx0QKCjY6lAIBkcEtjE1Im0N6BcHwY+TPwq+ZSgPUaKGGmSqpb59mrqPFYU1FEMkYYCjeKxGep+4bUYcFfDVPMjW+/CZCkm0FC+A1xcuonTRR99yrVTiAAVRCkhBGjESdFJHzGSaOgE8GFh4uJh42KgE8DCj6lymQy0HPPk4CoPBZ7ycOYVpQmM+NDezv7jQii2v7eNaqroR7Dc1QgCIR2O1ZNonjwvXmCEqHA9NGGQ7o/QBcSDScZ+bhUnngCnHbMLwypk/wgEG+lkKZt4nSb+whuspk2Zjnz8kLUfNdGlpjIUIPCsuZPAh4cPQQgf5YSopYQGKhhDLaOoYjTVVOGxkn6eZTWvsYFHeZM/s0R9SUAu5mtWmWKoSeZhoBHEooIwwyijkQpKCFBCkCAWbfSziS5eYi0t9BSh2PeHwgW/PROaoYMxZAAbjz7SCFJFSE+itgA6Gmk0PDxEQZi8oWoo8EjiqJKz/ZMzHgMMPAyaydBMN/n+EvjQlOmSA0UIXyh74bwKnSxtYA2yv1111yVd0Bsh/OiYjKOSKiIEMAnjw8YhkzN6EUjdemkLLFSdUtikcOgq0q+XpiJZIhDCIoilEJ9HGpsULhlc7BwKH9hz778GZG+4xBXp7SGlGA3pxDGt9GyD+CgnQpRQrm+ybIqsj5NrR6qgRgKhXHRIjyUmukKwumqDPYAYDjz0k/c8UMQ0Px9l4EmHoZkByax5CFLYaKCQvI8IAaIE0dBIkKFfMa2ZHJuQ/Z6UBqRzvZse8I3Cfh66DoXPZPDI4BAr6L3BIIm8ZDg8VbIkeENHV6fAvFAU9aWm7ulqnnm5Z94fsmZ+Nh5JPChwSFTcrqEYGT8gg942o2zVisCHAJJ4JIvKdUnmcN5Q3xn8f7Z9WQbJHSCJ+aTgM0GMq854GN+CSaSOeJVnfrkve/0KrGb43LJO6JZo8zmnjDQa6cpudjtxPd88oYQTDxtLKLAnAsELrOEm3mEpG3mDTXTmdmZZBO3SQClx0nQRA8VFj6SCMVQznhqGUcJ7bOMtNrORLnoKllweucvpG8KihCAlBIgQJIAfP9IuNUaSfpJFeSEH3o9OKxrv5lxB7Aiyk0xpMSoEL906ZPUUPTwcxSlKJO8CMSBGB5vYgA5UEWE0NYxjOOvYxipa6Mvpimfr4RXVSXLDpkKghYtCQggfdZRQRoAAGmnS9JCgjzgZbCUNcHAKiF12CQ2nkmOZybHM5DCmEdpO3Fzpf0fk/Cw108GrrGINW3CwSZAmTiq3u+4mTo/aSWYJq46DUELwNDoZNGx0DDRCQBCdMKbyMG4RULt3gKTaoeS/kyaJnUMa0xnHwezGEezBZBqJECA4RGD2VaxiIvW5NsVJESNFBoe8/zEvdy05/mLSk0eIDCl70HI7t/yuUShFJbkDs9S+QsshrcJrKX4WxEgSHTWK+SseR+nSkyaNiUEtUSopIYh/UBt3FuKk2EYPfSTUuBZ7+PJhUEqIakoJ4Mv1TXbnnFQEM3vE4RaRJWlglJV4yD6T94ePGsX8FX8D1a9pIE2GXjIUE4j8LtNAx49BEB9h1ebsfMwUMD9yzCTLb6rez7pG8RRr6alxHWrnLWtrIJmZ7OjLsqIEiRAiSrBobmUZmwRpuojTS0LNJglyl27mxln2jpfrY5+SIFgqz/5nYeTKzu8yRW7HmlJr21Zr0lXt2x5RF2S3DnkHlnqBFMZS39SAfpL0EVezPc/sZ9/aPuNQvFIcsp4OPh34TBDjKVN2ZyM6I48v4+1qSO4DmTLY75sytJsTLuP829sYPVbn4JnV6LrU7OslyS0s4lZe4F22YaIzhRFMooo36SZGEhAcyC7cy7doVD6XOujjOVbyD1byLCt4huU8A4TxE1d7mzrKOYU9OJzdmMV4QLCFDjbRxgZaaWIbG2hlA9tYx/oB4i5JNsdQxx6MZQIj2IV6dqGBRqrpJ0k7vbTRzUY6aKKNLXSyjV46iVFCgNHUMJERTKaRRmpooJrhVGK9z5DHSdFCN5uVyHgZTSxjA+tppZ0+XmMDr9FElseP4qORCiYygtEMYyQ1jKSGRmoYQRUVRHOLuJN+VtPCu7Rg43AgE9mVETuFkGV0IEctYLmIqyndqXezZMVSO6SJ1OeI2r8r6OhECRHdSb+5OS9bBXudwuvCncDHAVEC1FGOjUMPcRKkKCVMCeEhzw4/KIQJMJZhSM94KbbRTRqHCiJUUTJonusKaWchhJ8QfmqRjiGSZIiRwkBXxydWUV+4eMRJk1EEDgrZT6Ec02awcQniI6K8Tg8s5+MCJ3dsZQ/IpQfsMEGiKgWGYOzybZC6AqWEKCWkGCm5/4/gf198sSOQQUQ+WNuzInRbMRwWpmJIdn7O1FKKi0sXMTQ0Aoo5LtQN8fByTJDMi48GJY7Jivc/nfPjz8SZ8dZnBC98Dg571WXvdpOmDTB5guDtI15BQ+DM3RVzQT504TI2cyvP8ycWkyDDTEZzDvuToJOfsIBWUoDBZEbwR77JDHasyLWZDv7BSl5jLbsygsPZjYk7SWRAijk3084GtpEkzQTqGc2wj7QQPinoI87rrGUElTRSQ5BPwTXNfwH41wyh+F/4L3xWQSimwPcR8PB/3Jlx3ZEac/tA95tsug/QYF5PHA0bCKBfEiWFzUMs5VZeYBHrCWJxMntzJvvyOiu4jFtpV/4zh1PJ7zibE5ixUwS1gSpO5yBO/5Axdy1MxlDHGD6kYeunCCWEOZRp/9/V+C/8F/7lQAgQDmiGdJDxX/g3B6FheeZglYNPCD4TxBjADMnF4CUBC/a4V3ri9Ajwtb3u5zGW002C8dTwG77AoUzg5zzEYfyIFNKdXIQoP+FLnM+RH4kb+k8GZxukV4BRBf6pHx4peSqaglD6NSJ73O7lr7UAGGGJ/P4L/94gxEdzCLPdcj3wEuDGQaRAD4FRAvrHKNDxbHA6wekAT6lQaDpoFmimTBRca1bBvWz+6VvS/NuB8CSzI1SUM+Gq9f8BwzCCohVxOV7CUeUV5uoaAeHpnw6O+UxQnL/xJmdwMxWt+4L3dQh5xJ9rJQI012k8xnKOYyqzGEUz2/gND/NdOsmaIhzFbpzFYcxmGtHtaPHuDHxSCOVfEUQG0qsg/Rakl0NK5W5b/hmjGkKHQfgImayGweW4cUiuguRKSKyE5AqZZzbtfF2yRFmPDMhDEulqAZnrAdAKck0Ht08mp1ddF+ReEoK7QngviOwNkb3AP/ajjbGXhPRmSG+EzEaw20DzgR4ckEL53KoCa4AzLyFAJMGTuoRo6j3NkvdwwcsoxOUUEIIscTCGbofwFEIqRE5Z3ShdvaOU8LWsMn7W5aZftkXbTtnZ8r2URIRuXPbHCy8/z03zbuDh3z2OWQFmhWrLB+jn2bNns3XrVhzbYb+ZB3Djlb9DSxnc+PtfM+/ROzENk6ryam694g801o1ED0iibJSAoVx+uilZd90P0WikKATgoHYIOUecDjl3EGBEwFev+sOBex+Yx89+9xMQcMnZl3Py504fpCj8zzde5LJfX8iKdcuZ98sHOPFzc+V8CKjxlxEUufqaq4hEIlx00UUsWLCAq666ilWrVrF48WJmzMhLPL0UuP3yvYceW8A1113FqncHP7czkE6nOe2001i6dCmVlZXMnz+fUaNGAXDJJZfwxBNP4HkeRxxxBDfddDGNtdUAACAASURBVBPC0XD7we0GkYCNW5s46YJjeeOZFfx90d+44vrLyGQy+Cwf133/lxy096HF80ld//K26/njgrswdIMbLr+Zw/c5qngeAl29XZzxwy+xaWsTjSNG8afbH6SqoZyeTCdf/MpclixZwhlnnMFvf/vb3Hh5qfx69/rJ2fMJAK2YQcquJe1TpJCfCWK8lCZacGh5SxmKV3cQ7rcBkwVfWEU3LfyZVu7JKV84jKOGS5nDmRz+kRQsvBjEHoO+ByD+VzDrIDAD/NOkC2CjTi5yux2cdjnAVh346lQ+TA78Dr+RArcL3E7weuRCx5Wc4aDcA6NCEj6zQRKidBPE34DEmzJ3esAoBbNU5npQ+s0nBcRA9CmOUaqKItIKqWdTGkQXeeNUH/h2gfBRENgT/FPA2QLxZyD+N+h/QD6m14IxGqgE24XkGkhvIIegNB8EJ0J0fwiMV0RzIOJX18KTdfES4MYUci/MY2D3gpeWCF+kZCKFtKhwlPGIQnxaSO2awmBGgDL5rtsCXb+DrhtlHY2gGrtqsCrANwF8s2Q/e0lFaJKKUCbB6ZKEN70pT3w/LASfhmShBdZQ6h7KvHOg0cZQlsloAwieIqoU/zXk9U6BQq6aVPCVyHQIWxqhlqWXAXubTJoBRhmYlZLIDZSwCEf1dUKmedc+SNQswXMEp1w6lwcfWMCX5nyZPWZN55sXvU6kOsTtd97GVfMu4b5b5uP0yDWZHY8ioyFleJ1sAiMkv68HwfNcNNvA7pA7YWFLZG3VglVZvI67urr46W1Xs3jx6+Bo7L3vnpzwleMpDZWjm3kkP5ZG7rrlj/z69hvkf0Ixh4U+XzRZTzsF6WaYUDuFP9/yCBf84FxS70HCBFzQBgzQBN8U7r/mEb51/bmkVkEq63M8Gw5uKGZMdYQQ8PsH7iIqylm+cB0PPvkA3z/3Uu75+XxeXfYKLz3zMovuWQ7AEV/bn6d//wIH7XlwcZEpWS+vAyq8Khb8/DGGVw9n5boVHP/to1j35JaiuSmAVevfYcGjD7D0/pVsbW/hmG8ezlsL12D4DbRInpG+6Z6fcfgxh3Hx+Zfxs1/8jF/+5mdcc8HP8ZIBfnTmtbx75AreeW8FmWZJeL2kHNPstwqnkx4FcxjoJf+/m6nPBDHek12AELQOAw0u7HpH4aQgv/3uX4Gksgr0mM00ruVUZjDhA30jsRK6/yIRvdsP7hqZRDOSEPpAlMkFnn4Y9Ify7xbGBR7Kulb3KUIQUIhLGtNKu4mMevFDgqfJUGtCXRu1oIdBrAU7BnZGBqgphIGm/0PlXkGbvAzwtkz6w2BWSYJtt8sHpSYzmK0yZdseDENkVwhMhdBBED0KrNH5BWF3Q+K9fEquV9frJFLyBSBQA4Fy8IWRAcU1Gd9dS0uC7HVLRma7fZhRaaDZInkr7CLfW0kQ68FeL19LPgXiJhWfWKVCnKgHwdcI/pEQmip3uGY1GJWglciHRb9EGEJx7cTkPCMOXh+4G2TKZO2SlAmqJ/LjoenKh64Gmhqcgch5EBSasqpczyJjr+jvonfuf/I+bnvgZjJ2hhlTZ3LpBT/kmK8dznMLFlEeqeDIUw7isnOuYGzDBOZ8YzYzpsxk+eo3GTdyAnf89B7C0RC6ocp2wTQgFu/jlIvnsHbjavabfiA3XnorXqdO2eQI3/jyd3j65ccJBII8+JtHqS2tHcQZlGglEvG7DradwdA0tDQcOOkQ6IV0H0yr3Yd73ruP1Jb867op+23jpg187QcyhOLhs2YD4HbA80uf5/o7rmZYVR3L1yzj4RufZM63Z7PX1Jm8tfpNxo+ewB0/v4dQfyhnni48ePSJv3LwtCPwbapAAAftcQSPz3+auUd9Jd+VFgwvHUXDcDD8Oma1lMSAFH27/YqxTCpJSEoeA40PKYUgaWeHpqxvhLSJksmFCWMnymMdNUk8tWA91+WK317Gi0ufJ2OnOecL3+TsE4uduWvAE39/lB99/SpIw4kHzeX711+AsAV4Gql0CltxhrZjM6yiVuJcTdUVGZRL6KCVwvSZyqG8B5N3m0w6kyIj0jlf4dm5+PgrjzL3c1/GX+ZnZMloxjSMY+nbi5k5dRZkQMTkUv7fRx/lyf95nnQLnHzs6Rx9xsH89JKfU+oLs9+k/Vm/bp1cO9sKireUlCykJGMBEHFw2iCzVq5Vowa0sOx/kZG4zT/80yHSnwlifDC7sFxcydSEDhb8+q6RwEaEHmLNqDtYQRPLeI89Gc9UxrxveYUQXwZbfgJdD8vO8mlgCbUB0cErBVENWpUkcv5KsGrUWUYCRCe4zWCvBXfLEB9QYj6SUrTjARggDBAW4JffEbqa6MjF6SYYtMsotCjWkKIqXxn4SyXBdTvAU5PTrANrLxBRSPVB71pItMr1bVVCRnHmehBKZkDZvlB+AJTuC1aJ3F07HTLZ7SrvkLt/u11ysNYwmXx1igjVgtMH3Y9A6hXwNoPTArFVEJ8P7cgF7FiQUTvfgg0xhgERDaKuQuQpYJNKqjts8m47srlnIAMUqaRFJRfseRB7RyI9DblbiYyH8K4Q2QUCDZDpgsQGiK2D2LuQKtjZBsqlc39/AnwJCDlyDDJBSIUhE5FBOfrbgPVg2pKwF6adOYqyVVNNdS0EBB65EKtlWTG13A7xHewLaWhwh08jNefG3EuakkJoqF0gsHrDKh7++3yeu/tlTN3iOz/7Bi+98ALfO+VSvn3peey120wmjZ7EkfseycatTazduJrfX38X++65H1+/5Ezu/NOtXHjqRbI+uhSvaxF4/Z3FLH/+HRqHjeSYr87msUWPMOeQucSTcfaesg9Xf+M6fnTzJdy94A4uPevyXHMLmcbPf+so3li5mCP2PZoTDpmLa4Nm57vonvl3cdQ+R+eYK81UYnULLr3xO5x35vl89cTTuO3u34Em57nhh6UrF7PkoRWMGjaajVtkm26/4i5m7b4f515zJnf8QbapsL+3bdtCQ21D7lsNNfW0dW4hEFT1VboPol8difRJyUn8DVXfAmZIAzTFXGV3dJolJ4Q5DPy7qXZsZ6drRKSUTB8u8cYf7r2LSGkpLyxYQsZNc/jJ+3HY4UcyunF0vgwPWjq3UD+qQeIRw6Q0Ukp3byf7Tp3FQXsewtij6xAIvnH2BUz7/ERZJ/LHJMHNEgcFBjg0fOihh5k+Yzplew0+uG9ztrDPPvsQlCGbGTmpnvboFvyT8uJlLQHtXa3UV9WBDcPDdbR3tuElVCG6wp0WaOWS6OYonVBd60pCLBwQYSnJEinwNsrHshsNAF8NubZ9kvCZIMYWBvGOEVIMEQRe7kGg4Y2rwMJkOuOYzrgPVGZsCTRfA/2Pg98HZWEgLpF49CQo+TIEDwQ3Kc+MnF5w+pErzcgjssLr3BlTP9j9kOmVu7+MImCZdnmOpvnUGWc2V9eaXyLFvtchpY6zDB9Ep8gUHg/BenBs6F0JnU9DfDXQCqHxUH0aVB4s32v/K2x+FNLbJFKqOBTGfh5qToDAcEg1Q/fL0P0SdP8T1v8C+Ll8tmQ6hHeB4CiZAiMhPAWCDcWKMZl26F0CnYuh9/fQuxjsrvx9IwRmidxJ+02wPDAzYMbB6getTIrRjUpJyM0q0Eul+FIvUzvMGnnPqJH30u2Q2gTJTWB3yr521U4ze+2ohAG1X4WSPWSKTn5/xZ5MO/S/Df3LZe72y/8dwO0BYzP4NoG/A0Q3iAhoMYlMcxAFYwSYI8FolGfcWhDwK+IUUAgkKOeC0OQ866oAf4NE4kZY3iuistqAnaw25OWQ4slsvQIjFJEYoDinB+RYvbLoWZatXcoB5+wFQDKRZNiYGq783lX85Z8LuGvh7Sx5cpk8c/NBfV0Ds6bth3Dg5Llf5db7bsY37iLZTkVArFYZQnHCPpJRPuXMr/Da8n/yle/MxefzMedbx+L2wR777cmzL/0NcxR5Ebuev/7r3/5KOpPi1LNOYVHXPzjyyCNyZ5H3zruPZU2v84/fvoClROZCSaBEBhYteZn7r30Ytw2+fNCp/OjnlyJicmBnTNmbMQ2jpfQhBA11DRxw+H7gg1O/9lV+e9fN+CdfJBG2AbhgPCMwkuAbI7+lR0H3afkx85TkInttgK4ryYQGKCYhe4xilMrzbf/EPAOhB9X5+g7mrKaouRmV6xrgxZXPsHz5ch77pxTf9cZ7aXbWMmnc6OKXLUFgAgSUSb7mh+AUjc1t61jTvorNW5rRdDjiiCN4adGLHHjggflvbkcpbeXKlVx66aU888wzQ9Z3KFNbXdekDkUIcoHQDHlElD3jxQBrgjqmSqhutSHdvf2+kZXN41gtqsYkAUYSTB30yu0vl48bPhPEGOAbb8m8phpIxNEw4WslO/1+892wbT54XSDWga9b+gmOIheTHYV0PaQ0aHkG7AV5RPxRQA+Cr1qlKgg0yu95aXVmGZcEO/sboGxvKLsQymZJwqj7BpebDcGZWA/tT0HHk7D597DxZvm/EYaqo6F2DlR/Dqyy4vcD9VD3JZlAnr/2vCIJc88i6HoJUvdTvDvXpEgn2AjpVilWlo2EyGSoPRFK94bS6TaRUSn0qigfN4QiEBr9/s99WPBVQ+WhMm0PhAfJRdD3Z3A2yfN0367gmwj+XeWZ/oeBvlXgz4ap++GNH66QHYD00fZ+sIMQiu3NYEK6IkZFXRSfDrql4VdSVWsb6EGN11cPDqE4VKhFkCEUDUvDqIRApYEwHYzy7YdQNAlwwueP57EnHuWoo/MhFH/6MxlCMVQjKVdhiMJly5aBAcE9NEwTMv2yMwJ7gK8PorVhAlNl+f4IaJaGNVL+NkplG5csL25Tw+h6nn/++dxYb+1r5uCDD8Y32O29LKccfKMhKJs1qH56WOl27CDO/cAQitsDIQS33HILRx11VNH/A7+ZDa9YX1+P4zj09vZSWVvB3ff+gVn770O0JALA0Ucfzauvvorf7y/qg6lTpxaV39zczJw5c7jnnnsYO1b6bli4cCFXX301AHfeeWdRSMfsO8OHDx/UhtraWtrixeEhrRJAofxAPVgtEM3Gi1DTKzfNCvKhmAYvCU6r1NH5tPwDfWaI8dstgAa/2xRDw0EQwjhvBzO3ANoeh1VnCsotCNoapiwKJwLJWrBrkZyqKQPam6VqR6eUoCz12yiRO+CsIlV2V+G5sNWFjS4EI7B7NZTUSMRu7lwVPzSExsDIb8rkJqHrBVmnikPlGfWOQIi8iDRZAsnZ4M4GP9AAVNmQaBG0NAnaN0Jvk6C/CbyNGtp0iJwnGDlTY9weGv6IBl09cPt8OPY+6OiBzx0IZ58kc3Pnp6IQ0AJ0I4/VUwNzIfMg0KjJutYhz5M/DdB0CO0n02cNDjvsME444QS++93vUlNTQ1dXF/39/dxwww2ccsopjBw5kq9//es8/vjjAGzatImXF73CPrNm8ec//5n999+fmTNnFsWfff7551m8eDEbNmxg5MiRzJ8/n3POOSd3XyDIAGmENEI09KL3Y7EY/f391NXV4TgOTz75JAcccAAAb775Jueeey5PP/10UTzf6667juuuuy73e7/99mP+gw/w1a9+lfvv/9MO+2DTpk0sWrSIWTtoU1dXFz/84Q/p7pZbs2eeeYbrrv8pcSXKKNalGjwxB9ZvZ+Duu+/e7j0hICmki9sZRx7FjbfdxgGHHErIZ7FmzRpGjBgx6JvHH3888+bNY9asWTz00EMceuihaJpGY2Mjd9xxBz/4wQ8QQvDCCy9w4YUXDuqDpqam3HVPTw/HHHMM119/Pfvtl18Yc+bMYc6cObnfwWCQk08+me9973u0tLSwdu1a9t5770HtydbtsssuY968eZxwwgmDntF00D+keFkPgm+UxOGfls34Z4IYCwFOArBgzl3yUE+YEfSy9+/F2DuClSe51GFg2hqalaTs2HbKrh6Gf7chtpxDgIugFcGmeJzmRII3hWClYfKeZdFi+ek2fbh6vi6aEIzSBAdoMFdoHIpGeGcIhedBSxt09kB3H/T0yby7D6+3n1giQY+doSsapLMiSldZhM6yMJ2lITqjQTrDAVon+fFZfnZxyxhPCSOFQTc6y4XGSmC10GhBI01WGWkHFTMENKh0YGFwBVEggxP4PY8JWzqZ9Mpb7JrpY9fTDmNcby/DXlpGzdy/4yuvgDPmSsI8ftSgz3QIWAIsFrBEXe+0UrKSepnACAQNtk1jbx8Nm5sZ3tZOScMIoo31REpKiMKg5BuKa0awDodl2JSgsRc+Kgec/goBHUAnUsIyMPkZmjlwEGxG8B4e6/HYiKAUGInGOATbhCeZI3JK4YB0kx9UdQ5qGgE0LHhfpzUiS+AKns0q4BSMZi4fOXESP7r2Wg478kgcz8OwLL5/wy95Ycli7n7pJQzTIPHwQ1z1h7vY85CDGT1xIr+eN4/l557HqPHj+PZ557BReOjIMzkbaBIeu82axXmXXca6t99mzwMOYMLnT+BtIZ3EviGky85mIehCsFQIDLycLkFXrJdvHn8CdjqNcD32O+QQTjz3HHqEx3cvvpj+WIyTvvAFABobG3ns0f8dtBvabghFIfCEoMVO0alrbBRpxkzclZv/eDdnnnsOY8eP59rzzyWNwFfQhxUVFVxxxRXM2GsvPODcKy9nU0UZHh63X/ljJs6YwUHHH8fKJUu4ZM5c+rq7+ctjj3HZlVfy6BtLpYKEYeQkBO1CEBeCd4THswsX8tNvf4eu9nY+d8wx7D5tGk89/VfplTqr/Chg/sKFXPztb9HZ3s7sY49hwrRp3PL0Xzns7LNY09TE1D33ACGoqa5m4cKFhBBF8+XMs87k1FNPY+y4cZRWVHDrA/ezEY+pc+dQ+Y9nmbTbbpiaxuzZsznuuOMGza2sr+kYHr/47c2sXbeOK6+9hiuuvQYPuOOvT1FXU41PkxsgC41hk3dl9hfnMn7SJAzT5Me/u4UeQyOK4Btnf53zzjuPGTNm5MJD3nXXXTQ2NnL/gwuIKyZ899Gj6O/rw85kePgvf2H+X59hj0mTCLLzDHl2I5LRILJzr3xk+Ey4w1zcDjMXAKXgnfkGWqYfe+YuWK+qAwYh4C9PQ2s7hIIQDkE4hP1uB69dchDldjU64Bz5DLssvQpfZzeURRFH7EPfpHpa7QStmzayzXNomjqZVVN2ZX3DcLZUVdBWUkJfMCIPLsQAmwEh0ISN6aTxZxIEkzEcy0d/pALHDOSfFYISXCboHrtrglLPJdzXi97WQbq9g3RXD6l4jFQ6RTzgo7OyjK6KMnpLI/SVhIlHgiQDAXnolFf5KE4CefiYtRESRkF985GI5AGWW/BboAmByKnmKkKb1cBBk9plDCxrAIhCAp0vW2oHSTGCLjw04WF4LroGQvfhaD7crB2IEATcNNFUP9H+biKpFGHXI+w4RBMpIv0Joh09lGxtJbKtndLefsIZh1QgSPOIWjYPr2NTQz2b6+vZ3FCP7Xt/ZiuIR4nrELLTmJkUKTK0BzVSfsgGFACLsn6XiK0hDD8JX5B+y4ejv496lshGdxL53i/qZ9Vvql+fWr2aqpxrPflc1u29lxvrPBOk4RHwPIKui98DTdNxdJ2MrpPWdGwNnCGJ9ccjQmhpauK7xx3L/Lff3kHZA3X1t/ftnalToaHM+zwnBLoQ6J6H4XmYjoPlOGqug6vrZHwmGctC6Hm185amJr577Ak8uPxNqb08wGhML0CnQtPyrRICSwh8rocnBK6m4WoanqYjdA2haXz0fhe5WeAVGQwNlWfrXjxvNCHk+kPg6AbeALmupooQSkFBQxBGEEH5e3ZdMkJg6xq2rmTAuU8qLdScUTHkbKkGqv7ncIyWq54FBNGwkCEfbLVpSDOUxVx2HRT2q8BAMq4BICxrkpOoSeZWyyl+Zt+bisD3IdWp/+PcYf5kPaBDTYmATBww0c4vlTc3NcNZ34e/v1T0jkBnOQupUMEfLrvT5X/POArdPRx/OgmaR9pv4Jka0k4k9yJ5Yqa8J6CB5xGN9VDW00lpXxclve2Ekv14hoFr6LiGgWtZJEIBekoidJeV0hctlVoJwk+fsHhdWLwu1IdKQlAyDMZld5oFexQtV5GiXPPkwggK8MUzmPEkWtrB0XQSwTB9JaU4lpTbaJ5HZWcH5T2daCJFX4mPbcNKFeuYL3PkhmYmvrueiavWM3HVe0xctZ5x6zaT9pt0VpbSWVmWSx2V5bSMGEbzqFEkfJKIuoaJY/pwLD+24SMVCJAIR0lEwtimhWOaOIaBp1t4mg66jpujYVnGICXbLxw8N0NSt3HCfjqiQWzLxDFNXMPA07Nac1A4YJrn4UunicbilPX0M6xtI9PfWoqpGawZU8/Ghjq6KsrzzIwA3fXQXY+k5SNpGPKQPRDJl+uhGAz5rZ4w9ORuyCAa/nQvwWSCVDBA2udHZG2PsvXTZPxjhKyjJgRGDi9JJCI0nWCyn8qeHnx2hpJUAsMwEIZBRtfIaGp3LAqJmXoXg6QuSOb4o0KEIhGv6TqYjoOn67iGjqfrijAUr5b8+wLDdfFlbAKpFKFkiqDjohkGtmHgGDqOpuMYOrH+PgzPI5RI4Om6JHiZDLrnIXQNx7JIBfxkfHlZouXYhGNxIv1xwvEElmMj/AE8vw8hBCKdkbmmISwLNxDE8fux/T4cXQfXxfFkXCFH13FNtfYMfRDBE5qGYxg4hknaN5QWlCQIuuNiOTaW7RCKpdCEkAyoNtBYV+BtB2cLTSOjaWT0wv5UuZBjrwuBrsn54CFw9fcjAIXEVP7Os7tS+85yXXyZDMFEinA8QSQWx5+xQQjSfh+xcJDe0hLi4Qi25UOosRtMyGSZokjqJSN6xdCJqd864LczhNNp0HRsyyLt9+MYktT4HZuSRJxIMknSNOiJhEn5/RRuYnTXxZ9OoyHI+HzyXU3DRiuIzSUKGPyC/wq7Jvdc/k8XjaRKg3W7BuJUSZJdAZ+GC67PxM74hLfhf1fBn9/r48s/fANBCFIz0O57AL57lRTv/uJy2G8v+NWdMP8xXo7cTnnX4YDg8ttg4TkOmpdGaDKycH6nJ8GXThKOx+ktLcczDEzbYdrbqzjyxVc48oUX2eeVl/F3tUMgCNEyebgcjEgDWDMgd84ZWxqHaoBrI5w0MdOlV3fp8Wu8OXEMS/acRn+0lJ7SMnpLS+kuL6e7vJzOigpi0Q+u8BSKxxnT3MLYvj7GhkKMGTuKSaEgewIl2Qnb0gavvkVs6Qre6m5ni2czvifFLr1JQsKBTBr6+6C1DVq2gutJCcPECVBVAWjQ1glbt0Jnp/ROEInCcUfBhWfDntOk2K29E157AxYthTXroVeJ2nv6oLsHevrwXJdUIEBvSZhEJMC2kXW0DqtiW00FrZWltFaXsa22hraaKnTPI5RIEk5nCOkGIb+fgGVhmRa6rtNTUcam2gpaIkE6DI0eBGltIALLEs+cIRTheJK69k7qtraz27J32GPJcsav3UQorrNq0lRWTtqVdeMa2TSmgXAqzYTVG5i+5G1mvvoqZT1bWDllFIv33p3Fe0+js7Kc+uY2GprbqG/rpqG1i4ZtHdRvbae6vQtch3AsLm2gPE8m4SrjcKVw4Ep7zlVPLWRiVbWqt2qDLgmoo4FjGiqZ2D6LRDBIMhjENQws28Z0HDTPReiQ9vtIBXyIguMThCCQShNMpvFlHEk0NQ3HtLAcm0gsQTiRwrRdcsjTsiAcBEOHRApS6TxjoOkQ9EMoAD41/+MJSKeU0atE6rZpkggF8Wcy+FOZAaL1oQiSKEg7Ak0iUZ+F8Puxw0FSfoukZZI0DVKmQdLS5RFSAcI2XEEobeOzXRBgm4ZKiqCkM/jTGQLpDL6Mje7KttiWJPqRmCR6ujLWFgg5RqaBbZkYnlDhS3V0TaZcsxCQccCRAfxcQ+AaGq6pS8bBNPF0HU2IAYncNUAwkcL0duSgYKAmk5QG9JaW0llZTsZn4Utn8Nk2lm1juC6G5+DpGq6u4+kaPtvBcKTkqbusjGQw6zYtX6ahCKvp2GjCwzUMMj4LW0kcDMelrLePiv4YhitI+P3EAwHi4RCOaeJLZwikU5iOA8i+SAX8JAN+PNNEd10s28GXseWYpFIEUhlM10F3Zf97ao1kk2OapP0+ksEAoOHLyPf8ajyza0XPzuPJEyH44TwzfpCd8WeCGLsCno3Dofu8h7lyM66/FuPQ6+Cpf8BBs2DOYYhrf8Y7tZXcd8pJJFu/xTk3lyKAn/08w30X9xNK9XLYe5sZF4wydngDYwIRSjDpxGSl0FiWybAtnmLfTIZDLJP9SkKEB4o5XVcSnY8LhIBMBhJJSKZIJlO0ZDLEY0kS8QSJZJJEKk0iliDR20MiHifhONR4HmPrhjFm/5kMmzAO7X057A8AqRRsbIbRjTCUmFcISVyj4Q+klJV7N5GEnl5IpmBkvUT2heC60LQR1q6DinKYMB7KyoYubwjowWMVNiuxacWjGp1aDIapvBadIMUEildehdvugIcegXQGxk+A3WdAWSXE4rB2Fax8U/ZNfSMcdTQccgiUlUJFKYweAbVVQ6tt7gw4Dqx4h1XpFBMrq2Tf2BlJuAeCpo4iNL3gWpPz0jSKcs80SPksUj4Tv4CgJ8hNlWxds7nfnx9vz5OEN55UKSGZhyzhDQZkHvBvv82uJ9/r7oX+mOw7TVP2PSoZRj438kc6eUZF5Y4LrtozBQJQWgIlUVmfQmZjCJCReSCFIIUggKaCfn6IsRJqt2ZLYopdkAp/D9W/uRy5bgJ+lXzStjKVgs4u6OqWOKEQsuLyLCHMluH3SU84lpVPPkv2pyfkWnI9mWdsSCYlM5VWDJWhy3IsS84Z08zPH9OU4xzwy7Ylk9jpNG2WRVtJBNdQ7sRU1XTPw3I8fJ6H5Xn4gHDKprSzF70vJr+n6xJvREPy27YNybSc7ynlek5H3hMenif1BmSdzHy9TAssVW8hZP2KkitzzKijbQAAIABJREFU181/V1drJXskUchUTBj7wXGZgv84YpwFYS5Fc2PYegeW/2I4+jB45SX6Y50c+uwjvD5jb75yo48rvq9JBYKLYmz7RYovZVyO7tpCIN1L3sBS5PPsf4YPovVQ2gjWzsWR/ZeBdD+sWgBvz4NUN4yYJVP9vlAx/sMTiiG/1QtWWLo3+jBgJyHeKq+zBCXrB7OQ0Li29DXqqJRsh+7V0oNJ/wYIVsGUc2DYPjvfvkQHrH0MVi+EzS/B8Jkw8YuwyxxIeDDvT/CH30PDajjCBUfAChNC+8MpV8P+B+zctzwHOt6C9jekMWSmFzJ9g3M7BuWToP5QVukHMXHybvnyPU8iUCEkobSs4m8LIfvHs6X3Cn07niGGgtz8V2YBusknqlb6n+TY/YOA8MBJg5OUyU5KqYIVAl9EJuNT8EjxAcBD0ItAV0qEPrKHedtjzFzoT0BvP/TFJMML5A6LfRaUl0B5qZTC/BvNk/9MYry8FXZfDRg4of/BTP0DvG6EpnHUomf424x9+OLtOlddIHDRaD3sLWZ++WtEutaAHd+5bxRKOAOlEK6CYDn4o2AFwQpAaBiUjILSsVC+C5SNl0T8o4CTgsQ2mZJtsr5uqmCBxqG/RaZ4u6xLuAYiwyDdA23LoW2FJF7hWghWQu8GubA1wAzK/zSf3HHZNgTKJDELVUO4GkJV4C9RCN4Bn19JATKQ6YH+Juh9D/rek98MVsP4k2HX06FqWp54rv4bLJsPnatlGaYhz4W9pCRAyQ5IdW2/LwrHoNDPbvGpQvExp+aH8ikw5iTY7euyLYXQtxlW/0US4E0vSjFxSQPU7w9bXpV9pVsw6jCoGAZbnoJkK3SNlmNf2iRdi/lKYfQJMO4L0HCEJIBZcDPQ9jq0vAgtL8DWl6Xnl1y7DPCVyDJ8JTJppkTEfesg1c6qvZ5i4uhaaZOWTZohCaUZkPV2ktK0wEnI66JzNF3WyQjI9gghmQInI9/NEt6c148BHW+FZXt9EbAiyv/mJwTCy8/tbFuEV7D7yyoBFUgAChU7ipjpgmsoLiM7mbJlGT7Zl4ZfXu+ojZ6bZwSzdfUysm9Nn8wNixxRyX7f8OXHL1u+54KbVoS3YG07KfnuwNOVQim97suPCbr8jumXeGAgoRaCnDPwLGMrCpgu4cq6FP4eOC+EUlz0RcAX/XDzIDsuQ9HVdAZ6Y3IHW1YipSz/RgS4EP7ziPGdDyC+/jYaRyAIg/k5NCcO++7LTx65kx+XN3LajXDJpRoOoI1+hcnfOxbNMOUxYSoFiZic3AaSE7Ms5YJFOVksDBmyPcjqPAz8TyjKkXUVIwpvZjOlaKCpCapDVhFop5xTZxenR/HC/aBzuJCIfaB3TBlhIVADkXpItkDfGlUhv1RXTKaHfr/w2DZLVC1dikZNQ/mMVLHTBupN6j4I10NkJETHSCaobFeIjoSOlbDmT9D2mnSPpanXRQD0anBDkNyqHEIDwpK+OJOuFNdlwQRKVTJlVejXIemXRuaRcgjpYPRLZ7giI90mVUyXfdG3FnpXSWQLsn7DD4QRB8OwWVJk2PUedKyA1uXQ/ja0r1TENNtOWHXIU0wcXVU8PkOOlyb7xfBLgu6hvMYUxKXc3lHswLzweuB8MoMSGfsikoANLNRNS4bDjkkj91yg3wLlJ01T60MxBtnYeAPPg3cWTX0cOLuoH5SxquGX7dU0sLPMgZ3/5of+rqb6uRAXIBldTSvuiyzR1S1Vh3gx0zRw/LJ1G+p6IGyvf4f8X8vjLJBMgD+qmMjwYAmK8CRTke6T0h43qebizkKW+TLkfM4yOZqlmAcV89BzC3KFVDRdSXUMyTTkHLiremm6jP5i+JVRsibLczMq2VA++kNLhf7jtKmZMAbp1kHgoWHUlMBN/8OzE0zefqSRp27QaFyvSdX1yiZ2P+8YtExvfkcVUAnILT5hKkfsLqScPE30hkhu/lUMVFSEwiTAcGQarDcxeDG7yO9lyxcDrrPPF+mwaHJ3G6qBzlXyRslYMIdDIgHta6UT6sJ3K0bDiOnQMAMa9oKqsdC9Su5aDUs+l+qGWLsUG8fbZEq0Q1+HFNF6yGcj5ZKBiXdBy3vyA5oJegb8aWlY6wP8dVB/BAybCSItnT13vQOdyyG2iTyxVYja9SBpQ9rO94uLLEyPgPCpvt0ExlbQX5P1MSxIx6CnOd/uEqTRYDAF2mY5ViFN/mnWSrc9wREQrFPIJST9arY9AckN0vdgaHeI9YG1BrR+ICl9ihbyGSZgpaBtkXS4XVhvB+h5Fza8C+L3+XmTm35+CFRDxe5QNhaqJkkphz8CWo2UtGi6RDpOQhK6rKKOq85OhaMIoapUIZOYYw6zfazu6dkdZrYi2R1QIaiHXU+WY6vdW6Kt+JGCR/PfBGkRMLjI519eyg233sfjf/pNthNkJ2aJoBGQOz3NYMhjJASzP/8Vtra2/h97Zx4fRZH+4afnSEIuCIFASCAQEghJuMMll8ACQfHAjYqwiqJyiedyuK66oiKsK64XuMqhePxQcVEU8QIF14uEKxACIRxBgQA5OHLOWb8/umeYyUzCJEsIZOvh00ymq6rrreqefquqq+uL1Wpj8IC+LP7H0+gVePG1N1n23kcYDHpaNm/Gin88QUx0pLuNOuP5G7VQJT+CYwdRevgHtR5w9FjPuadz/Q3aXP7WfpMrP17Hs6+sAODxBycz6daxVepJ4Ydft/PQk4vYlX2AD96YT9p1I7QINtRXD9XVhp56fokqoThzCqs//YSnnn+ZvbmHSf/sbVJ6JqnPSXWo9mv1vPqzjTz1wpvs3X+Y9PVvk9Ij0YujVqr9bjKZuOP+J9m2ax/hYU358M3naN+uDSCY8/QrfLHhR+x2wcgh/Xj52T+jlOVr51vtTeQdzWfs7Q+QtfkDvt28hUfnv4bZbMHPz8g//vYIw4cO0OrLvee94JW3WL7qM/R6Ha88M4vRwwdo9WFTG7p2KC44y61THiPv93zat43ko6ULCGsWSlHxGdLufpSMndncOX4sry2Yo6Zx3EO9NS6UM+7fqzZqrG3UUYZ6plE4Y1OBAT8CgXLOhgZTkPQrppkWWhZFMs+qrsdVBtj8TtPzjrHoW46C2EHQcTBEas/gHEOGfk09h0TsNtUhlZxUb0DmcnWzlLt/t1aqNw2/IPXm6Rfk+bdOr7a87FZ1uNduVW+grvucw0Uuw0SO1p6iU51ocJg6nFtyDEq1IeqSY1B2ArqkQfc7oVmH82UQAs7lw4m9avmie0Ggl4lP4R0g7poLV7rVBPl74NhOOLpD3Y5nqg7QQUgYdBsH3W6CllFwYBXkvAuH3lE3ABS1NxvRExLugBbdILyr2pBwHf6qLIHiI1Ccd34zl52vP0cdOv62WaBpFHQaAc2ioWk0NItS/w5uCSd/ht++VoeAi7Kg5CBUHFRX0zAGQ/MksDSF37+BJhEwdAl0uef8sJ+ww/EMtXEC568Zuw0qzkLFaSgrVD/t1vOOyzH06HjWbbcAAWDXabONz8KpQsj7FfjVvc5v+RJOVh0Z0LlP5NIZ1B6K0Z/z0kiKJmsVVLvni0JoPQ2LNgyr9caUcvcemeNP19fVnQ7K9Zl/VU/t6KH4qeFWf+134Gj1WgDH6v8189HLfyM0JBghBGnT5rJ61SrG3zCanl3i2Pr1xwSGNOX1lR8w54VlfPju29pwtJ/Wa/LSZVR0EN5dkzYrBUsFNks5ep3LUL+hibo5e17asexWigtOMO+Vt9m6eQOKsNJ7aCrXXzuWsBDHTV0tf7uoDrz98kJeWPKWWg/CEa5z6S27zKo3lZIc3541K99k6uwnITwW2vRyL4NQh8eSBwaxZvCN6hKV4V0gPFm9Dh3Pnd3mBbjMjdGGkJevWktYs3AObNnIB598wdxn/sWHS1/k54zt/JS+m13ffwLYGXTdJDb/soOrB/ZyuQBsqHJSahlaNGvG52+9SJuIlmTtO8zo22dybOs35yfeKTrwDyL78HE+WLeZPXv2cfzkKf7whz+wP/tu9GiPLawmsFWy8NXXGTF4AI8+eC8LX1nOwtdW8fenHiUgJJBnnnyMrL25ZO3dD0Htzzt8R4/XblavaeeMftcJj44LWouP/ZI9k28Uztiyvy3+7EVg5GR5DGzww0/oORckKLEJbLoKWvVJp/0bMRi77vb+4/OvYUauTq++8xvauvo4DUJ7iOx1wViAWuambdTtYmDwh7a91M2B3Q6FB1WnHBoJ7fu7O9TwZ6DvPDj+Hzh3SHV4zZNUJ3EhAkKgTbK6XQxiUtXNgfmc1kPfDcVZ6ufZA5DyBPScrQ7HuqLoIKrfxbHFGzaLOspQWqBOvjOVgqk5hMe4vP6kfeoM2oSeQG1E4yI9X1MUdShQZwRDIASEA/Deu+/yyisvYzab6Ne7G489eBd/GHc3v2z8lOat2jF01A088cTjdOrUmdQxY+jXrx87duygU6dOvPPOOwQGVpn82LyAcybBuPueJCcnhyGDB7PktVfQIQgOa8GDM6ay7suvaRLgz9oPVtLKZVlLFUFoGKDosNrBrAtACY+B6F4Mu7m3M1b/4WN4b80XEBjmUdTDhw8zYcIErFYrqanadaE3suk/mcybN4/IyEh27tzJ+vXrSU1N9VIml3kheiNff/8jI0eNpnk7Vap15OgxfLU1l9tuu80t3/at1SFM3cpPoVlbaJXk/VyEREBwMLTpSpc2XbV8nlHnqVQ939qQqtvwqKKocY0B2GyhPProo2zatAmTycR9993nXFPalbXf/cpTTz0FEZ1IuzuWmX+dj2jZGaX5aSptOszNOiGEwIIfrRIGQ8vO2tCu6jAJ1Yb2W/ak59WJ2uiCiaSeLag0mTHhh39YpNpZMaqPANYuX8P42ybiHxhEhw4diIuLI317JgMGDFDjOWz79kc2bdoELSOZNGM2V199NX9/ZSlBwKCoRA7kvw3G39V5PXXF8Xy9rhNRa0mjcMZ+AX6oc/gCUKz+7BhajulUMK33KgQlfUm/p3/Hf9y9F+8mJfGOTgcR8epWHYoOooaq2+WEX6g667p1/4a2REVvhNBW6uZg7173m8sDV3umG3YLjJsBleUwx8sIx5g71e1MITyZ5h72yqYLmrV3714+/Ogjfvr5F4xGIzNmzGBz5nHmPvYE02bPp1+/fiQmJTFqdCp5eXnk5OSwfPlyBg4cyOTJk1myZAmzZs3yOG56ejrZ2dnExMSQmprKmrWfk5aWRllZGf0HX8385xcxZ84clq76lMcff9yrbaNHjyY9PZ0xY8aQdst4j9/78uXLGTNmjNe0Dz74INOnT+eOO+5g8eLFHrZlZWXRoUMHn8t07Ngx2rZt6/weHR3NsWPeNFQvPcuXL6dp06ZkZGRgMpkYOHAgo0aNokOHDm7xXMtgMBho2rQpRUVFDBgwgGHDhhEZGYkQgpkzZ553/IYAbf5AU/DT5jzo9GpD0U9thP3744/p2as3/lHuz1Idefbvf/43WF29nTx5kshI9XFDZGQkp075vECu7yiK+qjtElGP7ypcOsT6g4ABq74J6+76jeCfg2lSILA88DKD1zXH/6Yp0hFLJBeBjRs3sm3bNvr06UOPHj3YuHEjhw4d4p577qGkpIR//etfvPDCC874bdu2dQoD/OlPf+LHH3/0ety+ffsSGxuLXq/ntttuc8bz8/Nj7Fj1WWvv3r3dxAeq8vXXX5Ofn4/JZOK7775zC3vvvffYunUrs2fP9pr2p59+cvZab7/9dg/bXB2VL2XyNjG2qjKVO3bslGPjBDbysVGEnRKEUx7j4vHNN9/wzjvv0KNHD/r160dRURG5ubke8aorw4EDB9i7dy9Hjx7l2LFjfPfdd/zwww8+5e2QUHzjjTe8hte+3hoPjaJnbEhqCxuOkxsSRvJbrdl8ixUx/SMW9rkdguqoV/c/hrr4QT4mcrFSiD+x+BOPvpbLpAusWMgE9BjohA7f38cWmLGQjYVMrBxCRxh6ItBpm/p3C5RqLlt1WXoTggoE5SgEo6Nprey/UhDYEK98ibqirkBdZt+ofQIBgTX3dJu1cIYL3AUCasxXeEooCuyUlRdz9OjvgOBc6UmCQsDOORRFYKMYBR0CG4qisGVL7SQUFUVBINDpdVitVmy26iUUAwICuP7661m7di0jR6oSit9u+Ir5859m4+bVGPxPY8PIE39dyPovvgEUduzc4ZZnVYKC3B+jeLP1fJkE856eR1R0FJs3bXbGOXpUlVB01JegXNvKEJRhpxg7+dg4CsCTf13Cl1+oTj5j5/9pTjoEKwdxnGuBBTsl2ClDwcjku6awY8fOepVQbN68OStWrKB///4EB9ddQjG2YwcEgk8/+bSOEooRHMvfS+vIlpqEYjhWjuF43mvjFHbOavXlWDNf0e4R6lkQ2vNiBT90+KPKq/hr+y59A6BROOPiZscopxP7dU1Y9JEF86h9/BI63ufp6AILNo4gsGKgg3ZCaoeqflOAOl1W59wUl5dgbZShEICeprU62TZKMLGfSvZj5jd0BKAjGB3B6AlGRwg6AoByBCXoCEFPBBCqXX7np2QL7FgpwESudkz100QudjzftzYQjj8t8CMYIwp+VGCgFH86YCAZhS7YMWLmOGYyMPEfBOec6fW0w0BnDHTGSIL2dwIKAVjIxEImZnZgZgcmcrBhdU4cV5Vcqg7fKOgIR0dLrdbLnc5XUE7V6ZI6wjEQh56OGIjTNvVvHeHYOYmNY9p23O1vOydRCEJHGDqaoyMMheboCEJdBdiCjrboiHS7EtyxI1ymUwvnp+uUebVcON9psyEoQJCP4AR2KrBRgY1HsWBDXTOqptfdDC6OWV12QUcgCkHaPkW7Js6g6iCdRXunDwU/rdb9PL4r6Bg+Yhg33nAjDzw8mRYR/hQWH+VcSTEvvfAut04cRtuY1tx77118su6fWDjOb78d5cdfPmXAgG7836rFDBjUiZR+bdm+8ycUAlFQvEoo3jvlXuza+bRwADslWDmMnbMI/VG27fwGhSYoNHGTULRYLXyx/nMGDU7BSh7bd6QzdeojfP7VK7SIsDid3VPzb+Wp+apYt4VtDBiYxHsfPMfEP13LO+9/DNixkqXdF8qwcRgwYuMUv/32Gz/+8hn9B/Tg/VVvMGBQJ3r2CyR953Ln+S8uPstjj63j5OnNgI6vv1nH0wvuwEIWApPLdWLU6iEQHZEY6QEoPDd/Cc/NN6OKR5pRUF8ds1GmnX+BoBIzv2NCnc+w+K2Zzmupgp0o+KMjUHPaFmeja/To0bz++usMHz4cg9FAzv5s2kS1ZN78P/O3+fchKMPEAa69/mreWrmUfgN6sfrjNTVKKD740IP06deLbTt/RFCJHTN5eUcQWDCTx5kzp7nm2tt4esEMUgYGYWY7oHDNuDiuGbcKx69c1ySJOyfMZvojI8g/XsD+3D1079sUM4e0O6YNQSXXXt+Pt1cuZvajd7Jy5duMveEqbOTjkMqwUY4dM2bO4Gim+4qi/a9o928/EtDVwSfUlkbhjH++VfDl6UBW/dWCLryQXH0iepdbuOA0JuZj4wR2jNixY6MUG0VYOYqNPM7f3BTNgcShIwY7gZipxMRJrBRjpCVGmmHEgA4TgmPYOICNfHBfxhyrtkd7u9MtBwOhGInEj3j86Iwf0RiJQsGoOUfV+ZrIwUJ+PdWcgoFA1Lno/hgwoseGggU7JqwIrBRhpYgKqr7hewQ9m9x0WY3oCKAFTeiHQiuslGChgEoOYuEHbJjc3tI6/6aYUuPPxUgr/InBn+b4oceAGTiNQjN0tEEhyHlDU2/Q6qfgHFYOYuUAZn6mgg88SuGtTtSGThh6wrBzCqvWUKlpyFBUs4Fru9z9Dbba8zBQ6fLGkKJtOm20wKA1/tDstGgNFYvzzRvcwl3ttKJq1njOXlY4X5b2ifD4s5MZPepa7HaB0WhgwYsPsS0jmw0/LUOv1/PJv7/jrbc+Y8iwFDp36cA7K7/gvqkLiIuP4e7p47BwHFWo04COptg4x4AB/Zn76Cyydu9m0JBeXDuuPSayUZ3xGW1+rsCOBTMFbnV5uuws465/CJPJgs1m4erhKdwz7WrsnOYvs/9JWWkFE27+CyBo2641n3z2olYexXnzfuHlOUya8BivvvwhN/5xOAA2KrFTicCKjSJt3wkSunRg5cqVTJ/6Z+Li23Lv9Ps1p6nDITnarHk4f3niXq7qow55P/bkFJo2D8KOlaefXErvlO7ccP0YtmZk88dx93D69BnWfb6BeX97jqw9v2rXb6DWlDZhx6o138x89sn3zLr/BQoLTnPTtQ/TrUcnPv96CYqz0S0QWPn0k2+d8cZeO9YZ70/39Cc3L50evboghKBFyzA++PQF5yiYo14n3j2Ee27fSHxcHGHNQ3nngxeoJJfr065iw3dfkNy1C4oiGJl6FX+4LooKMt2uGysF2khZIa+9tpyDB47w3DNLeO6ZJQCs/eY1IiKa43gvUAESktpw0y0j6JV4EwaDnhcXzwZ9ORbKue+eZ7l72k30Sknk4Ucnccctf+Gt5Z8R3a4V765eqMmJChLbX0fJuTLMZivrPt3Mum/eIzGxi3NETXE2hFWdJk2WQ/s833kR2LBju2S95Eax6McG0xlGGgNQKGOLLpg+Lq0YM6s5x92YKPG43Z9fvCkEHS2wEEAlJVRSgplyLC7OVdHiV12OQAGtD6K2ca1au9f1lXbtbUEc8y2tWjxXh1QVHX6ac7Siw4RDvsL17ZGql4i6LwC7s/dUvXNwOFDXm5oqTqYO16jxrdipwPFjcdh7vk8XjB0jVsqwc369XNfXS6tDjx4DARgJwo8QjARrDZQQjDRDh5FKDlDBb1RQSCUVbnXqeJVbjx8GorUedzft7zD0NENgw8opLBzHTLrWEz+GFXUVNoGCHiMGraZVd2bBQCVGVLk1ddmVUGw0w0YgVvRYsWKlEgsl2CnFrvVUfEGHET06dNjQY3VpzOgwEoGRGPzohJFE9MSj0B6FICrZzZG9bYjrEu50EOfruubGjDfcz7u7+pDw+Ov81XO+14DWDHDnfFo9h/PyGTf2AXZkfaIdwaZdm+djeXtl17UkOgzo8NdGfvRaL8+MHZOzDlztcrXkYtzZFPTa70Jt6OTl/c5NY6exNevfCOev2DW+I3dfj3/+s2o9uB5Zhx86gtDTFB1NUN/BK0UdhXL89pqgEIpCsOZcKlCHwE3ab9m9Ttzz1mll9EMdGVSH0u2YEQgvV4K73e7Hcaztrd4tz58VA8I50mLU6lVbCEm7czqG7nG7RgK1kQGDlr9Z26za8a0uzSr1HqgQCDTRalFdeVwVS3S/usCIt1K41pCOeJQqeuW+8j+36McRfyNQykv4Ox2xjd85yw1UsAMB+DOYAG7DhoKVAszkUUkuZn7HTCEWDjuPp9NOfQjnnajr6RE0w0YUVppiBkycpZJjlHEGPc0IpDfN6UYTEggkHiPBCEpRZbYPY2c3NnZhYTc2Ktx60IDmeM3oMOMYuFQdaFN0RKGnPXpi0dEWhWjnp0IbHEPs6oV6GkER6lBkEXYKsHEEsKGjHTrao6cdCq2hhqFzddjptPZcqxg7JRjpioG2WrjAykmtJ6/26MGEAX/N8Qj0WNBRgZ5SVPGyMy6lNiOoAOeNRXVuTWhFIAlaudpgIxQT5VRQQAWHsZCHhRNUkoeNQwi+rPYaUetPj4FWBBKPgS7oCcRCPmaOYuIYpRxzNmLcOadtoCcMI5EYiacJkegJQ0cgOgzAMWA/kIXCWa02g7VRGDddKGwEaGMQJqyc1fI9oW1bADDQAgMtMXEYQSV6vsROiNZ4DEZHkDb8rNNuvqUISlCfQ5YjtLEYR8NNHV4PR0e4tr9Ci+tYNtNzCSfHbVghAJ12o3fvfavn6/zQ+fkheQMlKOi0Zo4d1zVL1Qcmds1BW7CjDqHq0KNDr9nrGF8q0za0c3DeSnfH5bBb0RqV/jgUcNF0ks5/Oh4j6Tn/OEmnOViz5hgcTl/9rjYCyrUcmmgO0t+Zlw4/XOczCI+msND+WVwciuux1XpU9Zz8MaJDwY5OG6pGGxFybfAohAKRKDRF4fzrVd5+yer1UIn6OEevOSz/C/b8VHvPoa447Rghquq2XMfI9Np3dTUlhSbap2/uxvFMHWza9VazI1Tr2QzOR1UV2v3Wsayuv3ZHD9XscKzyZLhg2S8ljaJnLBBsxsRQ/BGUcY6ZlPEuduxAFDYGUsqvmPnNLZ2BFvjREX9tC6ALgfTBn45ajEoEJcA5rQVqRUdHFO1mVtUGG2dr9TxYveh+w85up4O2cxIdseiJQaEdCu1cnG39rwJzJaLe1ndgYR1mvsRKBjZUeXU9wfhzI378CT0jarwhOJ6nWziGmaNYOeXifNtgpLXWQ/PNHhtfYOc4OhLQkYiOLtp5VDziWynCwnEv2wn8iSWI/uTvTSCxS1cf60R9pq32nmwoNNOc0uWJ2njUe/3tCBzLwno+4BBu+3QohKDecC/+TfZ8w6T+buBqedxVo86fywqt4WTXnHBQgziT842w8/NhLien5kBo83ccjceG4H9vbWrAThmlvMA5nsOCGQtGKgnBSjEKfoQymiAGOh2vPx3RE3rR8pdcPghOY+M7wIieUVpL+MrH2w9bIpFcvvzPDVNX8D2nuI4KyjChtpEVIISrCOMWmnE9+kb6iovEE4UwDPyxoc2QSCQSn/HJGSuKkgq8jDomsUwIsbBK+ERgrva1FJguhHCfWlePlPIJRdozpRAG0px7acoNGPBddF4ikUgkkobigs5YURQ9sBgYCRwFMhRF+UwIke0S7TAwVAhxWlGUMcCbQD0u3OtOGPOwc4rmvIiRi7T2skQikUgklwhfnmz3BQ4IIQ4JIczAB8ANrhGEED8LIU5rX38Foi+umTVjIIxWfCAdsURyBbJp0ybnkpd1JTU1le7du5OUlMS0adP5Lxn/AAAgAElEQVSw2dSZ5C+++CKJiYl069aNESNGcOTIEZ+O51hd6r9h5cqVxMfHEx8fz8qVK73G+eGHH+jVqxcGg4GPP/642mM99dRTzmVGV69eTVJSEjqdjprm3fgarzpMJhO33norcXFx9OvXz20p0jlz5pCUlESXLl144IEHvC5jmZeXR3KyKuzy7bff0rt3b7p27Urv3r09lit1ZcGCBcTFxdG5c2e+/vprr3GKi4sZOXIk8fHxjBw5ktOnT18w/bZt2+jatStxcXFuNvt6DuobX5xxFPC7y/ej2r7quBtqeMdEIpFILjIfffQRmZmZZGVlUVBQwOrVqwHo2bMnW7duZdeuXaSlpTFnzpw65+Fw8L5QXFzMvHnz2LJlC+np6cybN8/NYTho164db7/9NhMmTPD52MnJyaxZs4YhQ4ZclHjVsXz5csLCwjhw4AAPP/wwc+eqTyJ//vlnfvrpJ3bt2kVWVhYZGRls3ry5xmO1aNGCzz//nN27d7Ny5UqP9b8dZGdn88EHH7Bnzx6++uorZsyY4bXeFy5cyIgRI8jNzWXEiBEsXLjwgumnT5/Om2++SW5uLrm5uXz11VdA3c5BfeCLM/b+ypq3iIoyDNUZz60mfIqiKFsVRdlaUFDgu5USieSy4b333qNv37706NGDqVOncuTIEeLj4yksLMRutzN48GC++eYb8vLySEhIYNKkSXTr1o20tDTKy73rE587d45x48aRmJjItGnTsGsazcHBwfz1r3+le/fu9O/fn5MnT3pNHxqqvhlhtVoxm83O9aOHDRvmlGzs378/R48e9Zr+8OHDDBgwgD59+vDEE08492/atIlhw4YxYcIEunbt6nOZvv76a0aOHEnz5s0JCwtj5MiRzpu/K+3bt6dbt27odL6/ftOlSxc6d+5c53g2m43Zs2fTp08funXrVq1ow9q1a5k0aRIAaWlpbNy4ESEEiqJQWVmJ2WzGZDJhsVho1aqV12M46Nmzp3ON6aSkJCorKzGZTF7zHD9+PP7+/uclFNPTa7Rt0qRJfPrppzWmz8/P59y5cwwYMABFUbjjjjucaepyDuoDXyZwHQXaunyPBo5XjaQoSjdgGTBGCFHk7UBCiDdRnyeTkpLSMO9USSSNgWUPweGdF/eYHXrAPS/VGGXv3r18+OGH/PTTT+clFDdvZu7cuUybNk2VUExMZNSoUf+dhOKaNeclFPv3Z/78+aqE4tKlvkkopqV5hEsJRZV6lVD0gX//+9/07NkTf3/P9Z7/WwnF6tIbjUaio6M99l9O+NIUyADiFUXpoCiKHzAe+Mw1gqIo7YA1wO1CiP0X30yJRHI5ICUU60tC8dLRmCUUq0t/OZ8PBxfsGQshrIqizAS+Rn21aYUQYo+iKNO08H8BTwLhwBKtgFZvLzVLJJKLxAV6sPWFNwlFgPLycucQcGlpKSEhqpJQzXKDvksoAuj1+jpJKG7YsIH58+ezefNmZ2+sqlygN1sd1E5CUS1TdHQ0mzZtcsZxlVD0BW/2XYi77rqLHTt2XBESih07qqscfvLJJ3WUUGxFfn4+kZGRmoRiBEC16aOjo90eUVR33AZFCNEgW+/evYVEIvGd7OzshjZB7NmzR8TFxYmTJ08KIYQoKioSeXl5YubMmWL+/PnivffeE9dee60QQojDhw8LQPz8889CCCHuuece8cILL3gc8/vvvxcBAQHi0KFDwmaziVGjRomPP/5YCCFEUFCQM97q1avFpEmTPNKXlJSI48ePCyGEsFgs4pZbbhGvvvqqEEKI7du3i9jYWLF///4ay3XdddeJd999VwghxJIlS5z5fv/9987y1KZMRUVFon379qK4uFgUFxeL9u3bi6KiomrznzRpkli9enW14X/729/EP/7xD7d9Q4cOFRkZGTWWy1u8N954Q9xwww3CbDYLIYTIyckRpaWlHulee+01MXXqVCGEEKtWrRI333yzEEKIDz74QIwYMUJYLBZhNpvF8OHDxWeffeaR/vDhwyIpKUkIIcTp06dFt27dnOe1OrKyskS3bt1EZWWlOHTokOjQoYOwWq0e8WbNmiUWLFgghBBiwYIFYvbs2RdMn5KSIn755Rdht9tFamqq+OKLL9yOeaFzUBe8/WaBrcKLT5TOWCK5QrgcnLEQ6s24e/fuomvXrqJXr15i06ZNol+/fs6b3rhx48SKFSvE4cOHRZcuXcTUqVNF165dxU033STKyso8jvf999+LYcOGiVtuucUZ32azCSF8c8YnTpwQKSkpomvXriIxMVHMnDlTWCwWIYQQI0aMEBEREaJ79+6ie/fu4rrrrvNapkOHDon+/fuLlJQUsWDBghqdsS9lEkKI5cuXi44dO4qOHTuKFStWOPc/8cQTYu3atUIIIdLT00VUVJQIDAwUzZs3F4mJiV6P5eqM16xZI6KiooSfn5+IiIgQo0aN8pqmung2m0385S9/EcnJySIpKUlcffXV4syZMx7pKyoqRFpamujYsaPo06ePOHjwoBBCCKvVKqZMmSISEhJEly5dxMMPP+w1f1dn/Mwzz4jAwEDneejevbuzQVeVZ599VsTGxopOnTqJ9evXO/fffffdzkZFYWGhGD58uIiLixPDhw93a+hUlz4jI0MkJSWJ2NhYcd999wm73S6E8P0c1IXaOONGsza1RNLYudLWps7Ly2Ps2LFkZWU1tCkXjcZYJkn9UZu1qRt2LrdEIpFIJBLpjCUSSf3Qvn37RteDbIxlklweSGcskUgkEkkDI52xRCKRSCQNjHTGEolEIpE0MNIZSyQSiUTSwEhnLJFIGhQpoSglFF2REooSiURyhSIlFOserzqkhOKlRTpjiURSK6SEopRQlBKKFx/pjCWSK5W/Xu25rV+ihpnKvYdvfFsNP1foGeYDrhKKO3fuRK/Xu0koLlq0yCmhCJCTk8OUKVPYtWsXoaGhLFmyxOtx09PTWbRoEbt37+bgwYOsWbMGwCmhmJmZyZAhQ1i6dGm1to0ePZqIiAhCQkLqLKGYkZFB69atPWybP38+2dnZPpfpSpFQzMjIYOnSpRw+fNgjni8SipGRkYwePfqiSij6Um81SSh6S3/s2LFGIaEokUgkgJRQ9LVM3p6hXi6SfVJCsfbHvRRcUEJRIpFcpszfVH2Yf2DN4aEtag6vBiElFKWEopRQrB+8qUdcik2qNkkkteNyUG2SEopSQlFKKPqOlFCUSBohl4MzFkJKKEoJRSmh6CtSQlEiaYRICcWGpzGWSVJ/SAlFiUQikUiuIKQzlkgk9UJjlBtsjGWSXB5IZyyRSCQSSQMjnbFEIpFIJA2MdMYSiUQikTQw0hlLJBKJRNLASGcskUgaFCmhKCUUHRQVFTFs2DCCg4OZOXNmrW2G6ut948aN9OrVix49ejBo0CAOHDhQp+PXF9IZSySSKx4poVj3eNXREBKKAQEBPPPMM27rm9eGmup9+vTpvP/+++zcuZMJEybw7LPP1imP+kI6Y4lEUiukhKKUUKwvCcWgoCAGDRpEQECAR9g333zDgAED6NWrFzfffDOlpaUecWqqd0VROHfuHABnz5697NamlkIREsmVyPsPwW++CQj4TLseMPGlGqO4SigajUZmzJjhJqHYr18/p4RiXl4eOTk5LF++nIEDBzJ58mSWLFnCrFmzPI6bnp5OdnY2MTExpKamsmbNGtLS0pwSivPnz2fOnDksXbqUxx9/3Ktto0ePJj09nTFjxtRZQvGOO+5g8eLFHrZlZWXRoUMHn8t0pUgomkwmBg4cyKhRo9yUqcA3CUUhBDNnzrxoEorVUVhYyLPPPsuGDRsICgri73//Oy+++CJPPvlktTaDe70vW7aMa665hiZNmhAaGsqvv/7qc/6XAtkzlkgkPiMlFKWEYn1KKFbHr7/+SnZ2NgMHDqRHjx6sXLnS6/P/mur9n//8J+vXr+fo0aPcddddPPLII7Wyob6RPWOJ5ErkAj3Y+kJICUUpoViPEoopKR5LNjttHjlyJKtWrXLb72u9FxQUkJmZSb9+/QC49dZbSU1Nrb4yGwJv6hGXYpOqTRJJ7bgcVJukhKKUUKxPCUUHb731lrjvvvuc30+dOiXatm0rcnNzhRBClJWViZycHI901dW7xWIR4eHhzjTLli0TN910k0+2/DdICUWJpBFyOThjIaSEopRQrF8JxZiYGBEWFiaCgoJEVFSU2LNnjxBCiI0bNzrPc9euXZ11WJXq6n3NmjUiOTlZdOvWTQwdOtRZnvpESihKJI0QKaHY8DTGMknqDymhKJFIJBLJFYR0xhKJpF5ojHKDjbFMkssD6YwlEolEImlgpDOWSCQSiaSB8ckZK4qSqihKjqIoBxRFedRLeIKiKL8oimJSFMVzeR2JRCKRSCTVcsFFPxRF0QOLgZHAUSBDUZTPhBDZLtGKgQeAG+vFSolEIpFIGjG+9Iz7AgeEEIeEEGbgA+AG1whCiFNCiAzAUg82SiSSRoyUUJQSig6khGLNRAG/u3w/qu2TSCSSywIpoVj3eNUhJRQvLb44Y28LttZppRBFUaYoirJVUZStBQUFdTmERCJpYKSEopRQlBKKFx9froCjQFuX79HA8bpkJoR4UwiRIoRIadmyZV0OIZFIHCy42nPbuEQNM5V7D//P22p4SaFnmA+4Siju3LkTvV7vJqG4aNEip4QiQE5ODlOmTGHXrl2EhoayZMkSr8dNT09n0aJF7N69m4MHD7JmzRoAp4RiZmYmQ4YMYenSpdXaNnr0aCIiIggJCamzhGJGRgatW7f2sG3+/PlkZ2f7XKYrRUIxIyODpUuXcvjwYY94vkgoRkZGMnr06Esqobh9+3ZSUlJ48cUXa7QZvEsoRkdH8+677/Loox5zkRsUX5xxBhCvKEoHRVH8gPHAZ/VrlkQiuRyREopSQlFKKNYPF5xNLYSwKooyE/ga0AMrhBB7FEWZpoX/S1GU1sBWIBSwK4ryEJAohDhXj7ZLJP/b/GVT9WH+gTWHh7SoObwahJRQlBKKUkKxfvCmHnEpNqnaJJHUjstBtUlKKEoJRSmh6DtSQlEiaYRcDs5YCCmhKCUUpYSir0gJRYmkESIlFBuexlgmSf0hJRQlEolEIrmCkM5YIpHUC41RbrAxlklyeSCdsUQikUgkDYx0xhKJRCKRNDDSGUskEolE0sBIZyyRSCQSSQMjnbFEImlQ/pclFH21ry4SisXFxYwcOZL4+HhGjhzpVTUK4KuvvqJz587ExcWxcOFC535f87nzzjud8o8TJ06kc+fOJCcnM3nyZCwW76q6hw8fpl+/fsTHx3PrrbdiNpu9xquuDl977TXi4uJQFIXCwsJqbbuSkM5YIpFc8VypEop1sc9XacSFCxcyYsQIcnNzGTFihJujdS3Tfffdx5dffkl2djarVq1yCmLURYJx4sSJ7Nu3j927d1NRUcGyZcu8xps7dy4PP/wwubm5hIWFsXz5co84NdXhwIED2bBhAzExMT7bdrkjnbFEIqkVUkLx4kko+mqfK75KKLpKIE6aNIlPP/3UI056ejpxcXHExsbi5+fH+PHjWbt2ba3yceWaa65BURQURaFv375eyyOE4LvvvnMqa1VnW0112LNnT9q3b18r2y53LigUIZFILkPWPATHfBMQ8JmoHnDTSzVGcZVQNBqNzJgxw01CsV+/fk4Jxby8PHJycli+fDkDBw5k8uTJLFmyhFmzZnkcNz09nezsbGJiYkhNTWXNmjWkpaU5JRTnz5/PnDlzWLp0KY8//rhX20aPHk16ejpjxoyps4TiHXfcweLFiz1sy8rKokOHDj6XqS4SijXZVxdOnjxJZGQkAJGRkZw6dcojjjc7t2zZ8l/nbbFYePfdd3n55Zc9woqKimjWrBkGg8GZp7e6uZxlKOsD2TOWSCQ+IyUU60dC8UL21Re1tdNXZsyYwZAhQxg8eHCd86wv2y5XZM9YIrkSuUAPtr4QUkLxokso+mrfhagqodiqVSvy8/OJjIwkPz+fiIgIjzQOmURXO9u0aVOrfKoyb948CgoK3DSLR48ezcmTJ0lJSWHp0qWcOXMGq9WKwWCoNs//VobyisObesSl2KRqk0RSOy4H1SYpoXhxJRR9ta8uEoqzZs0SCxYsEEIIsWDBAjF79myPOBaLRXTo0EEcOnRImEwm0a1bN5GVlVWrfFzlH5cuXSoGDBggysvLayxPWlqaWLVqlRBCiKlTp4rFixd7xPGlDmNiYkRBQUGNeTUkUkJRImmEXA7OWAgpoXgxJRR9ta8uEoqFhYVi+PDhIi4uTgwfPtzpyI4dOybGjBnjjPfFF1+I+Ph4ERsbK5599lnnfl/zcXXGer1exMbGOsszb948r2kOHjwo+vTpIzp27CjS0tJEZWWlEEKIjIwMcffdd1+wDl9++WURFRUl9Hq9iIyMdEtzOSElFCWSRoiUUGx4GmOZJPWHlFCUSCQSieQKQjpjiURSLzRGucHGWCbJ5YF0xhKJRCKRNDDSGUskEolE0sBIZyyRSCQSSQMjnbFEIpFIJA2MdMYSiaRBkRKKUkJRSihKZyyRSBoBUkLREymheGUhnbFEIqkVUkJRSihWh5RQrDvSGUskVyqvXu25/WeJGmYu9x6+5W01vLTQM8wHXCUUd+7ciV6vd5NQXLRokVNCESAnJ4cpU6awa9cuQkNDWbJkidfjpqens2jRInbv3s3BgwdZs2YNgFNCMTMzkyFDhrB06dJqbRs9ejQRERGEhITUWUIxIyOD1q1be9g2f/58Z4/RlzJdyRKKF0Om0CGhmJqa6hEmJRS9I52xRCLxGSmhKCUUfUFKKNYeKaEokVyp3L+p+jC/wJrDg1vUHF4NQkooSglFKaFYP3hTj7gUm1Rtkkhqx+Wg2iQlFKWEYlWkhGL1SAlFiaQRcjk4YyGkhKKUUHRHSihWj5RQlEgaIVJCseFpjGWS1B9SQlEikUgkkisI6YwlEkm90BjlBhtjmSSXB9IZSyQSiUTSwEhnLJFIJBJJAyOdsUQikUgkDYxPzlhRlFRFUXIURTmgKMqjXsIVRVFe0cJ3KYrS6+KbKpFIJBJJ4+SCzlhRFD2wGBgDJAK3KYqSWCXaGCBe26YAr19kOyUSSSNFSihKCcXaSihWl14IwQMPPEBcXBzdunVj+/btzjSTJ08mIiKC5OTkasvSkPiyHGZf4IAQ4hCAoigfADcA2S5xbgDe0V5o/lVRlGaKokQKIfIvusXVIJSfPPbZCMUgujLzmp959UvP96ktNMNPJPFa5FHuO+H5IzARToBI4IuAU1xjyvUILyOCYBHPDt1xeojDHuFniaSZiOWgcpRYPI9/kmhaixhOKEdohae6ySFi6CiiOaMcoimeVblT6UBPextKlVyC8FwEfr1/PNdWRlCp7MOfIo/wxa1jmJkfjVnZg5EzHuH3j1F4bf1VWJXd6DnnEa4IdX1em5KJjtKqoSjiKi18BzqqKtvoUMQAAOzKNhQqq4TrUUR/AISSAVT9sRpRRF8tPB2o+qP3QxF9tPBfAXf5O0EAOtFbC/8FsLuF2wlEL3pq4T8Dokp4MHrRXQu/RNfel0GIslItfwP6lADKt5pp4lE3YMOIIcWfyq1m/L2EWzFiTPHHstWEwaPuwIQfASl+WLea0HsJr8CPwBQ/bFsr0WH1CD+r+NOstxH71goUPKUHC4x+RHT3w761ApFTAWetiK3nr6Hfm0K7+GDE1nKqnhsAJUV1lo7wDx9dQWhwKEIIbp77J1avXs348ePpEdiFjDc3ERgQyOsfL2POPY/wwYKVLunLqHpuXXENt9ls6PV6QEFJCaohvcLpWBPz5s0jY+kmFEUh5fYhXNd2OGGhYW7pewQmeLHvXZSUQO34ap2I42ZEExNiaylJdGTNmjVMnToVkV2O8Pjt6VBSAnls7tMM7zyIRxd8wsK3F7Hgoaf5+/3PINCjS2nCqUwzzSsruO+eGXzz2lqiW0XRd9JQxsaOIvmWXrRTOvPvee8ybcGDbvl4XHuFFsTBSsTWUib0vYm3H1qOIcWfW1PHs/SJxUxPu8fNOitG5j4/l/tvmMnEUeOYtuBBlj25xBnPce2d2pjPvMeeIuOdzW51GBDairnPz+XBG+7jtlE3uaVf/9PXZG/bT25uLr+8/QPT75jKr29/D8Ck/rdw3/DJTHxKXba0umvT9dpznIdLgS/D1FHA7y7fj2r7ahsHRVGmKIqyVVGUrQUFBbW1VSKRXAa8t/4DhkwaSI8ePZj+3EyO5P9Gp5t6UHhGlVAccu8ovvv1W/Ly8khM68GdT02h+239uXnunyivrEZCsayEm2bfRtItKUxb8KBTQjFkSAR/XTKPHhMGMOCuYZws8mx0AoQGaxKKNitmi4uEYspQAgM0icKufTh6yrvqz+FjeVw1eTh97xjKE68/49y/adsPDJ92DRMfn0y32/qRd/wIXdJ6OiUUb5470WuZnPJ/TZsTFhrGH/oN46tfNnjEG5YyxCf7XOnSIcEnacNvN37BpLETAZg0diJrN63ziJO+ZytxbWOJje6An9GPW0f+kc82q/E6d+hC5/adLpiPK9cMHO2UUExJSvFaHqFJKP5x+E2qbddOYO1mT9u++fVb/tBvmEcd1pR+7eYvGH/NRBRFoX/XvpwpOUN+4QkAhvQaRPPQsFqV51LiS8/Y2+rpnk3BC8dBCPEm8CaoK3D5kLfPOHpprjgK99r6q7ym8dM+Z+ZHA9Ee4QHa57WVEYDnIuuOgaye9jaA50LnzbTPjsL78R1Cba1FDOApkt3RcRwRC8R6hPd02CEcTwjcuVb7DBAJHmEAM7VPP5HkNfw17dMgunoNd+DoIVYf3rPGcEcPtTocPdzqw/teILy/5z638AEe4Xq3cM/rxz38El17e/eidFGvOv03D8G7O6mu3W4A2Hv+OFUxauFG152tesCol9zyN6T4A/7OKHv37uWjjLX8svNnjEYjM2bM4IfTW5n75KNM/9cs+vXrR2Lfrtx03zXk5eWRc2Q/y99fwcCBA5k8eTKv//oOs2bNcv6adClNUEqbkJ69jezsbGJiYkhNTWXr7m9o3zmNsooyBowbwnMr/sGcOXNYlvF/PP744057XHsuo0ePJj09nTFjxjglFF3DV7y9ijE3j3X2itVwtYf60NOPMX3WTO644w4WL14MH2rhnZuQvncbWVlZdOjQQStTLsunvOVRJleObVLl/xx5te3ZgeP+RW55q/mf/37evkCPcGWdH0qwv2f6xECPfQ6KigtokxoHQBviOHWuECUl2HntR3T344fc07RNan/ezr0d2bJlCwDNehsBI4To3fJxXPuBKX6AH7QwonQMcIYbUCUUP9i0ipdfftnDvnOFhTRr1owm/dW6b9uqE8dePOGM57j2Tvifol2vWI86rOhQQrNmzfDvH+yR/rj5FAlDVYUtXUoTouPacbzFGdqkqPWg5AVhCFCc4d5o56z7S9crBt96xkeBti7fo4HjdYgjkUiucKSEopRQ9IX6lFCsKX19ledS4EvPOAOIVxSlA3AMGA9MqBLnM2Cm9jy5H3D2Uj4vlkj+59B6sJcaISUUpYRiA0sotmjRotr0dSnPZYM39YiqG3ANsB84CPxV2zcNmKb9raDOuD4I7AZSLnRMqdokkdSOy0G1SUooSgnFqjSEhGJ16detWydSU1OF3W4Xv/zyi+jTp4/bMQ8fPiySkpJqtO1iIiUUJZJGyOXgjIWQEopSQtGdhpBQrC693W4XM2bMELGxsSI5OdmtETF+/HjRunVrYTAYRFRUlFi2bJlX2y4mUkJRImmESAnFhqcxlklSf0gJRYlEIpFIriCkM5ZIJPVCY5QbbIxlklweSGcskUgkEkkDI52xRCKRSCQNjHTGEolEIpE0MNIZSyQSiUTSwEhnLJFIGhQpoSglFKWEonTGEomkEfDRRx+RmZlJVlYWBQUFrF69GoCePXuydetWdu3aRVpaGnPmzKlzHg4H7wvFxcXMmzePLVu2kJ6ezrx587w6w7rYl5yczJo1axgyZEiN8RYuXMiIESPIzc1lxIgRbo7WtUz33XcfX375JdnZ2axatYrs7Oxa5ePKxIkT2bdvH7t376aiooJly5Z5jTd37lwefvhhcnNzCQsLY/ny5R5xaqrD6tJ/+eWX5Obmkpuby5tvvsn06dOdx7vzzjv56quvfC7LpcaXtanrhW3bthUqiuJbM9U3WgCFF/F4/8vIurx4XLS6/Pbbb7vabDZP8eBLzGeffaZ///33jVarleTkZPuUKVMs9957b8B7771X0axZMyZNmhQwdepUS/v27e3Tpk0L6Nq1q23fvn36mJgY+4IFC0xNmrir5Rw8eFB3/Phxv2HDhokjR47oevXqZXvyySfNOp2Ovn37Bk6YMMHyww8/6P39/ZVXX321okWLFtXaZrFYKCgo8P/tt9+sWVlZtpYtW3Lo0CEAwsPDdTk5OX5ZWVlVxbP5/ffflblz5/rbbDauuuoqm91uN2ZlZZVv2bJF9/rrr/u1bNlS5OTk6JYsWVLpS5nWrVun79mzp/748eNmgJ49e/q98cYbtrFjx7p5dF/tO3HihDEwMFBkZWVZQXWipaWlAbm5ueaAgABPwWfgww8/bPLWW29VZmVlib59+yp33XVXwO23316hpTfo9Xrrjh07dBEREcby8nLT/v37GTJkiPH1119n6tSpFl/zKSoq8svLy7NlZWXZ2rVrx549ewCIiooybNu2TcnKynLrHgsh+OabbwIfe+yx8qysLAYOHKhbsmSJcfDgwSZf6vDaa6+1VZd++fLlfkOHDrXt2bPHFhwczIkTJ5p89913lREREaJ58+YcPXpUqaioCMjKyqrwVpa64KhLb2EnTpwwJCYm7q6y21OijwZ0xkKIlhfzeIqibPW2qomk9si6vHhczLrMzMzMS05OPu/YV/T1FLVNuKmYqx4twFyi48o5DMwAACAASURBVL0RnrqaXf9USJ8HiijNN/DRDR3dwian51zIhu3btwds2LAhevv27Xv8/f3Fn/70p3a5ubllDz30kPLcc8+F9unTp6xLly4B06ZNO5KTk+N35MiRrm+++eaBUaNGld18883tP//884qnn376pOsx8/LyQvbs2RO/Y8eOPZ06dTIPGTIkftu2bYV33XXX6YqKit7Dhw8/smzZsrOTJk3qtn79+jPPP/+8VxGaQYMGxe/atSto6NChZx955JHDBoP77e35559vN2rUKEtycrJH+gceeCBuypQpJ2fOnFm0YMGClkB0cnLyXs22uB07dmQnJCSYfS3TRx991Kpjx446R16xsbGR5eXl9uTk5JNV8/bFvsDAwDbBwcE21/Q6na5zVFTU78nJyV5FoouLi3sMHz482/H99OnTPZKTk/cCZGVldUlOTt6bkZER1q5du9Dk5OQjAAkJCc23bNkSnJyc/Juv+fj5+bUPDw8/m5yc7Oz6m0wmZf369Qkvvvji78nJyaWu8fPz8w2hoaEJPXr02AsQEBBgfPrppzs5bLtQHbZo0aKouvTFxcVxPXv2POHIs02bNp0MBsNRh+1Go9FPp9PFV83rv8FRl97CbDZbC19//3KYWiKR+MxXX30VkpWVFdi9e/cuCQkJiT/++GPooUOH/B955JHC0tJS/dtvv91y8eLFTtmc1q1bm0eNGlUGcPvttxf9/PPPXh/Gdu3atSwxMdFsMBi45ZZbiv/zn/8EAxiNRjF+/PizAElJSfYjR474eUsP8OOPP+aeOHEi02w26z7//PNQ17AlS5Y0z8zMDJw3b94Jb2m3b98efO+99xYDTJ06tcg1rFu3bmUJCQnOh5q+lMnbMsM1SfldyL76oho7/+s1kidNmtSuf//+pampqaVVw3zNs7o6rCl9bev9cqLBesYSieS/pKaerF+Ivcbw4EirLz3hqgghlJtvvrlo8eLFx1z3l5SU6E6cOOEHcO7cOX1YWJgdvMsNfvfdd0EzZsyIAXjiiSeONW3a1F6dhKLBYBA6ndpn0Ol0WK1WRRseTwRITU0989JLLzm10wMDA8XYsWPPfPLJJ83GjRt3DuDTTz8NeeGFFyL/85//5DRp0kQA3H///VHffvttU4B9+/Zla8f36oQCAwPdhmd9KVN0dLRl8+bNIY44x44d8xs6dGiJt+P7at+FSEtLa5+VlRXYqlUr8+bNmw+Eh4dbjxw5YoyJibEcOXLE2Lx5c4+h1Hbt2pmPHTvmbOAcPXrUr02bNt5nXVWTT9XwP//5z5GFhYWGr7/++qBj36BBg+ILCwuN3bt3L1u1atWRkpISvcViwWg0kpeX5xcREeGRZ3V12Lp1a2t16du0aWPJy8tzlic/P9+vXbt2NZbncqEx9YzfbGgDGhGyLi8ejaouU1NTz61bty7s2LFjBoCTJ0/q9+/f7zdz5syotLS0oscee+z4nXfe6Xwmlp+f77dhw4YggP/7v/9rftVVV5UOHz68bN++fdn79u3Lnjhx4lmA3bt3B+3bt8/PZrPx8ccfNx88eLCH42rSpMk5AIPBgCP9Sy+9dPzs2bO6I0eOGEF9ZvzVV181TUhIqAD46aefmtx///0xa9euPRAVFeV0Rq+++uoxxzEAevXqVbp06dLmAEuXLg2vqQ58KdONN954dvPmzaEFBQX6goIC/ebNm0NvvPHGs1WP5at9vvDxxx/n7du3L9vhIEePHn3mjTfeCAd44403wlNTU8844rZo0aIAYOjQoWV5eXkB+/bt86usrFTWrFnT/I9//OMZ7zl4z8eVF198scV3333X9NNPPz2k1+ud+3/88cfcffv2ZX/44YdHdDod/fv3L3nrrbfCAFasWBE+duxYjzyrq8Oa0l9//fVn3n///XC73c7GjRuDQkJCbDExMfXqjB11+d/SaJyxEKJR3fQaElmXF4/GVpe9e/eufPzxx4+NGDGiU6dOnRKHDx/eKTc312/nzp1Bzz777Inp06cXG41G8fLLL4cDxMbGVq5YsSK8U6dOiadPnzbMmjXL642rR48epX/+85+jO3XqlNSuXTvT7bff7nFzDgwM9NqzPHfunO7aa6+N69SpU2KXLl2SWrRoYZk9e3YBwOzZs9uWl5frb7755o4JCQmJw4cPj/N2jCVLlvz25ptvRiQnJ3c5e/as3lscB76UqVWrVrbZs2cf7927d5fevXt3mTNnzvFWrVrZAB566KE277//ftPa2OfKO++806xVq1bddu7cGTRu3Lj4QYMGec4NAObNm5f//fffh8bExCR///33ofPmzcsHyMvLM956663NAIxGI4sWLfotNTW1U3x8fNKNN95YnJKSUlmbfFyZM2dOTGFhoSElJaVLQkJC4qxZsyK9xVu0aNHRV199tXW7du2ST58+bXjwwQcLAX744YfAW2+9NeZCdVhd+ltuueVsTEyMKSYmJnn69Okxixcvdk4Svu666zoMGjQo4fDhw/6tWrXq9s9//rP6mYC1oHXr1hdlgmaDSShKJJLakZmZmde9e/crZpZ7Tk6O39ixY+Nzc3P3NLQtF4vGWCZJ/ZGZmdmie/fu7X2J2yieGSuKkgq8DOiBZUIIzxfqJF5RFGUFMBY4JYRI1vY1Bz4E2gN5wC1CCO8rBkicKIrSFngHaA3YgTeFEC/L+qwdNptN2bdvX4IQQhFCKE2bNj3drl274xaLRX/gwIFYi8XibzQaTXFxcYeMRqPvL//+DyOEYM+ePYlGo9HcuXPnA7Iu60ZmZmZXnU5n0+YNiOTk5L0Xqy6v+J6xoih6YD8wEjgKZAC3CSF8ftbyv4yiKEOAUuAdF2f8PFAshFioKMqjQJgQYm5D2nkloChKJBAphNiuKEoIsA24EbiTi1CfV1rPuK4IIbDZbDqDwWC32+3K3r17O7dt2/b306dPh+n1emt0dPSJo0ePtrbZbPqYmJhjFz6i5Pjx463KysoC7Xa7vnPnzgeOHDkSLeuy9mRmZnZNTEzcazQanc/3a6rL2vSMG8Mz477AASHEISGEGfgAuKGBbbpiEEL8ABRX2X0D4Fh7biWqQ5FcACFEvhBiu/Z3CbAXiELWZ61QFAWDwWAHdfa2EEIBOHv2bLOWLVsWAbRs2bLo7NmzYQ1p55WCyWQynj17tmnLli2dDTlZlxePi1WXjWGYOgr43eX7UaBfA9nSWGglhMgH1cEoihLR0AZdaSiK0h7oCWxB1metcQyrms1m//Dw8FOhoaFlVqvV4O/vbwHw9/e3WK3WxnD/qneOHDnSNjo6+qjNZnNOTJN1WXdycnLiQZ1F3bp168KLVZeN4QR4e6P7yh57l1zRKIoSDPwbeEgIce5KWXTgckJRFJKTk7OtVqs+Nze3Y1lZWUBD23QlUlxc3NRgMFhDQkLKz5w5E3LhFJKaSEhI2Ofv728xm82G/fv3d2rSpInH0qV1pTE446NAW5fv0cDxauJKfOOkoiiRWi8uEjjV0AZdKSiKYkR1xO8LIdZou2V91hGDwWALDg4uOXPmTFODwWA1mUxGf39/i8lkMhoMhgZfp/typ6SkJPjcuXPNMjMzmwohdDabTXfgwIEOsi7rhqMH7OfnZ23atOmZ0tLSoItVl43hmXEGEK8oSgdFUfyA8cBnDWzTlc5nwCTt70nA2ga05YpBUbvAy4G9QogXXYJkfdbAunXrQoYNG+Z8v9ZsNhusVqse1JnVJSUloU2aNKkMDQ09U1BQEA5QUFAQ3rRpU+e7yIMHD47v3LlzYlxcXNKECRPaWa3q/fCpp55q1bFjx6ROnTolDhgwoNP+/furXU7TlcDAwJ7/bbleffXV8JiYmOSYmJjkV1991etCIr7a98gjj7R58sknWwGsWLEiLC4uLkmn0/X+4YcfAqvL/+TJk/rbbrst8IYbbrBPnz69MiQkJC84OLgkLu7/2bv/qCbv+///z4SfQoMChfAziQohBMT6k7ZSf1Racf6oB6XtpF+GzE7krZ9O29Nz6lrLcLVO2lJ1xbq9K62tx1kjq5apW9e3MqVdXS0TERJETFSMmaj8lB+B8P2DXhjzywtKuLji43YO51SvXLnyuujxmVyE3KMumZ/LvXv3hi1evNhdIpHEb9iwIYTZn+1xli5dKmM+gGPx4sVjZTJZfHR0dFxaWpqss7PT5mWhzZs3B0kkkniBQDBFr9cP+EWhwWBwe/zxx6OlUmn8448/Hn3jxg03or7PxE5NTZXJ5XLluHHj4l577bWQ+90XWz09PcLu7m4h898//n/Z7uj/y4Hg/TDu7e3tJqI1RPQ36nvDzOe9vb34HUCWBALBPiL6lohiBALBVYFA8Esi2kJETwkEggvU9y51/KoYOzOI6P8joicFAsF/fvz6GeF8DkhXV5eHWq2OOXfunLKqqkopEomaAwICmsLDw/UtLS1+FRUV8S0tLX5hYWH9QYVDhw5d1Gg0VTU1Nedv3rzpsXv3bn8ioilTptz5z3/+U11TU1O1ZMmS2+vWrYsY7ONiBjwbBoPB7fe//33Y6dOnq7///vvq3//+92HMwDA3mMf3yCOPtB88eLB26tSpVp/7bO7NN98MnT17dotOp6ucPXt2y+9///sAZhtzLsvLy+M3btwY+OWXX2pqamrOHzx4MODMmTPeAzmOufT09Ft1dXWVGo3mfEdHh+D999+3+cEas2bNav3qq69qwsLCbIeM78NybRs3bgwhIioqKvLv6uoS1tTUVJ09e7Z6z549QRqNhtUTsPvp6upyV6vVisrKSmVVVVWsn59fY0BAQLOj/y8HwhUuU1Nvb+8RIjrC9ePgo97e3p/b2TR3WB+IC+jt7T1Ftt/DQORC57OwsDBg586dYqPRKJg8eXJbbm6u/qmnnpL/61//UgcHB3dPnz495je/+Y0+Li6uIyUlJXrSpEltlZWVPuPGjes4cOCAViQSWaX4Wlpa3J566qnxdXV13omJiS2ffvpplZubG/n4+Ez65S9/Kfz73/+u9Pb2NpWUlNRGRkZaTcWAgAATEZHRaBQYjUYB83P6RYsW9X9qV1JSUuv+/fttvkJVq9Wezz///Lju7m7B3Llz+z+2sqSkRLRp06bQ4OBgY1VVlc+RI0cusFnTF198MXrmzJnNzCdGzZw5s7m4uHj0qlWr7vnNBbaPz9zkyZNZ/Zzy2LFjY0pLSzVEffGLWbNmxfzxj3+sJCLy8PDoiY2NrfnHP/7hK5PJwiZMmNBORJSamnpLpVKNmTJlynW2xzH33HPP9Z+7qVOntl29etXmIJwxY4bNhGFzc7Pwl7/8paS6unpUT0+P4De/+c21F154weqVpq21EVG9QCCgO3fuCI1GI7W1tQk8PDx6x4wZMyS/Pz1q1Kiu+Ph4q1+ZZc7lT71/lxjGAA+cr7Mi6Val3UuHgxIQf4fm7r7i6CY//PCDt0qlCvj+++/VTELx73//u+ill166vmLFCsm0adPaYmJiOlJTU5s1Go2nVqv13rVrl5bJDebn5wdZ5gaJ+j6bury8vJJJKO7Zs8f/x4Si8LHHHmvdsWNHfXZ2dsSOHTuC2CQUV6xYYfWhKrt27QpKTk62+nxoIqKcnBzJypUrb5glFPtVVFT4lpeXn2cSimzWVF9f7xEREdH/qi88PLyrvr7ew9G5dfT4BuPmzZvuzOcyS6VS461bt6z+vb9y5YpneHh4/+OMiIjo+u6772yWtQais7NTsH///sD33nvP4f9PljZs2BA6Z86c5gMHDmgbGhrcpk6dGrt48eJmPz+/e57s2FtbZmbm7S+//HJMcHDwxI6ODuGmTZuuME+IRjreX6YGgOHDZUJxypQpbUgoDi0uEoqOnDhxwq+goCBUoVAok5KSYjo7OwW1tbWsLzOXlpb6CIXC3uvXr1fU1tae+8Mf/hBSVVU1JJepnQ2vjAH46D6vYJ2Fy4Siu7s7EooO8CWhuH//fp3lPoze3l5SqVS1EydO7BzM2j799NPAefPmNXl5efWGh4d3T5s2rfWbb77xVSqVg/rZ9HDCMAYA1lJSUppTU1OjNmzYYAgPD+82GAxuTU1Nbm+99ZZ42bJlN6VSaVdmZqb0+PHjtUR3c4PJycltlrlB5j5LSkpETEIxOjq6S6VSBaxcudJulo5JKDJ/bmpqEjY2NrpJpVIjk1CcMWNGC9HdROGRI0cuWCYKiaj/CQWTUMzJybnFNqHoaE0Gg8EtLy8vnHnTVmlpqV9BQcFVy/ti+/jYUKlUWvM/MwnFzZs3X7dMKDLME4oymcxYXFwcsHfv3rqBHMcck1A8efKkxjKhyGYNc+bMaX733XfFH3/88WWhUEhlZWWjZsyY0c52bRKJpOv48eN+q1evvtXa2ir84YcffF955RWrH4uMRLhMDQCscZlQtAcJxYEnFGfNmhVFxF1C8Xe/+12wWCxOMBgMnhMnTlQy2cQtW7Zc6+7uFigUCmV0dHTc66+/Hj6Qtb366qv/bWtrE8rl8rhJkybFLl++vCExMdHmm8VGGt6HIgAeFHwLRbhibtAV1wTO86CFIgAAAHgNwxgAnCImJqbL1V5BuuKaYGTAMAYAAOAYhjEAAADHMIwBAAA4hmEMAADAMQxjAOCUZUJxMJBQtGYvM2hJpVL5yWSyeCQUuYVhDAC8h4SiNXuZQcs1rVu3TnLkyJEaJBS5hWEMAANSWFgYMGHChFiFQqFcvny5tKamxlMqlcbr9Xr3np4emjJlSkxxcbGfRqPxHDt2bBzzSiUlJWVcS0uLzX9zmITi+PHj45YvXy7p6ekL7fj4+Exau3ZteExMjHLixImKK1eu2HwV5SihyOQNk5KSWvV6vc1/mNVqtecjjzyiiI+Pj33ppZfCmL8vKSkRJSYmyhctWjQ2JiYmju2azBOKQUFBPUxC0fJ2bB+fucmTJ3dYfnazLceOHRvDRC9WrVp18+jRo/6Wtzlx4oSvVCrtVCqVXd7e3r1MQnEgxzH33HPPNQmFQhIKhfdNKMbExFgN4ubmZmFaWposPj4+NjY2VvnZZ5+NGcjanJlQdDYMYwC+OjA9xurrzJa+/F9Xi9Dm9ortfZdL2/TuVttYME8oqtXqKqFQ2GueUMzNzRUzCUUiIq1W652dnX2jpqamSiQSmfLz84Ns3e+5c+d8t23bdkWj0ZzXarVee/bs8SciYhKKGo2m6seUos39ifpiBEFBQRN9fX17BptQrKysrA4JCbknlFBRUeGbn59ff/HixfNs18TnhKJ5OGKwmITiggULBrQeJqFYWVlZffLkSc3rr78e0dzcbDWnHCUUfXx8TMHBwRPHjh2bsGbNmutIKAKAy0FCEQlFNpBQHDhUmwD4Ku20xu42T5HJ4Xbf0G6H2+1AQhEJRSQUnQPDGABYQ0IRCUUkFJ0Dl6kBgDUkFJFQdAQJxcFDQhGAJ5BQ5J4rrgmcBwlFAAAAHsEwBgCncMXcoCuuCUYGDGMAAACOYRgDAABwDMMYAACAYxjGAAAAHMMwBgBOIaE4MhOKjvZ/7bXXQiQSSbxMJos/ePBg/0ePrl27NjwkJCThfucvPDx8gl6vd6+trfVITEyUjxs3Li4qKipu06ZNwfb2sfc4zZlMJsrMzIyUSCTxcrlceerUqf7zk5aWJgsICJgYHR0d5+ixcQXDGAB4DwlFaz81oWhv/zNnzngXFxcHaDSa88eOHav59a9/3f/kZ8mSJY3fffddNcvTxHzoyNW6urrz//73v6s/+uijYOb4bB+nuQMHDoyuq6vz1mq1lTt37tTl5ORImG1ZWVkNhw8fZvVJYFzAMAaAAUFC8cFIKNrbX6VSjUlNTb01atSoXoVC0SWVSjtPnDjhS0Q0d+7cNqamxIZUKjUmJSXdISLy9/c3jR8/vv3y5ctW58DR4zR36NChMenp6TeFQiHNnTu3rbm52V2n03kQEc2fP781KCiI/TOqYYZhDMBH32ZF0rHpMUP69W1W5P0Oi4Tig5NQtLd/fX29Z2RkZP8+YWFhXVeuXPnJZSSNRuNZVVXlM2vWLKtX/GxTj3q93kMmk/XfLjQ0tIsZxiMdhjEAsIaEIhKKzsguNjU1CVNTU8dv2bLlCnOVYzDHHOh5H0lQbQLgo8d2X7n/jYYeEooPTkLR3v4RERH3vBK+du2aZ0REhN1L046+X0REnZ2dggULFoxPS0u79Ytf/KKRiKi2ttZj4cKF0UREWVlZNyZPnnyHTeoxLCzMqNVq+2+n1+s9JRIJ68vmXMIwBgDWkFB8cBKK9vZfunRpY3p6+riNGzcadDqdh1ar9Z49e3abvcdl+f0yZzKZ6Pnnn5fK5fKO3Nzc/tRhVFSU0Xwfo9FIbFKPixcvbiwsLAx+8cUXbx0/ftxXJBL1DORn2FzCZWoAYA0JxQcnoWhv/6lTp3YsWbLkllwuj0tJSZG/9957Onf3vtd12dnZEWKxOKGjo0MoFosT1q9fH2brsTG++uqrh7744ovAU6dOiRQKhVKhUCj3799v9UY3R49z69atQVu3bg0iInr22WebpFJpp1QqjV+9erX0gw8+0DH3sWjRorFJSUmKS5cueYnF4oSCgoKH73euhxMSigA8gYQi91xxTeA8SCgCAADwCIYxADiFK+YGXXFNMDJgGAMAAHAMwxgAAIBjGMYAAAAcwzAGAADgGIYxAHAKCUUkFJFQxDAGABeAhKI1JBSRUAQAF4aEIhKKSCgOPQxjAL6ylUE8v6Uv52dsEdrcrt7ed7m0Xe9utY0FJBSRUERC0TkwjAGANSQUkVBEQtE5UG0C4KuU0xq72zxEJofbR4V2O9xuBxKKSCgioegcGMYAwBoSikgoIqHoHLhMDQCsIaGIhCISis6BhCIATyChyD1XXBM4DxKKAAAAPIJhDABO4Yq5QVdcE4wMGMYAAAAcwzAGAADgGIYxAAAAxzCMAQAAOIZhDACcQkIRCcXhSCgOdJ3Xr193S0xMlPv4+EzKyMiQ2DreUMIwBgDeQ0LRGhKKdxOKg1mnj49Pb15e3rXc3FyrT05zBgxjABgQJBSRUORbQnEw6/Tz8zPNmzev1dvb2ypc4QwYxgB8dDYrkk5NjxnSr7NZkfc7LBKKSCjyMaE4mHUONwxjAGANCUUkFPmYUHTGYx5qqDYB8NHE3Vfuf6Ohh4QiEop8TCh2dnYKBrrO4YZXxgDAWkpKSnNJSYl/fX29O1HfG5Vqamo816xZE75s2bKbGzZsuJaZmSllbs/kBomILHODarW6Kj09vYmo7zK1Wq327OnpIZVKFfDEE0/YHFxEd5N8arW66v3337/W1NQk1Ol0HkR9qb1jx46NVigU7UR3E4WHDh2qtUwUMvdBdDehSETENqHoaE1LlixpKi0t9btx44bbjRs33EpLS/2WLFlidQma7eNjQ6VSadVqdVVpaWkt0d0EIhERm4RiR0eHoLi4OGDp0qWNjvZfunRpY3FxcUB7e7tArVZ7sk0oMt8v8233Syiq1eqqV1999Yajx2lu8eLFjXv37g00mUz09ddf9ycUB7PO4YZhDACsIaGIhCIfE4qDWSdR369gvfHGG5EqlSpQLBYn2HoH91BBQhGAJ5BQ5J4rrgmcBwlFAAAAHsEwBgCncMXcoCuuCUYGDGMAAACOYRgDAABwDMMYAACAYxjGAAAAHMMwBgBOIaGIhCISihjGAOACkFC0hoQiEooA4MKQUERCEQnFoYdhDMBXtjKItVv6cn7dLUKb2y9t77tc2qF3t9rGAhKKSCgioegcGMYAwBoSikgoIqHoHEgoAvBV0mmN3W3uIpPD7d6h3Q6324GEIhKKSCg6B14ZAwBrSCgioYiEonNgGAMAa0goIqGIhKJzIKEIwBNIKHLPFdcEzoOEIgAAAI9gGAOAU7hibtAV1wQjA4YxAAAAxzCMAQAAOIZhDAAAwDEMYwAAAI5hGAMAp5BQREKRTUIxLS1NFhAQMDE6OjrO0X3bc/LkSR+5XK6USCTxmZmZkSZT3werXbhwwTMxMVEeGxurlMvlNn/PeThgGAMA7yGhaM2VEopERFlZWQ2HDx++wPa+LeXk5EgLCwt1Wq22sq6uzlulUvkREW3cuDE0NTX1dnV1ddW+ffvq1q9f7/R2sS0YxgAwIEgoIqE43AlFIqL58+e3BgUFWT0jOn/+vNcTTzwRHRcXFztlypSY8vJyq2Gu0+k8WltbhcnJyW1CoZDS09NvfvHFF/5EfZ8t3tzc7EZEdPv2bbfg4GDWj38oYRgD8NGFrEg6Oz1mSL8uZEXe77BIKCKhyEVC0ZGVK1dKCwsLL58/f746Pz//6urVq61e2ep0Oo/Q0ND+76tUKu3S6/UeRERvv/32tQMHDgSIxeKE1NTU6O3bt1/+qWsZDAxjAGANCUUkFLlIKDrar7y8/CHms71zcnKk//3vf62e9Dj6fhQVFQX8/Oc/v2kwGCqKi4svZGZmjmWuzAwnJBQB+Ch695X732joIaGIhCIXCcVXX33VZmCkp6eHRCJRt+U5sjzmunXrbjCvhImIdDqdJ3MF5LPPPnv42LFjNUREycnJbZ2dncLr16+7m1e0hgNeGQMAa0goIqHIRULR3n0HBASYIiIiupg37JlMJvr2229HWR5TKpUafX19TV9//bWvyWSivXv3Bj7zzDONRH2X2Y8cOeJH1PdjmK6uLkFoaOiwN40xjAGANSQUkVDkIqFIRLRo0aKxSUlJikuXLnmJxeKEgoKCh4mI9u3bV1dUVPRwTEyMMjo6Ou7gwYNjbO1fWFioy87Olkml0niZTNaZlpbWRERUUFBw5eOPPw6KiYlRLl++fNyHH36oZa7GDCckFAF4AglF7rnimsB5kFAEAADgEQxjAHAKV8wNuuKaYGTAMAYAAOAYhjEAAADHMIwBAAA4hmEMAADAMQxjAOAUEopIKCKhiGEMAC4ACUVrSCjeCwlFAHApSCgioYiE4tDDMAbgK1sZxKtb+nJ+PS1Cm9uvNrN1qQAAIABJREFUbe+7XNqld7faxgISikgoIqHoHBjGAMAaEopIKCKh6BxIKALw1cTTGrvb3EQmh9s9Q7sdbrcDCUUkFJFQdA68MgYA1pBQREIRCUXnwDAGANaQUERCEQlF50BCEYAnkFDkniuuCZwHCUUAAAAewTAGAKdwxdygK64JRgYMYwAAAI5hGAMAAHAMwxgAAIBjGMYAAAAcwzAGAE4hoeichCLb29nT3t4uWLBgwTiJRBKfkJCg0Gg0/Y8tOzs7IioqKm7cuHFx5jlCcxqNxpPJHf7lL3/xi4uLi5XL5cq4uLjYw4cPi6x2+JG9PKM5e3nH69evuyUmJsp9fHwmZWRkcFJfGiwMYwDgPSQUB387e7Zt2/bw6NGjuy9fvly5Zs0aw/r16yOIiL766ivf06dPP6RWq8/X1NSc/89//uN75MgRu8OViCg4ONj417/+tbampqbq448/vrRy5cqxtm7nKM9ozl7e0cfHpzcvL+9abm7u1cGsmUsYxgAwIEgo8iOhaO923d3dtGrVqoj4+PhYuVyuzM/Pf9jW/iUlJWOysrJuEhGtWLHi9jfffCMymUwkEAios7NT0NHRIWhvbxd2d3cLmM+ztmfGjBntMpnMSNT3KW5dXV3C9vZ2q3KGozyjOXt5Rz8/P9O8efNavb29WccmRgoMYwA+MmRF0uXpMUP6ZciKvN9hkVDkT0LRnvfff//h0aNH91RWVlafPXu2+pNPPglSq9VWTwIMBoPn2LFju4j6PjbzoYce6jEYDO7JycltM2bMaAkNDZ0YFhaWMGfOnObJkyd3sD3+J5984q9UKu8wUQxzbPOMbPKQfINhDACsIaHI/4TiP/7xD7/PP/88UKFQKCdNmhR7+/Zt96qqKm/L29lLJVZWVnrV1NR4X716teLq1asVJ0+eFB09etTm99XS999/771x48bwP/3pTzpb252RZ+QL3j+bAHggiXdfuf+Nhh4SivxJKNq7XW9vr+Ddd9+9vHTp0mbzv7c8ZkhISNelS5c8x48fbzQajdTa2uoWHBzc88EHHzw8bdq0ttGjR5uIiJKTk5vKysp8vby8es3PwdSpU9vN7//ixYsey5Yti/roo48uxcXFdRL1RS82b94cRkT0xz/+Ucs2z8gmD8k3GMYAwFpKSkpzampq1IYNGwzh4eHdBoPBrampye2tt94SL1u27KZUKu3KzMyUHj9+vJbobm4wOTm5zTI3yNxnSUmJiEkoRkdHd6lUqoCVK1fazeYxeTzmz01NTcLGxkY3qVRqZBKKM2bMaCG6myg8cuTIBctEIRH1P6FgEoo5OTm32CYUHa3JYDC45eXlhTNv2iotLfUrKCiwelMR28fHhkql0rK53VNPPdW0c+fOoIULF7Z4eXn1VlRUeMlkMqPlMRcsWNC4e/fuwOTk5LaioiL/xx57rEUoFJJEIukqKioKMhqNepPJJCgrKxOtXbvWYHkOzN993dDQ4Pazn/0sOjc39ypzVYGIKCMjozEjI6O/0OXj42NKT08ft3HjRoNOp/Owl2dk8o6bN2++bi8PyTe4TA0ArCGhyJ+Eor3brVu3rkGhUHRMmDAhNjo6Ou7FF1+UGo1Gq2voL730UsPt27fdJRJJ/I4dO0Leeeedq0R9b+aSyWSdMTExcUqlUhkXF3dn+fLlDn/WvXXr1uDLly97bdmyJYxJJTJNbHOO8ozPPfeclPkVLXt5RyKi8PDwCW+88UakSqUKFIvFCWfOnLG6BD8SIaEIwBNIKHLPFdcEzoOEIgAAAI9gGAOAU7hibtAV1wQjA4YxAAAAxzCMAQAAOIZhDAAAwDEMYwAAAI5hGAMAp5BQRELRHBKKAAA8hYTi4G9nDxKKwwvDGAAGBAlFJBSRUBx6GMYAfGUrg3hrS1/Oz9QitLm9cXvf5dJuvbvVNhaQUERCEQlF58AwBgDWkFBEQhEJRefg/bMJgAeW5LTG7jahyORwu3tot8PtdiChiIQiEorOgWEMAKwhoYiEIhKKzoHL1ADAGhKKSCgioegcSCgC8AQSitxzxTWB8yChCAAAwCMYxgDgFK6YG3TFNcHIgGEMAADAMQxjAAAAjmEYAwAAcAzDGAAAgGMYxgDAKSQUkVA091MSio72P3nypI9cLldKJJJ488d89OjRh5RKZay7u/uUoqIi/4Gep6GCYQwAvIeE4uBvZw8fE4qO9s/JyZEWFhbqtFptZV1dnbdKpfIjIho3blxXUVGRdtGiRTetDjSMMIwBYECQUERCcaQmFO3tr9PpPFpbW4XJycltQqGQ0tPTb37xxRf+RH2/rpaYmNjOfAY6VzCMAfioJSuSbk+PGdKvlqzI+x0WCUUkFEdyQtHe/jqdziM0NLT/+yqVSrv0er3D78dwwzAGANaQUERCcSQnFO3tP9DvBxdQbQLgI9HuK/e/0dBDQhEJxZGcULS3v0wmM5q/EtbpdJ6WV0C4hlfGAMBaSkpKc0lJiT9T3DEYDG41NTWea9asCV+2bNnNDRs2XMvMzJQyt2dyg0RElrlBtVpdlZ6e3kTUd5larVZ79vT0kEqlCnjiiSdsDi6iuwlFtVpd9f77719ramoS6nQ6DyIiJqGoUCjaie4mCg8dOlRrmShk7oPobkKRiIhtQtHRmpYsWdJUWlrqd+PGDbcbN264lZaW+i1ZssTqEjTbx8eGSqXSqtXqKkeDmOhuQrGzs1NARFRRUeHV3NwstDwmk1AkIrJMKJaVlYmMRiN1dnYKysrKREqlssPW95XhKKHI7DNz5sw7S5cubSwuLg5ob28XqNVqz/slFImIzBOK9vaXSqVGX19f09dff+1rMplo7969gc8888yIyi5iGAMAa0goIqE4khOKjvYvLCzUZWdny6RSabxMJutMS0trIiIqLS31EYvFCUeOHPFft26dNCoqKu5+3wNnQEIRgCeQUOSeK64JnAcJRQAAAB7BMAYAp3DF3KArrglGBgxjAAAAjmEYAwAAcAzDGAAAgGMYxgAAABzDMAYATiGhiISiOSQUAQB4CgnFwd/OHiQUhxeGMQAMCBKKSCgioTj0MIwB+MpWBvHOlr6cn6lFaHv79r7LpT16d6ttLCChiIQiEorOgWEMAKwhoYiEIhKKzoGEIgBf+Z/W2N0mFJkcbncL7Xa43Q4kFJFQRELROfDKGABYQ0IRCUUkFJ0DwxgAWENCEQlFJBSdAwlFAJ5AQpF7rrgmcB4kFAEAAHgEwxgAnMIVc4OuuCYYGTCMAQAAOIZhDAAAwDEMYwAAAI5hGAMAAHAMwxgAOIWEIhKKjOvXr7slJibKfXx8JmVkZEgG+piJ7J/3Q4cOiZRKZaxCoVBOmTIlprKy0msw9+8sGMYAwHtIKA7+dvZwkVD08fHpzcvLu5abm3t1MI/Z0Xl/6aWXpJ999tkltVpdlZaWduvNN98MHcwxnAXDGAAGBAlFJBSdlVD08/MzzZs3r9Xb29vqpXZxcbHfI488olAqlbHz588f19TUNODz3tjY6EZE1NTU5GZecRoJMIwB+KgnK5K6p8cM6VdPVuT9DouEIhKKzkwo2qPX6903b94c+s9//rOmqqqqevLkyXc2bdoktrydo/P+4YcfalNTU6PFYnHC559/HpiXl6dne/zhgGEMAKwhoYiEojMTivacOHHC9+LFi97Tp09XKBQK5Z///OfAy5cvW/2/4Oi8v/fee+Li4uILBoOhYvny5Q2rV6++75PP4YSEIgAfue2+cv8bDT0kFJFQdGZCcebMmXfsPGZKSkpq/vLLLy+Z/z3b837t2jX36urqUU8++WQbEVFGRsbtlJQUm4ENrmAYAwBrKSkpzampqVEbNmwwhIeHdxsMBrempia3t956S7xs2bKbUqm0KzMzU3r8+PFaoru5weTk5DbL3CBznyUlJSImoRgdHd2lUqkCVq5cabPuRHQ3ocj8uampSdjY2OgmlUqNTEJxxowZLUR3E4VHjhy5YJkoJKL+JxRMQjEnJ+cW24SiozUZDAa3vLy8cObNQ6WlpX4FBQVWb0pi+/jYUKlUWja3YxKKCxcubPHy8uqtqKjwkslkRstjMgnF5OTkNsuEYlFRUZDRaNSbTCZBWVmZaO3atQbLc2D+7mtHCcWMjIz7Frpmz57d9vLLL0sqKyu94uPjO1taWoSXLl3yYHveAwICelpbW90qKiq8EhISOktKSvyioqJYX1ofDrhMDQCsIaGIhKIzE4pEROHh4RPeeOONSJVKFSgWixPOnDnjHRYW1r1r1y7t888/P04ulyunTJmiOHfunNWldXvn3cPDg7Zt26ZbtmzZ+JiYGOW+ffsCCwoKOLm6ZA8SigA8gYQi91xxTeA8SCgCAADwCIYxADiFK+YGXXFNMDJgGAMAAHAMwxgAAIBjGMYAAAAcwzAGAADgGIYxAHAKCUUkFBlIKAIA8BgSioO/nT1IKA4vDGMAGBAkFJFQREJx6GEYA/CVrQyiaUtfzq+3RWh7+/a+y3a9enerbSwgoYiEIhKKzoFhDACsIaGIhCISis6BahMAX7mf1tjdJhCZHG8P7Xa43Q4kFJFQRELROTCMAYA1JBSRUERC0TlwmRoAWENCEQlFJBSdAwlFAJ5AQpF7rrgmcB4kFAEAAHgEwxgAnMIVc4OuuCYYGTCMAQAAOIZhDAAAwDEMYwAAAI5hGAMAAHAMwxgAOPUgJxQZRUVF/gKBwG7qcDAJRYPB4Pb4449HS6XS+McffzzaVjWKiEilUvnJZLJ4iUQSv2HDhhDm79keZ+nSpbKioiJ/IqLFixePlclk8dHR0XFpaWmyzs5Om58BqlarPRMSEhRSqTR+wYIF4zo6Omzezt453Lx5c5BEIokXCART9Hq9S3x4FYYxAPAeXxOKRES3b98WfvDBB8EJCQlttrZbYptGfPPNN0Nnz57dotPpKmfPnt2ycePGEMvbdHd307p16yRHjhypqampOX/w4MGAM2fOeA/kOObS09Nv1dXVVWo0mvMdHR2C999/32YRav369RFr1qwx6HS6ytGjR3dv27bN6naOzuGsWbNav/rqq5qwsLAu63vnJwxjABgQJBSHLqFIRPTyyy+Hv/zyy9e9vLxYfQIT24TisWPHxjDRi1WrVt08evSov+VtTpw44SuVSjuVSmWXt7d3b2pq6i2VSjVmIMcx99xzzzUJhUISCoU0derUtqtXr1qdb5PJRN9++62IKWtlZWXd/PLLL8dY3s7ROZwxY0Z7TEyMywxiIgxjAF7qoKzIOzQ9Zii/OijrvhUbJBSHNqFYVlY2qr6+3vPnP//5kKcTb9686S6VSo1ERFKp1Hjr1i2rJzJXrlzxDA8P73+cERERXfX19awu5TvS2dkp2L9/f+CCBQus1mUwGNxFIlGPh0ff6ZDJZF0Gg8HqmIPJUPIZhjEAsIaE4tAlFHt6emjdunWS7du3c/YZyfYyiT/1fn/xi19IHn300daUlBSrS9xsjznQDCXfucQPvgEeNN60m5N/wJFQHLqEYmNjo9uFCxe8n3zyyRgiooaGBo9ly5ZFqVSq2gMHDvj/1IRiYGBgt06n85BKpUadTucREBBg9UNviURyzyvhq1eveoaFhRktb+foOJbbX3755dCGhgb3v/3tbxeZv0tKSopuaGjwmDhxYtu+fft0LS0tbkajkTw8PEir1XoGBwdbHXMgGUpXgGEMAKwhoTh0CcXAwMCe27dvn2X+PH369Jh33nnnysyZM+/82PX9SQnFefPmNe7atStw8+bN13ft2hWYkpJiVcKaNWtWm1ar9Var1Z4ymcxYXFwcsHfv3rqBHMfce++99/D//d//jT558qTGze3u+9VOnTp1wfx2jz76aEtRUZH/r371q9u7d+8OXLhwodVjW7JkSRObDKWrwGVqAGANCcWhTSgOBtuE4m9/+1v98ePH/aRSafzx48f9fvvb3+qJiLRarcesWbOiiIg8PDzo3XffvZySkiKPjo6OW7Jkya2pU6d2DOQ45l599VVpQ0OD+9SpU2MVCoXylVdeCbV1u3fffffqjh07QiQSSfzt27fdX3rppQYion/+858+zz33nJTI8Tn83e9+FywWixMMBoPnxIkTlcw+fIaEIgBPIKHIPVdcEzgPEooAAAA8gmEMAE7hirlBV1wTjAwYxgAAABzDMAYAAOAYhjEAAADHMIwBAAA4hmEMAJxCQhEJRSQUMYwBwAUgoWgNCUV+wTAGgAFBQhEJRXuQUBw8DGMAnrKVQeyiLUFERL3UIrS9fXsgEZGJ9O6W29gcEwlFJBTZQEJx4DCMAYA1JBSRUGQDCcWBc4kffAM8iHzotMbeNgGJTI62Cym029F2e5BQREIRCUXnwDAGANaQUERCEQlF58BlagBgDQlFJBQdQUJx8JBQBOAJJBS554prAudBQhEAAIBHMIwBwClcMTfoimuCkQHDGAAAgGMYxgAAABzDMAYAAOAYhjEAAADHMIwBgFNIKCKhONCEor39TSYTZWZmRkokkni5XK48depU/+NOS0uTBQQETIyOjo6ztxYuYRgDAO8hoWjNlROK9vY/cODA6Lq6Om+tVlu5c+dOXU5OjoS5v6ysrIbDhw9fsDzOSIFhDAADgoQiEor2DEdC0dH+hw4dGpOenn5TKBTS3Llz25qbm911Op0HEdH8+fNbg4KC2D+jGmYYxgA8dIuyIg00PWYov25RVuT9jouEIhKKbDgzoehof71e7yGTyfr3CQ0N7WKG8UiHYQwArCGhiIQiG85MKDran8/ZRVSbAHgogHZz8g84EopIKHKdUAwJCem2t39YWJhRq9X2r0ev13tKJBKH6xkpMIwBgDUkFJFQ5DqhKBQK7e6/ePHixsLCwuAXX3zx1vHjx31FIlEPc6l+pMNlagBgDQlFJBQdGa6Eor39n3322SapVNoplUrjV69eLf3ggw90zDEXLVo0NikpSXHp0iUvsVicUFBQYPOd3lxBQhGAJ5BQ5J4rrgmcBwlFAAAAHsEwBgCncMXcoCuuCUYGDGMAAACOYRgDAABwDMMYAACAYxjGAAAAHMMwBgBOIaGIhCISihjGAOACkFC0hoQiEooA4MKQUERC0R4kFAcPwxiAp2xlEJtpSxARkYlahLa2t9D2QCKiHtK7W25jc0wkFJFQZAMJxYHDMAYA1pBQREKRDSQUBw7VJgCeEtNpjb1tQhKZHG13o9BuR9vtQUIRCUUkFJ0DwxgAWENCEQlFJBSdA5epAYA1JBSRUHQECcXBQ0IRgCeQUOSeK64JnAcJRQAAAB7BMAYAp3DF3KArrglGBgxjAAAAjmEYAwAAcAzDGAAAgGMYxgAAABzDMAYATiGh+OAlFDdv3hwkkUjiBQLBFL1eP+APn7K3ts7OTgET8Rg3blzca6+9ZlWqGqkwjAGA95BQtDaSE4qzZs1q/eqrr2rCwsK6bG2/H3trKyoq8u/q6hLW1NRUnT17tnrPnj1BGo3mJ4cvhgOGMQAMCBKKSCjawyahSEQ0Y8aM9piYGKtB3NzcLExLS5PFx8fHxsbGKj/77DOrtKKjtQkEArpz547QaDRSW1ubwMPDo3fMmDE9A1kDVzCMAXhIR1mRapoeM5RfOsqKvN9xkVBEQpENRwlFRzZs2BA6Z86c5srKyuqTJ09qXn/99Yjm5marOWVvbZmZmbd9fHxMwcHBE8eOHZuwZs2a68xHaI50GMYAwBoSikgosuEooejIiRMn/AoKCkIVCoUyKSkpprOzU1BbW8v6yUFpaamPUCjsvX79ekVtbe25P/zhDyFVVVW8uEyNahMAD0lpNyf/gCOhiITiT00o7t+/X2e5D6O3t5dUKlWt5eVxtmv79NNPA+fNm9fk5eXVGx4e3j1t2rTWb775xlepVA7qZ9PDCcMYAFhDQhEJxaFIKNozZ86c5nfffVf88ccfXxYKhVRWVjZqxowZ7WzXJpFIuo4fP+63evXqW62trcIffvjB95VXXjGwOTbXcJkaAFhDQhEJRUfYJhR/97vfBYvF4gSDweA5ceJEJZNN3LJly7Xu7m6BQqFQRkdHx73++uvhA1nbq6+++t+2tjahXC6PmzRpUuzy5csbEhMT29mcV64hoQjAE0gocs8V1wTOg4QiAAAAj2AYA4BTuGJu0BXXBCMDhjEAAADHMIwBAAA4hmEMAADAMQxjAAAAjmEYAwCnkFBEQtHefQ90bUgoAgBwCAlFa0goIqEIAC4MCUUkFO1BQnHwMIwBeMpWBvE6bQkiIuqhFqGt7f+l7YFEREbSu1tuY3NMJBSRUGQDCcWBwzAGANaQUERCkQ0kFAcO1SYAnlLQaY29bW4kMjna7kGh3Y6224OEIhKKSCg6B4YxALCGhCISikgoOgcuUwMAa0goIqHoCBKKg4eEIgBPIKHIPVdcEzgPEooAAAA8gmEMAE7hirlBV1wTjAwYxgAAABzDMAYAAOAYhjEAAADHMIwBAAA4hmEMAJxCQnFkJhQd7f/aa6+FSCSSeJlMFn/w4MH+jx5du3ZteEhISML9zl94ePgEvV7vXltb65GYmCgfN25cXFRUVNymTZuC7e1j73GaM5lMlJmZGSmRSOLlcrny1KlT/ecnLS1NFhAQMDE6OjrO0WPjCoYxAPAeEorWfmpC0d7+Z86c8S4uLg7QaDTnjx07VvPrX/+6/8nPkiVLGr/77rtqNusg6v/Qkat1dXXn//3vf1d/9NFHwczx2T5OcwcOHBhdV1fnrdVqK3fu3KnLycmRMNuysrIaDh8+zOqTwLiAYQwAA4KE4oORULS3v0qlGpOamnpr1KhRvQqFoksqlXaeOHHCl4ho7ty5bUxNiQ2pVGpMSkq6Q0Tk7+9vGj9+fPvly5etvkeOHqe5Q4cOjUlPT78pFApp7ty5bc3Nze46nc6DiGj+/PmtQUFB7J9RDTMMYwAeqqasyH/T9Jih/KqmrMj7HRcJxQcnoWhv//r6es/IyMj+fcLCwrquXLnyk8tIGo3Gs6qqymfWrFlWr/jZph71er2HTCbrv11oaGgXM4xHOgxjAGANCUUkFJ2RXWxqahKmpqaO37JlyxXmKsdgjsnmvI9UqDYB8FAs7ebkH3AkFB+chKK9/SMiIu55JXzt2jXPiIgIu5emHX2/iIg6OzsFCxYsGJ+WlnbrF7/4RSMRUW1trcfChQujiYiysrJuTJ48+Q6b1GNYWJhRq9X2306v13tKJBLWl825hGEMAKwhofjgJBTt7b906dLG9PT0cRs3bjTodDoPrVbrPXv2bLtvPrP8fpkzmUz0/PPPS+VyeUdubm5/6jAqKspovo/RaCQ2qcfFixc3FhYWBr/44ou3jh8/7isSiXoG8jNsLuEyNQCwhoTig5NQtLf/1KlTO5YsWXJLLpfHpaSkyN977z2du3vf67rs7OwIsVic0NHRIRSLxQnr168Ps/XYGF999dVDX3zxReCpU6dECoVCqVAolPv377c6N44e59atW4O2bt0aRET07LPPNkml0k6pVBq/evVq6QcffKBj7mPRokVjk5KSFJcuXfISi8UJBQUFDw/i9DsNEooAPIGEIvdccU3gPEgoAgAA8AiGMQA4hSvmBl1xTTAyYBgDAABwDMMYAACAYxjGAAAAHMMwBgAA4BiGMQBwCglFJBSRUMQwBgAXgISiNSQUkVAEABeGhCISikgoDj0MYwCespVB1NKWICKibmoR2tp+hbYHEhF1kt7dchubYyKhiIQiEorOgWEMAKwhoYiEIhKKzoFqEwBPTaPTGnvb3ElkcrTdi0K7HW23BwlFJBSRUHQODGMAYA0JRSQUkVB0DlymBgDWkFBEQhEJRedAQhGAJ5BQ5J4rrgmcBwlFAAAAHsEwBgCncMXcoCuuCUYGDGMAAACOYRgDAABwDMMYAACAYxjGAAAAHMMwBgBOIaGIhOJwJBQHus7r16+7JSYmyn18fCZlZGRIbB1vKGEYAwDvIaFoDQnFuwnFwazTx8enNy8v71pubu5Vy+M4A4YxAAwIEopIKPItoTiYdfr5+ZnmzZvX6u3tbRWucAYMYwAeOkNZkcdpesxQfp2hrMj7HRcJRSQU+ZhQHMw6hxuGMQCwhoQiEop8TCg64zEPNVSbAHhoCu3m5B9wJBSRUORjQrGzs1Mw0HUONwxjAGANCUUkFPmYUPxxSA9oncMNl6kBgDUkFJFQ5GNCcTDrJOr7Faw33ngjUqVSBYrF4gRb7+AeKkgoAvAEEorcc8U1gfMgoQgAAMAjGMYA4BSumBt0xTXByIBhDAAAwDEMYwAAAI5hGAMAAHAMwxgAAIBjGMYAwCkkFJFQREIRwxgAXAASitaQUERCEQBcGBKKSCgioTj0MIwBeMpWBlFDW4KIiLqpRWhrey1tDyQi6iC9u+U2NsdEQhEJRSQUnQPDGABYQ0IRCUUkFJ0D1SYAnppDpzX2trmTyORouzeFdjvabg8SikgoIqHoHBjGAMAaEopIKCKh6By4TA0ArCGhiIQiEorOgYQiAE8gocg9V1wTOA8SigAAADyCYQwATuGKuUFXXBOMDBjGAAAAHMMwBgAA4BiGMQAAAMcwjAEAADiGYQwAnEJCEQlFNgnFtLQ0WUBAwMTo6Og4R/dtz8mTJ33kcrlSIpHEZ2ZmRppMfR+sduHCBc/ExER5bGysUi6X2/w95+GAYQwAvIeEojVXSigSEWVlZTUcPnz4Atv7tpSTkyMtLCzUabXayrq6Om+VSuVHRLRx48bQ1NTU29XV1VX79u2rW79+vdPbxbZgGAPAgCChiITicCcUiYjmz5/fGhQUZPWM6Pz5815PPPFEdFxcXOyUKVNiysvLrYa5TqfzaG1tFSYnJ7cJhUJKT0+/+cUXX/gT9X22eHNzsxsR0e3bt92Cg4NZP/6hhGEMwEMnKSvyME2PGcqvk5QVeb/jIqGIhCIXCUVHVq5cKS0sLLx8/vz56vz8/KurV6+2emWr0+k8QkND+7/m7BnsAAAgAElEQVSvUqm0S6/XexARvf3229cOHDgQIBaLE1JTU6O3b99++aeuZTAwjAGANSQUkVDkIqHoaL/y8vKHmM8ez8nJkf73v/+1etLj6PtRVFQU8POf//ymwWCoKC4uvpCZmTmWuTIznFBtAuChJ2g3J/+AI6GIhCIXCcVXX33VZmCkp6eHRCJRt+U5sjzmunXrbjCvhImIdDqdJ3MF5LPPPnv42LFjNUREycnJbZ2dncLr16+7m1e+hgOGMQCwhoQiEopcJBTtCQgIMEVERHTt3r3bPysr67bJZKLvvvtu1GOPPdZuub+vr6/p66+/9p0zZ07b3r17A//nf/7nv0R9l9mPHDni9//+3/+7+cMPP3h3dXUJQkNDh71pjMvUAMAaEopIKHKRUCQiWrRo0dikpCTFpUuXvMRicUJBQcHDRET79u2rKyoqejgmJkYZHR0dd/DgwTG29i8sLNRlZ2fLpFJpvEwm60xLS2siIiooKLjy8ccfB8XExCiXL18+7sMPP9QyV2OGExKKADyBhCL3XHFN4DxIKAIAAPAIhjEAOIUr5gZdcU0wMmAYAwAAcAzDGAAAgGMYxgAAABzDMAYAAOAYhjEAcAoJRSQUkVDEMAYAF4CEojUkFO+FhCIAuBQkFJFQREJx6GEYA/CUrQziWdoSRERkpBahre3naXsgEdEd0rtbbmNzTCQUkVBEQtE5MIwBgDUkFJFQRELROVBtAuCpxXRaY2+bB4lMjrb7UGi3o+32IKGIhCISis6BYQwArCGhiIQiEorOgcvUAMAaEopIKCKh6BxIKALwBBKK3HPFNYHzIKEIAADAIxjGAOAUrpgbdMU1wciAYQwAAMAxDGMAAACOYRgDAABwDMMYAACAYxjGAMApJBSdk1Bkezt72tvbBQsWLBgnkUjiExISFBqNpv/cZWdnR0RFRcWNGzcuzjxHaE6j0XgyucO//OUvfnFxcbFyuVwZFxcXe/jwYZHVDj+yl2c0Zy/veP36dbfExES5j4/PpIyMDE7qS4OFYQwAvIeE4uBvZ8+2bdseHj16dPfly5cr16xZY1i/fn0EEdFXX33le/r06YfUavX5mpqa8//5z398jxw5Yne4EhEFBwcb//rXv9bW1NRUffzxx5dWrlw51tbtHOUZzdnLO/r4+PTm5eVdy83NvWq10wiHYQwAA4KEIj8SivZu193dTatWrYqIj4+Plcvlyvz8/Idt7V9SUjImKyvrJhHRihUrbn/zzTcik8lEAoGAOjs7BR0dHYL29nZhd3e3gPk8a3tmzJjRLpPJjER9n+LW1dUlbG9vF1jezlGe0Zy9vKOfn59p3rx5rd7e3qxjEyMFPpsagIf+RlmRDVQ54EuPjjxM8Xfm0W6HBSHzhKKXl1fvCy+8IDFPKE6bNq2NSShqNBpPrVbrvWvXLu3TTz/dlpaWJsvPzw/Ky8szWN7vuXPnfMvLyyvlcnnXzJkzo/fs2eO/YsWK20xCcceOHfXZ2dkRO3bsCNq6dave1mNLSkqKrqio8J01a1bTYBOKa9asufn222/fk0SsqKjwLS8vP69QKLrYrmkwCcWCgoIQ+2d+6Lz//vsPjx49uqeysrK6vb1dMG3aNMWiRYuazctUREQGg8Fz7NixXUR9H5v50EMP9RgMBvfk5OS2GTNmtISGhk4kIsrMzLwxefLkDrbH/+STT/yVSuUdJtphrr6+3vPRRx/tfyVvlme856oBmzwk3+CVMQCwhoQi/xOK//jHP/w+//zzQIVCoZw0aVLs7du33auqqrwtb2cvlVhZWelVU1PjffXq1YqrV69WnDx5UnT06FGb31dL33//vffGjRvD//SnP+lsbXdGnpEveP9sAuBBdL9XsM6ChCJ/Eor2btfb2yt49913Ly9durTZ/O8tz0lISEjXpUuXPMePH280Go3U2trqFhwc3PPBBx88PG3atLbRo0ebiIiSk5ObysrKfL28vHrNz8HUqVPbze//4sWLHsuWLYv66KOPLsXFxXUS9UUvNm/eHEZE9Mc//lHLNs/IJg/JNxjGAMAaEor8SSja89RTTzXt3LkzaOHChS1eXl69FRUVXjKZzGh5ThYsWNC4e/fuwOTk5LaioiL/xx57rEUoFJJEIukqKioKMhqNepPJJCgrKxOtXbvWYHkOzN993dDQ4Pazn/0sOjc39ypzVYGIKCMjozEjI6O/0OXj42Nik2dkk4fkG1ymBgDWkFDkT0LR3u3WrVvXoFAoOiZMmBAbHR0d9+KLL0qNRqPVm6leeumlhtu3b7tLJJL4HTt2hLzzzjtXifrezCWTyTpjYmLilEqlMi4u7s7y5ctt/iyesXXr1uDLly97bdmyJYxJJdbX11u9GHSUZ3zuueekzK9o2cs7EhGFh4dPeOONNyJVKlWgWCxOOHPmjNUl+JEICUUAnkBCkXuuuCZwHiQUAQAAeATDGACcwhVzg664JhgZMIwBAAA4hmEMAADAMQxjAAAAjmEYAwAAcAzDGAA4hYQiEormkFAEAOApJBQHfzt7kFAcXhjGADAgSCgioYiE4tDDMAbgqb00Pcby6zRtCSIi6qIWoa3t5bQ9kIiojfTultvYHNM8oahWq6uEQmGveUIxNzdXzCQUiYi0Wq13dnb2jZqamiqRSGTKz88PsnW/586d8922bdsVjUZzXqvVeu3Zs8efiIhJKGo0mqofU4o29yfqSygGBQVN9PX17RlsQrGysrI6JCTknsFSUVHhm5+fX3/x4sXzbNc0mISivXUNNfOE4tmzZ6s/+eSTILVabfUkhU1CMSwsLGHOnDnNQ5lQjIyM7D9vZgnFeyChCAAPNCQUkVBEQtE5eP9sAuBBlU6nNfa2eZLI5Gi7L4V2O9puDxKKSCgioegcGMYAwBoSikgoIqHoHLhMDQCsIaGIhCISis6BhCIATyChyD1XXBM4DxKKAAAAPIJhDABO4Yq5QVdcE4wMGMYAAAAcwzAGAADgGIYxAAAAxzCMAQAAOIZhDACcQkIRCUVzPyWh6Gj/kydP+sjlcqVEIok3f8xHjx59SKlUxrq7u08pKiryH+h5GioYxgDAe0goDv529vAxoeho/5ycHGlhYaFOq9VW1tXVeatUKj8ionHjxnUVFRVpFy1adNPqQMMIwxgABgQJRSQUR2pC0d7+Op3Oo7W1VZicnNwmFAopPT395hdffOFP1PfraomJie3MZ6BzBZ9NDcBDKsqKvE6VA7706EgIxd9ZRrsdFoTME4peXl69L7zwgsQ8oTht2rQ2JqGo0Wg8tVqt965du7RPP/10W1pamiw/Pz8oLy/PYHm/586d8y0vL6+Uy+VdM2fOjN6zZ4//ihUrbjMJxR07dtRnZ2dH7NixI2jr1q16W48tKSkpuqKiwnfWrFlNg00orlmz5ubbb799TxKxoqLCt7y8/LxCoehiu6bBJBQLCgpC7J/5oWOeUGxvbxdMmzZNsWjRombzMhURu4QiEVFmZuaNoUwoPvroo/2v5M0SivdcNbCXULS3v6enZ29oaGj/EwapVNql1+utvh9cwitjAGANCUUkFEdyQtHe/my+H1zDK2MAHrrfK1hnQUIRCcWRnFC0t79MJjOavxLW6XSeISEhDi+tDze8MgYA1lJSUppLSkr8meKOwWBwq6mp8VyzZk34smXLbm7YsOFaZmamlLk9kxskIrLMDarV6qr09PQmor7L1Gq12rOnp4dUKlXAE0880WL7EdxNKKrV6qr333//WlNTk1Cn03kQETEJRYVC0U50N6F46NChWsuEInMfRHcTikREbBOKjta0ZMmSptLSUr8bN2643bhxw620tNRvyZIl91wiZxKK9fX15+rr689NnDixTaVS1c6cOfOO5eNjQ6VSadVqdZWjQUx0N6HY2dkpICKqqKjwam5uFloek0koEvW929s8oVhWViYyGo3U2dkpKCsrEymVyg5b31eGo4Qis8/MmTPvLF26tLG4uDigvb1doFarPe+XUCQiMk8o2ttfKpUafX19TV9//bWvyWSivXv3Bj7zzDMjKruIYQwArCGhiITiSE4oOtq/sLBQl52dLZNKpfEymawzLS2tiYiotLTURywWJxw5csR/3bp10qioqDj2342hg4QiAE8gocg9V1wTOA8SigAAADyCYQwATuGKuUFXXBOMDBjGAAAAHMMwBgAA4BiGMQAAAMcwjAEAADiGYQwAnEJCEQlFc0goAgDwFBKKg7+dPUgoDi8MYwAYECQUkVBEQnHoYRgD8NQfaHqM5dcJ2hJERNRJLUJb28toeyARUTPp3S23sTmmeUJRrVZXCYXCXvOEYm5urphJKBIRabVa7+zs7Bs1NTVVIpHIlJ+fH2Trfs+dO+e7bdu2KxqN5rxWq/Xas2ePPxERk1DUaDRVP6YUbe5P1JdQDAoKmujr69sz2IRiZWVltWVAoKKiwjc/P7/+4sWL59muaTAJRXvrGmrmCcWzZ89Wf/LJJ0FqtdrqSQqbhGJYWFjCnDlzmocyoRgZGdl/3swSivdwlFC0tb9Op/NAQhEAXAYSikgoIqHoHEgoAvDUGjqtsbfNi0QmR9v9KLTb0XZ7kFBEQhEJRefAK2MAYA0JRSQUkVB0DgxjAGANCUUkFJFQdA4kFAF4AglF7rnimsB5kFAEAADgEQxjAHAKV8wNuuKaYGTAMAYAAOAYhjEAAADHMIwBAAA4hmEMAADAMQxjAOAUEopIKDKuX7/ulpiYKPfx8ZmUkZEhGehjJrJ/3g8dOiRSKpWxCoVCOWXKlJjKykqvwdy/s2AYAwDvIaE4+NvZw0VC0cfHpzcvL+9abm7u1cE8Zkfn/aWXXpJ+9tlnl9RqdVVaWtqtN998M3Qwx3AWDGMAGBAkFJFQdFZC0c/PzzRv3rxWb29vq5faxcXFfo888ohCqVTGzp8/f1xTU9OAz3tjY6MbEVFTU5ObecVpJEAoAoCH9lBWZD1VDvjSoyPhFH8ng3Y7LAiZJxS9vLx6X3jhBYl5QnHatGltTEJRo9F4arVa7127dmmffvrptrS0NFl+fn5QXl6ewfJ+z50751teXl4pl8u7Zs6cGb1nzx7/FStW3GYSijt27KjPzs6O2LFjR9DWrVv1th5bUlJSdEVFhe+sWbOaBptQXLNmzc233377niRiRUWFb3l5+XmFQtHFdk2DSSgWFBSE2D/zQ8c8odje3i6YNm2aYtGiRc3mZSoidglFIqLMzMwbQ5VQtEev17tv3rw59J///GeNn5+f6Te/+U3Ipk2bxO+88849/y84Ou8ffvihNjU1NdrLy8v00EMP9fz73/+uZnv84YBXxgDAGhKKSCg6M6Foz4kTJ3wvXrzoPX36dIVCoVD++c9/Drx8+bLV/wuOzvt7770nLi4uvmAwGCqWL1/esHr16siBPAZnwytjAB663ytYZ0FCEQlFZyYUZ86cecfOY6akpKTmL7/88pL537M979euXXOvrq4e9eSTT7YREWVkZNxOSUmxGdjgCoYxALCWkpLSnJqaGrVhwwZDeHh4t8FgcGtqanJ76623xMuWLbsplUq7MjMzpcePH68lupsbTE5ObrPMDTL3WVJSImISitHR0V0qlSpg5cqVNutORHcTisyfm5qahI2NjW5SqdTIJBRnzJjRQnQ3oXjkyJELlglFIup/QsEkFHNycm6xTSg6WpPBYHDLy8sLZ948VFpa6ldQUHDPm5KYhCLz5+nTp8e88847V2bOnHnnx6F0zxOe+1GpVFo2t2MSigsXLmzx8vLqraio8JLJZEbLc8IkFJOTk9ssE4pFRUVBRqNRbzKZBGVlZaK1a9caLM+B+buvHSUUMzIy7lvomj17dtvLL78sqays9IqPj+9saWkRXrp0yYPteQ8ICOhpbW11q6io8EpISOgsKSnxi4qKYn1pfTjgMjUAsIaEIhKKzkwoEhGFh4dPeOONNyJVKlWgWCxOOHPmjHdYWFj3rl27tM8///w4uVyunDJliuLcuXNWl9btnXcPDw/atm2bbtmyZeNjYmKU+/btCywoKODk6pI9SCgC8AQSitxzxTWB8yChCAAAwCMYxgDgFK6YG3TFNcHIgGEMAADAMQxjAAAAjmEYAwAAcAzDGAAAgGMYxgDAKSQUkVBkIKEIAMBjSCgO/nb2IKE4vDCMAWBAkFBEQhEJxaGHYQzAU2/T9BjLr2O0JYiIqINahLa2/x9tDyQiaiK9u+U2Nsc0Tyiq1eoqoVDYa55QzM3NFTMJRSIirVbrnZ2dfaOmpqZKJBKZ8vPzg2zd77lz53y3bdt2RaPRnNdqtV579uzxJyJiEooajabqx5Sizf2J+hKKQUFBE319fXsGm1CsrKysDgkJuecf6YqKCt/8/Pz6ixcvnme7psEkFO2ta6iZJxTPnj1b/cknnwSp1WqrJylsEophYWEJc+bMaR7OhGJVVVX15MmT72zatElseTs2CUWxWJzw+eefB+bl5dlMcXIFwxgAWENCEQlFJBSdA9UmAJ56jU5r7G3zJpHJ0fbRFNrtaLs9SCgioYiEonNgGAMAa0goIqGIhKJz4DI1ALCGhCISikgoOgcSigA8gYQi91xxTeA8SCgCAADwCIYxADiFK+YGXXFNMDJgGAMAAHAMwxgAAIBjGMYAAAAcwzAGAADgGIYxAHBqKBKKa9euDQ8JCUmwTB86SiiyyQBaWrp0qayoqMj/pzxWtVrtmZCQoJBKpfELFiwY19HRYfU7vkR9WUiRSPSIo3NjnikcSH7wtddeC5FIJPEymSz+4MGDfrZuYzAY3B5//PFoqVQa//jjj0czH6TB9jjm39edO3cGyOVypVwuV06aNEnx7bffjrK1j8lkoszMzEiJRBIvl8uVp06dspl+tHcOy8vLvR955BGFp6fnZCY5yRcYxgDAe0uWLGn87rvvqi3/3l5CcTAZQEcGkldcv359xJo1aww6na5y9OjR3du2bbNZTXrllVeu79q165KtbbawzQ+eOXPGu7i4OECj0Zw/duxYza9//WuJrcf/5ptvhs6ePbtFp9NVzp49u2Xjxo0hAzmOuaioqM6ysjJNTU1N1WuvvXZt1apVUlu3O3DgwOi6ujpvrVZbuXPnTl1OTo7NYW/vHAYHB3dv27bt8qpVqwxsH9tIgWEMAAMyEhOKc+fObZNKpVZJPHsJRbYZQJPJRBkZGZLx48fHzZ49O6qhoaH/+OHh4RNeeeWV0ClTpsTs3r3bf/r06TFZWVmRkyZNUkRHR8cdP37c6lWdyWSib7/9VsRUpbKysm5++eWXY2yt6Zlnnmnx8/O7/8v1HznKD5pTqVRjUlNTb40aNapXoVB0SaXSzhMnTvha3u7YsWNjmGjGqlWrbh49etR/IMcx99RTT7UFBQX1EBHNmTOnjfkcc0uHDh0ak56eflMoFNLcuXPbmpub3XU63T21K0fnMDw8vHvWrFl3PDw8ePdpVvhsagAe2klZkVeo0uYlvMGKpPg7q2m3w48INE8oenl59b7wwgsS84TitGnT2piEokaj8dRqtd67du3SPv30021paWmy/Pz8oLy8PKtXLefOnfMtLy+vlMvlXTNnzozes2eP/4oVK24zCcUdO3bUZ2dnR+zYsSNo69atg0rfmScUzTOARESZmZk3bGUAP/300zG1tbVeGo3m/NWrVz0mTJgQl5mZ2V918vb2Np05c0ZDRPS///u/wXfu3BGWl5erjx49+tCvfvWrsZa/k2wwGNxFIlGPh0fffJHJZF0Gg8FuicoZ6uvrPR999NFW5s9hYWFdV65c8SSiNvPb3bx50515giOVSo23bt0aknmxY8eOh+fMmWPz4zP1er2HTCbrL2SFhoZ26XQ6D/MnWiPhHDoDXhkDAGsjOaHoiGVCkW0GsLS0VPTss8/ecnd3J5lMZnzsscfuKS9lZGTc001evnz5LSKi+fPnt7a2tgobGhru+Zxre1nCwaxpsLh8DF9++aXos88+e3jbtm02L3GzSU+OhHPoDHhlDMBD93sF6ywjPaFoi62E4v79+8ewyQDaWoM55hK45eM2/3NSUlJ0Q0ODx8SJE9v27duna2lpcTMajeTh4UFardYzODjY6vK4PZbnzjJTaItlpjAiIoJ5JUxERNeuXfOMiIiwegyBgYHdzKtSnU7nERAQ4PAH45bHsdz+3XffjcrJyZH+9a9/vRASEtJDRPT2228HffLJJ0FERMeOHbsQFhZm1Gq1/Y9Nr9d7SiSSex5bSEhI9085hyMVXhkDAGspKSnNJSUl/kxxx2AwuNXU1HiuWbMmfNmyZTc3bNhwLTMzs//NOUxukIjIMjeoVqur0tPTm4j6LlOr1WrPnp4eUqlUAU888USL7UdwN6GoVqur7jeImYTioUOHas0TihKJpKusrExkNBqps7NTUFZWJlIqlR2Wj23WrFktBw4cCOju7iadTufxr3/9y+GbvPbt2+dPRPS3v/3tIZFI1BMYGNhz6tSpC2q1umr//v06oVBIjz76aAvzjuzdu3cHLvz/2bv/sKbuu//jbwIhWH5YpBjlRwIKIU2AWhFrezksrkW8+nWrP5jbpP0Gey9Ga+9We3W7a1eL2O22pNpC1h84RmnutV07tPZab2nXOau9+0O7gmsQk2j1REBuZhXlh/w0fP+gh+8h5CQHJJ6kvh7X5R/15OTkxFx98wnJef6f/yO4UOXuufPmwQcfvMTuk5OTc2XlypWX9u7dO62npyfIarWGMgwTdvfdd3e77rdkyZJLFRUVMUREFRUVMfn5+R4fp+txuNtOnjwZWlBQMLuqqupMZmZmH/v3Tz755Hl2n6SkpIEf/ehHl954440Yp9NJBw4cCI+MjLzq+lmAa30O/RWGMQAI5o8JRaLhrynJ5fLM3t5eiVwuz9y8eXMcEX9CUWgG8IEHHrg0a9asvrS0NO1DDz2kmD9/Pu8PCURE0dHRV2+//Xb1xo0blRUVFYy72+zcubPZZDLNUCgU6e3t7SGPPvrot0REhw8fvmn16tUjP8hkZWWlPfDAA7M+//zzKLlcnsn3FSQud/lB19vMmzev9/7777+oUqm0+fn5ql27djlCQobfJF29erXy8OHDNxERbdu2rfXgwYNRSqUy/eDBg1Hbtm1rHc9xuH7961/PvHTpUsgjjzyiVKvVmvT09Fvd3e4nP/nJZaVS2adUKtPXr1+vfOmllxzstkWLFqUwDCP19ByePXs2RC6XZ+7evVv+wgsvzJTL5ZkXL14MiDmHhCJAgEBC0b/Nnz8/7fnnn29yXRXCjQsJRQAAgACCD3ABgE/caLnBo0eP2sR+DBC4sDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKSCiykFAEAAhgSCgioUiEhCIA3ECQUByGhCISipMJwxggQG2h+Wmuf/bRjlgioh7qlLjbXkvlMURE7dQa4rpNyDG5CUWr1dookUiGuAnF4uJiOZtQJCJiGCbMYDCct9vtjZGRkU6j0Rjr7n4tFkt4WVlZk81mO84wjMxsNkcTEbEJRZvN1vhdStHt/kLwJRTj4uIyc3NzO7wlFKurqx11dXWjyk5sQlGv17cTEbEJxfLycoder092vT9/yP+1tLSEJiYmjmQKOQnFUfwpoci9jT88h76AYQwAgiGhiITitUBCkR+uwAUQoH5L/Fd8mkKRTk/bo2nmoKftfJBQHA0JRf7juG5HQtEzrIwBQDAkFJFQFHoc7jYkFL3DMAYAwZBQREJR6HG4kFD0DglFgACBhKJ/Q0IRXCGhCAAAEEDwAS4A8AkkFAGEw8oYAABAZBjGAAAAIsMwBgAAEBmGMQAAgMgwjAFAVEgoIqHIutaEoqf9a2pqopKSktIVCkX6li1bZrB/X1VVFZ2SkqKVSCRZ7HesxYBhDAABDwlFJBQ97T84OEibNm1S7N+/326324/v2bNnGnuhkjlz5vTs2bPn1Lx587qEno8vYBgDwLggoTgMCUX/Syjy7f/xxx+HK5XKPo1G0x8WFja0YsWKizU1NTcTEc2dO7f3tttu6xv7aK4vfM8YIADtpLWJDDVM6ltqSZR+5XGqavJ0G25CUSaTDRUWFiq4CcXs7OxuNqFos9lCGYYJq6ioYPLy8roLCgqSjEZjbElJyZjwu8ViCa+vr29QqVT9OTk5qWazObqoqKidTSiaTKYWg8GQYDKZYktLS1vdPTZv+BKKREQ6ne68t4Ric3OzNCMjQ6vT6S6w29mEIhFRZWXldDahWFtbG6HX65Ndv2ftD/m/lpaW0AULFoysAjkJxVHXp/anhCL3By1PzyHf/k1NTaHx8fEjf5+QkNB/5MgRtwUxsWBlDACCIaGIhOK18HVCkW9/f3jevcHKGCAAeVvB+goSiqMhoch/HNft1yOhyLd/X19fUEtLy8jfNzc3h7r7tYSYsDIGAMGQUERCUehxuNuuV0KRb/9FixZ1MwwTZrVaQ3t7e4P27t07beXKlX6VXcQwBgDBkFBEQlHocbiuV0KRb3+pVEo7d+48m5+fr0pNTdXef//9F+fNm9dLNLyil8vlmceOHQtfvnx56sKFC1O9Pc++gIQiQIBAQtG/IaEIrpBQBAAACCD4ABcA+AQSigDCYWUMAAAgMgxjAAAAkWEYAwAAiAzDGAAAQGQYxgAgKiQUkVBkIaEIABDAkFBEQtHT/kgoAsD3DhKKw5BQREJxMmEYAwSoR2h+muuft2lHLBFRD3VK3G3fR+UxREQXqTXEdZuQY3ITilartVEikQxxE4rFxcVyNqFIRMQwTJjBYDhvt9sbIyMjnUajMdbd/VoslvCysrImm812nGEYmdlsjiYiYhOKNput8buUotv9heBLKMbFxWXm5uZ2eEsoVldXO+rq6kaVndiEol6vbyciYhOK5eXlDr1en+x6f/6SUExMTBzJCXISiqP4U0KRe5vJSihywxH+AMMYAARDQhEJxWuBhCI/XIELIFjmZGIAACAASURBVECZiP+KT1Mo0ulp+zSaOehpOx8kFEdDQpH/OK7bkVD0DCtjABAMCUUkFIUeh7sNCUXvMIwBQDAkFJFQFHocLiQUvUNCESBAIKHo35BQBFdIKAIAAAQQfIALAHwCCUUA4bAyBgAAEBmGMQAAgMgwjAEAAESGYQwAACAyDGMAEBUSikgosurr68PmzJmjDg0Nnbt161a5p3MY77lVVFSMPIYf/OAHqa2trX71AWYMYwAIeEgofj8SitOnTx8sKys7u27dujah9y3k3AYGBujJJ59MPHTokN1utzdqtdoeo9E4fSLH8BUMYwAYFyQUhyGhOPkJxfj4+MFFixZdkUqlY65G5fq6c/cDBN+5OZ3OoKGhIers7JQ4nU7q6OiQxMXF9Y+5AxH51TIdAITZTmsTT1PDmP/ZX4tZlH7laapq8nQbbkJRJpMNFRYWKrgJxezs7G42oWiz2UIZhgmrqKhg8vLyugsKCpKMRmNsSUnJmFWPxWIJr6+vb1CpVP05OTmpZrM5uqioqJ1NKJpMphaDwZBgMpliS0tLW909Nm/4EopERDqd7ry3hGJzc7M0IyNDq9PpLrDb2YQiEVFlZeV0NqFYW1sbodfrk12/Z+0vCcUFCxZ0sf/NSSiOuj61GAlFPu5ed6+++mrMxo0bL3Bvx3duMpmse9euXWfnzp2rnTJlylWlUtlnNpvPTsb5TBasjAFAMCQUkVC8Ft4Sinz4Xneut+M7t76+vqDdu3fHHjlypLGtre1rjUbTs2XLlpnXcCqTDitjgADkbQXrK0gojoaEIv9xXLcLSSgmJSW5fS74XndCz+2LL76YQkSk1Wr7iIh+9rOfXdyxY8cMT+dzvWFlDACCIaGIhKLQ43C3CU0o8t033+tO6LkplcqBU6dOhZ07dy6EiOiDDz6IUqlUY34tISasjAFAMG5C0el0klQqHSotLW06duxY+B/+8AdrSEgIvfvuu9FlZWUx+fn5nWxCccOGDcrk5OQ+bwlFq9U65Y477uicSELx3XffncYmFNesWfPtrl27znETikTDv0P8+9//fqqoqKj94MGDUWlpadqgoCDKzc29zJdQPHDgQFRaWpo2OTm5V2hCsaurK3j37t1uPwm9c+fO5tWrV89+9tln47Va7RVuQvGll16Kffvttx3fPddpp0+fDuvp6QmWy+WZL7/8MrNy5coOT8ePj4/P6OrqCh4YGAj68MMPb96/f789Kytr1NDhJhSDg4PJNaH48MMPn8/Jybmybdu21uXLl89WKpW3xMXF9e/bt++b8RyHi5tQJBp+x6OhoWHMp9/Pnj0bkp2drenu7g4OCgoaqqiokJ84caLB3euuvLz8rEqlGvUhLL5zS0pKGnjiiSdaFy5cmBYSEjKUkJDQ/+abbwr+pPr1gIQiQIBAQtG/IaEIrpBQBAAACCB4mxoAfAIJRQDhsDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKSCiykFAEAAhgSCgioejp3JBQBIDvHSQUhyGhiITiZMIwBghQRTQ/zfXP67QjlojoCnVK3G1/m8pjiIi+pdYQ121CjslN2Vmt1kaJRDLETSgWFxfL2YQiERHDMGEGg+G83W5vjIyMdBqNxlh392uxWMLLysqabDbbcYZhZGazOZqIiE0o2my2xu9Sim73F4IvoRgXF5eZm5vb4S2hWF1d7airqxtVdmITinq9vp2IiE0olpeXO/R6fbLr/flLQjExMXFkEHESiqP4a0KRfd29+uqrMa634zs3mUw2xCYU5XJ5pt1un/LYY4/51dXsMIwBQDAkFJFQvBZIKPLzq19gA4BwrxH/FZ9uokinp+230MxBT9v5IKE4GhKK/Mdx3Y6EomdYGQOAYEgoIqEo9DjcbUgoeoeVMQAIhoQiEopCj8OFhKJ3SCgCBAgkFP0bEorgCglFAACAAIK3qQHAJ5BQBBAOK2MAAACRYRgDAACIDMMYAABAZBjGAAAAIsMwBgBRIaEYWAlFT/t/8sknN6lUKo1CoUjnPqe1tbURGo3m1pCQkCxPz9/mzZvj2HTiunXrEpKTk7UqlUpz7733zna9tKiQx8lVU1MTlZSUlK5QKNK3bNkycvWtqqqq6JSUFK1EIsk6fPjwmLjH9YJhDAABDwnF65dQ9LT/hg0blC+//LKDYZiG06dPh9XU1EQREc2aNav/tddeY5YtW3ZB6PksWbKkw263H7fb7Y0pKSm9Tz/9tNvLV/I9Tq7BwUHatGmTYv/+/Xa73X58z54907766qswIqI5c+b07Nmz59S8efO6hD42X8AwBoBxQUJx2I2aUOTb3+FwSLu6uiT33HNPt0QioTVr1lzYt29fNNHw19zuuOOOHvY640KsWLGig61b3Xnnnd0tLS1uIyF8j5Pr448/DlcqlX0ajaY/LCxsaMWKFRdrampuJiKaO3du72233dbnus/1hu8ZAwSgX9LaRBs1TOpbammUfqWUqpo83YabspPJZEOFhYUKbkIxOzu7m00o2my2UIZhwioqKpi8vLzugoKCJKPRGFtSUjImHG+xWMLr6+sbVCpVf05OTqrZbI4uKipqZxOKJpOpxWAwJJhMptjS0tLWiZwfX0KRiEin0533llBsbm6WZmRkaHU63cjqjk0oEhFVVlZOZxOKtbW1EXq9Ptn1e9b+klBcsGDByCqQk1AcdX1qvoQi3/6hoaFDM2fOHPmBRqlU9re2tkon4zFXV1ffsmrVqovutglJPTY1NYXGx8ePXDozISGh/8iRI24LYmLByhgABENCEQlFvv15/n6cj26sX/3qVzOCg4OHDAaD22EshD88795gZQwQgLytYH0FCcXRbsSEIt/+SUlJA9yVsMPhCJ0xY4bHc3vkkUfiP/roo6lERFartdF1u8lkivnwww9v/uSTT+zs62DVqlVJDQ0NN8nl8v5Dhw6dEpJ6VCgU/dy3uZubm0Pd/VpCTFgZA4BgSCgioegpUxgeHu48cOBAuNPppDfeeCPmxz/+scdzM5lMLexjc91WU1MT9eKLL87Yv3//Ke4PPTU1NYzVam08dOjQKU+Pk2vRokXdDMOEWa3W0N7e3qC9e/dOW7ly5bjKYL6GYQwAgnFTdiqVSrN48WLVyZMnQ48dOxb+7LPP/u/69esvSqXSobKyshgiIjahqFKpNO3t7SHeEooqlUqrUCj6JpJQlMvlmWxCcfPmzXFERNyEolqt1ixevDiFiKioqKg9KSmpLy0tTavRaDRarfYKX0Jx1qxZfWlpadqHHnpIITShuHHjRmVFRQXj7jY7d+5sNplMMxQKRXp7e3sIN6G4evXqkR9ksrKy0h544IFZn3/+eZRcLs/k+woSV3x8fMbTTz+dWFNTEyOXyzPZTwxzcTOD+fn5KteEIvv1nm3btrUePHgwSqlUph88eDBq27Ztrd72f/nllx0GgyFJqVSmJyUl9RUUFFwmIjp06NBNcrk8c//+/dGbNm1SpqSkaL2dy+bNmxXd3d3BixcvVn33YUG3X9fie5wMw0gXLVqUQkQklUpp586dZ/Pz81Wpqana+++//+K8efN6iYbfOZDL5ZnHjh0LX758eerChQtTvT02X0BCESBAIKHo35BQBFdIKAIAAAQQfIALAHwCCUUA4bAyBgAAEBmGMQAAgMgwjAEAAESGYQwAACAyDGMAEBUSikgospBQBAAIYEgoIqGIhCIA3FCQUByGhCISipMJwxggQP2Y5qe5/nmFdsQSEXVTp8Td9moqjyEi+he1hrhuE3JMbkLRarU2SiSSIW5Csbi4WM4mFImIGIYJMxgM5+12e2NkZKTTaDTGurtfi8USXlZW1mSz2Y4zDCMzm83RRERsQtFmszV+l1J0u78QfAnFuLi4zNzc3A5vCcXq6mpHXV3dqLITm1DU6/XtRERsQrG8vNyh1+uTXe/PXxKKiYmJIzlBTkJxFE8JRXf7OxwOqS8Tivn5+W6vxT3RhCLfcBcLhjEACIaEIhKKSCj6Bq7ABRCg3iP+Kz6FU6TT0/bpNHPQ03Y+SCiOhoQiEoqTBStjABAMCUUkFJFQ9A0MYwAQDAlFJBSRUPQNJBQBAgQSiv4NCUVwhYQiAABAAMEHuADAJ5BQBBAOK2MAAACRYRgDAACIDMMYAABAZBjGAAAAIsMwBgBRIaGIhCJLjITiRM6T7/V2LTCMASDgIaGIhOJEE4oTOU++19u1wDAGgHFBQnEYEorfj4TieM+TiP/1di3wPWOAALSR1iaeoIYx/7O/FrdS+pXfUVWTp9twE4oymWyosLBQwU0oZmdnd7MJRZvNFsowTFhFRQWTl5fXXVBQkGQ0GmNLSkraXO/XYrGE19fXN6hUqv6cnJxUs9kcXVRU1M4mFE0mU4vBYEgwmUyxpaWlrRM5P76EIhGRTqc77y2h2NzcLM3IyNDqdLqR1R2bUCQiqqysnM4mFGtrayP0en2y6/es/SWhuGDBgi72vzkJxVHXp/aUUHS3f2ho6JAvE4qrVq1yW22aaELxyJEjERM5T3J5niYLVsYAIBgSikgo3igJxev9b4WVMUAA8raC9RUkFEdDQjHwE4rjPU9P53MtsDIGAMGQUERC8fuWUBzveQp5zicCwxgABENCEQnF71tCcSLnyfd6uxZIKAIECCQU/RsSiuAKCUUAAIAAgg9wAYBPIKEIIBxWxgAAACLDMAYAABAZhjEAAIDIMIwBAABEhmEMAKJCQhEJRRYSigAAAQwJRSQUkVAEgBsKEorDkFBEQlHwyQiAYQwQoH5I89Nc/7xAO2KJiLqoU+JuewWVxxARtVFriOs2IcfkJhStVmujRCIZ4iYUi4uL5WxCkYiIYZgwg8Fw3m63N0ZGRjqNRmOsu/u1WCzhZWVlTTab7TjDMDKz2RxNRMQmFG02W+N3KUW3+wvBl1CMi4vLzM3N7fCWUKyurnbU1dWNKjuxCUW9Xt9ORMQmFMvLyx16vT7Z9f78JaGYmJg4khPkpAFH8ZQWdLe/w+GQ+jKhmJ+f7/Za3BNNKLLDfbznORnn4w6GMQAIhoQiEopIKPoGrsAFEKAOEP8VnyIo0ulpu5xmDnrazgcJxdGQUERCcbJgZQwAgiGhiIQiEoq+gWEMAIIhoYiEIhKKSCgC3NCQUPRvSCiCKyQUAQAAAgg+wAUAPoGEIoBwWBkDAACIDMMYAABAZBjGAAAAIsMwBgAAEBmGMQCICglFJBRZE0koVlVVRaekpGglEkkW+x3p8ejp6Qm67777ZikUivTMzEy1zWa7ptfIRGEYA0DAQ0Lxxk0ozpkzp2fPnj2n5s2b1yX0vrnKyspumTp16uDZs2cbNm7c2LZ582afvEa8wTAGgHFBQnEYEor+kVCcO3du72233dbn+veDg4O0bt26hPT09FtVKpXGaDS6/aHn/fffv3nt2rUXiIavzPbZZ59FOp1Owa+RyYLvGQMEoLW0NrGBGsb9lpwn6ZR+pYqqmjzdhptQlMlkQ4WFhQpuQjE7O7ubTSjabLZQhmHCKioqmLy8vO6CgoIko9EYW1JS0uZ6vxaLJby+vr5BpVL15+TkpJrN5uiioqJ2NqFoMplaDAZDgslkii0tLW2dyPnxJRSJiHQ63XlvCcXm5mZpRkaGVqfTjazu2IQiEVFlZeV0NqFYW1sbodfrk12/Z+0vCcUFCxaMrCI5acBR1132lBZ0t39oaOiQLxOKq1atGle16cUXX7xl6tSpVxsaGk709PQEZWdnq5ctW9ahVqv7ubdra2sLTU5O7icavmxmRETE1ba2thChr5HJgpUxAAiGhCISioGSUPzb3/4W9c4778So1WrN7bfffmt7e3tIY2PjmGt1852P0NfIZMHKGCAAeVvB+goSiqMhoSh+QpHvvoeGhoJ27tx5duXKlR2ejjljxoz+M2fOhM6ePXtgYGCAurq6gqdPn371pZdeusXda2Tp0qUT+t20N1gZA4BgSCgioehvCUU+99577+VXXnkltq+vL4iI6Ouvv5Z1dHRIXI953333XaqqqoohInrttdei77zzzk6JRML7GvH+jE8MhjEACIaEIhKK/pZQNJvNN8vl8sxjx46FL1++PHXhwoWpRESbNm36Vq1W92ZkZNyampqq/cUvfqEcGBgY8zbHo48++m17e3uIQqFIN5lMM55//vlmIuGvkcmChCJAgEBC0b8hoQiukFAEAAAIIPgAFwD4BBKKAMJhZQwAACAyDGMAAACRYRgDAACIDMMYAABAZBjGACAqJBSRUGQhoQgAEMCQUERCEQlFALihIKE4DAlFJBQnE4YxQICaT/PTXP/soB2xRESd1Clxt72cymOIiFqpNcR1m5BjchOKVqu1USKRDHETisXFxXI2oUhExDBMmMFgOG+32xsjIyOdRqMx1t39WiyW8LKysiabzXacYRiZ2WyOJiJiE4o2m63xu5Si2/2F4EsoxsXFZebm5nZ4SyhWV1c76urqRlV72ISiXq9vJyJiE4rl5eUOvV6f7Hp//pJQTExMHMkIchKKo3hKKLrb3+FwSH2ZUMzPzx/XpSi5CcV//vOfJ15//fVYq9U65jyFJBQ9vUYmC4YxAAiGhCISikgo+gauwAUQoI4S/xWfIinS6Wn7TJo56Gk7HyQUR0NCEQnFyYKVMQAIhoQiEopIKPoGhjEACIaEIhKKSCj6BhKKAAECCUX/hoQiuEJCEQAAIIDgA1wA4BNIKAIIh5UxAACAyDCMAQAARIZhDAAAIDIMYwAAAJFhGAOAqJBQvL4JxfGkFvmYTKYYpVKZrlQq000mUwz79++9916kRqO5Va1Wa7KystIaGhpk7vafP39+2uHDh2/q7OyU3H333SnJycnalJQU7YYNG+L5jsmXZ3TFl3fke434CwxjAAh4SCgKTygKvR2ftra24Oeeey7u6NGjJ/7xj3+ceO655+LY1vGjjz6q/OMf/3jGarU2FhQUXHzmmWdmeru/xx9/vO3MmTPHGxoaGo8cORLxzjvvuL24CV+ekctT3pHvNeIvMIwBYFyQUBwWqAlFT7fbu3dv1Jw5c9QajebWpUuXzrp8+fKYf699+/ZNzcnJ6ZDL5VdjY2Ov5uTkdOzdu3cqu/3SpUvBRESXL18O5lac3ImMjHQuW7ask4goLCxsKDMz84q7gpSnPCOXpzwk32vEX+B7xgABaC1tTGygE2P+Z38t0unWK1X0uyZPt+EmFGUy2VBhYaGCm1DMzs7uZhOKNpstlGGYsIqKCiYvL6+7oKAgyWg0xpaUlLS53q/FYgmvr69vUKlU/Tk5Oalmszm6qKionU0omkymFoPBkGAymWJLS0tbJ3J+fAlFIiKdTnfeW0KxublZmpGRodXpdBfY7WxCkYiosrJyOptQrK2tjdDr9cmu37P2h4Qin9bW1pDf/va3Mw8fPmyPiopyPvXUUzO2b98uf/7550c93y0tLdKEhISRhGJ8fHx/S0uLlIjo1VdfZVasWJEqk8mcERERV7/88kvBK9Fvv/02+KOPPrr5iSeeGPP6EJpnbGlpCV2wYMFIyIGThxxz7W1/g5UxAAiGhGLgJxT5fPzxx+HffPNN2Pz589VqtVrzpz/9Kebs2bNjnm9PqcRdu3bJ9+7de7Ktre3rn//859+uX78+UcixBwYGaMWKFbP0en2bRqPpd90uNM/oz8+vN1gZAwQgbytYX0FCcbRATCjyXTt7aGiIFi5c2PGXv/xl1O+pXY+ZkJAwcOjQoZHfr7e0tIQuWrSo89y5cyEnTpyYsnjx4m6i4R9U8vPzU4lo1HPw9ttvO1yP/fOf/zxp1qxZvVu3bv0X0fDv4Ln/xps2bTovJM8oNA/pjzCMAUCw/Pz8jhUrVqRs2bKlLT4+frCtrS348uXLwb/5zW/kq1atuqBUKvt1Op3y4MGDp4j+f0Lxnnvu6XZNKLL3+f7770eyCcXU1NT+mpqaaf/2b//mtu5E9P8TikIeL5tQ3L9//0nXhOJrr70WOzAw0Op0OoM+/fTTyEceeaTN9bENDg4G/f73v499+OGHL7S0tEi/+OKLyJ/97Ge8kfu33noretmyZZ2uCUXubdiEol6vb59oQpH9b5vN5vWdggcffPDSgw8+6PUYd999d/fjjz+uaGhokKWnp/d1dnZKzpw5I3U9ZltbW3BJSUk8+6GtQ4cORb3wwgvN06ZNu9rV1RX89ddfyzIzM/vef//9qJSUlF4iItfngOvf//3f4zo6OoL/9Kc/Mezfufs3ZvOMubm53W+88UbMww8//C/X+1q5cuWlNWvWzNq6dWubw+GQ8uUh/RHepgYAwZBQDPyEIt/t4uLiBisqKpif/vSns1QqlSYrK0ttsVjG7C+Xy68+8cQT57Kysm7Nysq69Ze//OU5uVx+VSqVUllZmWPVqlWz09LSNG+99VbMCy+84PEdnG+++UZqMplmnjx5Mkyr1WrUarVm165dbj9dzpdnfOONN6Y+9thjcUSe8458rxF/gYQiQIBAQtG/IaEIrpBQBAAACCD4nTEA+AQSigDCYWUMAAAgMgxjAAAAkWEYAwAAiAzDGAAAQGQYxgAgKiQUkVBEQhHDGAC+B5BQREKRCAlFALiBIKE4DAlFJBQnE4YxQICaTz9Mc/2zg16IJSLqpC6Ju+3lVBFDRNRKbSGu24Qck5tQtFqtjRKJZIibUCwuLpazCUUiIoZhwgwGw3m73d4YGRnpNBqNse7u12KxhJeVlTXZbLbjDMPIzGZzNBERm1C02WyN36UU3e4vBF9CMS4uLjM3N7fDW0KxurraUVdXN6rsxCYU9Xp9OxERm1AsLy936PX6ZNf7C5SEYmNj44m5c+de2b59u9z1dkISinK5PPOdd96JKSkpEZy7ZBOKS5cu7XDdNp6EYmJi4shj4yQU/R6GMQAIhoQiEopIKPoGrsAFEKCO0gHeKz5FUoTT0/aZJB/0tJ0PEoqjIaGIhOJkwTAGAMGQUERCEQlF38Db1AAgGBKKSCgioegbSCgCBAgkFP0bEorgCglFAACAAILfGQOATyChCCAcVsYAAAAiwzAGAAAQGYYxAACAyDCMAQAARIZhDACiQkIRCcXrkVDk27+npyfovvvum6VQKNIzMzPV3AupCPk3mCwYxgAQ8JBQREKRyHNCkW//srKyW6ZOnTp49uzZho0bN7Zt3rw5gb2/8f4bXAsMYwAYFyQUhyGhGDgJRU/7v//++zevXbv2AtHwldk+++yzSHbVPN5/g2uB7xkDBKC19MvEBrKN+Z/9tUintCtVVOrx8oXchKJMJhsqLCxUcBOK2dnZ3WxC0WazhTIME1ZRUcHk5eV1FxQUJBmNxtiSkpI21/u1WCzh9fX1DSqVqj8nJyfVbDZHFxUVtbMJRZPJ1GIwGBJMJlNsaWmp4CwfF19CkYhIp9Od95ZQbG5ulmZkZGh1Ot0FdjubUCQiqqysnM4mFGtrayP0en2y6/esAyWhGBUV5XzqqadmbN++Xf7888+Per6FJBRlMpkzIiLi6pdffjnm3Qo+bELxiSeeGPP6GE9CccGCBV3sf7MJxdDQ0CG+/dva2kKTk5P7iYikUilFRERcbWtrC5k5c6bwtzsmAVbGACAYEopIKAZiQtHT/v7yb4KVMUAA8raC9RUkFEdDQjEwEopJSUkDfPvPmDGj/8yZM6GzZ88eGBgYoK6uruDp06df9fa8TjYMYwAQDAlFJBQDMaEYEhLCu/999913qaqqKuaee+7pfu2116LvvPPOTvYHwOsJwxgABOMmFJ1OJ0ml0qHS0tKmY8eOhf/hD3+whoSE0LvvvhtdVlYWk5+f38kmFDds2KBMTk7u85ZQtFqtU+64447OiSQU33333WlsHm/NmjXf7tq16xw3oUg0/DvEv//976eKioraDx48GJWWlqYNCgqi3Nzcy3wJxQMHDkSlpaVpk5OTe4UmFLu6uoJ3797t9lO4O3fubF69evXsZ599Nl6r1V7hJhRfeumlWHblmJWVlXb69Omwnp6eYLlcnvnyyy8zK1eu7PB0/Pj4+Iyurq7ggYGBoA8//PDm/fv327Oyssb8LpzvdmxCsb+/P4iI6JlnnmnJzMzs4+7LTSgSEbEJRSIaSSgGBQXR1KlTr1ZXV3v8JDKbUExOTu7VarUaIiK9Xv+vzZs3j6mTvfzyy46HHnooube3Nyg3N7eDm1D88ssvw1988cVz3IRicHAwcROKfPs/+uij365cuTJZoVCkT5069erbb7/9DXvMifwbTBQSigABAglF/4aEIrhCQhEAACCA4G1qAPAJJBQBhMPKGAAAQGQYxgAAACLDMAYAABAZhjEAAIDIMIwBQFRIKCKhiIQihjEAfA8goYiEIhESigBwA0FCcRgSikgoTiYMY4AANZ9+nOb6Zwe9EktE1EndEnfby6k6hoiolf4V4rpNyDG5CUWr1dookUiGuAnF4uJiOZtQJCJiGCbMYDCct9vtjZGRkU6j0Rjr7n4tFkt4WVlZk81mO84wjMxsNkcTEbEJRZvN1vhdStHt/kLwJRTj4uIyc3NzO7wlFKurqx11dXWjyk5sQlGv17cTEbEJxfLycoder092vb9ASSg2NjaemDt37pXt27fLXW8nJKEol8sz33nnnZiSkhLBuUs2obh06dIxl5scT0IxMTFx5LGxCUVP+/MlFIU+7smCYQwAgiGhiIQiEoq+gStwAQSoo/Qe7xWfIinc6Wn7TJo+6Gk7HyQUR0NCEQnFyYJhDACCIaGIhCISir6BYQwAgiGhiIQiEopIKALc0JBQ9G9IKIIrJBQBAAACCN6mBgCfQEIRQDisjAEAAESGYQwAACAyDGMAAACRYRgDAACIDMMYAESFhCISikISinz/xkLxPe8XLlwIXrx4cUpaWpomJSVFW1ZWFuPtvnwBwxgAAh4Sit//hCLfv7FQfM+70WiMTUtL67HZbI2HDx+2bd26NZHvByRf8xBPmAAAIABJREFUwjAGgHFBQnEYEorXL6FIxP9vfO7cuZAlS5bMTk9PvzU9Pf3Wv/71r+Gut/H0vAcFBVFnZ2ew0+mkjo4OydSpUwelUilCEQDg3VranthAp8f8z/5apNOsK1X0dJOn23ATijKZbKiwsFDBTShmZ2d3swlFm80WyjBMWEVFBZOXl9ddUFCQZDQaY0tKStpc79disYTX19c3qFSq/pycnFSz2RxdVFTUziYUTSZTi8FgSDCZTLGlpaWCs3xcfAlFIiKdTnfeW0KxublZmpGRodXpdBfY7WxCkYiosrJyOptQrK2tjdDr9cmu37MOlIRiVFSU86mnnpqxfft2+fPPPz/q+RaSUJTJZM6IiIirX375peCVLJtQfOKJJ8a8PjxZt25d4ubNm9uWLFnSdfLkydAlS5aknj59WvDz/stf/vJf+fn5KXK5PLO7uzu4qqrqdHBwsJsj+RZWxgAgGBKKSCiKkVD05NNPP4169NFHFWq1WrNs2bKUrq6u4Pb29lGzzdPzvm/fvqnp6ek9bW1tXx89erTx8ccfV1y8ePG6z0asjAECkLcVrK8goTgaEorXJ6Ho6d94aGiI/vGPf5yIiIgYNXGFPu+vv/56zH/8x3/8r0QiofT09L7ExMS+f/7zn2G5ubnX9RrjGMYAIBgSikgoipVQ5LNw4cKO5557bvr27dvbiIg+++yzKXfddVeP0Oc9Pj6+/69//WtUfn5+V1NTU8jp06fD1Gr1uFbnkwFvUwOAYNyEokql0ixevFh18uTJ0GPHjoU/++yz/7t+/fqLUql0iP16CJtQVKlUmvb29hBvCUWVSqVVKBR9E0koyuXyTDahuHnz5jgiIm5CUa1WaxYvXpxCRFRUVNSelJTUl5aWptVoNBqtVnuFL6E4a9asvrS0NO1DDz2kEJpQ3Lhxo7KiooJxd5udO3c2m0ymGQqFIr29vT2Em1BcvXq1kr1dVlZW2gMPPDDr888/j5LL5Zl79uxx+yljrvj4+Iynn346saamJkYul2d+9dVXYUJvFxcXN8gmFFUqlSYrK0ttsVjG7M9NKGZlZd3KJhSlUulIQjEtLU3z1ltvxbzwwgse38FhE4onT54M02q1GrVardm1a5fbT5fz/Rvv3r27qa6uLlylUmlmz56t/d3vfhfrbn++5/03v/lN65EjR8K/ez2nFRcXN8+cOVP4x+MnCRKKAAECCUX/hoQiuEJCEQAAIIDgd8YA4BNIKAIIh5UxAACAyDCMAQAARIZhDAAAIDIMYwAAAJFhGAOAqJBQREIRCUUMYwD4HkBCEQlFb5BQBIDvFSQUhyGhiITiZMIwBghQ86kozfXPDno9loiok65I3G0vp7djiIha6dsQ121CjslNKFqt1kaJRDLETSgWFxfL2YQiERHDMGEGg+G83W5vjIyMdBqNRreXKrRYLOFlZWVNNpvtOMMwMrPZHE1ExCYUbTZb43cpRbf7C8GXUIyLi8vMzc3t8JZQrK6udtTV1Y0qO7EJRb1e305ExCYUy8vLHXq9Ptn1/gIlodjY2Hhi7ty5V7Zv3y53vZ2QhKJcLs985513YkpKSgTnLtmE4tKlSzvG87jZhGJDQ8OJd9999xuDwZDkehtvCcWTJ0+GyeXyzLlz52pLS0ubkFAEAL+GhCISikgo+gauwAUQoI7Sa7xXfIqkm5yets+kWwY9beeDhOJoSCgioThZMIwBQDAkFJFQRELRN/A2NQAIhoQiEopIKPoGEooAAQIJRf+GhCK4QkIRAAAggOB3xgDgE0goAgiHlTEAAIDIMIwBAABEhmEMAAAgMgxjAAAAkWEYA4CokFAcWwj67LPPpsyZM0edkpKiValUmt///vdujzmRhCIR0ZNPPjlDoVCkJyUlpfN9f7mtrS34rrvuSlUqlel33XVXKnuRD6HH4f67vvLKK9NUKpVGpVJpbr/9dvXnn38+xd0+TqeTdDpdokKhSFepVJr/+Z//GRPbIOJ/Duvr68PmzJmjDg0Nnbt169Yx19X2ZxjGABDwvm8JxYiICOd//dd/nTl16tTxv/71rye3bNmS6Hqda1dC04hfffVV2N69e6fZbLbjH3zwgf2xxx5TuHv8zzzzzMy777670+FwNNx9992dW7dunTGe43ClpKT0ffrppza73d745JNPnlu3bp3S3e3+/Oc/Tz19+nQYwzANr7zyimPDhg1uhz3fczh9+vTBsrKys+vWrWsT+tj8BYYxAIwLEorDfJlQzMzM7MvIyOgjIkpKShqYNm3aYGtrq8evogpNKNbU1Ny8YsWKi1OmTBlSq9X9SqWy7+OPPx6THfzggw9uXrdu3QUionXr1l2ora2NHs9xuO69997u2NjYq0REubm53ex1zF299957N69Zs+aCRCKhH/7wh90dHR0hDodDyr2Np+cwPj5+cNGiRVfESCBeK3zPGCAAraWdiQ3EuH0Lb6LSKelKFT3u8fKF3ISiTCYbKiwsVHATitnZ2d1sQtFms4UyDBNWUVHB5OXldRcUFCQZjcbYkpKSMasWi8USXl9f36BSqfpzcnJSzWZzdFFRUTubUDSZTC0GgyHBZDLFlpaWCs7ycfElFImIdDrdeW8JxebmZmlGRoZWp9NdYLezCUUiosrKyulsQrG2tjZCr9cnu37PeiIJxYMHD940MDAQpNFo+iZy3q5aWlpCFyxY0MX+d1xcXP93DeFu7u0uXLgQwv6Ao1QqBy5evDgp88JkMt2Sm5s75tKjREStra3SpKSkketCz5w5s9/hcEi5P2j5c4byWmBlDACCIaF4fROKDodDWlRUNOv3v/89M1mNXTEzjn/5y18i//jHP95SVlbm9i1uT3lGL7cJuJWwK6yMAQKQtxWsryChOJovE4oXL16ULF26NGXr1q0tP/zhD7uJJiehmJCQwK6EiYjo3LlzoQkJCWMeQ0xMzCC7KnU4HNJp06Z5/MW463Fctx85cmTKhg0blP/93/99csaMGVeJiP7zP/8z9vXXX48lIvrggw9OxsXFDTAMM/LYWltbQxUKxajHNmPGjMFryVD6K6yMAUCw/Pz8jvfffz+6paUlhGj4E7d2uz1048aN8atWrbqwZcuWczqdbuTDOWxCkYjINaFotVob16xZc5lo+G1qq9UaevXqVaqpqZn2gx/8gLeOxOb1rFZro7dBzCYU33vvvVOuCcVPP/00cmBggPr6+oI+/fTTSI1G0+v62BYtWtT55z//edrg4CA5HA7pF1984fFDXm+99VY0EZFrQtFqtTa+/fbbDolEMpLyIyLiSyj29vYG3XfffSk//elPL6xdu3Zk9e3uufPmwQcfvMTuk5OTc2XlypWX9u7dO62npyfIarWGMgwTdvfdd3e77rdkyZJLFRUVMUREFRUVMfn5+R5LWq7H4W47efJkaEFBweyqqqozmZmZI2+3P/nkk+fZfZKSkgZ+9KMfXXrjjTdinE4nHThwIDwyMvKq62cBhD6HgQbDGAAEQ0Lx+iQUq6qqor/88suIN9988xa1Wq1Rq9Wazz77zO3XgbiEJBTnzZvXe//9919UqVTa/Px81a5duxwhIcNvkq5evVp5+PDhm4iItm3b1nrw4MEopVKZfvDgwaht27a1juc4XL/+9a9nXrp0KeSRRx5RqtVqTXp6+q3ubveTn/zkslKp7FMqlenr169XvvTSSw5226JFi1IYhpF6eg7Pnj0bIpfLM3fv3i1/4YUXZsrl8syLFy8GxJxDQhEgQCCh6N+QUARXSCgCAAAEEHyACwB8AglFAOGwMgYAABAZhjEAAIDIMIwBAABEhmEMAAAgMgxjABAVEopIKLKQUAQACGBIKCKhSISEIgDcQJBQHIaEIhKKkwnDGCBAzadH0lz/7KC3Y4mIOqlH4m57Oe2LISJqpYshrtuEHJObULRarY0SiWSIm1AsLi6WswlFIiKGYcIMBsN5u93eGBkZ6TQajbHu7tdisYSXlZU12Wy24wzDyMxmczQREZtQtNlsjd+lFN3uLwRfQjEuLi4zNze3w1tCsbq62lFXVzeq7MQmFPV6fTsREZtQLC8vd+j1+mTX+/OXhGJiYuJIppCTUBzFnxKK3NsgoQgANzwkFJFQvBZIKPLDFbgAAtRRMvFe8SmSpjg9bZ9J0wY9beeDhOJoSCjyH8d1OxKKnmFlDACCIaGIhKLQ43C3IaHoHYYxAAiGhCISikKPw4WEondIKAIECCQU/RsSiuAKCUUAAIAAgg9wAYBPIKEIIBxWxgAAACLDMAYAABAZhjEAAIDIMIwBAABEhmEMAKJCQhEJRda1JhQ97V9TUxOVlJSUrlAo0rds2TKD/fuqqqrolJQUrUQiyWK/Yy0GDGMACHhIKCKh6Gn/wcFB2rRpk2L//v12u91+fM+ePdPYC5XMmTOnZ8+ePafmzZvXJfR8fAHDGADGBQnFYUgo+l9CkW//jz/+OFypVPZpNJr+sLCwoRUrVlysqam5mYho7ty5vbfddtukFLGuBb5nDBCA1tIriQ3UNKlvqaVT4pUqWt/k6TbchKJMJhsqLCxUcBOK2dnZ3WxC0WazhTIME1ZRUcHk5eV1FxQUJBmNxtiSkpIx4XeLxRJeX1/foFKp+nNyclLNZnN0UVFRO5tQNJlMLQaDIcFkMsWWlpa2unts3vAlFImIdDrdeW8JxebmZmlGRoZWp9NdYLezCUUiosrKyulsQrG2tjZCr9cnu37P2l8SigsWLBhZBXISiqOuT+1PCUXuD1qenkO+/ZuamkLj4+NH/j4hIaH/yJEjbgtiYsHKGAAEQ0IRCcVr4euEIt/+gZBdxMoYIAB5W8H6ChKKoyGhyH8c1+3XI6HIt39fX19QS0vLyN83NzeHuvu1hJiwMgYAwZBQREJR6HG4265XQpFv/0WLFnUzDBNmtVpDe3t7g/bu3Ttt5cqVfpVdxDAGAMGQUERCUehxuK5XQpFvf6lUSjt37jybn5+vSk1N1d5///0X582b10s0vKKXy+WZx44dC1++fHnqwoULU709z76AhCJAgEBC0b8hoQiukFAEAAAIIPgAFwD4BBKKAMJhZQwAACAyDGMAAACRYRgDAACIDMMYAABAZBjGACAqJBSRUGQhoQgAEMCQUERC0dP+SCgCwPcOEorDkFBEQnEyYRgDBKj5tCXN9c8O2hdLRNRJPRJ328upNoaIqJXaQ1y3CTkmN6FotVobJRLJEDehWFxcLGcTikREDMOEGQyG83a7vTEyMtJpNBpj3d2vxWIJLysra7LZbMcZhpGZzeZoIiI2oWiz2Rq/Sym63V8IvoRiXFxcZm5uboe3hGJ1dbWjrq5uVNmJTSjq9fp2IiI2oVheXu7Q6/XJrvfnLwnFxMTEkZwgJ6E4ij8lFLm3mayEIjcc4Q8wjAFAMCQUkVC8Fkgo8sMVuAAC1FH6Le8VnyJpitPT9pkUPehpOx8kFEdDQpH/OK7bkVD0DCtjABAMCUUkFIUeh7sNCUXvMIwBQDAkFJFQFHocLiQUvUNCESBAIKHo35BQBFdIKAIAAAQQfIALAHwCCUUA4bAyBgAAEBmGMQAAgMgwjAEAAESGYQwAACAyDGMAEBUSikgosurr68PmzJmjDg0Nnbt161a5p3MY77lVVFSMPIYf/OAHqd7CG9cbhjEABDwkFL8fCcXp06cPlpWVnV23bl2b0PsWcm4DAwP05JNPJh46dMhut9sbtVptj9FonD6RY/gKhjEAjAsSisOQUJz8hGJ8fPzgokWLrkil0jFXo3J93bn7AYLv3JxOZ9DQ0BB1dnZKnE4ndXR0SOLi4vrH3IGI/GqZDgDCrKXXExvo3Jj/2V+LdIq7UkX/t8nTbbgJRZlMNlRYWKjgJhSzs7O72YSizWYLZRgmrKKigsnLy+suKChIMhqNsSUlJWNWPRaLJby+vr5BpVL15+TkpJrN5uiioqJ2NqFoMplaDAZDgslkii0tLW1199i84UsoEhHpdLrz3hKKzc3N0oyMDK1Op7vAbmcTikRElZWV09mEYm1tbYRer092/Z61vyQUFyxY0MX+NyehOOr61GIkFPm4e929+uqrMRs3brzAvR3fuclksu5du3adnTt3rnbKlClXlUpln9lsPjsZ5zNZsDIGAMGQUERC8Vp4Syjy4Xvdud6O79z6+vqCdu/eHXvkyJHGtra2rzUaTc+WLVtmXsOpTDqsjAECkLcVrK8goTgaEor8x3HdLiShmJSU5Pa54HvdCT23L774YgoRkVar7SMi+tnPfnZxx44dMzydz/WGlTEACIaEIhKKQo/D3SY0och333yvO6HnplQqB06dOhV27ty5ECKiDz74IEqlUo35tYSYsDIGAMG4CUWn00lSqXSotLS06dixY+F/+MMfrCEhIfTuu+9Gl5WVxeTn53eyCcUNGzYok5OT+7wlFK1W65Q77rijcyIJxXfffXcam1Bcs2bNt7t27TrHTSgSDf8O8e9///upoqKi9oMHD0alpaVpg4KCKDc39zJfQvHAgQNRaWlp2uTk5F6hCcWurq7g3bt3n3F3m507dzavXr169rPPPhuv1WqvcBOKL730Uuzbb7/tYBOK7e3tIW+++eYtRERVVVVn7rrrLo8r4fj4+Iyurq7ggYGBoA8//PDm/fv327OyskYNHW5CMTg4mFwTig8//PD5nJycK9u2bWtdvnz5bKVSeUtcXFz/vn37vhnPcbi4CUWi4Xc8Ghoaxnz6/ezZsyHZ2dma7u7u4KCgoKGKigr5iRMnGty97srLy8+qVKpRH8LiO7ekpKSBJ554onXhwoVpISEhQwkJCf1vvvmm238fsSChCBAgkFD0b0gogiskFAEAAAII3qYGAJ9AQhFAOKyMAQAARIZhDAAAIDIMYwAAAJFhGAMAAIgMwxgARIWEIhKKLCQUAQACGBKKSCh6OjckFAHgewcJxWFIKCKhOJkwjAEC1Hz6zzTXPzvog1giok7qlbjbXk5/jyEiaqXLIa7bhByTm7KzWq2NEolkiJtQLC4ulrMJRSIihmHCDAbDebvd3hgZGek0Go2x7u7XYrGEl5WVNdlstuMMw8jMZnM0ERGbULTZbI3fpRTd7i8EX0IxLi4uMzc3t8NbQrG6utpRV1c3quzEJhT1en07ERGbUCwvL3fo9fpk1/vzl4RiYmLiyCDiJBRH8deEIvu6e/XVV2Ncb8d3bjKZbIhNKMrl8ky73T7lscce86ur2WEYA4BgSCgioXgtkFDk51e/wAYA4Y7Sk7xXfIqkMKen7TNp6qCn7XyQUBwNCUX+47huR0LRM6yMAUAwJBSRUBR6HO42JBS9w8oYAARDQhEJRaHH4UJC0TskFAECBBKK/g0JRXCFhCIAAEAAwdvUAOATSCgCCIeVMQAAgMgwjAEAAESGYQwAACAyDGMAAACRYRgDgKiQUAyshKKn/T/55JObVCqVRqFQpHOf09ra2giNRnNrSEhIlqfnb/PmzXFsOnHdunUJycnJWpVKpbn33ntn81WrPD1OrpqamqikpKR0hUKRvmXLlpGrb1VVVUWnpKRoJRJJ1uHDh8fEPa4XDGMACHhIKF6/hKKn/Tds2KB8+eWXHQzDNJw+fTqspqYmioho1qxZ/a+99hqzbNmyC0KfpyVLlnTY7fbjdru9MSUlpffpp592e/lKvsfJNTg4SJs2bVLs37/fbrfbj+/Zs2faV199FUZENGfOnJ49e/acmjdvXpfQx+YLGMYAMC5IKA67UROKfPs7HA5pV1eX5J577umWSCS0Zs2aC/v27YsmGv6a2x133NHDXmdciBUrVnSwdas777yzu6WlxW0khO9xcn388cfhSqWyT6PR9IeFhQ2tWLHiYk1Nzc1ERHPnzu297bbbJqWIdS3wPWOAALSW/pzYQP87qW+ppdOMK1VU0OTpNtyUnUwmGyosLFRwE4rZ2dndbELRZrOFMgwTVlFRweTl5XUXFBQkGY3G2JKSkjHheIvFEl5fX9+gUqn6c3JyUs1mc3RRUVE7m1A0mUwtBoMhwWQyxZaWlrZO5Pz4EopERDqd7ry3hGJzc7M0IyNDq9PpRlZ3bEKRiKiysnI6m1Csra2N0Ov1ya7fs/aXhOKCBQtGVoGchOKo61PzJRT59g8NDR2aOXPmyA80SqWyv7W1VToZj7m6uvqWVatWXXS3TUjqsampKTQ+Pn7k0pkJCQn9R44ccVsQEwtWxgAgGBKKSCjy7c/z9+N8dGP96le/mhEcHDxkMBjcDmMhxMxGCoWVMUAA8raC9RUkFEe7EROKfPsnJSUNcFfCDocjdMaMGbwlJqLhD9599NFHU4mIrFZro+t2k8kU8+GHH978ySef2NnXwapVq5IaGhpuksvl/YcOHTolJPWoUCj6uW9zNzc3h7r7tYSYsDIGAMGQUERC0VOmMDw83HngwIFwp9NJb7zxRsyPf/xjj/Utk8nUwj421201NTVRL7744oz9+/ef4v7QU1NTw1it1sZDhw6d8vQ4uRYtWtTNMEyY1WoN7e3tDdq7d++0lStXjqsM5msYxgAgGDdlp1KpNIsXL1adPHky9NixY+HPPvvs/65fv/6iVCodKisriyEiYhOKKpVK097eHuItoahSqbQKhaJvIglFuVyeySYUN2/eHEdExE0oqtVqzeLFi1OIiIqKitqTkpL60tLStBqNRqPVaq/wJRRnzZrVl5aWpn3ooYcUQhOKGzduVFZUVDDubrNz585mk8k0Q6FQpLe3t4dwE4qrV69WEg1/3ebLL7+MePPNN29Rq9UatVqt+eyzz6Z4ex7i4+Mznn766cSampoYuVyeyX5imIubGczPz1e5JhTZr/ds27at9eDBg1FKpTL94MGDUdu2bWv1tv/LL7/sMBgMSUqlMj0pKamvoKDgMhHRoUOHbpLL5Zn79++P3rRpkzIlJUXr7Vw2b96s6O7uDl68eLHquw8Luv26Ft/jZBhGumjRohQiIqlUSjt37jybn5+vSk1N1d5///0X582b10s0/M6BXC7PPHbsWPjy5ctTFy5cmOrtsfkCEooAAQIJRf+GhCK4QkIRAAAggOADXADgE0goAgiHlTEAAIDIMIwBAABEhmEMAAAgMgxjAAAAkWEYA4CokFBEQpGFhCIAQABDQhEJRSQUAeCGgoTiMCQUkVCcTBjGAAFqPpnSXP/soIOxRESd1Cdxt72cPo0hImqljhDXbUKOyU0oWq3WRolEMsRNKBYXF8vZhCIREcMwYQaD4bzdbm+MjIx0Go3GWHf3a7FYwsvKyppsNttxhmFkZrM5moiITSjabLbG71KKbvcXgi+hGBcXl5mbm9vhLaFYXV3tqKurG1V2YhOKer2+nYiITSiWl5c79Hp9suv9+UtCMTExcSQnyEkojuIpoehuf4fDIfVlQjE/P9/ttbgnmlDkG+5iwTAGAMGQUERCEQlF38AVuAAC1FF6hPeKT5Ekc3raPpOiBj1t54OE4mhIKCKhOFmwMgYAwZBQREIRCUXfwDAGAMGQUERCEQlF30BCESBAIKHo35BQBFdIKAIAAAQQfIALAHwCCUUA4bAyBgAAEBmGMQAAgMgwjAEAAESGYQwAACAyDGMAEBUSikgossRIKE7kPPleb9cCwxgAAh4SikgoTjShOJHz5Hu9XQsMYwAYFyQUhyGh+P1IKI73PIn4X2/XAt8zBghAa+nDxAb6dsz/7K9FOt1ypYqWNHm6DTehKJPJhgoLCxXchGJ2dnY3m1C02WyhDMOEVVRUMHl5ed0FBQVJRqMxtqSkpM31fi0WS3h9fX2DSqXqz8nJSTWbzdFFRUXtbELRZDK1GAyGBJPJFFtaWto6kfPjSygSEel0uvPeEorNzc3SjIwMrU6nG1ndsQlFIqLKysrpbEKxtrY2Qq/XJ7t+z9pfEooLFizoYv+bk1AcdX1qTwlFd/uHhoYO+TKhuGrVKrfVpokmFI8cORIxkfMkl+dpsmBlDACCIaGIhOKNklC83tlFrIwBApC3FayvIKE4GhKKgZ9QHO95ejqfa4GVMQAIhoQiEorft4TieM9TyHM+ERjGACAYEopIKH7fEooTOU++19u1QEIRIEAgoejfkFAEV0goAgAABBB8gAsAfAIJRQDhsDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKSCiykFAEAAhgSCgioYiEIgDcUJBQHIaEIhKKgk9GAAxjgAA1n95Ic/2zg47EEhF1Ur/E3fZyqoshImqlrhDXbUKOyU0oWq3WRolEMsRNKBYXF8vZhCIREcMwYQaD4bzdbm+MjIx0Go3GWHf3a7FYwsvKyppsNttxhmFkZrM5moiITSjabLbG71KKbvcXgi+hGBcXl5mbm9vhLaFYXV3tqKurG1V2YhOKer2+nYiITSiWl5c79Hp9suv9+UtCMTExcSQnyEkDjuIpLehuf4fDIfVlQjE/P9/ttbgnmlBkh/t4z3MyzscdDGMAEAwJRSQUkVD0DVyBCyBAHaU1vFd8iqRQp6ftMyli0NN2PkgojoaEIhKKkwUrYwAQDAlFJBSRUPQNDGMAEAwJRSQUkVBEQhHghoaEon9DQhFcIaEIAAAQQPABLgDwCSQUAYTDyhgAAEBkGMYAAAAiwzAGAAAQGYYxAACAyDCMAUBUSCgiociaSEKxqqoqOiUlRSuRSLLY70iPR09PT9B99903S6FQpGdmZqptNts1vUYmCsMYAAIeEoo3bkJxzpw5PXv27Dk1b968LqH3zVVWVnbL1KlTB8+ePduwcePGts2bN/vkNeINhjEAjAsSisOQUPSPhOLcuXN7b7vttjFFq8HBQVq3bl1Cenr6rSqVSmM0Gsf80ENE9P7779+8du3aC0TDV2b77LPPIp1Op+DXyGTB94wBAtBaOpzYQO3jfkvOk3SKvlJFOU2ebsNNKMpksqHCwkIFN6GYnZ3dzSYUbTZbKMMwYRUVFUxeXl53QUEJJCSZAAAgAElEQVRBktFojC0pKWlzvV+LxRJeX1/foFKp+nNyclLNZnN0UVFRO5tQNJlMLQaDIcFkMsWWlpa2TuT8+BKKREQ6ne68t4Ric3OzNCMjQ6vT6UZWd2xCkYiosrJyOptQrK2tjdDr9cmu37P2l4TiggULRlaRnDTgqOsue0oLuts/NDR0yJcJxVWrVo2r2vTiiy/eMnXq1KsNDQ0nenp6grKzs9XLli3rUKvV/dzbtbW1hSYnJ/cTDV82MyIi4mpbW1uI0NfIZMHKGAAEQ0IRCcVASSj+7W9/i3rnnXdi1Gq15vbbb7+1vb09pLGxccy1uvnOR+hrZLJgZQwQgLytYH0FCcXRkFAUP6HId99DQ0NBO3fuPLty5coOT8ecMWNG/5kzZ0Jnz549MDAwQF1dXcHTp0+/+tJLL93i7jWydOnSCf1u2husjAFAMCQUkVD0t4Qin3vvvffyK6+8EtvX1xdERPT111/LOjo6JK7HvO+++y5VVVXFEBG99tpr0XfeeWenRCLhfY14f8YnBsMYAARDQhEJRX9LKJrN5pvlcnnmsWPHwpcvX566cOHCVCKiTZs2fatWq3szMjJuTU1N1f7iF79QDgwMjHmb49FHH/22vb09RKFQpJtMphnPP/98M5Hw18hkQUIRIEAgoejfkFAEV0goAgAABBB8gAsAfAIJRQDhsDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKSCiykFAEAAhgSCgioYiEIgDcUJBQHIaEIhKKkwnDGCBAzaf30lz/7KB/xhIRddKAxN32cjoeQ0TUSldCXLcJOSY3oWi1WhslEskQN6FYXFwsZxOKREQMw4QZDIbzdru9MTIy0mk0GmPd3a/FYgkvKytrstlsxxmGkZnN5mgiIjahaLPZGr9LKbrdXwi+hGJcXFxmbm5uh7eEYnV1taOurm5UtYdNKOr1+nYiIjahWF5e7tDr9cmu9+cvCcXExMSRjCAnoTiKp4Siu/0dDofUlwnF/Pz8cV2KkptQ/Oc//3ni9ddfj7VarWPOU0hC0dNrZLJgGAOAYEgoIqGIhKJv4ApcAAHqKP2Y94pPkSR1eto+k24a9LSdDxKKoyGhiITiZMHKGAAEQ0IRCUUkFH0DwxgABENCEQlFJBR9AwlFgACBhKJ/Q0IRXCGhCAAAEEDwAS4A8AkkFAGEw8oYAABAZBjGAAAAIsMwBgAAEBmGMQAAgMgwjAFAVEgoXt+E4nhSi3xMJlOMUqlMVyqV6SaTKYb9+/feey9So9HcqlarNVlZWWkNDQ0yd/vPnz8/7fDhwzd1dnZK7r777pTk5GRtSkqKdsOGDfF8x+TLM7riyzvyvUb8BYYxAAQ8JBSFJxSF3o5PW1tb8HPPPRd39OjRE//4xz9OPPfcc3Fs6/jRRx9V/vGPfzxjtVobCwoKLj7zzDMzvd3f448/3nbmzJnjDQ0NjUeOHIl455133PaV+fKMXJ7yjnyvEX+BYQwA44KE4rBATSh6ut3evXuj5syZo9ZoNLcuXbp01uXLl8f8e+3bt29qTk5Oh1wuvxobG3s1JyenY+/evVPZ7ZcuXQomIrp8+XIwt+LkTmRkpHPZsmWdRERhYWFDmZmZV9wVpDzlGbk85SH5XiP+At8zBghAa+kfiQ3UMeZ/9tcinaKuVNG8Jk+34SYUZTLZUGFhoYKbUMzOzu5mE4o2my2UYZiwiooKJi8vr7ugoCDJaDTGlpSUtLner8ViCa+vr29QqVT9OTk5qWazObqoqKidTSiaTKYWg8GQYDKZYktLS1sncn58CUUiIp1Od95bQrG5uVmakZGh1el0F9jtbEKRiKiysnI6m1Csra2N0Ov1ya7fs/aHhCKf1tbWkN/+9rczDx8+bI+KinI+9dRTM7Zv3y5//vnnRz3fLS0t0oSEhJGEYnx8fH9LS4uUiOjVV19lVqxYkSqTyZwRERFXv/zyS8Er0W+//Tb4o48+uvmJJ54Y8/oQmmdsaWkJXbBgwUjIgZOHHHPtbX+DlTEACIaEYuAnFPl8/PHH4d98803Y/Pnz1Wq1WvOnP/0p5uzZs2Oeb0+pxF27dsn37t17sq2t7euf//zn365fvz5RyLEHBgZoxYoVs/R6fdv/Y+/+w6Kq8///PxkYwOWHIuHIrxlAmMEZIBekrLeBuKV49XUrlXVL311g+x7IbEvKPqtthljvNUhzmLRwjYhr09VQ650L1r7LtLX1R4EbhDOD6YyALJmi/JDfw/cPPLwPhznDQRkPU4/bdXFdxZkzZ2aYyyevmeHc1Wp1N3e70DzjreYhxYSVMYATGmkF6yhIKA7ljAlFvnNn9/f30+zZs1s+/vjj8+zvc48ZEhLSc+TIkcH31xsaGtyTk5NbL1686HbmzJkJc+fObSca+EUlNTU1ioiGPAZ79uyxcI/92GOPhUVERHSuX7/+B6KB9+DZP+PVq1dfEpJnFJqHHI8wjAFAsNTU1JZFixZFrlu3rik4OLi3qanJ9dq1a66vvvqqbMmSJZcVCkV3enq64vDhw2eJ/i+heP/997dzE4rMdR48eNCHSShGRUV1l5aWTv7d735ns+5E9H8JRSG3l0kolpWV1XITiu+++25AT09Po9VqdTl27JjP008/3cS9bb29vS5//vOfA5566qnLDQ0N0uPHj/s8+uijvJH73bt3+y1cuLCVm1BkX4ZJKGq12uabTSgy/280Gkd8peDxxx+/+vjjj49YwZozZ077c889J6+urvaIiYnpam1tlZw/f17KPWZTU5Nrbm5uMPOhrSNHjvi+8cYb9ZMnT+5ra2tz/fbbbz3i4uK6Dh486BsZGdlJRMR9DNh+//vfB7W0tLj+9a9/NTPfs/UzZvKMKSkp7e+//77/U0899QP3uhYvXnx12bJlEevXr2+yWCxSvjzkeISXqQFAMCQUnT+hyHe5oKCg3sLCQvNvf/vbCKVSqU5ISIiuqqoatr9MJutbs2bNxYSEhOkJCQnTX3jhhYsymaxPKpWSTqezLFmyZJpKpVLv3r3b/4033rD7Cs73338v1ev1gbW1tZ4ajUYdHR2t3rJly7BPlxPx5xnff//9ic8++2wQkf28I99zZLxAQhHASSChOL4hoQhcSCgCAAA4EbxnDAAOgYQigHBYGQMAAIgMwxgAAEBkGMYAAAAiwzAGAAAQGYYxAIgKCUUkFJFQxDAGgJ8AJBSRUCRCQhEAfkaQUByAhCISimMJwxjASd1Fn6u4X5vIEEBE1Eo9ElvbC+isPxFRI3W6cbcJOSY7oWgwGGokEkk/O6GYk5MjYxKKRERms9kzKyvrkslkqvHx8bHm5+cH2LreqqoqL51OV2c0Gr8zm80eJSUlfkRETELRaDTW3Egp2txfCL6EYlBQUFxKSkrLSAnF4uJiS0VFxZCyE5NQ1Gq1zURETEKxoKDAotVqw7nX5ywJxZqamjPx8fHXN27cKONeTkhCUSaTxe3du9c/NzdXcO6SSSguWLCghbttNAnF0NDQwdvGSiiOexjGACAYEopIKCKh6Bg4AxeAkzpJc3nP+ORDUqu97YHk2WtvOx8kFIdCQhEJxbGCYQwAgiGhiIQiEoqOgZepAUAwJBSRUERC0TGQUARwEkgojm9IKAIXEooAAABOBO8ZA4BDIKEIIBxWxgAAACLDMAYAABAZhjEAAIDIMIwBAABEhmEMAKJCQhEJxduRUOTbv6Ojw+XBBx+MkMvlMXFxcdHsE6ncd999UT4+PjNu9fkpBIYxADg9JBSRUCSyn1Dk21+n090xceLE3gsXLlSvWrWqKTs7O4S5vueff/7fhYWF57nHcQQMYwAYFSQUByCh6DwJRXv7Hzx4cNKKFSsuEw2cme2rr77yYVbNDz30UKuvr+/IL5mMAfydMYATWkE1odXUPuwf+1sRQ17Xi0ht9/SF7ISih4dH//Lly+XshGJiYmI7k1A0Go3uZrPZs7Cw0Dxv3rz2tLS0sPz8/IDc3Nwm7vVWVVV5VVZWViuVyu6kpKSokpISv4yMjGYmoajX6xuysrJC9Hp9QF5enuAsHxtfQpGIKD09/dJICcX6+nppbGysJj09/TKznUkoEhHt3LlzCpNQLC8v99ZqteHcv7N2loSir6+v9cUXX5y6ceNG2euvvz7k8RaSUPTw8LB6e3v3nTp1atirFXyYhOKaNWuGPT9Gk1CcNWtWG/P/TELR3d29n2//pqYm9/Dw8G4iIqlUSt7e3n1NTU1ugYGBwl/uGANYGQOAYEgoIqHojAlFe/uPl+wiVsYATmikFayjIKE4FBKKzpFQDAsL6+Hbf+rUqd3nz593nzZtWk9PTw+1tbW5TpkypW+kx3WsYRgDgGBIKCKh6IwJRTc3N979H3zwwatFRUX+999/f/u7777rd88997QyvwDeThjGACAYO6FotVpJKpX25+Xl1Z0+fdrrnXfeMbi5udGBAwf8dDqdf2pqaiuTUFy5cqUiPDy8a6SEosFgmHD33Xe33kxC8cCBA5OZPN6yZct+3LJly0V2QpFo4D3Ezz///GxGRkbz4cOHfVUqlcbFxYVSUlKu8SUUP/vsM1+VSqUJDw/vFJpQbGtrc92xY4fNT+Fu3ry5funSpdNeeeWVYI1Gc52dUNy2bVvAnj17LExCsbm52W3Xrl13EBEVFRWdv/fee+2uhIODg2Pb2tpce3p6XD755JNJZWVlpoSEhGHvhfNdjkkodnd3uxARvfzyyw1xcXFD3qtmJxSJiJiEIhENJhRdXFxo4sSJfcXFxXY/icwkFMPDwzs1Go2aiEir1f6QnZ09rE62fft2yxNPPBHe2dnpkpKS0sJOKJ46dcpr69atF9kJRVdXV2InFPn2f+aZZ35cvHhxuFwuj5k4cWLfnj17vmeOmZCQoDp37pxnR0eHq0wmi9u+fbt58eLFLfbu081CQhHASSChOL4hoQhcSCgCAAA4EbxMDQAOgYQigHBYGQMAAIgMwxgAAEBkGMYAAAAiwzAGAAAQGYYxAIgKCUUkFJFQxDAGgJ8AJBSRUCRCQhEAfkaQUByAhCISimMJwxjASd1Fp1Tcr01kDiAiaqVeia3tBVTnT0TUSF1u3G1CjslOKBoMhhqJRNLPTijm5OTImIQiEZHZbPbMysq6ZDKZanx8fKz5+fkBtq63qqrKS6fT1RmNxu/MZrNHSUmJHxERk1A0Go01N1KKNvcXgi+hGBQUFJeSktIyUkKxuLjYUlFRMaTsxCQUtVptMxERk1AsKCiwaLXacO71OUtCsaam5kx8fPz1jRs3yriXE5JQlMlkcXv37vXPzc0VnLtkEooLFiwYdrrJ0SQUQ0NDB28bk1C0tz9fQlHo7R4rGMYAIBgSikgoIqHoGDgDF4CTOkmJvGd88iE3q73tgeTRa287HyQUh0JCEQnFsYJhDACCIaGIhCISio6BYQwAgiGhiIQiEopIKAL8rCGhOL4hoQhcSCgCAAA4EbxMDQAOgYQigHBYGQMAAIgMwxgAAEBkGMYAAAAiwzAGAAAQGYYxAIgKCUUkFIUkFPl+xkLxPe6XL192nTt3bqRKpVJHRkZqdDqd/0jX5QgYxgDg9JBQ/OknFPl+xkLxPe75+fkBKpWqw2g01hw9etS4fv36UFu/IDkahjEAjAoSigOQULx9CUUi/p/xxYsX3ebPnz8tJiZmekxMzPRPP/3Ui3sZe4+7i4sLtba2ulqtVmppaZFMnDixVyqVIhQBACNbQebQauoY9o/9rYihCdeLKKzO3mXYCUUPD4/+5cuXy9kJxcTExHYmoWg0Gt3NZrNnYWGhed68ee1paWlh+fn5Abm5uU3c662qqvKqrKysViqV3UlJSVElJSV+GRkZzUxCUa/XN2RlZYXo9fqAvLw8wVk+Nr6EIhFRenr6pZESivX19dLY2FhNenr6ZWY7k1AkItq5c+cUJqFYXl7urdVqw7l/Z+0sCUVfX1/riy++OHXjxo2y119/fcjjLSSh6OHhYfX29u47deqU4JUsk1Bcs2bNsOeHPZmZmaHZ2dlN8+fPb6utrXWfP39+1Llz5wQ/7i+88MIPqampkTKZLK69vd21qKjonKMLWbZgZQwAgiGhiISiGAlFe44dO+b7zDPPyKOjo9ULFy6MbGtrc21ubh4y2+w97h9++OHEmJiYjqampm9PnjxZ89xzz8mvXLly22cjVsYATmikFayjIKE4FBKKtyehaO9n3N/fT19//fUZb2/vIRNX6OP+3nvv+f/hD3/4t0QioZiYmK7Q0NCuf/3rX54pKSm39RzjGMYAIBgSikgoipVQ5DN79uyW1157bcrGjRubiAY+iX7vvfd2CH3cg4ODuz/99FPf1NTUtrq6Ordz5855RkdHj2p1PhbwMjUACMZOKCqVSvXcuXOVtbW17qdPn/Z65ZVX/v3kk09ekUql/cyfhzAJRaVSqW5ubnYbKaGoVCo1crm862YSijKZLI5JKGZnZwcREbETitHR0eq5c+dGEhFlZGQ0h4WFdalUKo1arVZrNJrrfAnFiIiILpVKpXniiSfkQhOKq1atUhQWFpptXWbz5s31er1+qlwuj2lubnZjJxSXLl2qICJiEoq7du26Izo6Wh0dHa3+6quvJoz0OAQHB8e+9NJLoaWlpf4ymSzum2++8RR6uaCgoF4moahUKtUJCQnRVVVVw/ZnJxQTEhKmMwlFqVQ6mFBUqVTq3bt3+7/xxht2X8FhEoq1tbWeGo1GHR0drd6yZcuwT5cT8f+Md+zYUVdRUeGlVCrV06ZN07z55psBtvbne9xfffXVxhMnTnjdeD6rcnJy6gMDA4V/PH6MIKEI4CSQUBzfkFAELiQUAQAAnAjeMwYAh0BCEUA4rIwBAABEhmEMAAAgMgxjAAAAkWEYAwAAiAzDGABEhYQiEopIKGIYA8BPABKKSCiOBAlFAPhJQUJxABKKSCiOJQxjACd1F51Rcb820b8DiIhaqU9ia3sB/eBPRNRIPW7cbUKOyU4oGgyGGolE0s9OKObk5MiYhCIRkdls9szKyrpkMplqfHx8rPn5+TZPVVhVVeWl0+nqjEbjd2az2aOkpMSPiIhJKBqNxpobKUWb+wvBl1AMCgqKS0lJaRkpoVhcXGypqKgYUnZiEoparbaZiIhJKBYUFFi0Wm049/qcJaFYU1NzJj4+/vrGjRtl3MsJSSjKZLK4vXv3+ufm5grOXTIJxQULFrSM5nYzCcXq6uozBw4c+D4rKyuMe5mREoq1tbWeMpksLj4+XpOXl1eHhCIAjGtIKCKhiISiY+AMXABO6iRN5z3jkw+5Wu1tDyRpr73tfJBQHAoJRSQUxwqGMQAIhoQiEopIKDoGXqYGAMGQUERCEQlFx0BCEcBJIKE4viGhCFxIKAIAADgRvGcMAA6BhCKAcFgZAwAAiAzDGAAAQGQYxgAAACLDMAYAABAZhjEAiAoJRf5C0JUrVyRTpkyJ40sd3kxCkYho7dq1U+VyeUxYWFjMvn37bFaSmpqaXO+9994ohUIRc++990YxJ/kQehz2z/Wtt96arFQq1UqlUv3LX/4y+p///KfNv5m2Wq2Unp4eKpfLY5RKpfof//jHsNgGEf9jWFlZ6Tljxoxod3f3+PXr1w87r/Z4hmEMAE7vp5ZQZDz33HPBd999t90TjTCEphG/+eYbz/379082Go3fHTp0yPTss8/Kbd3+l19+OXDOnDmtFoules6cOa3r16+fOprjsEVGRnYdO3bMaDKZatauXXsxMzNTYetyH3zwwcRz5855ms3m6rfeesuycuVKm8Oe7zGcMmVKr06nu5CZmdkk9LaNFxjGADAqSCgOcGRCkYjoyy+//MWlS5ekDzzwgKCKkdCEYmlp6aRFixZdmTBhQn90dHS3QqHo+uKLL4ZlBw8dOjQpMzPzMhFRZmbm5fLycr/RHIftgQceaA8ICOgjIkpJSWlnzmPO9dFHH01atmzZZYlEQr/61a/aW1pa3CwWi5R9GXuPYXBwcG9ycvJ1MRKItwp/ZwzghFbQldBq6rH5Et7NiiHp9SKabPf0heyEooeHR//y5cvl7IRiYmJiO5NQNBqN7maz2bOwsNA8b9689rS0tLD8/PyA3NzcYauWqqoqr8rKymqlUtmdlJQUVVJS4peRkdHMJBT1en1DVlZWiF6vD8jLyxOc5WPjSygSEaWnp18aKaFYX18vjY2N1aSnp19mtjMJRSKinTt3TmESiuXl5d5arTac+3fWQhOKfX199Nxzz4Xu2rXrXFlZmc2XkW9WQ0OD+6xZs9qY/w8KCuq+0RBuZ1/u8uXLbswvOAqFoufKlStjMi/0ev0dKSkpw049SkTU2NgoDQsLGzwvdGBgYLfFYpGyf9G6mQylM8DKGAAEQ0Lx9iQUX3vttYB58+ZdjYyMtFl0uhWjzTiOpY8//tjnL3/5yx06nc7mS9z28owjXMbpVsJcWBkDOKGRVrCOgoTiUI5KKB4/ftz71KlT3u++++6U69evS3p6eiTe3t59S5YsuXqrCcWQkBBmJUxERBcvXnQPCQkZdhv8/f17mVWpxWKRTp482e4b49zjcLefOHFiwsqVKxV/+9vfaqdOndpHRPSnP/0p4L333gsgIjp06FBtUFBQj9lsHrxtjY2N7nK5fMhtmzp1aq/QDKUzwcoYAARLTU1tOXjwoF9DQ4Mb0cAnbk0mk/uqVauClyxZcnndunUX09PTBz+cwyQUiYi4CUWDwVCzbNmya0QDL1MbDAb3vr4+Ki0tnXzffffxfmiJyesZDIaakQYxk1D86KOPznITiseOHfPp6emhrq4ul2PHjvmo1epO7m1LTk5u/eCDDyb39vaSxWKRHj9+3O6HvHbv3u1HRMRNKBoMhpo9e/ZYJBLJYMqPiIgvofg///M/5xsbG6saGhqqNmzYUL9o0aLL27dvb7D12I3k8ccfv8rsk5SUdH3x4sVX9+/fP7mjo8PFYDC4m81mzzlz5rRz95s/f/7VwsJCfyKiwsJC/9TUVLslLe5x2Ntqa2vd09LSphUVFZ2Pi4vrYr6/du3aS8w+YWFhPb/+9a+vvv/++/5Wq5U+++wzLx8fnz7uZwGEPobOBsMYAARDQvH2JBRvlpCE4syZMzsffvjhK0qlUpOamqrcsmWLxc1t4EXSpUuXKo4ePfoLIqINGzY0Hj582FehUMQcPnzYd8OGDY2jOQ7bH//4x8CrV6+6Pf3004ro6Gh1TEzMdFuX+81vfnNNoVB0KRSKmCeffFKxbds2C7MtOTk50mw2S4n4H8MLFy64yWSyuB07dsjeeOONQJlMFnflyhWnmHNIKAI4CSQUxzckFIELCUUAAAAngg9wAYBDIKEIIBxWxgAAACLDMAYAABAZhjEAAIDIMIwBAABEhmEMAKJCQhEJRQYSigAATgwJRSQUiZBQBICfESQUByChiITiWMIwBnBSd1GTivu1iVoCiIhaySqxtb2AWv2JiBqpz427Tcgx2QlFg8FQI5FI+tkJxZycHBmTUCQiMpvNnllZWZdMJlONj4+PNT8/P8DW9VZVVXnpdLo6o9H4ndls9igpKfEjImISikajseZGStHm/kLwJRSDgoLiUlJSWkZKKBYXF1sqKiqGlJ2YhKJWq20mImISigUFBRatVhvOvb7RJhS3bt065kGQhoYG99DQ0MFMISuhOMR4SiiyL4OEIgD87CGhiITirUBCkR/OwAXgpE6SjPeMTz4ksdrbHkiuvfa280FCcSgkFPmPw92OhKJ9WBkDgGBIKCKhKPQ47G1IKI4MwxgABENCEQlFocdhQ0JxZEgoAjgJJBTHNyQUgQsJRQAAACeCD3ABgEMgoQggHFbGAAAAIsMwBgAAEBmGMQAAgMgwjAEAAESGYQwAokJCEQlFxq0mFO3tX1pa6hsWFhYjl8tj1q1bN5X5flFRkV9kZKRGIpEkMH9jLQYMYwBwekgoIqFob//e3l5avXq1vKyszGQymb7bt2/fZOZEJTNmzOjYt2/f2ZkzZ7YJvT+OgGEMAKOChOIAJBTHX0KRb/8vvvjCS6FQdKnV6m5PT8/+RYsWXSktLZ1ERBQfH9955513dg2/NbcXhjGAE1pBHaF3UbtqLL9WUEfoSMdFQhEJxVvlyIQi3/51dXXuwcHBg98PCQnpbmhoGFfZRQxjABAMCUUkFG+FoxOKfPs7Q3YRZ+ACcEJFNGHMV0xCIKE4FBKK/Mfhbr8dCUW+/bu6ulzYK+H6+np3W29LiAkrYwAQDAlFJBSFHoe97XYlFPn2T05ObjebzZ4Gg8G9s7PTZf/+/ZMXL148rrKLGMYAIBgSikgoCj0O2+1KKPLtL5VKafPmzRdSU1OVUVFRmocffvjKzJkzO4kGVvQymSzu9OnTXo888kjU7Nmzo0b5sI8JJBQBnAQSiuMbEorAhYQiAACAE8EHuADAIZBQBBAOK2MAAACRYRgDAACIDMMYAABAZBjGAAAAIsMwBgBRIaGIhCIDCUUAACeGhCISivb2R0IRAH5ykFAcgIQiEopjCcMYwEnZyiBuoq4AIqJW6pfY2l5A3f5ERI1kdeNuE3JMJBSRULxVSCjahmEMAIIhoYiE4q1AQpEfzsAF4KROkhfvGZ98yMVqb3sgSXrtbeeDhOJQSCjyH4e7HQlF+7AyBgDBkFBEQlHocdjbkFAcGYYxAAiGhCISikKPw4aE4siQUARwEkgojm9IKAIXEooAAABOBB/gAgCHQEIRQDisjAEAAESGYQwAACAyDGMAAACRYRgDAACIDMMYAESFhCISiozKykrPGTNmRLu7u8evX79eZu8+jPa+FRYWDt6G++67L6qxsXFcfYAZwxgAnB4Sij+NhOKUKVN6dTrdhczMzCah1y3kvvX09NDatWtDjxw5YjKZTDUajaYjPz9/ys0cw1EwjAFgVJBQHICE4tgnFIODg3uTk5OvS6XSYWej4j7vbP0CwXffrG8dvOwAACAASURBVFarS39/P7W2tkqsViu1tLRIgoKCuoddgYgwjAGc0Aorhd7VR6qx/FphpdCRjouEIhKKt8peQpGPrefd22+/7c+9HN998/Dw6N+yZcuF+Ph4jUwmizOZTBOeffbZcXU2OwxjABAMCUUkFG/FSAlFPnzPO+7l+O5bV1eXy44dOwJOnDhR09TU9K1are5Yt25d4C3clTE3rt7ABgBhiiQ05ismIZBQHAoJRf7jcLcLSSiGhYXZ/OWD73kn9L4dP358AhGRRqPpIiJ69NFHr2zatGmqvftzu2FlDACCIaGIhKLQ47C3CU0o8l033/NO6H1TKBQ9Z8+e9bx48aIbEdGhQ4d8lUrlsLclxISVMQAIxk4oWq1Wkkql/Xl5eXWnT5/2eueddwxubm504MABP51O55+amtrKJBRXrlypCA8P7xopoWgwGCbcfffdrTeTUDxw4MBkJqG4bNmyH7ds2XKRnVAkGngP8fPPPz+bkZHRfPjwYV+VSqVxcXGhlJSUa3wJxc8++8xXpVJpwsPDO4UmFNva2lx37Nhx3tZlNm/eXL906dJpr7zySrBGo7nOTihu27YtYM+ePRZb+wkRHBwc29bW5trT0+PyySefTCorKzMlJCQMGTrshKKrqytxE4pPPfXUpaSkpOsbNmxofOSRR6YpFIo7goKCuj/88MPvR3McNnZCkWjgFY/q6uphn36/cOGCW2Jiorq9vd3VxcWlv7CwUHbmzJlqW8+7goKCC0qlcsiHsPjuW1hYWM+aNWsaZ8+erXJzc+sPCQnp3rVrl82fj1iQUARwEkgojm9IKAIXEooAAABOBC9TA4BDIKEIIBxWxgAAACLDMAYAABAZhjEAAIDIMIwBAABEhmEMAKJCQhEJRQYSigAATgwJRSQU7d03JBQB4CcHCcUBSCgioTiWMIwBnJStDOImKwUQEbX2k8TW9gIr+RMRNfaTG3ebkGMioYiE4q1CQtE2DGMAEAwJRSQUbwUSivzG1RvYACDcSVfiPeOTjwtZ7W0PdKFee9v5IKE4FBKK/MfhbkdC0T6sjAFAMCQUkVAUehz2NiQUR4aVMQAIhoQiEopCj8OGhOLIkFAEcBJIKI5vSCgCFxKKAAAATgQvUwOAQyChCCAcVsYAAAAiwzAGAAAQGYYxAACAyDCMAQAARIZhDACiQkLRuRKK9vb/8ssvf6FUKtVyuTyG/ZiWl5d7q9Xq6W5ubgn2Hr/s7OwgJp2YmZkZEh4erlEqleoHHnhgGvfUokJuJ1tpaalvWFhYjFwuj1m3bt3g2beKior8IiMjNRKJJOHo0aPD4h63C4YxADg9JBRvX0LR3v4rV65UbN++3WI2m6vPnTvnWVpa6ktEFBER0f3uu++aFy5ceFnIfSEimj9/fovJZPrOZDLVREZGdr700ks2T1/JdzvZent7afXq1fKysjKTyWT6bt++fZO/+eYbTyKiGTNmdOzbt+/szJkz24TeNkfAMAaAUUFCccDPNaHIt7/FYpG2tbVJ7r///naJRELLli27/OGHH/oRDfyZ2913393BnGdciEWLFrUwdat77rmnvaGhwWYkhO92sn3xxRdeCoWiS61Wd3t6evYvWrToSmlp6SQiovj4+M4777yzi7vP7YZhDOCEVrRR6F1XSTWWXyvaKHSk4yKhiIQi3/4Wi0UaGBg4+AuNQqHobmxslI7FbS4uLr4jNTXV5rm4haQe6+rq3IODgwdvc0hISDffcBcLhjEACIaEIhKKfPvzfH+Ut264//f//t9UV1fX/qysrCs3ex1iZiOFwhm4AJxQkTeN+YpJCCQUh/o5JhT59g8LC+thr4QtFov71KlT7f4y8fTTTwf//e9/n0hEZDAYarjb9Xq9/yeffDLpyy+/NDHPgyVLloRVV1f/QiaTdR85cuSskNSjXC4fshKur693t/W2hJiwMgYAwZBQRELRXqbQy8vL+tlnn3lZrVZ6//33/R966CG79S29Xt/A3DbuttLSUt+tW7dOLSsrO8v+pae0tNRsMBhqjhw5ctbe7WRLTk5uN5vNngaDwb2zs9Nl//79kxcvXjyqMpijYRgDgGDslJ1SqVTPnTtXWVtb63769GmvV1555d9PPvnkFalU2q/T6fyJiJiEolKpVDc3N7uNlFBUKpUauVzedTMJRZlMFsckFLOzs4OIiNgJxejoaPXcuXMjiYgyMjKaw8LCulQqlUatVqs1Gs11voRiREREl0ql0jzxxBNyoQnFVatWKQoLC822LrN58+Z6vV4/VS6XxzQ3N7uxE4pLly5V2NpHqODg4NiXXnoptLS01F8mk8UxnxhmY2cGU1NTldyEIvPnPRs2bGg8fPiwr0KhiDl8+LDvhg0bGkfaf/v27ZasrKwwhUIRExYW1pWWlnaNiOjIkSO/kMlkcWVlZX6rV69WREZGaka6L9nZ2fL29nbXuXPnKm98WNDmn2vx3U6z2SxNTk6OJCKSSqW0efPmC6mpqcqoqCjNww8/fGXmzJmdRAOvHMhksrjTp097PfLII1GzZ8+OGv0jf+uQUARwEkgojm9IKAIXEooAAABOBB/gAgCHQEIRQDisjAEAAESGYQwAACAyDGMAAACRYRgDAACIDMMYAESFhCISigwkFAEAnBgSikgoIqEIAD8rSCgOQEIRCcWxhGEM4KRsZRA3dVAAEVFrP0lsbS/oIH8iokYruXG3CTkmEopIKCKh6BgYxgAgGBKKSCgioegYOAMXgJM6OYl4z/jk40JWe9sDJdRrbzsfJBSHQkIRCcWxgpUxAAiGhCISikgoOgaGMQAIhoQiEopIKDoGEooATgIJxfENCUXgQkIRAADAieADXADgEEgoAgiHlTEAAIDIMIwBAABEhmEMAAAgMgxjAAAAkWEYA4CokFBEQpEhRkLxZu4n3/PtVmAYA4DTQ0IRCcWbTSjezP3ke77dCgxjABgVJBQHIKH400gojvZ+EvE/324F/s4YwAmtaKLQ6m4a9o/9rYhxp+tFMrKb7GMnFD08PPqXL18uZycUExMT25mEotFodDebzZ6FhYXmefPmtaelpYXl5+cH5ObmNnGvt6qqyquysrJaqVR2JyUlRZWUlPhlZGQ0MwlFvV7fkJWVFaLX6wPy8vIab+b+8SUUiYjS09MvjZRQrK+vl8bGxmrS09MHV3dMQpGIaOfOnVOYhGJ5ebm3VqsN5/6d9WgTirt27TpXVlZm82Xkm9XQ0OA+a9asNub/WQnFIeentpdQtLW/u7t7vyMTikuWLLFZbbrZhOKJEye8b+Z+EudxGitYGQOAYEgoIqH4c0ko3u7sIlbGAE5opBWsoyChOBQSis6fUBzt/bR3f24FVsYAIBgSikgo/tQSiqO9n0Ie85uBYQwAgiGhiITiTy2heDP3k+/5diuQUARwEkgojm9IKAIXEooAAABOBB/gAgCHQEIRQDisjAEAAESGYQwAACAyDGMAAACRYRgDAACIDMMYAESFhCISigwkFAEAnBgSikgoIqEIAD8rSCgOQEIRCUXBd0YADGMAJ3VXHam4X5uaKYCIqNVKElvbC66SPxFRYy+5cbcJOSY7oWgwGGokEkk/O6GYk5MjYxKKRERms9kzKyvrkslkqvHx8bHm5+cH2LreqqoqL51OV2c0Gr8zm80eJSUlfkRETELRaDTW3Egp2txfCL6EYlBQUFxKSkrLSAnF4uJiS0VFxZCyE5NQ1Gq1zURETEKxoKDAotVqw7nXN9qE4tatW8c8CNLQ0OAeGho6mBNkpQGHsJcWtLW/xWKROjKhmJqaavNc3DebUGSG+2jv51jcH1swjAFAMCQUkVBEQtExcAYuACd1MpR4z/jkIyGrve2BbtRrbzsfJBSHQkIRCcWxgpUxAAiGhCISikgoOgaGMQAIhoQiEopIKCKhCPCzhoTi+IaEInAhoQgAAOBE8AEuAHAIJBQBhMPKGAAAQGQYxgAAACLDMAYAABAZhjEAAIDIMIwBQFRIKCKhyLiZhGJRUZFfZGSkRiKRJDB/Iz0aHR0dLg8++GCEXC6PiYuLizYajbf0HLlZGMYA4PSQUPz5JhRnzJjRsW/fvrMzZ85sE3rdbDqd7o6JEyf2XrhwoXrVqlVN2dnZDnmOjATDGABGBQnFAUgojo+EYnx8fOedd97Zxf1+b28vZWZmhsTExExXKpXq/Px8m7/0HDx4cNKKFSsuEw2cme2rr77ysVqtgp8jYwV/ZwzghFacpdDq6zTql+TsifkFXS+KJLvJPnZC0cPDo3/58uVydkIxMTGxnUkoGo1Gd7PZ7FlYWGieN29ee1paWlh+fn5Abm5uE/d6q6qqvCorK6uVSmV3UlJSVElJiV9GRkYzk1DU6/UNWVlZIXq9PiAvL6/xZu4fX0KRiCg9Pf3SSAnF+vp6aWxsrCY9PX1wdcckFImIdu7cOYVJKJaXl3trtdpw7t9ZjzahuGvXrnNlZWU2X0a+WQ0NDe6zZs0aXEWy0oBDzrtsLy1oa393d/d+RyYUlyxZMqpq09atW++YOHFiX3V19ZmOjg6XxMTE6IULF7ZER0d3sy/X1NTkHh4e3k00cNpMb2/vvqamJjehz5GxgpUxAAiGhCISis6SUPzf//1f37179/pHR0erf/nLX05vbm52q6mpGXaubr77I/Q5MlawMgZwQiOtYB0FCcWhkFAUP6HId939/f0umzdvvrB48eIhL/Nzjzl16tTu8+fPu0+bNq2np6eH2traXKdMmdK3bdu2O2w9RxYsWHBT702PBCtjABAMCUUkFMdbQpHPAw88cO2tt94K6OrqciEi+vbbbz1aWlok3GM++OCDV4uKivyJiN59912/e+65p1UikfA+R0Z+xG8OhjEACIaEIhKK4y2hWFJSMkkmk8WdPn3a65FHHomaPXt2FBHR6tWrf4yOju6MjY2dHhUVpfmv//ovRU9Pz7CXOZ555pkfm5ub3eRyeYxer5/6+uuv1xMJf46MFSQUAZwEEorjGxKKwIWEIgAAgBPBB7gAwCGQUAQQDitjAAAAkWEYAwAAiAzDGAAAQGQYxgAAACLDMAYAUSGhiIQiAwlFAAAnhoQiEopIKALAzwoSigOQUERCcSxhGAM4qbu+JRX3a1MDBRARtfaRxNb2gkbyJyJq7CY37jYhx2QnFA0GQ41EIulnJxRzcnJkTEKRiMhsNntmZWVdMplMNT4+Ptb8/PwAW9dbVVXlpdPp6oxG43dms9mjpKTEj4iISSgajcaaGylFm/sLwZdQDAoKiktJSWkZKaFYXFxsqaioGFLtYRKKWq22mYiISSgWFBRYtFptOPf6RptQ3Lp165gHQRoaGtxDQ0MHM4KshOIQ9hKKtva3WCxSRyYUU1NTR3UqSnZC8V//+teZ9957L8BgMAy7n0ISivaeI2MFwxgABENCEQlFJBQdA2fgAnBSJ+OI94xPPq5ktbc90J167W3ng4TiUEgoIqE4VrAyBgDBkFBEQhEJRcfAMAYAwZBQREIRCUXHQEIRwEkgoTi+IaEIXEgoAgAAOBF8gAsAHAIJRQDhsDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKtzehOJrUIh+9Xu+vUChiFApFjF6v92e+/9FHH/mo1erp0dHR6oSEBFV1dbWHrf3vuusu1dGjR3/R2toqmTNnTmR4eLgmMjJSs3LlymC+Y/LlGbn48o58z5HxAsMYAJweEorCE4pCL8enqanJ9bXXXgs6efLkma+//vrMa6+9FsS0jp955hnFX/7yl/MGg6EmLS3tyssvvxw40vU999xzTefPn/+uurq65sSJE9579+612VfmyzOy2cs78j1HxgsMYwAYFSQUBzhrQtHe5fbv3+87Y8aMaLVaPX3BggUR165dG/bz+vDDDycmJSW1yGSyvoCAgL6kpKSW/fv3T2S2X7161ZWI6Nq1a67sipMtPj4+1oULF7YSEXl6evbHxcVdt1WQspdnZLOXh+R7jowX+DtjACe04lsKrW6lYf/Y34oYH7peFEd2k33shKKHh0f/8uXL5eyEYmJiYjuTUDQaje5ms9mzsLDQPG/evPa0tLSw/Pz8gNzc3Cbu9VZVVXlVVlZWK5XK7qSkpKiSkhK/jIyMZiahqNfrG7KyskL0en1AXl5e483cP76EIhFRenr6pZESivX19dLY2FhNenr6ZWY7k1AkItq5c+cUJqFYXl7urdVqw7l/Zz3ahOKuXbvOlZWV2VwpjrXGxka3//7v/w48evSoydfX1/riiy9O3bhxo+z1118f8ng3NDRIQ0JCBhOKwcHB3Q0NDVIiorffftu8aNGiKA8PD6u3t3ffqVOnBK9Ef/zxR9e///3vk9asWTPs+SE0z9jQ0OA+a9aswZADKw857Nzb4w1WxgAgGBKKzp9Q5PPFF194ff/995533XVXdHR0tPqvf/2r/4ULF4Y93vZSiVu2bJHt37+/tqmp6dvHHnvsxyeffDJUyLF7enpo0aJFEVqttkmtVndztwvNM95qHlJMWBkDOKGRVrCOgoTiUM6YUOQ7d3Z/fz/Nnj275eOPPz7P/j735xUSEtJz5MiRwffXGxoa3JOTk1svXrzodubMmQlz585tJxr4RSU1NTWKiIY8Bnv27LFwj/3YY4+FRUREdK5fv/4HooH34Nk/49WrV18SkmcUmoccjzCMAUCw1NTUlkWLFkWuW7euKTg4uLepqcn12rVrrq+++qpsyZIllxUKRXd6erri8OHDZ4n+L6F4//33t3MTisx1Hjx40IdJKEZFRXWXlpZO/t3vfmez7kT0fwlFIbeXSSiWlZXVchOK7777bkBPT0+j1Wp1OXbsmM/TTz/dxL1tvb29Ln/+858DnnrqqcsNDQ3S48eP+zz66KO8kfvdu3f7LVy4sJWbUGRfhkkoarXaZnsJRea/CwoK/L/++muv7du3NxAN7f4ajcYRXyl4/PHHrz7++OMjVrDmzJnT/txzz8mrq6s9YmJiulpbWyXnz5+Xch+TpqYm19zc3GDmQ1tHjhzxfeONN+onT57c19bW5vrtt996xMXFdR08eNA3MjKyk4iI+xiw/f73vw9qaWlx/etf/2pmvmfrZ8zkGVNSUtrff/99/6eeeuoH7nUtXrz46rJlyyLWr1/fZLFYpHx5yPEIL1MDgGBIKDp/QpHvckFBQb2FhYXm3/72txFKpVKdkJAQXVVVNWx/mUzWt2bNmosJCQnTExISpr/wwgsXZTJZn1QqJZ1OZ1myZMk0lUql3r17t/8bb7xh9xWc77//XqrX6wNra2s9NRqNOjo6Wr1lyxabny7nyzO+//77E5999tkgIvt5R77nyHiBhCKAk0BCcXxDQhG4kFAEAABwInjPGAAcAglFAOGwMgYAABAZhjEAAIDIMIwBAABEhmEMAAAgMgxjABAVEopIKCKhiGEMAD8BSCgioUiEhCIA/IwgoTgACUUkFMcShjGAk7rrGKm4X5u+pwAiotZektjaXmAmfyKixk5y424Tckx2QtFgMNRIJJJ+dkIxJydHxiQUiYjMZrNnVlbWJZPJVOPj42PNz88PsHW9VVVVXjqdrs5oNH5nNps9SkpK/IiImISi0WisuZFStLm/EHwJxaCgoLiUlJSWkRKKxcXFloqKiiFlJyahqNVqm4mImIRiQUGBRavVhnOvb7QJxa1bt962IAg7oVhTU3MmPj7++saNG2XcywlJKMpksri9e/f65+bmCs5dMgnFBQsWDPvlYzQJxdDQ0MHbxkoojnsYxgAgGBKKSCgioegYOAMXgJM6+R/Ee8YnHzey2tse6Em99rbzQUJxKCQUkVAcKxjGACAYEopIKCKh6Bh4mRoABENCEQlFJBQdAwlFACeBhOL4hoQicCGhCAAA4ETwnjEAOAQSigDCYWUMAAAgMgxjAAAAkWEYAwAAiAzDGAAAQGQYxgAgKiQUkVC8HQlFvv07OjpcHnzwwQi5XB4TFxcXzT6Ryn333Rfl4+Mz41afn0JgGAOA00NCEQlFIvsJRb79dTrdHRMnTuy9cOFC9apVq5qys7NDmOt7/vnn/11YWHieexxHwDAGgFFBQnEAEorOk1C0t//BgwcnrVix4jLRwJnZvvrqKx9m1fzQQw+1+vr6jvySyRjA3xkDOKEVxym0+ioN+8f+VsRMoutFs8ju6QvZCUUPD4/+5cuXy9kJxcTExHYmoWg0Gt3NZrNnYWGhed68ee1paWlh+fn5Abm5uU3c662qqvKqrKysViqV3UlJSVElJSV+GRkZzUxCUa/XN2RlZYXo9fqAvLw8wVk+Nr6EIhFRenr6pZESivX19dLY2FhNenr6ZWY7k1AkItq5c+cUJqFYXl7urdVqw7l/Zz3ahOKuXbvOlZWV2VwpjjV2QtHX19f64osvTt24caPs9ddfH/J4C0koenh4WL29vftOnTo17NUKPkxCcc2aNcOeH6NJKM6aNauN+X8moeju7t7Pt39TU5N7eHh4NxGRVColb2/vvqamJrfAwEDhL3eMAayMAUAwJBSRUHTGhKK9/cdLdhErYwAnNNIK1lGQUBwKCUXnSCiGhYX18O0/derU7vPnz7tPmzatp6enh9ra2lynTJnSN9LjOtYwjAFAMCQUkVB0xoSim5sb7/4PPvjg1aKiIv/777+//d133/W75557WplfAG8nDGMAEIydULRarSSVSvvz8vLqTp8+7fXOO+8Y3Nzc6MCBA346nc4/NTW1lUkorly5UhEeHt41UkLRYDBMuPvuu1tvJqF44MCByUweb9myZT9u2bLlIjuhSDTwHuLnn39+NiMjo/nw4cO+KpVK4+LiQikpKdf4EoqfffaZr0ql0oSHh3cKTSi2tbW57tixw+ancDdv3ly/dOnSaa+88kqwRqO5zk4obtu2LcDWylGo4ODg2La2Nteenh6XTz75ZFJZWZkpISFh2HvhfJdjEord3d0uREQvv/xyQ1xcXBd7X3ZCkYiISSgS0WBC0cXFhSZOnNhXXFxs95PITEIxPDy8U6PRqImItFrtD9nZ2cPqZNu3b7c88cQT4Z2dnS4pKSkt7ITiqVOnvLZu3XqRnVB0dXUldkKRb/9nnnnmx8WLF4fL5fKYiRMn9u3Zs+d75pgJCQmqc+fOeXZ0dLjKZLK47du3mxcvXizoA3WjhYQigJNAQnF8Q0IRuJBQBAAAcCJ4mRoAHAIJRQDhsDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKSCgioYhhDAA/AUgoIqFIhIQiAPyMIKE4AAlFJBTHEoYxgJO66xCpuF+bvqMAIqLWHpLY2l5gJH8iosYOcuNuE3JMdkLRYDDUSCSSfnZCMScnR8YkFImIzGazZ1ZW1iWTyVTj4+Njzc/PD7B1vVVVVV46na7OaDR+ZzabPUpKSvyIiJiEotForLmRUrS5vxB8CcWgoKC4lJSUlpESisXFxZaKioohZScmoajVapuJiJiEYkFBgUWr1YZzr2+0CcWtW7fetiAIO6FYU1NzJj4+/vrGjRtl3MsJSSjKZLK4vXv3+ufm5grOXTIJxQULFgz75WM0CcXQ0NDB28YkFO3tz5dQFHq7xwqGMQAIhoQiEopIKDoGzsAF4KROphLvGZ98pGS1tz1wAvXa284HCcWhkFBEQnGsYBgDgGBIKCKhiISiY2AYA4BgSCgioYiEIhKKAD9rSCiOb0goAhcSigAAAE4EL1MDgEMgoQggHFbGAAAAIsMwBgAAEBmGMQAAgMgwjAEAAESGYQwAokJCEQlFIQlFvp+xUHyP++XLl13nzp0bqVKp1JGRkRqdTuc/0nU5AoYxADg9JBR/+glFvp+xUHyPe35+foBKpeowGo01R48eNa5fvz7U3i9IjoJhDACjgoTiACQUb19CkYj/Z3zx4kW3+fPnT4uJiZkeExMz/dNPP/XiXsbe4+7i4kKtra2uVquVWlpaJBMnTuyVSqUIRQDAyFZ8TqHVV2jYP/a3ImYyXS+aS3aTfeyEooeHR//y5cvl7IRiYmJiO5NQNBqN7maz2bOwsNA8b9689rS0tLD8/PyA3NzcJu71VlVVeVVWVlYrlcrupKSkqJKSEr+MjIxmJqGo1+sbsrKyQvR6fUBeXp7gLB8bX0KRiCg9Pf3SSAnF+vp6aWxsrCY9Pf0ys51JKBIR7dy5cwqTUCwvL/fWarXh3L+zHm1CcdeuXefKyspsrhTHGjuh6Ovra33xxRenbty4Ufb6668PebyFJBQ9PDys3t7efadOnRK8kmUSimvWrBn2/LAnMzMzNDs7u2n+/PlttbW17vPnz486d+6c4Mf9hRde+CE1NTVSJpPFtbe3uxYVFZ1zdXW1cSTHwsoYAARDQhEJRTESivYcO3bM95lnnpFHR0erFy5cGNnW1uba3Nw8ZLbZe9w//PDDiTExMR1NTU3fnjx5sua5556TX7ly5bbPRqyMAZzQSCtYR0FCcSgkFG9PQtHez7i/v5++/vrrM97e3kMmrtDH/b333vP/wx/+8G+JREIxMTFdoaGhXf/61788U1JSbus5xjGMAUAwJBSRUBQrochn9uzZLa+99tqUjRs3NhERffXVVxPuvffeDqGPe3BwcPenn37qm5qa2lZXV+d27tw5z+jo6FGtzscCXqYGAMHYCUWlUqmeO3eusra21v306dNer7zyyr+ffPLJK1KptJ/58xAmoahUKtXNzc1uIyUUlUqlRi6Xd91MQlEmk8UxCcXs7OwgIiJ2QjE6Olo9d+7cSCKijIyM5rCwsC6VSqVRq9VqjUZznS+hGBER0aVSqTRPPPGEXGhCcdWqVYrCwkKzrcts3ry5Xq/XT5XL5THNzc1u7ITi0qVLFaO531zBwcGxL730Umhpaam/TCaL++abbzyFXi4oKKiXSSgqlUp1QkJCdFVV1bD92QnFhISE6UxCUSqVDiYUVSqVevfu3f5vP3slsAAAIABJREFUvPGG3VdwmIRibW2tp0ajUUdHR6u3bNli89PlfD/jHTt21FVUVHgplUr1tGnTNG+++WaArf35HvdXX3218cSJE143ns+qnJyc+sDAQOEfjx8jSCgCOAkkFMc3JBSBCwlFAAAAJ4L3jAHAIZBQBBAOK2MAAACRYRgDAACIDMMYAABAZBjGAAAAIsMwBgBRIaGIhCISihjGAPATgIQiEoojQUIRAH5SkFAcgIQiEopjCcMYwEndVUoq7temCgogImrtJomt7QXfkj8RUWM7uXG3CTkmO6FoMBhqJBJJPzuhmJOTI2MSikREZrPZMysr65LJZKrx8fGx5ufn2zxVYVVVlZdOp6szGo3fmc1mj5KSEj8iIiahaDQaa26kFG3uLwRfQjEoKCguJSWlZaSEYnFxsaWiomJI2YlJKGq12mYiIiahWFBQYNFqteHc6xttQnHr1q23LQjCTijW1NSciY+Pv75x40YZ93JCEooymSxu7969/rm5uYJzl0xCccGCBYJ++WAwCcXq6uozBw4c+D4rKyuMe5mREoq1tbWeMpksLj4+XpOXl1eHhCIAjGtIKCKhiISiY+AMXABO6uQS4j3jk487We1tD/SiXnvb+SChOBQSikgojhUMYwAQDAlFJBSRUHQMvEwNAIIhoYiEIhKKjoGEIoCTQEJxfENCEbiQUAQAAHAieM8YABwCCUUA4bAyBgAAEBmGMQAAgMgwjAEAAESGYQwAACAyDGMAENWtJhTtZfgKCgr8/fz87oyOjh72N6y1tbXu//Ef/xEVERGhmTZtmkbICTRuZ0Lxvvvui/Lx8Zlh77G5mYQiEdHatWunyuXymLCwsJh9+/bZrCQ1NTW53nvvvVEKhSLm3nvvjWJO8iH0OOyf61tvvTVZqVSqlUql+pe//GX0P//5zwm29rFarZSenh4ql8tjlEql+h//+Mew2AYR/2NYWVnpOWPGjGh3d/f49evXDzuv9niGYQwATs9ehm/hwoXNBoOhxmAw1GRnZw/+nfayZcvCn3/++aZz5859V1FRcSYoKOimT/TgiITi888//+/CwsLztrbZIjSN+M0333ju379/stFo/O7QoUOmZ599Vm7r9r/88suBc+bMabVYLNVz5sxpXb9+/dTRHIctMjKy69ixY0aTyVSzdu3ai5mZmTZPbvLBBx9MPHfunKfZbK5+6623LCtXrrQ57PkewylTpvTqdLoLmZmZTUJv23iBYQwAozLeEoqjyfAxvvnmG8++vj565JFHWoiIJk6caOWeZ5pI3ITiQw891Orr62s3h8gmNKFYWlo6adGiRVcmTJjQHx0d3a1QKLq++OKLYdnBQ4cOTcrMzLxMRJSZmXm5vLzcbzTHYXvggQfaAwIC+oiIUlJS2pnzmHN99NFHk5YtW3ZZIpHQr371q/aWlhY3i8UiZV/G3mMYHBzcm5ycfF2MBOKtwt8ZAzihFQcptPoHsvkS3s2KmULXi/4/snv6QnZC0cPDo3/58uVydkIxMTGxnUkoGo1Gd7PZ7FlYWGieN29ee1paWlh+fn5Abm7usFVLVVWVV2VlZbVSqexOSkqKKikp8cvIyGhmEop6vb4hKysrRK/XB+Tl5fFm+ZgM35o1awaPUV5ePkmpVHpHRER0vvnmm3WRkZE9NTU1nr6+vn3z5s2bVldX55GUlNSybdu2eje3of8kshOK9fX10tjYWE16evplZjuTUCQi2rlz5xQmoVheXu6t1WrDuX9nLTSh6EgNDQ3us2bNamP+PygoqPvGLy/t7MtdvnzZjekHKxSKnitXrozJvNDr9XekpKQMO/UoEVFjY6M0LCxs8LzQgYGB3RaLRcruGI+Hx9ARsDIGAMHGc0LRVobvN7/5zdULFy5UmUymmrlz57YuX748nGggAPH11197b926te7bb7+tMZvNHnq9ftjLxWIlFB1JzNvw8ccf+/zlL3+5Q6fT2XyJ216ecYTLON1KmAsrYwAnNNIK1lHGc0KRm+EjIpo6dWof89/Z2dmXNm7cGEw0UG2aPn16BzO0f/3rXzcfP37cm3vbbN0HNkclFPlwb9/NJBRDQkK62S/jX7x40T0kJGTYbfD39+9lVqUWi0U6efJku2+Mc4/D3X7ixIkJK1euVPztb3+rZX4uf/rTnwLee++9ACKiQ4cO1QYFBfWYzebB29bY2Ogul8uH3LapU6f23spjOF5hZQwAgqWmprYcPHjQr6GhwY1o4BO3JpPJfdWqVcFLliy5vG7duovp6emDH85hEopERNyEosFgqFm2bNk1ooGXqQ0Gg3tfXx+VlpZOvu+++3jrSExez2Aw1DCDmMnwvfPOO0N+SWG/37hr165JERERnUREycnJ7deuXXO9ePGiGxHR4cOHfdVqdQf3tiUnJ7d+8MEHk3t7e8lisUiPHz/uQ3bs3r3bj4iIm1A0GAw1e/bssUgkksGUHxERX0KRj63HbiSPP/74VWafpKSk64sXL766f//+yR0dHS4Gg8HdbDZ7zpkzp5273/z5868WFhb6ExEVFhb6p6am2r2d3OOwt9XW1rqnpaVNKyoqOh8XF9fFfH/t2rWXmH3CwsJ6fv3rX199//33/a1WK3322WdePj4+feyXqImIbvUxHK+wMgYAwdgJRavVSlKptD8vL6/u9OnTXu+8847Bzc2NDhw44KfT6fxTU1NbmYTiypUrFeHh4V0jJRQNBsOEu+++u3U0CUUmwxceHt6p0WjURERarfaH7OzsH/Py8qZ88sknk1xdXfsnTZrUW1xcbCYaGOibNm2qnzNnjpKIKDY29vrq1auHFbH+8z//8+pnn33mq1KpNOHh4Z1CE4ptbW2uO3bssPlJ6M2bN9cvXbp02iuvvBKs0WiusxOK27ZtC9izZ4/lxmOtOnfunGdHR4erTCaL2759u3nx4sUt9o4fHBwc29bW5trT0+PyySefTCorKzMlJCR0si8zc+bMzocffviKUqnUuLq60pYtWyzMe+VLly5VPPXUU5eSkpKub9iwofGRRx6ZplAo7ggKCur+8MMPvx/Ncdj++Mc/Bl69etXt6aefVhANvOJRXV19hnu53/zmN9f+9re/TVQoFDETJkyw7ty508xsS05OjnzvvfcsYWFhPXyP4YULF9wSExPV7e3tri4uLv2FhYWyM2fOVE+ePFnwh83EgoQigJNAQnF8Q0IRuJBQBAAAcCJ4mRoAHAIJRQDhsDIGAAAQGYYxAACAyDCMAQAARIZhDAAAIDIMYwAQFRKKSCgykFAEAHBiSCgioUiEhCIA/IwgoTgACUUkFMcShjGAk7qriFTcr01fUQARUWs3SWxtLzhF/kREjW3kxt0m5JjshKLBYKiRSCT97IRiTk6OjEkoEhGZzWbPrKysSyaTqcbHx8ean58fYOt6q6qqvHQ6XZ3RaPzObDZ7lJSU+BERMQlFo9FYcyOlaHN/BpNQXLBgweBpI28kFNWpqakRZ8+elRIRsROK06dPV2dmZobYWh2yE4rFxcWWioqKIdUpJqGo1WqbiYiYhGJBQYFFq9WGc69vPOT/Ghoa3ENDQwczhayE4hDjKaHIvsx4eAwdAcMYAARDQhEJxVuBhCI/nIELwEmdXEG8Z3zycServe2B3tRrbzsfJBSHQkKR/zjc7Ugo2oeVMQAIhoQiEopCj8PehoTiyLAyBgDBkFBEQlHocdiQUBwZEooATgIJxfENCUXgQkIRAADAieBlagBwCCQUAYTDyhgAAEBkGMYAAAAiwzAGAAAQGYYxAACAyDCMAUBUSCgioci41YSivf1LS0t9w8LCYuRyecy6deumMt8vKiryi4yM1EgkkoSjR4/aPN7tgGEMAE4PCUUkFO3t39vbS6tXr5aXlZWZTCbTd/v27Zv8zTffeBIRzZgxo2Pfvn1nZ86c2Sb0/jgChjEAjAoSigOQUBx/CUW+/b/44gsvhULRpVaruz09PfsXLVp0pbS0dBIRUXx8fOedd97ZNfzW3F74O2MAJ7RiN4VWN9KYvqQWE0jXix6lOnuXYScUPTw8+pcvXy5nJxQTExPbmYSi0Wh0N5vNnoWFheZ58+a1p6WlheXn5wfk5uYOC79XVVV5VVZWViuVyu6kpKSokpISv4yMjGYmoajX6xuysrJC9Hp9QF5eXiPf7WMSimvWrBk8xo2EondERETnm2++WRcZGdnDTijW1dV5JCUltWzbtq2eOS0kg51QrK+vl8bGxmrS09MvM9uZhCIR0c6dO6cwCcXy8nJvrVYbzv076/GQ/2toaHCfNWvW4CqQlVAccn7q8ZRQZJ+f2t5jyLd/XV2de3Bw8OD3Q0JCuk+cOGGzICYWrIwBQDAkFJFQvBWOTijy7T8eHveRYGUM4IRGWsE6ChKKQyGhyH8c7vbbkVDk27+rq8uloaFh8Pv19fXuQUFB4yq7iJUxAAiGhCISikKPw952uxKKfPsnJye3m81mT4PB4N7Z2emyf//+yYsXLx5X2UWsjAFAMCQUkVAUehy225VQ5NtfKpXS5s2bL6Smpir7+vroscce+3HmzJmdRAMr+jVr1sibm5vdHnnkkajp06df/8c//lFr73F2BCQUAZwEEorjGxKKwIWEIgAAgBPBy9QA4BBIKAIIh5UxAACAyDCMAQAARIZhDAAAIDIMYwAAAJFhGAOAqJBQREKRgYQiAIATQ0IRCUV7+yOhCAA/OUgoDkBCEQnFsYRhDOCk7tpCKu7Xpv+lACKi1i6S2NpecJT8iYgaW8iNu03IMdkJRYPBUCORSPrZCcWcnBwZk1AkIjKbzZ5ZWVmXTCZTjY+PjzU/Pz/A1vVWVVV56XS6OqPR+J3ZbPYoKSnxIyJiEopGo7HmRkrR5v4MJqG4YMGCwdNG3kgoqlNTUyPOnj0rJSJiJxSnT5+uzszMDLG1OmQnFIuLiy0VFRVDqlNMQlGr1TYTETEJxYKCAotWqw3nXt94SSiGhoYO5gRZCcUhxlNCkX2ZsUoossMR4wGGMQAIhoQiEoq3AglFfjgDF4CTOplNvGd88vEgq73tgb7Ua287HyQUh0JCkf843O1IKNqHlTEACIaEIhKKQo/D3oaE4siwMgYAwZBQREJR6HHYkFAcGRKKAE4CCcXxDQlF4EJCEQAAwIngZWoAcAgkFAGEw8oYAABAZBjGAAAAIsMwBgAAEBmGMQAAgMgwjAFAVEgoIqHIqKys9JwxY0a0u7t7/Pr162X27sNo71thYeHgbbjvvvuiGhsbx9UHmDGMAcDpIaH400goTpkypVen013IzMxsEnrdQu5bT08PrV27NvTIkSMmk8lUo9FoOvLz86fczDEcBcMYAEYFCcUBSCiOfUIxODi4Nzk5+bpUKh12Niru887WLxB8981qtbr09/dTa2urxGq1UktLiyQoKKh72BWIaFwt0wFAmBU7KbS6nob9Y38rYkLoetHvqM7eZdgJRQ8Pj/7ly5fL2QnFxMTEdiahaDQa3c1ms2dhYaF53rx57WlpaWH5+fkBubm5w1Y9VVVVXpWVldVKpbI7KSkpqqSkxC8jI6OZSSjq9fqGrKysEL1eH5CXl9fId/uYhOKaNWsGj3EjoegdERHR+eabb9ZFRkb2sBOKdXV1HklJSS3btm2rZ04LyWAnFOvr66WxsbGa9PT0y8x2JqFIRLRz584pTEKxvLzcW6vVhnP/znq8JBRnzZrVxvw/K6E45PzUYiQU+dh63r399tv+q1atusy+HN998/DwaN+yZcuF+Ph4zYQJE/oUCkVXSUnJhbG4P2MFK2MAEAwJRSQUb8VICUU+fM877uX47ltXV5fLjh07Ak6cOFHT1NT0rVqt7li3bl3gLdyVMYeVMYATGmkF6yhIKA6FhCL/cbjbhSQUw8LCbD4WfM87offt+PHjE4iINBpNFxHRo48+emXTpk1T7d2f2w0rYwAQDAlFJBSFHoe9TWhCke+6+Z53Qu+bQqHoOXv2rCfz8z506JCvUqnkrUyJAStjABAMCUUkFIUeh01oQvHChQtuiYmJ6vb2dlcXF5f+wsJC2ZkzZ6ptPe8KCgouKJXKIR/C4rtvYWFhPWvWrGmcPXu2ys3NrT8kJKR7165dgj+pfjsgoQjgJJBQHN+QUAQuJBQBAACcCF6mBgCHQEIRQDisjAEAAESGYQwAACAyDGMAAACRYRgDAACIDMMYAESFhCISigwkFAEAnBgSikgo2rtvSCgCwE8OEooDkFBEQnEsYRgDOKm7ckjF/dp0kAKIiFo7SWJre8Gn5E9E1HiV3LjbhByTnbIzGAw1Eomkn51QzMnJkTEJRSIis9nsmZWVdclkMtX4+PhY8/PzA2xdb1VVlZdOp6szGo3fmc1mj5KSEj8iIiahaDQaa26kFG3uz2ASigsWLBg8beSNhKI6NTU14uzZs1IiInZCcfr06erMzMwQW/+4sxOKxcXFloqKiiHVKSahqNVqm4mImIRiQUGBRavVhnOvb7wkFENDQwcHESuhOMR4TSgyz7u3337bn3s5vvvm4eHRzyQUZTJZnMlkmvDss8+Oq7PZYRgDgGBIKCKheCuQUOQ3rt7ABgDhTuYQ7xmffDzJam974CTqtbedDxKKQyGhyH8c7nYkFO3DyhgABENCEQlFocdhb0NCcWRYGQOAYEgoIqEo9DhsSCiODAlFACeBhOL4hoQicCGhCAAA4ETwMjUAOAQSigDCYWUMAAAgMgxjAAAAkWEYAwAAiAzDGAAAQGQYxgAgKiQUnSuhaG//L7/88hdKpVItl///7N17XJP33f/xD4EQlJNIMRwTwBggHGpRrO26WA+14eej9zyxburdgd0jpK3+Ot3NdtfetRTb3S2prhCxpaWU5p5d7fCw35y06/qw2tpVXcUVxCTSesWAjFlFOcgZfn/IxX1xmYQLJIbU9/Px4A+5zgkPvnxjcr1kKdnZ2TEDAzduUFZVVRWgUqmSfHx85jh7/DZv3hzJphNzc3Oj4+LikpVKpeqhhx6ayb+1qJDz5KqsrAyKjY1NkclkKVu2bBm++1Z5eXmIQqFIFolEc44ePXpT3ON2wWAMAB4PCcXbl1B0tv2TTz4p37Vrl5VhmNpvv/3Wr7KyMoiIKD4+vuedd95hHnnkkctCr+fhhx9utVgsZywWS51Coeh67rnn7N6+0tF5cvX19dGmTZtkhw4dslgsljN79+6d/tVXX/kREc2ePbtz79699XPnzm0Xem6ugMEYAMYECcUb7tSEoqPtrVaruL29XbRkyZIOkUhEa9euvXzgwIEQohsfc7v33ns72fuMC7Fy5cpWtm513333dTQ2Ntp9Th2dJ9enn37qL5fLu1UqVY+fn9/gypUrr1RWVk4jIkpPT++6++67u/nb3G74nDGAB1pfTDG1F2hCX1JLkdH18v9LNmfrcFN2EolkcN26dTJuQjEjI6ODTSiazWZfhmH8SktLmaVLl3ZkZWXF6vX6sIKCgpvC8TU1Nf7V1dW1SqWyR61WzzIajSE5OTktbELRYDA06nS6aIPBEFZYWNjk6PzYhGJeXt7wMYYSigHx8fFdO3futCkUil5uQtFms0nUanVrSUlJA3tbSBY3odjQ0CBOTU1Nzs7OHp7dsQlFIqKysrIZbEKxqqoqQKvVxvE/Zz1ZEorz588fngVyEooj7k/tKKHoaHtfX9/BiIiI4ftLy+XynqamJjFNgIqKirtWr159xd4yIalHm83mGxUVNXzrzOjo6J7jx4/bLYi5C2bGACAYEopIKDra3sH3x3h2N/v1r38d7u3tPajT6ewOxkJMhsd9NJgZA3ig0WawroKE4kh3YkLR0faxsbG93Jmw1Wr1DQ8Pd3ptGzdujPr444+DiYhMJlMdf7nBYAj96KOPpn322WcW9udg9erVsbW1tVOlUmnPkSNH6oWkHmUyWQ/3Ze6GhgbfyMhIwY/77YCZMQAIhoQiEorOMoX+/v4Dn3zyif/AwADt3r079Ec/+pHTazMYDI3sufGXVVZWBr322mvhhw4dquf+0VNZWcmYTKa6I0eO1Ds7T64FCxZ0MAzjZzKZfLu6urz27ds3fdWqVYIf99sBgzEACMZN2SmVStWiRYuU586d8z19+rT/iy+++M8nnnjiilgsHiwqKgolImITikqlUtXS0uIzWkJRqVQmy2Sy7vEkFM+dO+eXnJw84iNMhYWFMxQKRXJCQoKqpKRkhr2EolKpVA0ODpKjhGJ8fHx3QkJC8uOPPy4TmlDcsGGDvLS0lLG3zvbt2xsMBkO4TCZLaWlp8eEmFB999NHhP2TmzJmT8O///u/xf/vb34KkUmmao48gcUVFRaU+99xzMZWVlaFSqTSNfccwFzczqNFolPyEIvvxnhdeeKHp8OHDQXK5POXw4cNBL7zwQtNo2+/atcuq0+li5XJ5SmxsbHdWVtY1IqIjR45MlUqlaYcOHQrZtGmTXKFQJI92LZs3b5Z1dHR4L1q0SDn0ZkG7H9dydJ4Mw4gXLFigICISi8W0ffv2CxqNRjlr1qzk5cuXX5k7d24X0Y1XDqRSadrp06f9V6xYMeuBBx6YNdq5uQISigAeAgnFyQ0JReBDQhEAAMCD4A1cAOASSCgCCIeZMQAAgJthMAYAAHAzDMYAAABuhsEYAADAzTAYA4BbIaGIhCILCUUAAA+GhCISikgoAsAdBQnFG5BQREJxImEwBvBQ8/6DEvhfL1dSGBFRWyeJ7C0v/hOFEhE1XSEf/jIhx+QmFE0mU51IJBrkJhTz8/OlbEKRiIhhGD+dTnfJYrHUBQYGDuj1+jB7+62pqfEvKiqymc3mMwzDSIxGYwgREZtQNJvNdUMpRbvbs9iEYmZmZiv7vaGEokqj0cTX19eLiYi4CcWkpCRVbm5utL3ZITehWFFRYT116tSI6hSbUNRqtS1ERGxCsbi42KrVauP4+5ssCcWYmJjhnCAnoTiCs4Sive2tVqvYlQlFjUZj917c400oOhrc3QWDMQAIhoQiEopIKLoG7sAF4KFOvEoO7/gUOIUGnC2PmE59zpY7goTiSEgoIqE4UTAzBgDBkFBEQhEJRdfAYAwAgiGhiIQiEoqugYQigIdAQnFyQ0IR+JBQBAAA8CB4AxcAuAQSigDCYWYMAADgZhiMAQAA3AyDMQAAgJthMAYAAHAzDMYA4FZIKCKhyHJHQnE817lx48ao8PDwtKlTp97j6FrGCoMxAHg8JBSRUBxvQnE817l8+fKrx48fPyv0WoTAYAwAY4KE4g1IKH4/EopjvU4iosWLF3ewpaiJgs8ZA3ig9S9TTO15uumX/a1IiaPr5f9JNmfrcBOKEolkcN26dTJuQjEjI6ODTSiazWZfhmH8SktLmaVLl3ZkZWXF6vX6sIKCgmb+fmtqavyrq6trlUplj1qtnmU0GkNycnJa2ISiwWBo1Ol00QaDIaywsLDJ0fmxCcW8vLzhYwwlFAPi4+O7du7caVMoFL3chKLNZpOo1erWkpKSBva2jixuQrGhoUGcmpqanJ2dPTy7YxOKRERlZWUz2IRiVVVVgFarjeN/znqyJBTnz5/fzv6bk1AccX9qZwlFe9v7+voOujKhuHr1arvVpvEmFI8fPx4wnusk3uM0UTAzBgDBkFBEQvFOSSje7ucKM2MADzTaDNZVkFAcCQlFz08ojvU6nV3PrcDMGAAEQ0IRCcXvW0JxrNcp5DEfD8yMAUAwbkJxYGCAxGLxYGFhoe306dP+b7/9tsnHx4f2798fUlRUFKrRaNrYhOKTTz4pj4uL6x4toWgymabce++9beNJKMbFxXUlJyeriIi0Wu2/Nm/e/F1hYeGMjz76aJq3t/fgtGnT+uwlFImIUlNTrztKKH7yySdBCQkJyXFxcV1CE4rt7e3eb775pt13Qm/fvr3h0Ucfnfniiy9GJScnX+cmFEtKSsL27NljHXqsE7799lu/zs5Ob6lUmrZr1y5m1apVrc6OHxUVldre3u7d29vr9dFHH007dOiQZc6cOV3cdbgJRG9vb+InFJ966qlLarX6+gsvvNC0YsWKmXK5/K7IyMieAwcOfDPa9rt27bI+/vjjcV1dXV4LFy5s5SYUf/zjHytaW1u9P/nkk2kvvfRSZH19vdP7lm/evFnW09MjWrRokZKIKD09vf299967wF/P0XkyDCP+2c9+Jj9y5Eg9N6HY399Pa9as+Y5NKI7nOnU6XfT+/fund3V1iaRSadratWu/27Fjx0Vn1zMaJBQBPAQSipMbEorAh4QiAACAB8HL1ADgEkgoAgiHmTEAAICbYTAGAABwMwzGAAAAbobBGAAAwM0wGAOAWyGhiIQiCwlFAAAPhoQiEopIKALAHQUJxRuQUERCUfDFCIDBGMBDzculBP7Xy7spjIio7TqJ7C0v3kuhRERNl8mHv0zIMbkJRZPJVCcSiQa5CcX8/Hwpm1AkImIYxk+n012yWCx1gYGBA3q9PszefmtqavyLiopsZrP5DMMwEqPRGEJExCYUzWZz3VBK0e72LDahmJmZOXzbyKGEokqj0cTX19eLiYi4CcWkpCRVbm5utL3ZITehWFFRYT116tSI6hSbUNRqtS1ERGxCsbi42KrVauP4+5ssCcWYmJjhnCAnDTiCs7Sgve2tVqvYlQlFjUZj917c400osoP7WK9zIq7HHgzGACAYEopIKCKh6Bq4AxeAhzpRSg7v+BQ4lQacLY8IpT5nyx1BQnEkJBSRUJwomBkDgGBIKCKhiISia2BmDACCIaGIhCISikgoAtzRkFCc3JBQBD4kFAEAADwIXqYGAJdAQhFAOMyMAQAA3AyDMQAAgJthMAYAAHAzDMYAAABuhsEYANwKCUUkFFnjSSiWl5eHKBSKZJFINOfo0aM3xTlG09nZ6bVs2bJ4mUyWkpaWlsj9OdDpdNEKhSI5Pj4+mXs9roDBGAA8HhKKd25Ccfbs2Z179+6tnzt3brvQfXMVFRXdFRwc3Hd6hbK6AAAgAElEQVThwoXaDRs2NG/evDmaiOjjjz/2P3HiRIDJZDpjsVjOnD592v/QoUNO78B2KzAYA8CYIKF4AxKKkyOhmJ6e3nX33Xd387/f19dHubm50SkpKUlKpVKl1+vt/tFz8ODBaevXr79MRJSTk9PyxRdfBA4MDJCXlxd1d3d7dXV1eXV2dor6+vq82PtZuwI+ZwzggdZvpZjaehrzS3LOpCjoenkB2Zytw00oSiSSwXXr1sm4CcWMjIwONqFoNpt9GYbxKy0tZZYuXdqRlZUVq9frwwoKCpr5+62pqfGvrq6uVSqVPWq1epbRaAzJyclpYROKBoOhUafTRRsMhrDCwsImR+fHJhTz8vKGjzGUUAyIj4/v2rlzp02hUPRyE4o2m02iVqtbS0pKGtjbHbK4CcWGhgZxampqcnZ29vDsjk0oEhGVlZXNYBOKVVVVAVqtNo7/OevJklCcP3/+8CySkwYccd9lZ2lBe9v7+voOujKhuHr16jFVm1577bW7goOD+2tra892dnZ6ZWRkJD7yyCOtiYmJPdz1mpubfePi4nqIiMRiMQUEBPQ3Nzf7LFmypOMHP/hBW0RExN1ERNnZ2ZfS09O77B1rImBmDACCIaGIhKKnJBT/+te/Bn3wwQehiYmJqnvuuSeppaXFp66uzo+/nqPrqa2tlVgsFr+GhoavGxoavv7ss88Cq6qq7P78TgTMjAE80GgzWFdBQnEkJBTdn1B0tO/BwUGv7du3X+DHNfjHDA8P7zl//rzvzJkze3t7e6m9vd17xowZ/SUlJXdlZGR0BAcHDxARLVmy5NqxY8f8MzMzx/V/06PBzBgABENCEQnFyZZQdOShhx669vrrr4d1d3d7ERF9/fXXktbWVhH/mMuWLbtaXl4eSkT0zjvvhNx3331tIpGIZDJZz7FjxwJ7e3upu7vb69ixY4EqlcplL1NjZgwAgiGhiITiZEsoGo3GaXl5ebKWlhafFStWzEpKSrr++eefn9u0adN3DMNIUlNTkwYHB72mT5/ee+jQoW/42z/99NPfrVq1Kk4mk6UEBwf379mz5xuiG2/mOnz4cFBCQkKyl5cXLVy48NqaNWsE/QE0HkgoAngIJBQnNyQUgQ8JRQAAAA+Cl6kBwCWQUAQQDjNjAAAAN8NgDAAA4GYYjAEAANwMgzEAAICbYTAGALdCQhEJRRYSigAAHgwJRSQUkVAEgDsKEoo3IKGIhOJEwmAM4KHmraEE/tfLb1MYEVFbB4nsLS/eTaFERE2XyIe/TMgxuQlFk8lUJxKJBrkJxfz8fCmbUCQiYhjGT6fTXbJYLHWBgYEDer0+zN5+a2pq/IuKimxms/kMwzASo9EYQkTEJhTNZnPdUErR7vYsNqGYmZk5fNvIoYSiSqPRxNfX14uJiLgJxaSkJFVubm60vdkhN6FYUVFhPXXq1IhqD5tQ1Gq1LUREbEKxuLjYqtVq4/j7mywJxZiYmOGMICehOIKzhKK97a1Wq9iVCUWNRjOmW1FyE4r/+Mc/zr777rthJpPppusUklCMjIxMW7hwYSsSigAwKSChiIQiEoqugTtwAXioE++Rwzs+BfrTgLPlEWHU52y5I0gojoSEIhKKEwUzYwAQDAlFJBSRUHQNzIwBQDAkFJFQRELRNZBQBPAQSChObkgoAh8SigAAAB4EL1MDgEsgoQggHGbGAAAAbobBGAAAwM0wGAMAALgZBmMAAAA3w2AMAG6FhOLtTSiOJbXoiMFgCJXL5SlyuTzFYDCEst//4x//GKhSqZISExNVc+bMSaitrZXY237evHkJR48enersueNzlGfkc5R33LhxY1R4eHja1KlT7xnPNbsaBmMA8HhIKApPKApdz5Hm5mbvV155JfLEiRNn//73v5995ZVXItnW8dNPPy3/3e9+d95kMtVlZWVdef755yNG25+z547LUZ6Ry1necfny5VePHz9+djzXfDtgMAaAMUFC8QZPTSg6W2/fvn1Bs2fPTlSpVEmZmZnx165du+n5OnDgQLBarW6VSqX9YWFh/Wq1unXfvn3B7PKrV696ExFdu3bNm1txskfoc+csz8jlLA+5ePHiDrZCNRnhc8YAHmj9JoqpNdFNv+xvRUoiXS//LdmcrcNNKEokksF169bJuAnFjIyMDjahaDabfRmG8SstLWWWLl3akZWVFavX68MKCgqa+futqanxr66urlUqlT1qtXqW0WgMycnJaWETigaDoVGn00UbDIawwsLCJkfnxyYU8/Lyho8xlFAMiI+P79q5c6dNoVD0chOKNptNolarW0tKShrY2zqyuAnFhoYGcWpqanJ2dvZldjmbUCQiKisrm8EmFKuqqgK0Wm0c/3PWkyGh6EhTU5PPb37zm4ijR49agoKCBp599tnwbdu2SV999dURj3djY6M4Ojp6OKEYFRXV09jYKCYieuONN5iVK1fOkkgkAwEBAf0nT54UPBO199yxhOYZGxsbfefPnz8ccuDkIW+69/Zkg5kxAAiGhKLnJxQd+fTTT/2/+eYbv3nz5iUmJiaq3n///dALFy7c9Hg7SyXu2LFDum/fvnPNzc1fr1mz5rsnnngiRsix7T13Qo8pYL1J8fiOBjNjAA802gzWVZBQHMkTE4qO7p09ODhIDzzwQOuf/vSnEf9PzT9mdHR075EjR4brVY2Njb4LFixou3jxos/Zs2enLFq0qIPoxh8qGo1mFhGNeAzYEAYX/7njP8ebNm26JCTPKDQPORlhMAYAwTQaTevKlSsVW7ZsaY6Kiuprbm72vnbtmvdLL70kXb169WW5XN6TnZ0tP3z4cD3R/yYUlyxZ0sFPKLL7PHjwYCCbUJw1a1ZPZWXl9J///Od2605E/5tQ5H6PTSi+//77DPf7bI+XyHFCMTIysu/w4cNBc+bM6eCfW19fn9dbb70V9tRTT11ubGwUf/nll4E//elPHUbuf//734c88sgjbfyEIncdNqGo1WpbxptQZP8t5B3gjz322NXHHnts1GM8+OCDHb/85S9ltbW1kpSUlO62tjbR+fPnxfxjNjc3excUFESxb9o6cuRI0G9/+9uG6dOn97e3t3t//fXXkrS0tO6DBw8GKRSKLiIi/mPAZe+5s/ccs3nGhQsXduzevTv0qaee+hd/X6tWrbq6du3a+K1btzZbrVaxozzkZITBGAAEQ0LR8xOKztYrLS1lfvKTn8T39PR4ERE9//zzjWlpad3cbaVSaX9eXt7FOXPmJBER/epXv7oolUr7iYiKioqsq1evnunl5UXBwcH9FRUVTt8N7uy546/rKM+4e/fu4JMnT/q/9tprF53lHXU6XfT+/fund3V1iaRSadratWu/27Fjx0Vn53c7IaEI4CGQUJzckFAEPiQUAQAAPAhepgYAl0BCEUA4zIwBAADcDIMxAACAm2EwBgAAcDMMxgAAAG6GwRgA3AoJRSQUkVDEYAwA3wNIKCKhSISEIgDcQZBQvAEJRSQUJxIGYwAPNS+TEvhfLxsojIiorZ1E9pYXl1EoEVFTM/nwlwk5JjehaDKZ6kQi0SA3oZifny9lE4pERAzD+Ol0uksWi6UuMDBwQK/Xh9nbb01NjX9RUZHNbDafYRhGYjQaQ4iI2ISi2WyuG0op2t2exWb4MjMzh28bOZRQVGk0mvj6+noxERE3oZiUlKTKzc2Ntje75SYUKyoqrKdOnRpRnWITilqttoWIiE0oFhcXW7VabRx/f56SUKyrqzubnp5+fdu2bVL+ekISilKpNO2DDz4ILSgocJi75LP33LHGklCMiYkZPjdOQnHSw2AMAIIhoYiEIhKKroE7cAF4qBNV5PCOT4EBNOBseYSU+pwtdwQJxZGQUERCcaJgMAYAwZBQREIRCUXXwGAMAIIhoYiEIhKKroGEIoCHQEJxckNCEfiQUAQAAPAgeJkaAFwCCUUA4TAzBgAAcDMMxgAAAG6GwRgAAMDNMBgDAAC4GQZjAHArJBSRULwdCUVH23d2dnotW7YsXiaTpaSlpSVyfw6EPAcTBYMxAHg8JBSRUCRynlB0tH1RUdFdwcHBfRcuXKjdsGFD8+bNm6PZ/Y31ObgVGIwBYEyQULwBCUXPSSg62/7gwYPT1q9ff5mIKCcnp+WLL74IZGfNY30ObgU+ZwzggdZrKaa2jm76ZX8rUlR0vfxNsjlbh5tQlEgkg+vWrZNxE4oZGRkdbELRbDb7MgzjV1payixdurQjKysrVq/XhxUUFDTz91tTU+NfXV1dq1Qqe9Rq9Syj0RiSk5PTwiYUDQZDo06nizYYDGGFhYUOs3xshi8vL2/4GEMJxYD4+PiunTt32hQKRS83oWiz2SRqtbq1pKSkgb11IoubUGxoaBCnpqYmZ2dnX2aXswlFIqKysrIZbEKxqqoqQKvVxvE/Z+0pCcWgoKCBZ599Nnzbtm3SV199dcTjLSShKJFIBgICAvpPnjx5Vujx7T13rLEkFOfPn9/O/ptNKPr6+g462r65udk3Li6uh4hILBZTQEBAf3Nzs09ERMS4XykZD8yMAUAwJBSRUPTEhKKz7SfLc4KZMYAHGm0G6ypIKI6EhKJnJBRjY2N7HW0fHh7ec/78ed+ZM2f29vb2Unt7u/eMGTP6+ft2NQzGACAYEopIKHpiQtHHx8fh9suWLbtaXl4eumTJko533nkn5L777mtj/wC8nTAYA4BgSCgioeipCUVH2z/99NPfrVq1Kk4mk6UEBwf379mz5xv2mON5DsYLCUUAD4GE4uSGhCLwIaEIAADgQfAyNQC4BBKKAMJhZgwAAOBmGIwBAADcDIMxAACAm2EwBgAAcDMMxgDgVkgoIqGIhCIGYwD4HkBCEQlFIiQUAeAOgoTiDUgoIqE4kTAYA3ioeQ9QAv/rZT2FERG1tZHI3vLiEgolImr6J/nwlwk5JjehaDKZ6kQi0SA3oZifny9lE4pERAzD+Ol0uksWi6UuMDBwQK/Xh9nbb01NjX9RUZHNbDafYRhGYjQaQ4iI2ISi2WyuG0op2t2exWb4MjMzh29ZOJRQVGk0mvj6+noxERE3oZiUlKTKzc2Ntje75SYUKyoqrKdOnRpRnWITilqttoWIiE0oFhcXW7VabRx/f56SUKyrqzubnp5+fdu2bVL+ekISilKpNO2DDz4ILSgocJi75LP33LHGklCMiYkZPjc2oehse0cJRaHnPVEwGAOAYEgoIqGIhKJr4A5cAB7qxOfk8I5PgYE04Gx5RDj1OVvuCBKKIyGhiITiRMFgDACCIaGIhCISiq6BwRgABENCEQlFJBSRUAS4oyGhOLkhoQh8SCgCAAB4ELxMDQAugYQigHCYGQMAALgZBmMAAAA3w2AMAADgZhiMAQAA3AyDMQC4FRKKSCgKSShu3LgxKjw8PG3q1Kn3jOecHT3uly9f9l60aJEiISFBpVAokouKikJH25crYDAGAI+HhOL3P6G4fPnyq8ePHz87nnMmcvy46/X6sISEhE6z2Vx39OhR89atW2Mc/YHkShiMAWBMkFC8AQnF25dQJCJavHhxB3trU66LFy/6PPzwwzNTUlKSUlJSkv7yl7/489dx9rh7eXlRW1ub98DAALW2toqCg4P7xGIxQhEAMDrdeoo5U0s3/bK/FckpdP2NcrI5W4ebUJRIJIPr1q2TcROKGRkZHWxC0Ww2+zIM41daWsosXbq0IysrK1av14cVFBQ08/dbU1PjX11dXatUKnvUavUso9EYkpOT08ImFA0GQ6NOp4s2GAxhhYWFDrN8bIYvLy9v+BhDCcWA+Pj4rp07d9oUCkUvN6Fos9kkarW6taSkpIG9dSKLm1BsaGgQp6amJmdnZ19ml7MJRSKisrKyGWxCsaqqKkCr1cbxP2ftKQnFoKCggWeffTZ827Zt0ldffXXE4y0koSiRSAYCAgL6T548KXgma++5EyI3Nzdm8+bNzQ8//HD7uXPnfB9++OFZ3377reDH/Ve/+tW/NBqNQiqVpnV0dHiXl5d/6+3tbedIroWZMQAIhoQiEoruSCg6c+zYsaCnn35alpiYqHrkkUcU7e3t3i0tLSPGNmeP+4EDB4JTUlI6m5ubvz5x4kTdL3/5S9mVK1du+9iImTGABxptBusqSCiOhITi7Ukoss+xo/P++9//fjYgIGDEiCv0cX/33XdD//M///OfIpGIUlJSumNiYrr/8Y9/+C1cuPC23mMcgzEACIaEIhKK7kooOvLAAw+0vvLKKzO2bdvWTET0xRdfTLn//vs7hT7uUVFRPX/5y1+CNBpNu81m8/n222/9EhMTxzQ7nwgYjAFAMCQUkVB0V0JRp9NF79+/f3pXV5dIKpWmrV279rsdO3ZcfPPNN20///nPZUqlUtXf3+917733tt1///0XhD7uL730UtPatWtjlUqlanBw0Cs/P78hIiJi3O+sHy8kFAE8BBKKkxsSisCHhCIAAIAHwcvUAOASSCgCCIeZMQAAgJthMAYAAHAzDMYAAABuhsEYAADAzTAYA4BbIaGIhCISihiMAeB7AAlFJBRHg4QiAHyvIKF4AxKKSChOJAzGAB7qh/Mogf/16ssURkTU3kYie8t3FVMoEdE/m8iHv0zIMbkJRZPJVCcSiQa5CcX8/Hwpm1AkImIYxk+n012yWCx1gYGBA3q9PszefmtqavyLiopsZrP5DMMwEqPRGEJExCYUzWZz3VBK0e72LDbDl5mZOXzbyKGEokqj0cTX19eLiYi4CcWkpCRVbm5utL3ZLTehWFFRYT116tSI6hSbUNRqtS1ERGxCsbi42KrVauP4+/OUhGJdXd3Z9PT069u2bZPy1xOSUJRKpWkffPBBaEFBgcPcJZ+9504INqFYW1t7dv/+/d/odLpY/jqjJRTPnTvnJ5VK09LT05MLCwttSCgCwKSGhCISikgougbuwAXgoT47QQ7v+BQQSAPOlodHUJ+z5Y4goTgSEopIKE4UDMYAIBgSikgoIqHoGhiMAUAwJBSRUERC0TWQUATwEEgoTm5IKAIfEooAAAAeBC9TA4BLIKEIIBxmxgAAAG6GwRgAAMDNMBgDAAC4GQZjAAAAN8NgDABuhYTizYWgL774Ysrs2bMTFQpFslKpVL311lt2jzmehCIR0TPPPBMuk8lSYmNjU/bu3Wu3ktTc3Ox9//33z5LL5Sn333//LPYmH0KPw31eX3/99elKpVKlVCpV99xzT+Lf/va3Kfa2GRgYoOzs7BiZTJaiVCpVn3/++U2xDSLHj2F1dbXf7NmzE319fdO3bt160321JzMMxgDg8b5vCcWAgICB//mf/zlfX19/5i9/+cu5LVu2xPDvc80nNI341Vdf+e3bt2+62Ww+8+GHH1p+8YtfyOyd//PPPx/x4IMPtlmt1toHH3ywbevWreFjOQ6XQqHoPnbsmNlisdQ988wzF3Nzc+X21vvDH/4Q/O233/oxDFP7+uuvW5988km7g72jx3DGjBl9RUVFF3Jzc5uFnttkgcEYAMYECcUbXJlQTEtL605NTe0mIoqNje2dPn16X1NTk9OPogpNKFZWVk5buXLllSlTpgwmJib2yOXy7k8//fSm7OCHH344LTc39zIRUW5u7uWqqqqQsRyH66GHHuoICwvrJyJauHBhB3sfc74//vGP09auXXtZJBLR4sWLO1pbW32sVquYu46zxzAqKqpvwYIF192RQLxV+JwxgAfavJ5iTLVk9yW88UpMoes7ysnmbB1uQlEikQyuW7dOxk0oZmRkdLAJRbPZ7MswjF9paSmzdOnSjqysrFi9Xh9WUFBw06ylpqbGv7q6ulapVPao1epZRqMxJCcnp4VNKBoMhkadThdtMBjCCgsLHWb52AxfXl7e8DGGEooB8fHxXTt37rQpFIpebkLRZrNJ1Gp1a0lJSYOPz8hfidyEYkNDgzg1NTU5Ozv7MrucTSgSEZWVlc1gE4pVVVUBWq02jv856/EkFA8fPjy1t7fXS6VSdTtbT6jGxkbf+fPnt7P/joyM7Bn646WDu97ly5d92Pt6y+Xy3itXrkzIeGEwGO5auHDhNXvLmpqaxLGxscP3hY6IiOjh3l+caHJnKG8FZsYAIBgSirc3oWi1WsU5OTnxb731FjNRjV13Zhz/9Kc/Bf7ud7+7q6ioyO5L3M7yjKOs43EzYT7MjAE80GgzWFdBQnEkVyYUr1y5IsrMzFRs3bq1cfHixR1EE5NQjI6O7uG+jH/x4kXf6Ojom84hNDS0j52VWq1W8fTp053+xzj/OPzlx48fn/Lkk0/K//znP59jn5f//u//Dnv33XfDiIg+/PDDc5GRkb0MwwyfW1NTk69MJhtxbuHh4X23kqGcrDAzBgDBNBpN68GDB0MaGxt9iG6849Zisfhu2LAhavXq1Ze3bNlyMTs7e/jNOWxCkYiIn1A0mUx1a9euvUZ042Vqk8nk29/fT5WVldN/+MMfOqwjsXk9k8lUxw7EbIbv7bffHvFHCvf/Gx0lFImIDh8+HKRSqTr557ZgwYK2P/zhD9P7+vrIarWKv/zyy0By4ve//30IERE/oWgymer27NljFYlEwyk/IiJHCcWuri6vZcuWKX7yk59cXr9+/fDs295jN5rHHnvsKruNWq2+vmrVqqv79u2b3tnZ6WUymXwZhvF78MEHO/jbPfzww1dLS0tDiYhKS0tDNRqN05IW/zjcZefOnfPNysqaWV5efp5bgXrmmWcusdvExsb2/tu//dvV3bt3hw4MDNAnn3ziHxgY2M99iZqISOhj6GkwMwYAwZBQvD0JxfLy8pCTJ08GtLS0+Lz33nt3ERGVl5efv//++53OhIUkFOfOndu1fPnyK0qlMtnb25t27NhhZf+v/NFHH5U/9dRTl9Rq9fUXXnihacWKFTPlcvldkZGRPQcOHPhmLMfh+q//+q+Iq1ev+mzcuFFOdOMVj9ra2rP89X784x9f+/Of/xwsl8tTpkyZMlBWVsawyxYsWKB49913rbGxsb2OHsMLFy74ZGRkqDo6Ory9vLwGS0tLpWfPnq2dPn264DebuQsSigAeAgnFyQ0JReBDQhEAAMCD4GVqAHAJJBQBhMPMGAAAwM0wGAMAALgZBmMAAAA3w2AMAADgZhiMAcCtkFBEQpGFhCIAgAdDQhEJRSIkFAHgDoKE4g1IKCKhOJEwGAN4qP8zjxL4X4aXKYyIqL2NRPaWv11MoUREzU3kw18m5JjchKLJZKoTiUSD3IRifn6+lE0oEhExDOOn0+kuWSyWusDAwAG9Xh9mb781NTX+RUVFNrPZfIZhGInRaAwhImITimazuW4opWh3exabUMzMzGxlvzeUUFRpNJr4+vp6MRERN6GYlJSkys3NjbY3O+QmFCsqKqynTp0aUZ1iE4parbaFiIhNKBYXF1u1Wm0cf3+TJaEYExMznCnkJBRHmEwJRe46SCgCwB0PCUUkFG8FEoqO4Q5cAB7q0AlyeMengEAacLZcGkF9zpY7goTiSEgoOj4OfzkSis5hZgwAgiGhiISi0ONwlyGhODrMjAFAMCQUkVAUehwuJBRHh4QigIdAQnFyQ0IR+JBQBAAA8CB4mRoAXAIJRQDhMDMGAABwMwzGAAAAbobBGAAAwM0wGAMAALgZBmMAcCskFJFQZN1qQtHZ9pWVlUGxsbEpMpksZcuWLeHs98vLy0MUCkWySCSac/ToUbvHux0wGAOAx0NCEQlFZ9v39fXRpk2bZIcOHbJYLJYze/funf7VV1/5ERHNnj27c+/evfVz585tF3o9roDBGADGBAnFG5BQnHwJRUfbf/rpp/5yubxbpVL1+Pn5Da5cufJKZWXlNCKi9PT0rrvvvntCili3Ap8zBvBA/7WeYs7V0oS+pDYrha6/WE42Z+twE4oSiWRw3bp1Mm5CMSMjo4NNKJrNZl+GYfxKS0uZpUuXdmRlZcXq9fqwgoKCm8LvNTU1/tXV1bVKpbJHrVbPMhqNITk5OS1sQtFgMDTqdLpog8EQVlhY2OTo/NiEYl5e3vAxhhKKAfHx8V07d+60KRSKXm5C0WazSdRqdWtJSUkDe1tIFjeh2NDQIE5NTU3Ozs6+zC5nE4pERGVlZTPYhGJVVVWAVquN43/OerIkFOfPnz88C+QkFEfcn3oyJRS596d29hg62t5ms/lGRUUNfz86Orrn+PHjdgti7oKZMQAIhoQiEoq3wtUJRUfbe0J2ETNjAA802gzWVZBQHAkJRcfH4S+/HQlFR9t3d3d7NTY2Dn+/oaHBNzIyclJlFzEzBgDBkFBEQlHocbjLbldC0dH2CxYs6GAYxs9kMvl2dXV57du3b/qqVasmVXYRM2MAEAwJRSQUhR6H63YlFB1tLxaLafv27Rc0Go2yv7+f1qxZ893cuXO7iG7M6PPy8mQtLS0+K1asmJWUlHT9888/P+fscXYFJBQBPAQSipMbEorAh4QiAACAB8HL1ADgEkgoAgiHmTEAAICbYTAGAABwMwzGAAAAbobBGAAAwM0wGAOAWyGhiIQiCwlFAAAPhoQiEorOtkdCEQC+d5BQvAEJRSQUJxIGYwAP9eg8SuB/vfUyhRERdbSRyN7y3xVTKBHRpSby4S8TckxuQtFkMtWJRKJBbkIxPz9fyiYUiYgYhvHT6XSXLBZLXWBg4IBerw+zt9+amhr/oqIim9lsPsMwjMRoNIYQEbEJRbPZXDeUUrS7PYtNKGZmZray3xtKKKo0Gk18fX29mIiIm1BMSkpS5ebmRtubHXITihUVFdZTp06NqE6xCUWtVttCRMQmFIuLi61arTaOv7/JklCMiYkZzglyEoojTKaEInediUoocsMRkwEGYwAQDAlFJBRvBRKKjuEOXAAeas8JcnjHJ/9AGnC2PCyC+pwtdwQJxZGQUHR8HP5yJBSdw8wYAARDQhEJRaHH4S5DQnF0mBkDgGBIKCKhKPQ4XEgojg4JRQAPgYTi5IaEIvAhoQgAAFkinz4AACAASURBVOBB8DI1ALgEEooAwmFmDAAA4GYYjAEAANwMgzEAAICbYTAGAABwMwzGAOBWSCgiociqrq72mz17dqKvr2/61q1bpc6uYazXVlpaOnwOP/zhD2eNFt643TAYA4DHQ0Lx+5FQnDFjRl9RUdGF3NzcZqH7FnJtvb299Mwzz8QcOXLEYrFY6pKTkzv1ev2M8RzDVTAYA8CYIKF4AxKKE59QjIqK6luwYMF1sVh8092o+D939v6AcHRtAwMDXoODg9TW1iYaGBig1tZWUWRkZM9NO3CjSTVNBwBhXllPMedr6aZf9rciLoWu/7qcbM7W4SYUJRLJ4Lp162TchGJGRkYHm1A0m82+DMP4lZaWMkuXLu3IysqK1ev1YQUFBTfNempqavyrq6trlUplj1qtnmU0GkNycnJa2ISiwWBo1Ol00QaDIaywsLDJ0fmxCcW8vLzhYwwlFAPi4+O7du7caVMoFL3chKLNZpOo1erWkpKSBva2kCxuQrGhoUGcmpqanJ2dfZldziYUiYjKyspmsAnFqqqqAK1WG8f/nPVkSSjOnz+/nf03J6E44v7U7kgoOmLv5+6NN94I3bBhw2Xueo6uTSKRdOzYseNCenp68pQpU/rlcnm30Wi8MBHXM1EwMwYAwZBQRELxVoyWUHTE0c8dfz1H19bd3e315ptvhh0/fryuubn5a5VK1blly5aIW7iUCYeZMYAHGm0G6ypIKI6EhKLj4/CXC0koxsbG2n0sHP3cCb22L7/8cgoRUXJycjcR0U9/+tMrL7/8criz67ndMDMGAMGQUERCUehxuMuEJhQd7dvRz53Qa5PL5b319fV+7PP94YcfBimVSoeVKXfAzBgABENCEQlFocfhEppQvHDhgk9GRoaqo6PD28vLa7C0tFR69uzZWns/d8XFxReUSuWIN2E5urbY2NjevLy8pgceeCDBx8dnMDo6uue9996z+/y4CxKKAB4CCcXJDQlF4ENCEQAAwIPgZWoAcAkkFAGEw8wYAADAzTAYAwAAuBkGYwAAADfDYAwAAOBmGIwBwK2QUERCkYWEIgCAB0NCEQlFZ9eGhCIAfO8goXgDEopIKE4kDMYAHko3jxL4X7tfpjAiouttJLK3fG8xhRIRXW4iH/4yIcfkpuxMJlOdSCQa5CYU8/PzpWxCkYiIYRg/nU53yWKx1AUGBg7o9fowe/utqanxLyoqspnN5jMMw0iMRmMIERGbUDSbzXVDKUW727PYhGJmZmYr+72hhKJKo9HE19fXi4mIuAnFpKQkVW5ubrS9X+7chGJFRYX11KlTI6pTbEJRq9W2EBGxCcXi4mKrVquN4+9vsiQUY2JihgciTkJxhMmaUGR/7t54441Q/nqOrk0ikQyyCUWpVJpmsVim/OIXv5hUd7PDYAwAgiGhiITirUBC0bFJ9R/YACDcGyfI4R2fpgbSgLPloRHU52y5I0gojoSEouPj8JcjoegcZsYAIBgSikgoCj0OdxkSiqPDzBgABENCEQlFocfhQkJxdEgoAngIJBQnNyQUgQ8JRQAAAA+Cl6kBwCWQUAQQDjNjAAAAN8NgDAAA4GYYjAEAANwMgzEAAICbYTAGALdCQtGzEorOtv/ss8+mKpVKlUwmS8nOzo4ZGLhxg7KqqqoAlUqV5OPjM8fZ47d58+ZINp2Ym5sbHRcXl6xUKlUPPfTQTEfVKmfnyVVZWRkUGxubIpPJUrZs2TJ8963y8vIQhUKRLBKJ5hw9evSmuMftgsEYADweEoq3L6HobPsnn3xSvmvXLivDMLXffvutX2VlZRARUXx8fM8777zDPPLII5eFPk4PP/xwq8ViOWOxWOoUCkXXc889Z/f2lY7Ok6uvr482bdokO3TokMVisZzZu3fv9K+++sqPiGj27Nmde/furZ87d2670HNzBQzGADAmSCjecKcmFB1tb7Vaxe3t7aIlS5Z0iEQiWrt27eUDBw6EEN34mNu9997byd5nXIiVK1e2snWr++67r6OxsdHuc+roPLk+/fRTf7lc3q1SqXr8/PwGV65ceaWysnIaEVF6enrX3XffPSFFrFuBzxkDeCDDeoq5UEsT+pKaLIWubywnm7N1uCk7iUQyuG7dOhk3oZiRkdHBJhTNZrMvwzB+paWlzNKlSzuysrJi9Xp9WEFBwU3h+JqaGv/q6upapVLZo1arZxmNxpCcnJwWNqFoMBgadTpdtMFgCCssLGxydH5sQjEvL2/4GEMJxYD4+PiunTt32hQKRS83oWiz2SRqtbq1pKSkgb0tJIubUGxoaBCnpqYmZ2dnD8/u2IQiEVFZWdkMNqFYVVUVoNVq4/ifs54sCcX58+cPzwI5CcUR96d2lFB0tL2vr+9gRETE8P2l5XJ5T1NTk5gmQEVFxV2rV6++Ym+ZkNSjzWbzjYqKGr51ZnR0dM/x48ftFsTcBTNjABAMCUUkFB1t7+D7Yzy7m/36178O9/b2HtTpdHYHYyHcmY0UCjNjAA802gzWVZBQHOlOTCg62j42NraXOxO2Wq2+4eHhDktMREQbN26M+vjjj4OJiEwmUx1/ucFgCP3oo4+mffbZZxb252D16tWxtbW1U6VSac+RI0fqhaQeZTJZD/dl7oaGBt/IyEin53a7YWYMAIIhoYiEorNMob+//8Ann3ziPzAwQLt37w790Y9+5LS+ZTAYGtlz4y+rrKwMeu2118IPHTpUz/2jp7KykjGZTHVHjhypd3aeXAsWLOhgGMbPZDL5dnV1ee3bt2/6qlWrBJfBbgcMxgAgGDdlp1QqVYsWLVKeO3fO9/Tp0/4vvvjiP5944okrYrF4sKioKJSIiE0oKpVKVUtLi89oCUWlUpksk8m6x5NQPHfunF9ycvKIjzAVFhbOUCgUyQkJCaqSkpIZ9hKKSqVSNTg4SI4SivHx8d0JCQnJjz/+uExoQnHDhg3y0tJSxt4627dvbzAYDOEymSylpaXFh5tQfPTRR+VENz5uc/LkyYD33nvvLvZjWV988cWU0R6LqKio1Oeeey6msrIyVCqVprHvGObiZgY1Go2Sn1BkP97zwgsvNB0+fDhILpenHD58OOiFF15oGm37Xbt2WXU6XaxcLk+JjY3tzsrKukZEdOTIkalSqTTt0KFDIZs2bZIrFIrk0a5l8+bNso6ODu9FixYph94saPfjWo7Ok2EY8YIFCxRERGKxmLZv335Bo9EoZ82albx8+fIrc+fO7SK68cqBVCpNO336tP+KFStmPfDAA7NGOzdXQEIRwEMgoTi5IaEIfEgoAgAAeBC8gQsAXAIJRQDhMDMGAABwMwzGAAAAbobBGAAAwM0wGAMAALgZBmMAcCskFJFQZCGhCADgwZBQREIRCUUAuKMgoXgDEopIKE4kDMYAHipvHiXwv/a+TGFERJ1tJLK3/GAxhRIRtTSRD3+ZkGNyE4omk6lOJBINchOK+fn5UjahSETEMIyfTqe7ZLFY6gIDAwf0en2Yvf3W1NT4FxUV2cxm8xmGYSRGozGEiIhNKJrN5rqhlKLd7VlsQjEzM7OV/d5QQlGl0Wji6+vrxURE3IRiUlKSKjc3N9re7JCbUKyoqLCeOnVqRHWKTShqtdoWIiI2oVhcXGzVarVx/P1NloRiTEzMcE6Qk1AcwVlC0d72VqtV7MqEokajsXsv7vEmFB0N7u6CwRgABENCEQlFJBRdA3fgAvBQ+hPk8I5PUwJpwNnykAjqc7bcESQUR0JCEQnFiYKZMQAIhoQiEopIKLoGBmMAEAwJRSQUkVB0DSQUATwEEoqTGxKKwIeEIgAAgAfBG7gAwCWQUAQQDjNjAAAAN8NgDAAA4GYYjAEAANwMgzEAAICbYTAGALdCQhEJRZY7Eorjuc6NGzdGhYeHp02dOvUeR9cyVhiMAcDjIaGIhOJ4E4rjuc7ly5dfPX78+Fmh1yIEBmMAGBMkFG9AQvH7kVAc63USES1evLiDLUVNFHzOGMADvb2eYhpr6aZf9rciKoWuP15ONmfrcBOKEolkcN26dTJuQjEjI6ODTSiazWZfhmH8SktLmaVLl3ZkZWXF6vX6sIKCgmb+fmtqavyrq6trlUplj1qtnmU0GkNycnJa2ISiwWBo1Ol00QaDIaywsLDJ0fmxCcW8vLzhYwwlFAPi4+O7du7caVMoFL3chKLNZpOo1erWkpKSBva2jixuQrGhoUGcmpqanJ2dPTy7YxOKRERlZWUz2IRiVVVVgFarjeN/znqyJBTnz5/fzv6bk1AccX9qZwlFe9v7+voOujKhuHr1arvVpvEmFI8fPx4wnusk3uM0UTAzBgDBkFBEQvFOSSje7uwiZsYAHmi0GayrIKE4EhKKnp9QHOt1OrueW4GZMQAIhoQiEorft4TiWK9TyGM+HpgZA4Bg3ITiwMAAicXiwcLCQtvp06f93377bZOPjw/t378/pKioKFSj0bSxCcUnn3xSHhcX1z1aQtFkMk25995728aTUIyLi+tKTk5WERFptdp/bd68+bvCwsIZH3300TRvb+/BadOm9dlLKBIRpaamXneUUPzkk0+CEhISkuPi4rqEJhTb29u933zzzfP21tm+fXvDo48+OvPFF1+MSk5Ovs5NKJaUlITt2bPHyiYUW1pafN577727iIjKy8vP33///U5nwlFRUant7e3evb29Xh999NG0Q4cOWebMmdPFXYebQPT29iZ+QvGpp566pFarr7/wwgtNK1asmCmXy++KjIzsOXDgwDejbb9r1y7r448/HtfV1eW1cOHCVm5C8cc//rGitbXV+5NPPpn20ksvRdbX1zu9b/nmzZtlPT09okWLFimJiNLT09vfe++9C/z1HJ0nwzDin/3sZ/IjR47UcxOK/f39tGbNmu/YhOJ4rlOn00Xv379/eldXl0gqlaatXbv2ux07dlx0dj2jQUIRwEMgoTi5IaEIfEgoAgAAeBC8TA0ALoGEIoBwmBkDAAC4GQZjAAAAN8NgDAAA4GYYjAEAANwMgzEAuBUSikgospBQBADwYEgoIqGIhCIA3FGQULwBCUUkFAVfjAAYjAE8VME8SuB//fllCiMi6mojkb3lHxdTKBHR1Sby4S8TckxuQtFkMtWJRKJBbkIxPz9fyiYUiYgYhvHT6XSXLBZLXWBg4IBerw+zt9+amhr/oqIim9lsPsMwjMRoNIYQEbEJRbPZXDeUUrS7PYtNKGZmZray3xtKKKo0Gk18fX29mIiIm1BMSkpS5ebmRtubHXITihUVFdZTp06NqE6xCUWtVttCRMQmFIuLi61arTaOv7/JklCMiYkZzgly0oAjOEsL2tvearWKXZlQ1Gg0du/FPd6EIju4j/U6J+J67MFgDACCIaGIhCISiq6BO3ABeKitJ8jhHZ/8AmnA2fJpEdTnbLkjSCiOhIQiEooTBTNjABAMCUUkFJFQdA3MjAFAMCQUkVBEQhEJRYA7GhKKkxsSisCHhCIAAIAHwcvUAOASSCgCCIeZMQAAgJthMAYAAHAzDMYAAABuhsEYAADAzTAYA4BbIaGIhCJrPAnF8vLyEIVCkSwSieYcPXr0pjjHaDo7O72WLVsWL5PJUtLS0hK5Pwc6nS5aoVAkx8fHJ3OvxxUwGAOAx0NC8c5NKM6ePbtz79699XPnzm0Xum+uoqKiu4KDg/suXLhQu2HDhubNmzdHExF9/PHH/idOnAgwmUxnLBbLmdOnT/sfOnTI6R3YbgUGYwAYEyQUb0BCcXIkFNPT07vuvvvum4pWfX19lJubG52SkpKkVCpVer3+pj96iIgOHjw4bf369ZeJiHJyclq++OKLwIGBAfLy8qLu7m6vrq4ur87OTlFfX58Xez9rV8DnjAE80O/XU8w/a2nML8k5E55C139aTjZn63ATihKJZHDdunUybkIxIyOjg00oms1mX4Zh/EpLS5mlS5d2ZGVlxer1+rCCgoJm/n5ramr8q6ura5VKZY9arZ5lNBpDcnJyWtiEosFgaNTpdNEGgyGssLCwydH5sQnFvLy84WMMJRQD4uPju3bu3GlTKBS93ISizWaTqNXq1pKSkgb2docsbkKxoaFBnJqampydnT08u2MTikREZWVlM9iEYlVVVYBWq43jf856siQU58+fPzyL5KQBR9x32Vla0N72vr6+g65MKK5evXpM1abXXnvtruDg4P7a2tqznZ2dXhkZGYmPPPJIa2JiYg93vebmZt+4uLgeIiKxWEwBAQH9zc3NPkuWLOn4wQ9+0BYREXE3EVF2dval9PT0LnvHmgiYGQOAYEgoIqHoKQnFv/71r0EffPBBaGJiouqee+5Jamlp8amrq/Pjr+foemprayUWi8WvoaHh64aGhq8/++yzwKqqKrs/vxMBM2MADzTaDNZVkFAcCQlF9ycUHe17cHDQa/v27RdWrVrV6uyY4eHhPefPn/edOXNmb29vL7W3t3vPmDGjv6Sk5K6MjIyO4ODgASKiJUuWXDt27Jh/ZmbmuP5vejSYGQOAYEgoIqE42RKKjjz00EPXXn/99bDu7m4vIqKvv/5a0traKuIfc9myZVfLy8tDiYjeeeedkPvuu69NJBKRTCbrOXbsWGBvby91d3d7HTt2LFClUrnsZWrMjAFAMCQUkVCcbAlFo9E4LS8vT9bS0uKzYsWKWUlJSdc///zzc5s2bfqOYRhJampq0uDgoNf06dN7Dx069A1/+6effvq7VatWxclkspTg4OD+PXv2fEN0481chw8fDkpISEj28vKihQsXXluzZo2gP4DGAwlFAA+BhOLkhoQi8CGhCAAA4EHwMjUAuAQSigDCYWYMAADgZhiMAQAA3AyDMQAAgJthMAYAAHAzDMYA4FZIKCKhyEJCEQDAgyGhiIQiEooAcEdBQvEGJBSRUJxIGIwBPNRv51EC/+uvL1MYEVF3G4nsLT9aTKFERK1N5MNfJuSY3ISiyWSqE4lEg9yEYn5+vpRNKBIRMQzjp9PpLlkslrrAwMABvV4fZm+/NTU1/kVFRTaz2XyGYRiJ0WgMISJiE4pms7luKKVod3sWm1DMzMwcjgMMJRRVGo0mvr6+XkxExE0oJiUlqXJzc6PtzQ65CcWKigrrqVOnRlR72ISiVqttISJiE4rFxcVWrVYbx9/fZEkoxsTEDGcEOQnFEZwlFO1tb7Vaxa5MKGo0mjHdipKbUPzHP/5x9t133w0zmUw3XaeQhGJkZGTawoULW5FQBIBJAQlFJBSRUHQN3IELwENtOkEO7/gkCaQBZ8uDIqjP2XJHkFAcCQlFJBQnCmbGACAYEopIKCKh6BqYGQOAYEgoIqGIhKJrIKEI4CGQUJzckFAEPiQUAQAAPAhepgYAl0BCEUA4zIwBAADcDIMxAACAm2EwBgAAcDMMxgAAAG6GwRgA3AoJxdubUBxLatERg8EQKpfLU+RyeYrBYAhlv//HP/4xUKVSJSUmJqrmzJmTUFtbK7G3/bx58xKOHj061dlzx+coz8jnKO+4cePGqPDw8LSpU6feM55rdjUMxgDg8ZBQFJ5QFLqeI83Nzd6vvPJK5IkTJ87+/e9/P/vKK69Esq3jp59+Wv673/3uvMlkqsvKyrry/PPPR4y2P2fPHZejPCOXs7zj8uXLrx4/fvzseK75dsBgDABjgoTiDZ6aUHS23r59+4Jmz56dqFKpkjIzM+OvXbt20/N14MCBYLVa3SqVSvvDwsL61Wp16759+4LZ5VevXvUmIrp27Zo3t+Jkj9DnzlmekctZHnLx4sUdbIVqMsLnjAE80P9bTzH/qqWbftnfihkpdP3fysnmbB1uQlEikQyuW7dOxk0oZmRkdLAJRbPZ7MswjF9paSmzdOnSjqysrFi9Xh9WUFDQzN9vTU2Nf3V1da1SqexRq9WzjEZjSE5OTgubUDQYDI06nS7aYDCEFRYWNjk6PzahmJeXN3yMoYRiQHx8fNfOnTttCoWil5tQtNlsErVa3VpSUtLA3taRxU0oNjQ0iFNTU5Ozs7Mvs8vZhCIRUVlZ2Qw2oVhVVRWg1Wrj+J+zngwJRUeampp8fvOb30QcPXrUEhQUNPDss8+Gb9u2Tfrqq6+OeLwbGxvF0dHRwwnFqKionsbGRjER0RtvvMGsXLlylkQiGQgICOg/efKk4JmoveeOJTTP2NjY6Dt//vzhkAMnD3nTvbcnG8yMAUAwJBQ9P6HoyKeffur/zTff+M2bNy8xMTFR9f7774deuHDhpsfbWSpxx44d0n379p1rbm7+es2aNd898cQTMUKObe+5E3pMAet5xD2fMTMG8ECjzWBdBQnFkTwxoejo3tmDg4P0wAMPtP7pT38aEbjgHzM6Orr3yJEjw/WqxsZG3wULFrRdvHjR5+zZs1MWLVrUQXTjDxWNRjOLiEY8Bnv27LHyj81/7vjP8aZNmy4JyTMKzUNORhiMAUAwjUbTunLlSsWWLVuao6Ki+pqbm72vXbvm/dJLL0lXr159WS6X92RnZ8sPHz5cT/S/CcUlS5Z08BOK7D4PHjwYyCYUZ82a1VNZWTn95z//ud26E9H/JhS532MTiu+//z7D/T7b4yVynFCMjIzsO3z4cNCcOXM6+OfW19fn9dZbb4U99dRTlxsbG8Vffvll4E9/+lOHkfvf//73IY888kgbP6HIXYdNKGq12pbxJhTZfwt5B/hjjz129bHHHhu1gvXggw92/PKXv5TV1tZKUlJSutva2kTnz58X84/Z3NzsXVBQEMW+aevIkSNBv/3tbxumT5/e397e7v31119L0tLSug8ePBikUCi6iIj4jwGXvefO3nPM5hkXLlzYsXv37tCnnnrqX/x9rVq16uratWvjt27d2my1WsWO8pCTEQZjABAMCUXPTyg6W6+0tJT5yU9+Et/T0+NFRPT88883pqWljfi/aqlU2p+Xl3dxzpw5SUREv/rVry5KpdJ+IqKioiLr6tWrZ3p5eVFwcHB/RUWF3ceA5ey546/rKM+4e/fu4JMnT/q/9tprF53lHXU6XfT+/fund3V1iaRSadratWu/27Fjx0Vn53c7IaEI4CGQUJzckFAEPiQUAQAAPAhepgYAl0BCEUA4zIwBAADcDIMxAACAm2EwBgAAcDMMxgAAAG6GwRgA3AoJRSQUkVDEYAwA3wNIKCKhSISEIgDcQZBQvAEJRSQUJxIGYwAPVTaPEvhfn79MYURE3W0ksrf8eDGFEhG1NZEPf5mQY3ITiiaTqU4kEg1yE4r5+flSNqFIRMQwjJ9Op7tksVjqAgMDB/R6fZi9/dbU1PgXFRXZzGbzGYZhJEajMYSIiE0oms3muqGUot3tWWyGLzMzs5X93lBCUaXRaOLr6+vFRETchGJSUpIqNzc32t7slptQrKiosJ46dWpEdYpNKGq12hYiIjahWFxcbNVqtXH8/XlKQrGuru5senr69W3btkn56wlJKEql0rQPPvggtKCgwGHuks/ec8caS0IxJiZm+Nw4CcVJD4MxAAiGhCISikgougbuwAXgoX5+ghze8UkSSAPOlgdGUJ+z5Y4goTgSEopIKE4UDMYAIBgSikgoIqHoGhiMAUAwJBSRUERC0TWQUATwEEgoTm5IKAIfEooAAAAeBC9TA4BLIKEIIBxmxgAAAG6GwRgAAMDNMBgDAAC4GQZjAAAAN8NgDABuhYQiEoq3I6HoaPvOzk6vZcuWxctkspS0tLRE7s/BD3/4w1mBgYGzb+XnUygMxgDg8ZBQREKRyHlC0dH2RUVFdwUHB/dduHChdsOGDc2bN2+OZvf3H//xH/8sLS11euOSiYLBGADGBAnFG5BQ9JyEorPtDx48OG39+vWXiYhycnJavvjii0B21vyjH/2oLSgoyOnjOVHwOWMAD3R4PcVcqaWbftnfiukpdH1hOdmcrcNNKEokksF169bJuAnFjIyMDjahaDabfRmG8SstLWWWLl3akZWVFavX68MKCgqa+futqanxr66urlUqlT1qtXqW0WgMycnJaWETigaDoVGn00UbDIawwsJCh1k+NsOXl5c3fIyhhGJAfHx8186dO20KhaKXm1C02WwStVrdWlJS0sDeOpHFTSg2NDSIU1NTk7Ozsy+zy9mEIhFRWVnZDDahWFVVFaDVauP4n7P2lIRiUFDQwLPPPhu+bds26auvvjri8RaSUJRIJAMBAQH9J0+ePCv0+PaeO9ZYEorz589vZ//NJhR9fX0HHW3f3NzsGxcX10NEJBaLKSAgoL+5udknIiJi3K+UjAdmxgAgGBKKSCh6YkLR2faTJbuImTGABxptBusqSCiOhISiZyQUY2Njex1tHx4e3nP+/HnfmTNn9vb29lJ7e7v3jBkz+vn7djUMxgAgGBKKSCh6YkLRx8fH4fbLli27Wl5eHrpkyZKOd955J+S+++5rY/8AvJ0wGAOAYEgoIqHoqQlFR9s//fTT361atSpOJpOlBAcH9+/Zs+cb9phz5sxJ+Pbbb/06Ozu9pVJp2q5du5hVq1a1Orum8UJCEcBDIKE4uSGhCHxIKAIAAHgQvEwNAC6BhCKAcJgZAwAAuBkGYwAAADfDYAwAAOBmGIwBAADcDIMxALgVEopIKCKhiMEYAL4HkFBEQpEICUUAuIMgoXgDEopIKE4kDMYAHmrvPErgf516mcKIiHraSGRv+dfFFEpE1NFEPvxlQo7JTSiaTKY6kUg0yE0o5ufnS9mEIhERwzB+Op3uksViqQsMDBzQ6/Vh9vZbU1PjX1RUZDObzWcYhpEYjcYQIiI2oWg2m+uGUop2t2exGb7MzMzhWxYOJRRVGo0mvr6+XkxExE0oJiUlqXJzc6PtzW65CcWKigrrqVOnRlSn2ISiVqttISJiE4rFxcVWrVYbx9+fpyQU6+rqzqanp1/ftm2blL+ekISiVCpN++CDD0ILCgoc5i757D13rLEkFGNiYobPjU0oOtveUUJR6HlPFAzGACAYEopIKCKh6Bq4AxeAh1p1wWaLCAAAIABJREFUghze8ck3kAacLfePoD5nyx1BQnEkJBSRUJwoGIwBQDAkFJFQRELRNTAYA4BgSCgioYiEIhKKAHc0JBQnNyQUgQ8JRQAAAA+Cl6kBwCWQUAQQDjNjAAAAN8NgDAAA4GYYjAEAANwMgzEAAICbYTAGALdCQhEJRSEJxY0bN0aFh4enTZ069Z7xnLOjx/3y5cveixYtUiQkJKgUCkVyUVFR6Gj7cgUMxgDg8ZBQ/P4nFJcvX371+PHjZ8dzzkSOH3e9Xh+WkJDQaTab644ePWreunVrjL0/kFwNgzEAjAkSijcgoXj7EopERIsXL+74/+3de1STd5748Q+BAAqISjFcE1AMGJBavG1di9XaiqenO17HndrTVTsHqNXjSNfu1NlaL+1uxdERqXbotlQ9Uzt28DI7DtbOeqy2dqq9aCtFLtYGASljFeUi9/D7g8ZfiEl4QGJI+36dwzm7Pnny5EmYfviG8LzNlza1dPnyZa8ZM2aMSEhIGJWQkDDq/fff97O+jaPn3cPDQ+rq6jxNJpPU1taqAgMD29RqNaEIAN07tUQibxTIbf+xvxOBCXJzYq6UO7qNZULRx8en44knntBaJhTHjx/fYE4oFhcXexuNRt+cnBzjI4880jB//vyoTZs2Ba9fv77a+n7PnTvnd+bMmQK9Xt+SnJw8cvfu3UMWL15cY04oZmdnV6anp0dkZ2cHZ2Zm2s3ymTN8q1atunWMHxKK/sOHD2969dVXy2NiYlotE4rl5eU+ycnJtdu3b68wXzrRzDKhWFFRoR49enT8okWLrpq3mxOKIiJvvPHGMHNC8fDhw/6pqanR1n9n7S4JxUGDBpl+85vfhGzYsEHz29/+tsvzrSSh6OPjY/L392//9NNPFa9kbb12SqSlpUVmZGRUz5gxo760tNR7xowZIy9evKj4eX/uuef+kZKSEqPRaBIbGho8c3NzLzq7kGULK2MAipFQJKHoioSiIydPnhy0YsUKbVxcnOGxxx6Lqa+v96ypqeky2xw97wcPHgxMSEhorK6u/ur06dOFzz77rPbatWt3fTayMgbcUHcrWGchodgVCcW7k1A0v8b2Hvdnn3123t/fv8vEVfq879q1K+jXv/71dyqVShISEpojIyObv/zyS9+pU6fe1WuMM4wBKEZCkYSiqxKK9kyePLl248aNwzZs2FAt0vlJ9EmTJjUqfd7Dw8Nb3n///UEpKSn15eXlXhcvXvSNi4vr0eq8L/A2NQDFLBOKer3eMG3aNH1paan32bNn/V566aXvnn766WtqtbrD/Och5oSiXq831NTUeHWXUNTr9fFarba5NwnF0tJS3/j4+C5/wpSZmTksJiYmPjY21rB9+/ZhthKKer3e0NHRIfYSisOHD2+OjY2Nf+qpp7RKE4rLli3T5eTkGG3dZvPmzRXZ2dkhWq02oaamxssyobhgwQKdiIg5obhnz557zH+W9fHHHw/o7rkIDw8f/cILL0Tm5eUFaTSaxM8//9xX6e3CwsLazAlFvV5vGDt2bNy5c+du298yoTh27NhR5oSiWq2+lVCMjY01vPPOO0G/+93vHL6D4+i1s5aenh6h0WgSm5qaVBqNJjEjI8O82i//4osv/PR6vWHEiBHxr776arCt/e097y+//HLVqVOn/H74fo5du3ZtRWhoaK8/Wd9bJBQBN0FCsX8joQhrJBQBAHAj/M4YgFOQUASUY2UMAICLMYwBAHAxhjEAAC7GMAYAwMUYxgBcioQiCUUSigxjAD8CJBRJKHaHhCKAHxUSip1IKJJQ7EsMY8BNvT9BYq2/Cl+RYBGR1jpR2dpesk2CREQaq8TLepuSY1omFIuKigpVKlWHZUJx7dq1GnNCUUTEaDT6pqenXykpKSkMCAgwbdq0yealCs+dO+eXlZVVXlxc/LXRaPTZvXv3EBERc0KxuLi48IeUos39zcwZvpkzZ9aa/+2HhKIhJSVl+IULF9QiIpYJxVGjRhnS0tIibK1uLROKO3fuLPviiy+6VKfMCcXU1NQaERFzQnHbtm1lqamp0db35y4JxcLCwvNJSUk3N2zYoLG+nZKEokajSXz33XeD1q9fbzd3ac3Wa6eEOaFYUFBw/sCBA9+kp6dHWd+mu4RiaWmpr0ajSUxKSorPzMwsJ6EIoF8joUhCkYSic3AFLsBNPXJa7F7xSR0gJkfbB4RKm6Pt9pBQ7IqEIgnFvsIwBqAYCUUSiiQUnYO3qQEoRkKRhCIJRecgoQi4CRKK/RsJRVgjoQgAgBvhd8YAnIKEIqAcK2MAAFyMYQwAgIsxjAEAcDGGMQAALsYwBuBSJBTtF4KuXbumGjZsWKK91GFvEooiIs8//3yIVqtNiIqKSti3b5/NSlJ1dbXnpEmTRup0uoRJkyaNNF/kQ+lxLF/X1157baherzfo9XrDfffdF/f3v//d5t9Mm0wmWbRoUaRWq03Q6/WGjz766LbYhoj95/DMmTO+Y8aMifP29k5as2bNbdfV7s8YxgDc3o8toWhxXuETJ050eKERM6VpxM8//9x3//79Q4uLi79+7733Sn71q19pbT3+F198MfTBBx+sKysrK3jwwQfr1qxZE9KT41iKiYlpPnnyZHFJSUnh888/fzktLU1n63Z/+tOfAi9evOhrNBoLXnvttbKlS5faHPb2nsNhw4a1ZWVlXUpLS6tW+tj6C4YxgB4hodjJmQlFEZEPP/xw4JUrV9QPP/ywooqR0oRiXl7e4Dlz5lwbMGBAR1xcXItOp2v+4IMPbssOvvfee4PT0tKuioikpaVdPXz48JCeHMfSww8/3BAcHNwuIjJ16tQG83XMrf35z38evHDhwqsqlUoeeuihhtraWq+ysjK15W0cPYfh4eFtU6ZMuemKBOKd4u+MATd0bolE1heIzbfwess/QW6OzhWHly+0TCj6+Ph0PPHEE1rLhOL48eMbzAnF4uJib6PR6JuTk2N85JFHGubPnx+1adOm4PXr19+2ajl37pzfmTNnCvR6fUtycvLI3bt3D1m8eHGNOaGYnZ1dmZ6eHpGdnR2cmZlpN8tnzvCtWrXq1jF+SCj6Dx8+vOnVV18tj4mJabVMKJaXl/skJyfXbt++vcLLq+t/Ei0TihUVFerRo0fHL1q06Kp5uzmhKCLyxhtvDDMnFA8fPuyfmpoabf131koTiu3t7fLss89G7tmz52J+fr7Nt5F7q7Ky0vuf/umf6s3/f1hYWMsPP7w0WN7u6tWrXubreut0utZr1671ybzIzs6+Z+rUqTdsbauqqlJHRUXdui50aGhoi+X1xUV6l6F0B6yMAShGQvHuJBQ3btwY/Mgjj1yPiYmxWXS6Ez3NOPalv/zlLwF/+MMf7snKyrL5FrejPGM3t3G7lbA1VsaAG+puBessJBS7clZC8ZNPPvH/9NNP/d96661hN2/eVLW2tqr8/f3b582bd/1OE4oREREtlm/jX7582TsiIuK2xxAUFNRmXpWWlZWphw4d6vAX49bHsd5+6tSpAUuXLtX99a9/LTW/Lv/93/8dvGvXrmARkffee680LCys1Wg03npsVVVV3lqttstjCwkJaVOaoXQnrIwBKJaSklJ76NChIZWVlV4inZ+4LSkp8V62bFn4vHnzrq5evfryokWLbn04x5xQFBGxTigWFRUVLly48IZI59vURUVF3u3t7ZKXlzf0gQcesPuhJXNer6ioqNA8iM0ZvjfffLPLDymWv2+0l1AUETl27Nggg8HQaP3YpkyZUvenP/1paFtbm5SVlak/+eSTAHHgnXfeGSIiYp1QLCoqKty7d2+ZSqW6lfITEbGXUPzf//3fb6uqqs5VVlaeW7duXcWcOXOu7tixo9LWc9edJ5988rp5n+Tk5Jtz5869vn///qGNjY0eRUVF3kaj0ffBBx9ssN5vxowZ13NycoJERHJycoJSUlIclrSsj2O5rbS01Hv+/PkjcnNzv01MTGw2//vzzz9/xbxPVFRU67/8y79cf/vtt4NMJpMcPXrULyAgoN3yLWoREaXPobthZQxAMcuEoslkErVa3ZGZmVl+9uxZvzfffLPIy8tLDhw4MCQrKysoJSWlzpxQXLp0qS46Orq5u4RiUVHRgIkTJ9b1JqEYHR3dFB8fbxARSU1N/UdGRsb3mZmZw44cOTLY09OzY/DgwW22EooiIqNHj75pL6F49OjRQbGxsfHR0dFNShOK9fX1nq+//vq3tm6zefPmigULFox46aWXwuPj429aJhS3b98evHfv3jKl524tPDx8dH19vWdra6vHkSNHBufn55eMHTu2yfI248aNa5o1a9Y1vV4f7+npKVu2bCkz/658wYIFumeeeeZKcnLyzXXr1lXNnj17hE6nuycsLKzl4MGD3/TkOJb+8z//M/T69etey5cv14l0vuNRUFBw3vp2P//5z2/89a9/DdTpdAkDBgwwvfHGG0bztilTpsTs2rWrLCoqqtXec3jp0iWv8ePHGxoaGjw9PDw6cnJyNOfPny8YOnSo4g+buQoJRcBNkFDs30gowhoJRQAA3AhvUwNwChKKgHKsjAEAcDGGMQAALsYwBgDAxRjGAAC4GMMYgEuRUCShaEZCEQDcGAlFEooiJBQB/ISQUOxEQpGEYl9iGANu6u8TJNb66+IrEiwi0lYnKlvby7ZJkIhIc5V4WW9TckzLhGJRUVGhSqXqsEworl27VmNOKIqIGI1G3/T09CslJSWFAQEBpk2bNgXbut9z5875ZWVllRcXF39tNBp9du/ePURExJxQLC4uLvwhpWhzfzNzQnHmzJm3BtgPCUVDSkrK8AsXLqhFRCwTiqNGjTKkpaVF2FodWiYUd+7cWfbFF190qU6ZE4qpqak1IiLmhOK2bdvKUlNTo63vr6cJxa1bt/Z5EKSystI7MjLyVqbQIqHYRX9KKFrehoQigJ88EookFO8ECUX7uAIX4KbuPy12r/jkFSAmR9t9QqXN0XZ7SCh2RULR/nGst5NQdIyVMQDFSCiSUFR6HMttJBS7x8oYgGIkFEkoKj2OJRKK3SOhCLgJEor9GwlFWCOhCACAG+FtagBOQUIRUI6VMQAALsYwBgDAxRjGAAC4GMMYAAAXYxgDcCkSiiQUze40oeho/7y8vEFRUVEJWq02YfXq1SHmf8/NzR0SExMTr1Kpxp44ccLm8e4GhjEAt0dCkYSio/3b2tpk5cqV2vz8/JKSkpKv9+3bN/Tzzz/3FREZM2ZM4759+y6MGzeuXun5OAPDGECPkFDsREKx/yUU7e3/wQcf+Ol0umaDwdDi6+vbMWfOnGt5eXmDRUSSkpKa7r333ubbH83dxTAG3NA3SyTy3ASJ7cuvb5ZIZHfHJaFIQvFOOTOhaG//8vJy7/Dw8Fv/HhER0VJZWdmvsosMYwCKkVAkoXgnnJ1QtLe/O2QXuQIX4IZG5Eqfr5iUIKHYFQlF+8ex3n43Eor29m9ubvawXAlXVFR4h4WF9avsIitjAIqRUCShqPQ4ltvuVkLR3v5TpkxpMBqNvkVFRd5NTU0e+/fvHzp37tx+lV1kZQxAMRKKJBSVHsfS3Uoo2ttfrVbL5s2bL6WkpOjb29vl8ccf/37cuHFNIp0r+lWrVmlramq8Zs+ePXLUqFE3P/roo9Levga9RUIRcBMkFPs3EoqwRkIRAAA3wtvUAJyChCKgHCtjAABcjGEMAICLMYwBAHAxhjEAAC7GMAbgUiQUSSiakVAEADdGQpGEoqP9SSgC+NEhodiJhCIJxb7EMAbclK0MYuUrEiwi0l4nKlvbq7ZJkIhIS5V4WW9TckwSiiQU7xQJRdsYxgAUI6FIQvFOkFC0jytwAW5q9Gmxe8UnzwAxOdruHSptjrbbQ0KxKxKK9o9jvZ2EomOsjAEoRkKRhKLS41huI6HYPVbGABQjoUhCUelxLJFQ7B4JRcBNkFDs30gowhoJRQAA3AhvUwNwChKKgHKsjAEAcDGGMQAALsYwBgDAxRjGAAC4GMMYgEuRUCShaHbmzBnfMWPGxHl7eyetWbNG4+gcenpuOTk5tx7DAw88MLKqqqpffYCZYQzA7ZFQ/HEkFIcNG9aWlZV1KS0trVrpfSs5t9bWVnn++ecjjx8/XlJSUlIYHx/fuGnTpmG9OYazMIwB9AgJxU4kFPs+oRgeHt42ZcqUm2q1+rarUVl/39n6AcLeuZlMJo+Ojg6pq6tTmUwmqa2tVYWFhbXcdgcuxDAG3FDVEok0TpDYvvyqWiKR3R2XhCIJxTvlKKFoj63vu9///vdB1rezd24+Pj4dW7ZsuZSUlBSv0WgSS0pKBvzqV7/qV1ezYxgDUIyEIgnFO9FdQtEee9931rezd27Nzc0er7/+evCpU6cKq6urvzIYDI2rV68OvYNT6XP96hfYAJQJzZU+XzEpQUKxKxKK9o9jvV1JQjEqKsrmDx/2vu+Untsnn3wyQEQkPj6+WUTkF7/4xbVXXnklxNH53G2sjAEoRkKRhKLS41huU5pQtHff9r7vlJ6bTqdrvXDhgq/59X7vvfcG6fV6u5UpV2BlDEAxEookFJUex5LShOKlS5e8xo8fb2hoaPD08PDoyMnJ0Zw/f77A1vfdtm3bLun1+i4fwrJ3blFRUa2rVq2qmjx5cqyXl1dHREREy549e2y+Pq5CQhFwEyQU+zcSirBGQhEAADfC29QAnIKEIqAcK2MAAFyMYQwAgIsxjAEAcDGGMQAALsYwBuBSJBRJKJqRUAQAN0ZCkYSio3MjoQjgR4eEYicSiiQU+xLDGHBTtjKIV1+RYBERU52obG2/tk2CRETaqsTLepuSY5JQJKF4p0go2sYwBqAYCUUSineChKJ9/eoX2ACUizotdq/4pAoQk6PtXqHS5mi7PSQUuyKhaP841ttJKDrGyhiAYiQUSSgqPY7lNhKK3WNlDEAxEookFJUexxIJxe6RUATcBAnF/o2EIqyRUAQAwI3wNjUApyChCCjHyhgAABdjGAMA4GIMYwAAXIxhDACAizGMAbgUCUX3Sig62v/DDz8cqNfrDVqtNmHRokWRJlPnBcoOHz7sbzAYRnl5eY119PxlZGSEmdOJaWlpEdHR0fF6vd7w8MMPj7C+tKiSx2kpLy9vUFRUVIJWq01YvXr1ratv5ebmDomJiYlXqVRjT5w4cVvc425hGANweyQU715C0dH+S5cu1e3YsaPMaDQWXLx40TcvL2+QiMjw4cNb3nrrLeNjjz12Vcm5iIjMmDGjtqSk5OuSkpLCmJiYphdeeMHm5SvtPU5LbW1tsnLlSm1+fn5JSUnJ1/v27Rv6+eef+4qIjBkzpnHfvn0Xxo0bV6/0sTkDwxhAj5BQ7PRTTSja27+srExdX1+vmj59eoNKpZKFCxdePXjw4BCRzj9zmzhxYqP5OuNKzJkzp9Zct7r//vsbKisrbb6m9h6npQ8++MBPp9M1GwyGFl9f3445c+Zcy8vLGywikpSU1HTvvfc2W+9ztzGMATdUv0Qib0yQ2L78ql8ikd0dl4QiCUV7+5eVlalDQ0NvXV9ap9O1VFVVqa3vtzd27tx5T0pKis1rcStJPZaXl3uHh4ffeswREREt9oa7qzCMAShGQpGEor397fx7Dx/d7f7jP/4jxNPTsyM9Pf1ab+/DldlIpbgCF+CG/HOlz1dMSpBQ7OqnmFC0t39UVFSr5Uq4rKzMOyQkxOEPE8uXLw//29/+FigiUlRUVGi9PTs7O+jIkSODP/zwwxLz98G8efOiCgoKBmo0mpbjx49fUJJ61Gq1XVbCFRUV3mFhYX3+g86dYGUMQDESiiQUHWUK/fz8TEePHvUzmUzy9ttvB/3sZz9zWN/Kzs6uND826215eXmDtm7dGpKfn3/B8oeevLw8Y1FRUeHx48cvOHqclqZMmdJgNBp9i4qKvJuamjz2798/dO7cuYrLYHcDwxiAYpYpO71eb5g2bZq+tLTU++zZs34vvfTSd08//fQ1tVrdkZWVFSQiYk4o6vV6Q01NjVd3CUW9Xh+v1Wqbe5NQLC0t9Y2Pj+/yJ0yZmZnDYmJi4mNjYw3bt28fZiuhqNfrDR0dHWIvoTh8+PDm2NjY+KeeekqrNKG4bNkyXU5OjtHWbTZv3lyRnZ0dotVqE2pqarwsE4oLFizQ2dpHqfDw8NEvvPBCZF5eXpBGo0k0f2LYkmVmMCUlRW+dUDT/ec+6deuqjh07Nkin0yUcO3Zs0Lp166q623/Hjh1l6enpUTqdLiEqKqp5/vz5N0REjh8/PlCj0STm5+cPWblypS4mJia+u3PJyMjQNjQ0eE6bNk3/w4cFbf65lr3HaTQa1VOmTIkREVGr1bJ58+ZLKSkp+pEjR8bPmjXr2rhx45pEOt850Gg0iWfPnvWbPXv2yMmTJ4/s+TN/50goAm6ChGL/RkIR1kgoAgDgRvgAFwCnIKEIKMfKGAAAF2MYAwDgYgxjAABcjGEMAICLMYwBuBQJRRKKZiQUAcCNkVAkoUhCEcBPCgnFTiQUSSj2JYYx4KZsZRAbX5FgEZGOOlHZ2t60TYJERExV4mW9TckxSSiSUCSh6BwMYwCKkVAkoUhC0Tm4AhfgpgJPi90rPnkEiMnRdlWotDnabg8Jxa5IKJJQ7CusjAEoRkKRhCIJRedgGANQjIQiCUUSis5BQhFwEyQU+zcSirBGQhEAADfCB7gAOAUJRUA5VsYAALgYwxgAABdjGAMA4GIMYwAAXIxhDMClSCiSUDRzRUKxN+e5fPny8JCQkMSBAwfeZ+9ceophDMDtkVAkodjbhGJvznPWrFnXT506dV7puSjBMAbQIyQUO5FQ/HEkFHt6niIiDz30UIO5FNVXGMaAG+pYIpEdEyS2T7+WSGR3xyWhSELxx5ZQ7Ol59sX52MIwBqAYCUUSij+VhOLdzi5yBS7ADXnkSp+vmJQgodgVCUX3Tyj29Dwdnc+dYGUMQDESiiQUf2wJxZ6ep5LnvDdYGQNQzDKhaDKZRK1Wd2RmZpafPXvW78033yzy8vKSAwcODMnKygpKSUmpMycUly5dqouOjm7uLqFYVFQ0YOLEiXW9SShGR0c3xcfHG0REUlNT/5GRkfF9ZmbmsCNHjgz29PTsGDx4cJuthKKIyOjRo2/aSygePXp0UGxsbHx0dHST0oRifX295+uvv/6trdts3ry5YsGCBSNeeuml8Pj4+JuWCcXt27cH7927t0zpuVsLDw8fXV9f79na2upx5MiRwfn5+SVjx45tsryNZQLR09NTrBOKzzzzzJXk5OSb69atq5o9e/YInU53T1hYWMvBgwe/6W7/HTt2lD311FPRTU1NHlOnTq21TCj+/Oc/j6mtrfU8evTo4JdffjnswoULDq9bnpGRoW1paVFNmzZNLyKSlJRUv2fPnkvWt7P3OI1Go/rf/u3fdMePH79gmVBsb2+Xxx9//HtzQrE355menh5x4MCBoU1NTSqNRpO4cOHC77ds2XK5t6+bCAlFwG2QUOzfSCjCGglFAADcCG9TA3AKEoqAcqyMAQBwMYYxAAAuxjAGAMDFGMYAALgYwxiAS5FQJKFoRkIRANwYCUUSiiQUAfykkFDsREKRhKLik1GAYQy4KZsZxFckWESko05UNrdvkyARkY4q8bLepuSYJBRJKJJQdA6GMQDFSCiSUCSh6BxcgQtwUx6nxe4VnzwCxCSOtodKm6Pt9pBQ7IqEIgnFvsLKGIBiJBRJKJJQdA5WxgAUI6FIQpGEIglF4CeNhGL/RkIR1kgoAgDgRnibGoBTkFAElGNlDACAizGMAQBwMYYxAAAuxjAGAMDFGMYAXIqEIglFs94kFHNzc4fExMTEq1SqsSdOnLgtztGdxsZGj0cffXS4VqtNSExMjLP8PkhPT4+IiYmJHz58eLzl+TgDwxiA2yOh+NNNKI4ZM6Zx3759F8aNG1ev9L4tZWVl3RMYGNh26dKlgmXLllVnZGREiIj87W9/8zt9+rR/UVHR1yUlJV+fPXvWLz8/3+EV2O4EwxhAj5BQ7ERCsX8kFJOSkpruvffeZut/b2trk7S0tIiEhIRRer3esGnTJps/9Bw6dGjwkiVLroqILF68uObjjz8OMJlM4uHhIc3NzR5NTU0ejY2Nqra2Ng/z9aydgWEMuKMlNyNlQn1sn34tuRnZ3WFJKJJQ7G8JRXu2bt16T2BgYHtBQcH5L7/88vyuXbuCi4qKbjvP6upq7+jo6BYREbVaLf7+/u3V1dVe06dPb/jnf/7nutDQ0HvDwsISp06dWpuUlNR0+5H6BsMYgGIkFEkouktC8f/+7/8Gvfvuu0FxcXGG++67b1RNTY1XYWGhr/Xt7J1PQUGBT0lJiW9FRcVXFRUVX3344YcBhw8ftvn92xe4AhfgjnIH9vmKSQkSil2RUHR9QtHefXd0dHhs3rz50ty5c7u8zW99zJCQkJZvv/3We8SIEa2tra1SX1/vOWzYsPbt27ffM378+IbAwECTiMj06dNvnDx50m/mzJm9+t10d1gZA1CMhCIJxf6WULTn4YcfvvHaa68FNzc3e4iIfPXVVz61tbUq62M++uij13Nzc4NERN56660h999/f51KpRKtVtty8uTJgNbWVmlubvY4efJkgMFgcNrb1KyMAShGQpGEYn9LKO7evXvwqlWrtDU1NV6zZ88eOWrUqJsfffRR6cqVK783Go0+o0ePHtXR0eExdOjQ1vz8/G+s91+xYsX3c+fOjdZqtQmBgYHte/fu/Uak88Ncx44dGxQbGxvv4eEhU6dOvfH444/36PfWPUFCEXATJBT7NxKKsEZCEQAAN8Lb1ACcgoQioBwrYwAAXIxhDACAizGMAQBwMYYxAAAuxjAG4FIkFEkompFQBAA3RkKRhCIJRQA/KSQUO5FQJKHYlxjGgLuylUF8pakzMVjXobK5fVtzkIiIVJm8btumAAlFEookFJ2DYQxAMRKKJBRJKDoGAGHrAAANdklEQVQHV+AC3NVpf/tXfArwMDncHqpqc7jdDhKKXZFQJKHYV1gZA1CMhCIJRRKKzsHKGIBiJBRJKJJQdA4SioCbIKHYv5FQhDUSigAAuBHepgbgFCQUAeVYGQMA4GIMYwAAXIxhDACAizGMAQBwMYYxAJcioXh3E4o9SS3ak52dHaTT6RJ0Ol1CdnZ2kPnf//znPwcYDIZRcXFxhrFjx8YWFBT42Np/woQJsSdOnBjo6LWzZi/PaM1e3nH58uXhISEhiQMHDryvN+fsbAxjAG6PhKLyhKLS29lTXV3tuXHjxrDTp0+f/+yzz85v3LgxzNw6XrFihe4Pf/jDt0VFRYXz58+/9uKLL4Z2d3+OXjtL9vKMlhzlHWfNmnX91KlT53tzzncDwxhAj5BQ7OSuCUVHt9u/f/+gMWPGxBkMhlEzZ84cfuPGjdter4MHDwYmJyfXajSa9uDg4Pbk5OTa/fv3B5q3X79+3VNE5MaNG56WFSdblL52jvKMlhzlIR966KEGc4WqP2IYA+5oyfeRMqEqtk+/lnwf2d1hSSi6f0LRnqqqKq//+q//Cj1x4kRJYWHh+aSkpJsbNmzQWN+usrJSHRERcSuhGB4e3lJZWakWEfn9739vnDNnzkiNRpP47rvvBq1fv75K6fFtvXZmSvOMSvOQ/RHDGIBiJBTdP6FozwcffOD3zTff+E6YMCEuLi7O8Mc//jHo0qVLtz3fjlKJW7Zs0ezfv7+0urr6q8cff/z7p59+utsf8ERsv3ZKj6ngdm5xzWeuwAW4o9x77tqKyRIJxa7cMaFo79rZHR0dMnny5Nq//OUvXQIX1s9JRERE6/Hjx2/VqyorK72nTJlSd/nyZa/z588PmDZtWoNI5w8qKSkpI0Wky3NgK4Rh/dpZv8YrV668oiTPqDQP2R8xjAEolpKSUjtnzpyY1atXV4eHh7dVV1d73rhxw/Pll1/WzJs376pOp2tZtGiR7tixYxdE/n9Ccfr06Q3WCUXzfR46dCjAnFAcOXJkS15e3tBf/vKXNutOIv8/oWj5b+aE4h//+Eej5b+be7wi9hOKYWFhbceOHRs0duzYBuvH1tbW5vE///M/wc8888zVyspK9SeffBLwi1/8wm7k/p133hny2GOP1VknFC1vY04opqam1jhKKJr/723btgV99tlnfjt27KgU6dr9VfIJ8CeffPL6k08+2W0F68EHH2x49tlntQUFBT4JCQnNdXV1qm+//VZt/ZxUV1d7rl+/Ptz8oa3jx48P+t3vflcxdOjQ9vr6es+vvvrKJzExsfnQoUODYmJimkRErJ8DS7ZeO1uvsTnPOHXq1Ia333476JlnnvmH9X3NnTv3+sKFC4evWbOmuqysTG0vD9kfMYwBKEZC0f0Tio5ul5OTY/zXf/3X4S0tLR4iIi+++GJlYmJis+W+Go2mfdWqVZfHjh07SkTkueeeu6zRaNpFRLKyssrmzZs3wsPDQwIDA9t37txp8zkwc/TaWd/WXp7x7bffDvz000/9tm7detlR3jE9PT3iwIEDQ5uamlQajSZx4cKF32/ZsuVyr55oJyChCLgJEor9GwlFWCOhCACAG+FtagBOQUIRUI6VMQAALsYwBgDAxRjGAAC4GMMYAAAXYxgDcCkSiiQUSSgyjAH8CJBQJKEoQkIRwE8ICcVOJBRJKPYlhjHgrmxlEF+50ZkYrDOpbG7fVtv5lmJVu9dt2xQgoUhCkYSiczCMAShGQpGEIglF5+AKXIC7Oh1q/4pPASqTw+2hnm0Ot9tBQrErEookFPsKwxiAYiQUSSiSUHQOhjEAxUgoklAkoegcJBQBN0FCsX8joQhrJBQBAHAjvE0NwClIKALKsTIGAMDFGMYAALgYwxgAABdjGAMA4GIMYwAuRUKRhOLdSCja27+xsdHj0UcfHa7VahMSExPjLL8PHnjggZEBAQFj7uT7UymGMQC3R0KRhKKI44Sivf2zsrLuCQwMbLt06VLBsmXLqjMyMiLM9/fv//7v3+Xk5Di8cElfYRgD6BESip1IKLpPQtHR/ocOHRq8ZMmSqyIiixcvrvn4448DzKvmn/3sZ3WDBg1y+Hz2FYYx4I6WXIqUCSWxffq15FK3hR0SiiQU3TGh6Gj/6upq7+jo6BYREbVaLf7+/u3V1dV3/RocDGMAipFQJKHojglFR/v3l+wiV+AC3FGu9q6tmCyRUOyKhKJ7JBSjoqJa7e0fEhLS8u2333qPGDGitbW1Verr6z2HDRvWbn3fzsYwBqAYCUUSiu6YUPTy8rK7/6OPPno9Nzc3aPr06Q1vvfXWkPvvv7/O/APg3cQwBqAYCUUSiu6aULS3/4oVK76fO3dutFarTQgMDGzfu3fvN+Zjjh07NvbixYu+jY2NnhqNJnHHjh3GuXPnKvpAXU+RUATcBAnF/o2EIqyRUAQAwI3wNjUApyChCCjHyhgAABdjGAMA4GIMYwAAXIxhDACAizGMAbgUCUUSiiQUGcYAfgRIKJJQFCGhCOAnhIRiJxKKJBT7EsMYcFe2MoivVHcmBuvaVTa3b7vS+ZZiVavXbdsUIKFIQpGEonMwjAEoRkKRhCIJRefgClyAuzqtt3/FpwBPk8Ptoeo2h9vtIKHYFQlFEop9hWEMQDESiiQUSSg6B8MYgGIkFEkoklAkoQj8pJFQ7N9IKMIaCUUAANwIb1MDcAoSioByrIwBAHAxhjEAAC7GMAYAwMUYxgAAuBjDGIBLkVAkoagkobh8+fLwkJCQxIEDB97Xm8ds73m/evWq57Rp02JiY2MNMTEx8VlZWUHd3ZczMIwBuD0Sij/+hOKsWbOunzp16nxvHrOI/ed906ZNwbGxsY3FxcWFJ06cKF6zZk2kox+QnIVhDKBHSCh2IqF49xKKIiIPPfRQg/nSppYuX77sNWPGjBEJCQmjEhISRr3//vt+1rdx9Lx7eHhIXV2dp8lkktraWlVgYGCbWq0mFAFAgSVFkVLQcNt/7O9Igt9NyY1zmOyzTCj6+Ph0PPHEE1rLhOL48eMbzAnF4uJib6PR6JuTk2N85JFHGubPnx+1adOm4PXr11db3++5c+f8zpw5U6DX61uSk5NH7t69e8jixYtrzAnF7OzsyvT09Ijs7OzgzMxMu1k+c4Zv1apVt47xQ0LRf/jw4U2vvvpqeUxMTKtlQrG8vNwnOTm5dvv27RXmSyeaWSYUKyoq1KNHj45ftGjRVfN2c0JRROSNN94YZk4oHj582D81NTXa+u+se5pQ3LNnz8X8/HybK8W+ZplQHDRokOk3v/lNyIYNGzS//e1vuzzfShKKPj4+Jn9///ZPP/1U8UrW1munRFpaWmRGRkb1jBkz6ktLS71nzJgx8uLFi4qf9+eee+4fKSkpMRqNJrGhocEzNzf3oqenp40jORcrYwCKkVAkoeiKhKIjJ0+eHLRixQptXFyc4bHHHoupr6/3rKmp6TLbHD3vBw8eDExISGisrq7+6vTp04XPPvus9tq1a3d9NrIyBtxRNytYZyGh2BUJxbuTUDS/xvYe92effXbe39+/y8RV+rzv2rUr6Ne//vV3KpVKEhISmiMjI5u//PJL36lTp97Va4wzjAEoRkKRhKKrEor2TJ48uXbjxo3DNmzYUC0i8vHHHw+YNGlSo9LnPTw8vOX9998flJKSUl9eXu518eJF37i4uB6tzvsCwxiAYiQUSSi6KqGYnp4eceDAgaFNTU0qjUaTuHDhwu+3bNly+fXXXy//5S9/qdXr9Yb29naPiRMn1k2aNOmS9f72nveXX365auHChVF6vd7Q0dHhsXbt2orQ0NBef7K+t0goAm6ChGL/RkIR1kgoAgDgRnibGoBTkFAElGNlDACAizGMAQBwMYYxAAAuxjAGAMDFGMYAXIqEIglFEooMYwA/AiQUSSh2h4QigB8VEoqdSCiSUOxLDGPAXU34PPa2r1fKgkVEpK5NZXP7torOt+Cqmr1u26aAZUKxqKioUKVSdVgmFNeuXasxJxRFRIxGo296evqVkpKSwoCAANOmTZuCbd3vuXPn/LKyssqLi4u/NhqNPrt37x4iImJOKBYXFxf+kFK0ub+ZOcM3c+bMWwPsh4SiISUlZfiFCxfUIiKWCcVRo0YZ0tLSImytbi0Tijt37iz74osvulSnzAnF1NTUGhERc0Jx27ZtZampqdHW99fThOLWrVvvWhDEMqFYWFh4Pikp6eaGDRs01rdTklDUaDSJ7777btD69evt5i6t2XrtlDAnFAsKCs4fOHDgm/T09Cjr23SXUCwtLfXVaDSJSUlJ8ZmZmeUkFAH0ayQUSSiSUHQOrsAFuKvTY+1f8SnAy+Rwe6hPm8PtdpBQ7IqEIgnFvsIwBqAYCUUSiiQUnYNhDEAxEookFEkoOgcJRcBNkFDs30gowhoJRQAA3AhvUwNwChKKgHKsjAEAcDGGMeA+TCaT6a5fpg9Az/3wv1WHV0OzxDAG3EfBlStXAhnIQP9mMpk8rly5EigiBUr34XfGgJtoa2v75XfffffGd999lyD8IA30ZyYRKWhra/ul0h340yYAAFyMn64BAHAxhjEAAC7GMAYAwMUYxgAAuBjDGAAAF/t/haSlOtwNcdkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "NUM_COLORS = 81\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
